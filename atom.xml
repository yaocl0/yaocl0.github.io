<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mr_Yao的驿站</title>
  
  
  <link href="http://yaocl.cn/atom.xml" rel="self"/>
  
  <link href="http://yaocl.cn/"/>
  <updated>2025-01-22T01:53:28.262Z</updated>
  <id>http://yaocl.cn/</id>
  
  <author>
    <name>Mr_Yao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Proof-of-History：Solana 区块链的创新时间证明机制</title>
    <link href="http://yaocl.cn/2025/01/22/35poh/"/>
    <id>http://yaocl.cn/2025/01/22/35poh/</id>
    <published>2025-01-22T01:49:13.000Z</published>
    <updated>2025-01-22T01:53:28.262Z</updated>
    
    <content type="html"><![CDATA[<p>Proof-of-History (PoH) 是 Solana 区块链提出的一种创新的共识机制，它并不是传统意义上的共识算法，而是一种利用加密哈希链来确定全局时间和交易顺序的技术。PoH 不仅仅通过哈希函数确保数据的完整性，还提供了一个无需节点间同步的可靠时间证明机制，从而提高区块链的效率和吞吐量。</p><p>本文将深入探讨 PoH 的核心概念、实现细节以及它如何与其他共识机制（如 Proof-of-Stake）结合使用，最终为 Solana 区块链提供高效、安全的交易处理能力。</p><h2 id="一、核心概念：哈希链与时间证明"><a href="#一、核心概念：哈希链与时间证明" class="headerlink" title="一、核心概念：哈希链与时间证明"></a>一、核心概念：哈希链与时间证明</h2><h3 id="1-加密哈希函数"><a href="#1-加密哈希函数" class="headerlink" title="1. 加密哈希函数"></a>1. <strong>加密哈希函数</strong></h3><p>PoH 的核心概念是通过一个连续的哈希链来生成时间证明。每个新区块的哈希值都依赖于前一个区块的哈希值，这样形成一个不可篡改的时间顺序链。PoH 使用加密哈希函数，尤其是 <strong>SHA-256</strong>，它是用于计算数据完整性的重要工具。给定一个输入 <code>X</code>，SHA-256 会输出唯一的哈希值 <code>Y</code>，任何对 <code>X</code> 的改动都会导致输出 <code>Y</code> 完全不同。</p><p>这种特性是 PoH 的关键，它确保了区块数据的顺序和完整性。</p><p>在 Solana 的 PoH 序列中，通过将每个区块的哈希值作为下一个区块哈希函数输入的一部分，形成一个链条，这样，任何变动都会改变区块的哈希值，确保数据的不可篡改性。</p><h3 id="2-时间戳的生成"><a href="#2-时间戳的生成" class="headerlink" title="2. 时间戳的生成"></a>2. <strong>时间戳的生成</strong></h3><p>PoH 通过链式哈希实现了时间证明。每个区块的哈希值不仅代表了区块的内容，还携带了时间信息，确保了区块之间的时间顺序。区块链网络中的节点无需依赖传统的时间同步协议，它们只需通过验证哈希链中的时间顺序来确认每个事件的发生顺序。</p><p>具体地，Solana 的实现是通过构造一个连续的哈希流（即 PoH 链）来实现“时间戳”功能。区块的顺序即为 PoH 链中的哈希流的顺序。因此，节点可以通过查看 PoH 链中的哈希值，快速确定一个区块的生成时间，而无需依赖外部时间源。</p><h3 id="3-POH序列与SHA-256"><a href="#3-POH序列与SHA-256" class="headerlink" title="3. POH序列与SHA-256"></a>3. <strong>POH序列与SHA-256</strong></h3><p>Solana 的 PoH 序列使用 SHA-256 哈希算法来确保交易的顺序和完整性。举个例子，如果将交易打包成一个区块并生成相应的 SHA-256 哈希值，则区块内的交易顺序就被确定了。任何对交易的更改都会导致该区块的哈希值发生变化，而该哈希值又会成为下一个区块的输入，形成链条式的时间证明。</p><p>这个过程的核心就是 <strong>Proof of History</strong>：上一个区块的哈希值作为下一个区块哈希函数的一部分，通过哈希链不断地“证明”历史交易的顺序。</p><p><img src="/2025/01/22/35poh/6.png" alt="POH序列，图源：Solana白皮书"></p><p><img src="/2025/01/22/35poh/1.png" alt="POH序列示意图，图源：Solana白皮书"></p><h2 id="二、PoH-的具体实现：哈希链的生成与验证"><a href="#二、PoH-的具体实现：哈希链的生成与验证" class="headerlink" title="二、PoH 的具体实现：哈希链的生成与验证"></a>二、PoH 的具体实现：哈希链的生成与验证</h2><h3 id="1-区块生成过程"><a href="#1-区块生成过程" class="headerlink" title="1. 区块生成过程"></a>1. <strong>区块生成过程</strong></h3><p>PoH 的区块生成过程由 Solana 网络中的领导者节点（Leader）负责。该节点从交易池中收集交易并将其排序，生成 PoH 链，最终创建新区块并广播给其他节点。</p><ol><li><p><strong>初始化哈希链</strong>：系统从一个初始的哈希值开始，这个哈希值可能是一个随机数或特定的时间戳。</p></li><li><p><strong>生成新区块</strong>：领导者节点通过将前一个区块的哈希值与当前区块的数据（如交易信息）结合，使用 SHA-256 计算出新区块的哈希值。</p></li><li><p><strong>广播新区块</strong>：生成的新区块会广播给网络中的其他节点，其他节点通过验证新区块的哈希值与前一个区块的哈希值的一致性来确保区块的有效性。</p></li><li><p><strong>验证哈希链</strong>：每个节点验证新区块时，都会检查当前区块的哈希值是否依赖于上一个区块的哈希值，从而确保哈希链的顺序性和一致性。</p></li></ol><p><img src="/2025/01/22/35poh/2.png" alt="交易Flow架构图，图源：Solana白皮书"></p><h3 id="2-PoH-时间验证机制"><a href="#2-PoH-时间验证机制" class="headerlink" title="2. PoH 时间验证机制"></a>2. <strong>PoH 时间验证机制</strong></h3><p>PoH 的时间验证与传统的时间同步协议（如 NTP）不同。通常，在区块链中，时间同步是通过各个节点交换时间戳来实现的。但是，PoH 的实现方式则是让每个新区块的哈希值与前一个区块的哈希值绑定，从而自动构建一个可信的时间线。</p><p>具体地，假设某个区块的时间戳为 T，该时间戳并不是由节点直接提供的，而是通过哈希链中的序列来确定。也就是说，区块的生成顺序（而非实际时间）决定了其时间戳。PoH 保证了即使网络中的节点时间不同，区块的时间顺序依然是可信的。</p><h2 id="三、PoH-与-Proof-of-Stake-PoS-的结合"><a href="#三、PoH-与-Proof-of-Stake-PoS-的结合" class="headerlink" title="三、PoH 与 Proof-of-Stake (PoS) 的结合"></a>三、PoH 与 Proof-of-Stake (PoS) 的结合</h2><p>PoH 并不是一个独立的共识机制，而是与其他共识机制（如 Proof-of-Stake）结合使用。在 Solana 中，PoH 与 PoS 结合，提供了一个高效的共识机制，能够确保区块的顺序性和时间验证。</p><h3 id="1-PoH-与-PoS-的结合"><a href="#1-PoH-与-PoS-的结合" class="headerlink" title="1. PoH 与 PoS 的结合"></a>1. <strong>PoH 与 PoS 的结合</strong></h3><p>在 Solana 网络中，PoS 负责选择验证者节点，这些节点通过锁定代币来获得生成新区块的机会，而 PoH 负责为区块生成提供时间戳。</p><ul><li><strong>PoS</strong>：确定了哪些节点有资格生成新区块。</li><li><strong>PoH</strong>：为区块生成提供了时间验证，确保了区块的顺序性。</li></ul><p>通过这种结合，Solana 可以高效且安全地生成和验证区块，避免了传统共识机制的性能瓶颈。</p><h3 id="2-领导者节点的选举与时间线"><a href="#2-领导者节点的选举与时间线" class="headerlink" title="2. 领导者节点的选举与时间线"></a>2. <strong>领导者节点的选举与时间线</strong></h3><p>Solana 网络采用 Leader Rotation 机制周期性地轮换领导者节点，每个周期由 PoS 确定新的领导者节点，领导者节点负责通过 PoH 生成新区块并广播给其他节点。PoH 的连续性保证了时间的顺序性，领导者节点在每个时隙（slot）内生成并广播区块，不依赖其他节点的时间同步。</p><h2 id="四、Leader节点与时间限制"><a href="#四、Leader节点与时间限制" class="headerlink" title="四、Leader节点与时间限制"></a>四、Leader节点与时间限制</h2><p>为了避免单点故障，Solana 引入了时间限制机制。在 Solana 中，时间单位以 epoch 进行划分，每个 epoch 包含 432,000 个时隙（slot），每个时隙持续 400 毫秒。在每个时隙内，PoS 会分配一个新的领导者节点，该节点必须在 400 毫秒内完成区块的生成并广播，否则会跳过该时隙并重新选举新的领导者节点。</p><p><img src="/2025/01/22/35poh/3.jpg" alt="Leader选举机制，图源：Helius"></p><p>通过这种机制，Solana 网络能够在每个时隙内保证新区块的生成，同时通过 PoH 保证了交易的历史顺序。</p><h2 id="五、Tower-BFT-共识机制"><a href="#五、Tower-BFT-共识机制" class="headerlink" title="五、Tower BFT 共识机制"></a>五、Tower BFT 共识机制</h2><p>虽然 PoH 提供了高效的时间证明，但单靠 PoH 还不足以保证区块链的最终一致性和安全性。因此，Solana 使用了 <strong>Tower BFT 共识机制</strong> 来对区块进行最终的验证和达成共识。</p><p>Tower BFT（拜占庭容错共识协议）是 Solana 网络的核心共识机制之一，它基于传统的 BFT 共识算法，并且与 Proof-of-History（PoH）紧密结合，提供了一种高效、去中心化的方式来确保区块链网络的安全性和一致性。</p><h3 id="1-Tower-BFT-的基本原理"><a href="#1-Tower-BFT-的基本原理" class="headerlink" title="1. Tower BFT 的基本原理"></a>1. <strong>Tower BFT 的基本原理</strong></h3><p>Tower BFT 协议是 BFT 共识算法的一种具体实现，核心理念是通过验证者节点的投票来达成共识。与传统的共识机制不同，Tower BFT 通过 PoH 提供的历史时间证明和哈希链来进行投票，避免了传统机制中的冗余数据和投票冲突。</p><p>在 Tower BFT 中，验证者的投票不仅仅是对区块的选择，它还作为交易的历史证明。每个区块的哈希值以及它与前一个区块的关联信息在整个网络中得到一致确认，确保了区块的顺序性和不可篡改性。</p><p><img src="/2025/01/22/35poh/4.jpg" alt="Tower BFT协议，图源：Helius"></p><h3 id="2-投票机制与区块确认"><a href="#2-投票机制与区块确认" class="headerlink" title="2. 投票机制与区块确认"></a>2. <strong>投票机制与区块确认</strong></h3><p>在 Tower BFT 协议中，验证者节点会对新区块进行投票。具体而言，如果超过2/3的验证者对一个区块投出了“同意”（approve）票，那么该区块就会被确认并最终加入到区块链中。这种投票机制的优势在于，它通过简单的哈希序列投票来确认区块的有效性，而不需要额外的资源来传递区块本身。这样做不仅节省了内存，还避免了传统共识机制中由于区块广播和冗余数据传输而产生的网络拥堵。</p><p><img src="/5.jpg" alt="投票图示"></p><p>这种设计减少了区块传播时的冗余，避免了传统方法中每个验证者接收到的区块需要向周围的节点再次广播的问题，减少了网络带宽的压力，提高了整个系统的效率。</p><h3 id="3-PoH与Tower-BFT的协作"><a href="#3-PoH与Tower-BFT的协作" class="headerlink" title="3. PoH与Tower BFT的协作"></a>3. <strong>PoH与Tower BFT的协作</strong></h3><p>Tower BFT 与 Proof-of-History（PoH）技术密切结合，PoH 提供了一个可靠的、不可篡改的时间证明，验证者可以根据 PoH 链中的历史证明来投票。每个区块的哈希不仅代表着区块的内容，还承载了与历史区块的关联信息，保证了交易顺序的不可篡改性。</p><p>PoH 确保了区块链的时间顺序，而 Tower BFT 确保了区块的最终一致性和网络中的验证者对区块的共识。两者的结合极大提升了区块链的性能和安全性。</p><h2 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h2><p>Proof-of-History (PoH) 是一种利用加密哈希链提供时间证明的技术，它通过确保区块的顺序性和不可篡改性来提高区块链网络的效率。PoH 通过与 Proof-of-Stake (PoS) 相结合，帮助 Solana 网络在高吞吐量的情况下，保持区块生成和验证的安全性。</p><p>Tower BFT 进一步提高了网络的共识效率，通过投票机制与 PoH 紧密结合，减少了冗余通信并提高了容错性。PoH 和 Tower BFT 的结合使 Solana 成为一个高效、低延迟且具有高吞吐量的区块链网络，在高频交易和大规模应用场景中具有广泛的应用潜力。随着区块链技术的不断发展，PoH 和 Tower BFT 技术有望推动更多区块链应用的普及与创新。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Proof-of-History (PoH) 是 Solana 区块链提出的一种创新的共识机制，它并不是传统意义上的共识算法，而是一种利用加密哈希链来确定全局时间和交易顺序的技术。PoH 不仅仅通过哈希函数确保数据的完整性，还提供了一个无需节点间同步的可靠时间证明机制，从而</summary>
      
    
    
    
    <category term="区块链" scheme="http://yaocl.cn/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    
    <category term="区块链" scheme="http://yaocl.cn/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    <category term="Solana" scheme="http://yaocl.cn/tags/Solana/"/>
    
  </entry>
  
  <entry>
    <title>LangChain：构建智能语言模型应用的开源框架</title>
    <link href="http://yaocl.cn/2025/01/20/34langchain/"/>
    <id>http://yaocl.cn/2025/01/20/34langchain/</id>
    <published>2025-01-20T01:39:58.000Z</published>
    <updated>2025-01-20T01:50:02.826Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是-LangChain"><a href="#什么是-LangChain" class="headerlink" title="什么是 LangChain"></a>什么是 LangChain</h2><p>LangChain 是一个强大的开源框架，旨在帮助开发者快速构建和管理基于大语言模型（LLMs）的应用程序。随着自然语言处理技术的飞速发展，LLMs 在文本生成、对话系统、内容推荐等领域展现出巨大的潜力。然而，要充分利用这些强大的模型并整合到复杂的应用中，开发者需要处理许多复杂的任务，如上下文管理、调用外部工具和数据整合。LangChain 通过提供一套模块化、可扩展的工具，简化了这些过程。</p><p>LangChain 的核心目标是使开发者能够构建 “智能” 应用，这些应用可以理解上下文、动态调整和集成外部资源。</p><hr><h2 id="LangChain-的主要应用场景"><a href="#LangChain-的主要应用场景" class="headerlink" title="LangChain 的主要应用场景"></a>LangChain 的主要应用场景</h2><h3 id="1-对话式-AI"><a href="#1-对话式-AI" class="headerlink" title="1. 对话式 AI"></a>1. <strong>对话式 AI</strong></h3><p>通过记忆功能和高级提示优化，可以构建更智能、更自然的聊天机器人。</p><h3 id="2-信息抽取与总结"><a href="#2-信息抽取与总结" class="headerlink" title="2. 信息抽取与总结"></a>2. <strong>信息抽取与总结</strong></h3><p>LangChain 可以处理长文档，提取关键信息并生成简洁摘要。</p><h3 id="3-搜索增强"><a href="#3-搜索增强" class="headerlink" title="3. 搜索增强"></a>3. <strong>搜索增强</strong></h3><p>结合搜索工具，构建支持实时信息检索的问答系统。</p><h3 id="4-多步骤工作流自动化"><a href="#4-多步骤工作流自动化" class="headerlink" title="4. 多步骤工作流自动化"></a>4. <strong>多步骤工作流自动化</strong></h3><p>通过链和代理，可以创建复杂的自动化工作流，例如客户支持、教育内容生成等。</p><h3 id="5-多模态应用"><a href="#5-多模态应用" class="headerlink" title="5. 多模态应用"></a>5. <strong>多模态应用</strong></h3><p>结合图像、视频等其他数据源，构建更丰富的交互体验。</p><hr><h2 id="LangChain-的核心组件"><a href="#LangChain-的核心组件" class="headerlink" title="LangChain 的核心组件"></a>LangChain 的核心组件</h2><p>LangChain 的设计是模块化的，以下是其主要组件：</p><h3 id="1-模型（Models）"><a href="#1-模型（Models）" class="headerlink" title="1. 模型（Models）"></a>1. <strong>模型（Models）</strong></h3><p>这是应用的核心，用于生成或理解自然语言。LangChain 支持多种语言模型，包括但不限于 OpenAI、Hugging Face，以及其他开源和商业模型。开发者可以选择最适合的模型来满足特定需求。</p><h3 id="2-提示（Prompts）"><a href="#2-提示（Prompts）" class="headerlink" title="2. 提示（Prompts）"></a>2. <strong>提示（Prompts）</strong></h3><p>提示（Prompts）是与语言模型交互的关键。LangChain 允许开发者设计、优化和动态构建提示，以确保更好的输出效果。它还支持模板化提示和参数化的动态生成。</p><h3 id="3-链（Chains）"><a href="#3-链（Chains）" class="headerlink" title="3. 链（Chains）"></a>3. <strong>链（Chains）</strong></h3><p>链是 LangChain 的核心概念，用于将多个模型或功能模块组合成复杂的工作流。例如，一个典型的链可能包括：</p><ul><li>先从用户输入中提取关键信息。</li><li>然后用提取的信息生成新的文本。</li><li>最后返回结构化的响应。</li></ul><h3 id="4-记忆（Memory）"><a href="#4-记忆（Memory）" class="headerlink" title="4. 记忆（Memory）"></a>4. <strong>记忆（Memory）</strong></h3><p>LangChain 支持应用记忆功能，用于存储上下文信息。这在构建对话系统时尤为重要，因为它允许模型记住对话历史，从而提供更连贯的交互体验。</p><h3 id="5-工具和代理（Tools-and-Agents）"><a href="#5-工具和代理（Tools-and-Agents）" class="headerlink" title="5. 工具和代理（Tools and Agents）"></a>5. <strong>工具和代理（Tools and Agents）</strong></h3><p>LangChain 支持与外部工具和 API 集成。例如，可以通过工具调用数据库、执行计算，甚至访问实时信息。此外，代理（Agents）允许模型根据上下文动态选择合适的工具。</p><hr><h2 id="安装-LangChain"><a href="#安装-LangChain" class="headerlink" title="安装 LangChain"></a>安装 LangChain</h2><p>在开始使用 LangChain 之前，需要先安装相关依赖。</p><h3 id="1-安装-LangChain"><a href="#1-安装-LangChain" class="headerlink" title="1. 安装 LangChain"></a>1. <strong>安装 LangChain</strong></h3><p>使用<code>pip</code>安装 LangChain：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install langchain</span><br></pre></td></tr></table></figure><h3 id="2-安装支持的-LLM-依赖"><a href="#2-安装支持的-LLM-依赖" class="headerlink" title="2. 安装支持的 LLM 依赖"></a>2. <strong>安装支持的 LLM 依赖</strong></h3><p>例如，安装 OpenAI API 的依赖：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install openai</span><br></pre></td></tr></table></figure><h3 id="3-其他依赖"><a href="#3-其他依赖" class="headerlink" title="3. 其他依赖"></a>3. <strong>其他依赖</strong></h3><p>根据具体需求安装其他库，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install sqlalchemy  <span class="comment"># 数据库支持</span></span><br><span class="line">pip install faiss       <span class="comment"># 向量搜索</span></span><br></pre></td></tr></table></figure><hr><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h3 id="1-Prompt-Templates（提示模板）示例"><a href="#1-Prompt-Templates（提示模板）示例" class="headerlink" title="1. Prompt Templates（提示模板）示例"></a><strong>1. Prompt Templates（提示模板）示例</strong></h3><p><strong>用途</strong>：定义一个可复用的提示模板，用于生成动态输入。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个提示模板</span></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一位经验丰富的翻译官。</span></span><br><span class="line"><span class="string">请将以下英文翻译成中文：</span></span><br><span class="line"><span class="string">&quot;&#123;text&#125;&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 PromptTemplate 实例</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;text&quot;</span>],</span><br><span class="line">    template=template,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模板生成提示</span></span><br><span class="line">result = prompt.<span class="built_in">format</span>(text=<span class="string">&quot;This is an example sentence.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><h3 id="2-Chains（链）示例"><a href="#2-Chains（链）示例" class="headerlink" title="2. Chains（链）示例"></a><strong>2. Chains（链）示例</strong></h3><p><strong>用途</strong>：将多个逻辑步骤连接在一起，形成一个完整的任务流程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义提示模板</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;topic&quot;</span>],</span><br><span class="line">    template=<span class="string">&quot;请为以下主题写一段简短的文章：&#123;topic&#125;&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个 LLM（大语言模型）</span></span><br><span class="line">llm = OpenAI(model_name=<span class="string">&quot;text-davinci-003&quot;</span>, api_key=<span class="string">&quot;your_openai_api_key&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个 LLMChain</span></span><br><span class="line">chain = LLMChain(llm=llm, prompt=prompt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行链操作</span></span><br><span class="line">response = chain.run(<span class="string">&quot;人工智能的未来&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure><h3 id="3-Agents（智能体）示例"><a href="#3-Agents（智能体）示例" class="headerlink" title="3. Agents（智能体）示例"></a><strong>3. Agents（智能体）示例</strong></h3><p><strong>用途</strong>：智能体根据工具动态决定解决问题的策略。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> load_tools, initialize_agent</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个 LLM</span></span><br><span class="line">llm = OpenAI(model_name=<span class="string">&quot;text-davinci-003&quot;</span>, api_key=<span class="string">&quot;your_openai_api_key&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载工具</span></span><br><span class="line">tools = load_tools([<span class="string">&quot;serpapi&quot;</span>, <span class="string">&quot;llm-math&quot;</span>], llm=llm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化智能体</span></span><br><span class="line">agent = initialize_agent(tools, llm, agent=<span class="string">&quot;zero-shot-react-description&quot;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 智能体执行任务</span></span><br><span class="line">response = agent.run(<span class="string">&quot;谁赢得了2018年世界杯冠军？17乘以23等于多少？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure><h3 id="4-Memory（记忆）示例"><a href="#4-Memory（记忆）示例" class="headerlink" title="4. Memory（记忆）示例"></a><strong>4. Memory（记忆）示例</strong></h3><p><strong>用途</strong>：为会话保存上下文，使模型能在多轮对话中理解用户意图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建记忆模块</span></span><br><span class="line">memory = ConversationBufferMemory()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 ConversationChain，绑定记忆模块</span></span><br><span class="line">llm = OpenAI(model_name=<span class="string">&quot;text-davinci-003&quot;</span>, api_key=<span class="string">&quot;your_openai_api_key&quot;</span>)</span><br><span class="line">conversation = ConversationChain(llm=llm, memory=memory, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行多轮对话</span></span><br><span class="line">response1 = conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;你好，你是谁？&quot;</span>)</span><br><span class="line">response2 = conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;你还记得我们之前聊过什么吗？&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Response 1:&quot;</span>, response1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Response 2:&quot;</span>, response2)</span><br></pre></td></tr></table></figure><hr><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h3 id="案例-1：创建一个简单的问答系统"><a href="#案例-1：创建一个简单的问答系统" class="headerlink" title="案例 1：创建一个简单的问答系统"></a>案例 1：创建一个简单的问答系统</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> OpenAI, PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 初始化LLM</span></span><br><span class="line">llm = OpenAI(model_name=<span class="string">&quot;text-davinci-003&quot;</span>, api_key=<span class="string">&quot;your_openai_api_key&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 定义Prompt模板</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;question&quot;</span>],</span><br><span class="line">    template=<span class="string">&quot;以下是一个问题：&#123;question&#125;。请提供详细回答。&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 构建LLM链</span></span><br><span class="line">qa_chain = LLMChain(llm=llm, prompt=prompt)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 输入问题并获取答案</span></span><br><span class="line">question = <span class="string">&quot;什么是LangChain？&quot;</span></span><br><span class="line">answer = qa_chain.run(question=question)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;回答：&quot;</span>, answer)</span><br></pre></td></tr></table></figure><h3 id="案例-2：多轮对话示例"><a href="#案例-2：多轮对话示例" class="headerlink" title="案例 2：多轮对话示例"></a>案例 2：多轮对话示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"></span><br><span class="line">llm = OpenAI(model_name=<span class="string">&quot;text-davinci-003&quot;</span>, api_key=<span class="string">&quot;your_openai_api_key&quot;</span>)</span><br><span class="line"></span><br><span class="line"> memory = ConversationBufferMemory()</span><br><span class="line"> qa_chain = LLMChain(llm=llm, prompt=prompt, memory=memory)</span><br><span class="line"></span><br><span class="line"> question1 = <span class="string">&quot;LangChain有哪些核心组件？&quot;</span></span><br><span class="line"> <span class="built_in">print</span>(qa_chain.run(question=question1))</span><br><span class="line"></span><br><span class="line"> question2 = <span class="string">&quot;可以详细说说记忆模块吗？&quot;</span></span><br><span class="line"> <span class="built_in">print</span>(qa_chain.run(question=question2))</span><br></pre></td></tr></table></figure><h3 id="案例-3：-结合外部数据源"><a href="#案例-3：-结合外部数据源" class="headerlink" title="案例 3： 结合外部数据源"></a>案例 3： 结合外部数据源</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> SQLDatabaseChain</span><br><span class="line"><span class="keyword">from</span> langchain.sql_database <span class="keyword">import</span> SQLDatabase</span><br><span class="line"></span><br><span class="line">db = SQLDatabase.from_uri(<span class="string">&quot;sqlite:///example.db&quot;</span>)</span><br><span class="line"></span><br><span class="line">llm = OpenAI(model_name=<span class="string">&quot;text-davinci-003&quot;</span>, api_key=<span class="string">&quot;your_openai_api_key&quot;</span>)</span><br><span class="line">db_chain = SQLDatabaseChain(llm=llm, database=db)</span><br><span class="line"></span><br><span class="line">query = <span class="string">&quot;SELECT * FROM users WHERE age &gt; 30;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(db_chain.run(query))</span><br></pre></td></tr></table></figure><h3 id="案例-4：知识库问答"><a href="#案例-4：知识库问答" class="headerlink" title="案例 4：知识库问答"></a>案例 4：知识库问答</h3><p>结合外部文档数据，实现基于知识库的问答系统：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> TextLoader</span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载文档</span></span><br><span class="line">loader = TextLoader(<span class="string">&quot;knowledge_base.txt&quot;</span>)</span><br><span class="line">documents = loader.load()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建向量存储</span></span><br><span class="line">vector_store = FAISS.from_documents(documents)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建问答链</span></span><br><span class="line">llm = OpenAI(model=<span class="string">&quot;text-davinci-003&quot;</span>, temperature=<span class="number">0.7</span>, api_key=<span class="string">&quot;your_openai_api_key&quot;</span>)</span><br><span class="line">qa_chain = RetrievalQA(llm=llm, retriever=vector_store.as_retriever())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提问</span></span><br><span class="line">response = qa_chain.run(<span class="string">&quot;这篇文档的主要内容是什么？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;什么是-LangChain&quot;&gt;&lt;a href=&quot;#什么是-LangChain&quot; class=&quot;headerlink&quot; title=&quot;什么是 LangChain&quot;&gt;&lt;/a&gt;什么是 LangChain&lt;/h2&gt;&lt;p&gt;LangChain 是一个强大的开源框架，旨在帮助开</summary>
      
    
    
    
    <category term="LLM" scheme="http://yaocl.cn/categories/LLM/"/>
    
    
    <category term="LLM" scheme="http://yaocl.cn/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>区块链预言机：智能合约与现实世界的桥梁</title>
    <link href="http://yaocl.cn/2025/01/14/33Oracles/"/>
    <id>http://yaocl.cn/2025/01/14/33Oracles/</id>
    <published>2025-01-14T07:39:19.000Z</published>
    <updated>2025-01-14T07:47:24.311Z</updated>
    
    <content type="html"><![CDATA[<p>18 年 11 月 6 日，中国人民银行发布的《区块链能做什么？不能做什么？》报告中，是这样对预言机定义的：</p><blockquote><p>区块链外信息写入区块链内的机制，一般被称为预言机 (oracle mechanism)。</p></blockquote><p>随着区块链技术的快速发展，区块链不仅在金融、供应链、物联网等领域取得了广泛应用，而且它的智能合约功能也逐渐成为去中心化应用（DApp）的核心。然而，区块链的智能合约有一个固有的限制——它只能在链内的数据上进行操作，无法与链外的世界进行交互。为了克服这一局限，区块链预言机（Oracle）应运而生，成为区块链和现实世界之间至关重要的桥梁。本文将深入探讨区块链预言机的工作原理、类型、应用场景以及面临的挑战，并展望其未来的发展趋势。</p><h2 id="一、什么是区块链预言机？"><a href="#一、什么是区块链预言机？" class="headerlink" title="一、什么是区块链预言机？"></a>一、什么是区块链预言机？</h2><p>区块链预言机（Oracle）是一种将外部世界数据引入区块链的机制，它能够为智能合约提供必要的链外数据，使得智能合约能够在真实世界的基础上执行。这些数据可能包括天气信息、市场价格、体育比赛结果、地理位置数据等，任何与区块链内部状态无关的外部数据，都可以通过预言机传递给区块链智能合约。</p><p>智能合约本质上是一个自动化执行合同的程序，但其运行只能依赖于区块链内部的数据。当智能合约需要外部信息来执行某些操作时，预言机的作用就显得尤为重要。例如，在一个去中心化保险平台中，智能合约可能需要根据天气预报来决定是否启动赔付程序。在这种情况下，预言机可以提供天气数据，并将其传递给智能合约，触发合同的执行。</p><h2 id="二、区块链预言机的工作原理"><a href="#二、区块链预言机的工作原理" class="headerlink" title="二、区块链预言机的工作原理"></a>二、区块链预言机的工作原理</h2><p>区块链预言机的工作原理主要包括以下几个步骤：</p><ol><li><p><strong>外部事件触发</strong>：预言机首先需要获取外部事件的数据。这些事件可能是金融市场的变化、传感器数据的读取、天气预报的变化等。</p></li><li><p><strong>数据源获取</strong>：预言机通过多个数据源（如 API 接口、传感器、网站抓取等）获取外部数据。这些数据源可以是金融数据提供商、天气预报平台、物联网设备等。</p></li><li><p><strong>数据验证与处理</strong>：获取到外部数据后，预言机会对数据进行验证，以确保数据的准确性、完整性和可信度。验证方法通常包括使用多个数据源进行比对，或者通过加密技术保证数据的可靠性。</p></li><li><p><strong>数据传递到区块链</strong>：经过验证的数据被传递到区块链上的智能合约，智能合约根据这些数据执行相应的操作。</p></li><li><p><strong>合约执行</strong>：智能合约根据外部数据的变化，自动执行合约条款。智能合约的执行是完全自动化和去中心化的，这意味着不需要任何中介参与。</p></li></ol><h4 id="例子说明"><a href="#例子说明" class="headerlink" title="例子说明"></a>例子说明</h4><p>假设有一个去中心化金融应用（DeFi），该应用允许用户借贷加密货币。该应用中的智能合约可能需要借助一个预言机获取外部市场的价格数据，以确定借贷利率或是否执行清算操作。预言机会实时监测市场数据，当价格波动达到某个阈值时，自动将数据传递给智能合约，智能合约则会基于预定规则执行相应的操作。</p><h2 id="三、区块链预言机的类型"><a href="#三、区块链预言机的类型" class="headerlink" title="三、区块链预言机的类型"></a>三、区块链预言机的类型</h2><p>根据预言机获取数据的方式和使用的验证机制，区块链预言机可以分为以下几种类型：</p><h3 id="1-软件预言机（Software-Oracles）"><a href="#1-软件预言机（Software-Oracles）" class="headerlink" title="1. 软件预言机（Software Oracles）"></a>1. <strong>软件预言机（Software Oracles）</strong></h3><p>软件预言机通过访问外部的在线数据源（如 API、数据库）来获取信息。它们将这些信息传递给区块链，通常用于获取价格数据、天气数据等。</p><ul><li><strong>例子</strong>：获取股票价格、货币汇率、天气预报等。</li></ul><h3 id="2-硬件预言机（Hardware-Oracles）"><a href="#2-硬件预言机（Hardware-Oracles）" class="headerlink" title="2. 硬件预言机（Hardware Oracles）"></a>2. <strong>硬件预言机（Hardware Oracles）</strong></h3><p>硬件预言机通过物理设备获取外部世界的数据。它们通常与传感器或物联网设备连接，实时收集数据并传递给区块链。例如，硬件预言机可以用于获取温度、湿度、地震活动等数据。</p><ul><li><strong>例子</strong>：利用 IoT 传感器获取温度、湿度等环境数据。</li></ul><h3 id="3-输入预言机（Input-Oracles）"><a href="#3-输入预言机（Input-Oracles）" class="headerlink" title="3. 输入预言机（Input Oracles）"></a>3. <strong>输入预言机（Input Oracles）</strong></h3><p>输入预言机主要是指通过人为输入的方式将数据传递到区块链。这类预言机通常依赖于人工操作来触发数据传递。</p><ul><li><strong>例子</strong>：某些竞猜类应用中，用户的输入可以作为智能合约执行的依据。</li></ul><h3 id="4-输出预言机（Output-Oracles）"><a href="#4-输出预言机（Output-Oracles）" class="headerlink" title="4. 输出预言机（Output Oracles）"></a>4. <strong>输出预言机（Output Oracles）</strong></h3><p>输出预言机将区块链上的数据传递到外部系统。这类预言机主要用于将区块链上执行的结果反馈到现实世界，影响外部系统的状态。</p><ul><li><strong>例子</strong>：智能合约执行后，将结果传递给一个传统的数据库或支付系统，触发后续操作。</li></ul><h3 id="5-去中心化预言机（Decentralized-Oracles）"><a href="#5-去中心化预言机（Decentralized-Oracles）" class="headerlink" title="5. 去中心化预言机（Decentralized Oracles）"></a>5. <strong>去中心化预言机（Decentralized Oracles）</strong></h3><p>去中心化预言机通过多个数据源来提供信息，避免了单一数据源可能带来的可信度问题。多个节点会对数据的正确性进行验证，并最终汇总结果。去中心化预言机被认为更加安全和可靠，因为它减少了单点故障和数据操控的风险。</p><ul><li><strong>例子</strong>：Chainlink 就是一个知名的去中心化预言机网络，它利用多个独立的节点来提供可靠的数据源。</li></ul><h2 id="四、区块链预言机的应用场景"><a href="#四、区块链预言机的应用场景" class="headerlink" title="四、区块链预言机的应用场景"></a>四、区块链预言机的应用场景</h2><p>区块链预言机为多个行业带来了创新和变革，以下是一些典型的应用场景：</p><h3 id="1-去中心化金融（DeFi）"><a href="#1-去中心化金融（DeFi）" class="headerlink" title="1. 去中心化金融（DeFi）"></a>1. <strong>去中心化金融（DeFi）</strong></h3><p>在 DeFi 应用中，预言机的作用至关重要。DeFi 平台需要从外部获取数据，如市场价格、借贷利率等。例如，去中心化交易所（DEX）依赖预言机提供实时的资产价格，以确保交易的公平性和透明度。在借贷平台中，预言机帮助计算利率和资产的抵押价值。</p><h3 id="2-智能合约与保险"><a href="#2-智能合约与保险" class="headerlink" title="2. 智能合约与保险"></a>2. <strong>智能合约与保险</strong></h3><p>在去中心化保险平台中，预言机用来提供有关外部事件的数据，如天气、自然灾害、事故等。智能合约会根据这些数据自动判断是否触发保险赔付。如果天气预报显示某个地区将发生暴雨，预言机将触发保险合约，开始赔付过程。</p><h3 id="3-供应链管理"><a href="#3-供应链管理" class="headerlink" title="3. 供应链管理"></a>3. <strong>供应链管理</strong></h3><p>在供应链管理中，预言机可用于追踪和验证物品的运输、储存和交付情况。例如，传感器可以提供实时的温度和湿度数据，确保易腐物品的运输过程符合要求。预言机将这些数据传递给智能合约，以确保供应链的透明度和高效性。</p><h3 id="4-物联网（IoT）"><a href="#4-物联网（IoT）" class="headerlink" title="4. 物联网（IoT）"></a>4. <strong>物联网（IoT）</strong></h3><p>在物联网应用中，预言机为设备之间提供数据交互的能力。例如，智能家居设备可以通过传感器获取温度、湿度、空气质量等数据，预言机将这些信息传递给区块链上的智能合约，从而自动调节设备的工作状态。</p><h2 id="五、目前的区块链预言机项目与解决方案"><a href="#五、目前的区块链预言机项目与解决方案" class="headerlink" title="五、目前的区块链预言机项目与解决方案"></a>五、目前的区块链预言机项目与解决方案</h2><p>随着区块链技术的发展，越来越多的预言机项目应运而生，各自采用不同的技术架构、数据源和验证机制，以满足不同领域的需求。以下是一些主流的区块链预言机项目和解决方案，它们在去中心化金融（DeFi）、保险、供应链等行业中发挥着重要作用。</p><h3 id="1-Chainlink"><a href="#1-Chainlink" class="headerlink" title="1. Chainlink"></a>1. <strong>Chainlink</strong></h3><p>简介： Chainlink 是目前最知名且应用最广泛的区块链预言机平台之一。它通过去中心化的节点网络，为智能合约提供可靠的外部数据，确保数据的准确性和防篡改性。</p><p>特点：</p><ul><li>去中心化：Chainlink 使用多个数据提供者和节点来确保数据的多样性与可靠性，避免了单点故障的问题。</li><li>强大的生态系统：Chainlink 支持数百个去中心化应用（dApps），包括 DeFi 项目、保险、预测市场等。</li><li>安全性：通过加密和多重签名机制，确保链外数据传输的完整性和安全性。</li><li>Oracle 聚合：通过聚合多个数据源，Chainlink 提供的数据具有更高的准确性和可信度。</li></ul><p>官方链接：<a href="https://chain.link/">https://chain.link/</a></p><h3 id="2-Band-Protocol"><a href="#2-Band-Protocol" class="headerlink" title="2. Band Protocol"></a>2. <strong>Band Protocol</strong></h3><p>简介：  Band Protocol 是一个去中心化的预言机平台，旨在为区块链提供高效、安全的外部数据。它支持多链操作，并通过去中心化的验证机制确保数据的准确性。</p><p>特点：</p><ul><li>跨链兼容性：Band Protocol 支持多种区块链平台，能够为跨链应用提供预言机服务。</li><li>高效性：与 Chainlink 相比，Band Protocol 提供了更低延迟的数据验证，并在成本上具有优势。</li><li>去中心化的数据验证：通过多个节点和数据源验证数据，确保结果的准确性。</li></ul><p>官方链接：<a href="https://bandprotocol.com/">https://bandprotocol.com/</a></p><h3 id="3-Tellor"><a href="#3-Tellor" class="headerlink" title="3. Tellor"></a>3. <strong>Tellor</strong></h3><p>简介：  Tellor 是一个去中心化的预言机平台，通过矿工网络提供链外数据。Tellor 的矿工通过工作量证明（PoW）机制验证和提供数据，这种机制增加了数据的可信度和防篡改性。</p><p>特点：</p><ul><li>去中心化的数据源：Tellor 的数据提供者（矿工）通过挖矿的方式提供数据，确保数据来源的去中心化。</li><li>数据验证和奖励机制：矿工提交的数据经过其他矿工的验证，确保数据的正确性。成功提交有效数据的矿工会获得奖励。</li><li>开放性：任何人都可以参与 Tellor 网络，成为数据提供者或验证者。</li></ul><p>官方链接：<a href="https://tellor.io/">https://tellor.io/</a></p><h2 id="五、区块链预言机面临的挑战"><a href="#五、区块链预言机面临的挑战" class="headerlink" title="五、区块链预言机面临的挑战"></a>五、区块链预言机面临的挑战</h2><p>尽管区块链预言机在多个领域展现出巨大的潜力，但它仍然面临许多挑战：</p><h3 id="1-数据的准确性与可靠性"><a href="#1-数据的准确性与可靠性" class="headerlink" title="1. 数据的准确性与可靠性"></a>1. <strong>数据的准确性与可靠性</strong></h3><p>预言机依赖外部数据源，而外部数据的质量直接影响智能合约的执行。如果预言机提供的数据不准确或受到篡改，可能会导致合约执行的错误，从而带来不必要的风险。</p><h3 id="2-去中心化与信任问题"><a href="#2-去中心化与信任问题" class="headerlink" title="2. 去中心化与信任问题"></a>2. <strong>去中心化与信任问题</strong></h3><p>许多区块链应用强调去中心化，但预言机往往是中心化的数据源，这可能引发信任问题。中心化的预言机容易受到单点故障或攻击的影响，因此，去中心化的预言机成为了新的研究方向。</p><h3 id="3-延迟问题"><a href="#3-延迟问题" class="headerlink" title="3. 延迟问题"></a>3. <strong>延迟问题</strong></h3><p>数据传递的延迟可能影响智能合约的执行，尤其是在需要快速响应的场景中。例如，高频交易应用中，延迟可能导致重大的经济损失。</p><h3 id="4-数据隐私问题"><a href="#4-数据隐私问题" class="headerlink" title="4. 数据隐私问题"></a>4. <strong>数据隐私问题</strong></h3><p>许多区块链应用涉及敏感数据，如金融交易、个人健康信息等。如何确保预言机在提供数据时不泄露用户隐私，是未来需要解决的重要问题。</p><h2 id="六、区块链预言机的未来展望"><a href="#六、区块链预言机的未来展望" class="headerlink" title="六、区块链预言机的未来展望"></a>六、区块链预言机的未来展望</h2><p>随着区块链技术和预言机的不断发展，未来的预言机将变得更加高效、安全和去中心化。以下是未来发展的一些趋势：</p><ol><li><p><strong>去中心化预言机的普及</strong>：随着去中心化预言机技术的成熟，更多区块链应用将采用这种方式来保证数据的可靠性和透明性。</p></li><li><p><strong>隐私保护技术的引入</strong>：为了保护用户隐私，未来的预言机可能会采用零知识证明、同态加密等技术，确保数据传输过程中的安全性和隐私性。</p></li><li><p><strong>跨链数据互操作性</strong>：随着区块链技术的发展，跨链互操作性将成为未来的趋势。预言机可以实现不同区块链之间的数据交换，促进不同平台之间的协同工作。</p></li></ol><h2 id="七、结语"><a href="#七、结语" class="headerlink" title="七、结语"></a>七、结语</h2><p>区块链预言机作为区块链技术的关键组件，解决了区块链与现实世界数据对接的难题，推动了智能合约和去中心化应用的发展。随着技术的不断创新，预言机将更加完善，助力区块链生态系统实现更广泛的应用。然而，如何解决数据可信性、安全性和隐私保护等问题，仍是区块链预言机发展的关键挑战。随着这些问题的逐步解决，区块链预言机的前景无疑是光明的，它将为区块链的广泛应用打开新的大门。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;18 年 11 月 6 日，中国人民银行发布的《区块链能做什么？不能做什么？》报告中，是这样对预言机定义的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;区块链外信息写入区块链内的机制，一般被称为预言机 (oracle mechanism)。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
      
    
    
    
    <category term="区块链" scheme="http://yaocl.cn/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    
    <category term="区块链" scheme="http://yaocl.cn/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
  </entry>
  
  <entry>
    <title>使用 HSDIS 和 JITWatch 探索 Java 汇编指令</title>
    <link href="http://yaocl.cn/2025/01/11/33JavaAssembly/"/>
    <id>http://yaocl.cn/2025/01/11/33JavaAssembly/</id>
    <published>2025-01-11T07:11:31.000Z</published>
    <updated>2025-01-14T07:53:37.420Z</updated>
    
    <content type="html"><![CDATA[<p>Java 虚拟机（JVM）作为一种现代化的虚拟机，具备即时编译（Just-In-Time, JIT）功能，可以将热点代码编译为高效的本地机器码以提高性能。在实际开发和性能调优中，我们可能需要分析 JVM 将 Java 字节码编译成的汇编指令。本篇博客将详细介绍如何使用 HSDIS 和 JitWatch 工具来查看和分析这些生成的汇编代码。</p><hr><h3 id="一、HSDIS-简介"><a href="#一、HSDIS-简介" class="headerlink" title="一、HSDIS 简介"></a>一、HSDIS 简介</h3><p>HSDIS（HotSpot Disassembler）是 HotSpot JVM 的反汇编插件，可以将 JIT 编译器生成的机器码转换成人类可读的汇编指令。HSDIS 是 JDK 的非官方组件，因此需要手动下载或编译。</p><h3 id="二、JITWatch-简介"><a href="#二、JITWatch-简介" class="headerlink" title="二、JITWatch 简介"></a>二、JITWatch 简介</h3><p>JITWatch 是一个用于分析 JVM JIT 编译过程的可视化工具。它可以解析 JVM 日志文件（通常是通过 <code>-XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation</code> 生成的），并展示 JIT 编译的详细信息，包括内联决策和汇编代码。</p><h3 id="三、环境准备"><a href="#三、环境准备" class="headerlink" title="三、环境准备"></a>三、环境准备</h3><p>以下步骤基于 Linux 环境，但可以适配其他操作系统。</p><ol><li><p><strong>安装 JDK</strong></p><p>确保你的系统安装了支持 HSDIS 和 JIT 日志的 JDK（推荐使用 OpenJDK 或 Oracle JDK 8/11，<code>本文使用的是Oracle JDK 8</code>）。</p></li><li><p><strong>下载或编译 HSDIS</strong></p></li></ol><ul><li><p>检查你的 JDK 是使用哪种架构（<code>x86_64</code> 或 <code>aarch64</code>）。</p></li><li><p>安装 HSDIS：</p><ul><li><p>方式一： 从<a href="https://github.com/liuzhengyang/hsdis">https://github.com/liuzhengyang/hsdis</a>下载编译 <code>本文使用该方式</code>。</p></li><li><p>方式二：<br>从 <a href="https://github.com/graalvm/labs-openjdk-11">GraalVM 的 GitHub 仓库：https://github.com/graalvm/labs-openjdk-11</a> 下载预编译的 HSDIS 动态库，或者自己编译：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/openjdk/jdk.git</span><br><span class="line"><span class="built_in">cd</span> jdk/src/utils/hsdis</span><br><span class="line">make ARCH=&lt;x86_64 或 aarch64&gt;</span><br></pre></td></tr></table></figure></li><li><p>方式三： 从<a href="https://chriswhocodes.com/hsdis/">https://chriswhocodes.com/hsdis/</a>下载已经编译好的</p></li></ul></li></ul><ul><li>将生成的 <code>hsdis-&lt;arch&gt;.so</code> 放到 JDK 的 <code>$JAVA_HOME/jre/bin/server</code> 目录下。</li></ul><ol start="3"><li><strong>安装 JITWatch</strong></li></ol><ul><li>从 <a href="https://github.com/AdoptOpenJDK/jitwatch">JitWatch GitHub 仓库：https://github.com/AdoptOpenJDK/jitwatch</a> 下载最新版本。</li><li>解压后运行 <code>launchUI.sh</code>（Linux/macOS）或 <code>launchUI.bat</code>（Windows）。</li><li>确保你已安装 Java 8 或更高版本。</li></ul><h3 id="生成汇编代码"><a href="#生成汇编代码" class="headerlink" title="生成汇编代码"></a>生成汇编代码</h3><h4 id="1-编写测试代码"><a href="#1-编写测试代码" class="headerlink" title="1. 编写测试代码"></a>1. 编写测试代码</h4><p>首先，创建一个简单的 Java 类用于测试：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10_000_000</span>; i++) &#123;</span><br><span class="line">            compute(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">compute</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (x * <span class="number">2</span> + <span class="number">1</span>) / <span class="number">3</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-使用-HSDIS-查看汇编"><a href="#2-使用-HSDIS-查看汇编" class="headerlink" title="2. 使用 HSDIS 查看汇编"></a>2. 使用 HSDIS 查看汇编</h4><p>运行上述代码时，启动 JVM 时添加 HSDIS 配置参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-XX:+UnlockDiagnosticVMOptions</span><br><span class="line">-XX:+PrintAssembly</span><br><span class="line">-Xcomp</span><br><span class="line">-XX:+LogCompilation</span><br><span class="line">-XX:LogFile=/home/yao/hotspot.log</span><br></pre></td></tr></table></figure><p>其中：</p><ul><li><code>-XX:+PrintAssembly</code>：启用汇编代码打印。</li><li><code>-XX:+LogCompilation</code>：生成 JIT 日志文件。</li><li><code>-XX:LogFile</code>：指定 JIT 日志文件的位置。</li></ul><p><img src="/2025/01/11/33JavaAssembly/1.png"></p><p>运行后，终端将输出大量信息，其中包含 <code>compute</code> 方法的汇编代码。你可以通过分析这些汇编指令了解 JVM 如何优化你的代码。</p><p><img src="/2025/01/11/33JavaAssembly/2.png"></p><h4 id="3-使用-JitWatch-分析"><a href="#3-使用-JitWatch-分析" class="headerlink" title="3. 使用 JitWatch 分析"></a>3. 使用 JitWatch 分析</h4><ol><li>配置源码目录和编译字节码目录</li></ol><p><img src="/2025/01/11/33JavaAssembly/3.png"><br>2.打开生成的 hotspot.log 文件。并启动分析</p><p><img src="/2025/01/11/33JavaAssembly/4.png"></p><p><img src="/2025/01/11/33JavaAssembly/5.png"></p><hr><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><ol><li><p><strong>未加载 HSDIS 动态库</strong></p><ul><li>检查 HSDIS 文件名是否正确，并确认其路径与 JVM 的 <code>lib</code> 目录匹配。</li><li>使用 <code>java -version</code> 确认使用的是预期的 JVM。</li></ul></li><li><p><strong>汇编输出乱码</strong></p><ul><li>确保 JVM 使用的指令集架构与 HSDIS 编译版本一致（如 x86_64）。</li><li>检查终端编码是否支持正确显示特殊字符。</li></ul></li><li><p><strong>JitWatch 无法加载日志</strong></p><ul><li>确保日志文件完整无误。</li><li>使用 <code>grep</code> 检查日志是否包含方法编译记录。</li></ul></li></ol><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过 HSDIS 和 JitWatch，我们可以深入了解 JVM 的 JIT 编译过程以及生成的汇编代码。对于性能调优或研究 JVM 工作原理，这些工具提供了强大的支持。希望本文能够帮助你快速上手这些工具，进一步探索 Java 性能优化的奥秘！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Java 虚拟机（JVM）作为一种现代化的虚拟机，具备即时编译（Just-In-Time, JIT）功能，可以将热点代码编译为高效的本地机器码以提高性能。在实际开发和性能调优中，我们可能需要分析 JVM 将 Java 字节码编译成的汇编指令。本篇博客将详细介绍如何使用 HS</summary>
      
    
    
    
    <category term="JAVA" scheme="http://yaocl.cn/categories/JAVA/"/>
    
    
    <category term="JAVA" scheme="http://yaocl.cn/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>Solana：重塑区块链生态的高速革命</title>
    <link href="http://yaocl.cn/2025/01/05/32Solana/"/>
    <id>http://yaocl.cn/2025/01/05/32Solana/</id>
    <published>2025-01-05T07:22:18.000Z</published>
    <updated>2025-01-09T08:10:39.007Z</updated>
    
    <content type="html"><![CDATA[<p>Solana 是一个高性能的区块链平台，以其卓越的可扩展性和极快的交易速度吸引了全球开发者和加密爱好者的关注。作为一个相对较新的区块链项目，Solana 不仅在技术创新上突破重围，还在实际应用上展现出强大的潜力。本文将详细探讨 Solana 的背景、技术特点、与其他区块链的比较以及它在去中心化金融（DeFi）和非同质化代币（NFT）等领域的应用。</p><h2 id="一、Solana-背景简介"><a href="#一、Solana-背景简介" class="headerlink" title="一、Solana 背景简介"></a>一、Solana 背景简介</h2><p>Solana 是由 Anatoly Yakovenko 于 2020 年推出的一个区块链平台。Yakovenko 是前 Qualcomm 的工程师，他设计 Solana 的初衷是为了克服以太坊等现有区块链平台在扩展性和交易速度上的局限。Solana 提供了一个非常快速、低成本且高可扩展的区块链环境，旨在支持大规模的去中心化应用（DApps）和智能合约。</p><p>与以太坊、比特币等传统区块链相比，Solana 的最大特点就是其极高的吞吐量。Solana 采用了一系列创新的技术，使其能够处理数万笔交易，而不会出现拥堵的现象。这一特点使得 Solana 成为加密行业中的新兴领导者，特别是在去中心化金融（DeFi）和非同质化代币（NFT）等热门领域中，Solana 的应用前景广阔。</p><h2 id="二、Solana-的核心技术特点"><a href="#二、Solana-的核心技术特点" class="headerlink" title="二、Solana 的核心技术特点"></a>二、Solana 的核心技术特点</h2><h3 id="1-Proof-of-History-PoH"><a href="#1-Proof-of-History-PoH" class="headerlink" title="1. Proof of History (PoH)"></a>1. Proof of History (PoH)</h3><p>Solana 的创新之一是其独特的“历史证明”（Proof of History，PoH）共识机制。传统的区块链共识机制，如比特币的 Proof of Work（PoW）或以太坊的 Proof of Stake（PoS），都需要通过节点间的竞争或选举来验证交易和区块。这种方式虽然能够保证网络的去中心化，但在处理速度和吞吐量上存在一定的瓶颈。</p><p>Solana 通过 PoH 技术，解决了这一问题。PoH 并不依赖传统的竞争方式来验证交易，而是使用一种加密算法，通过时间戳记录交易顺序，使得区块链上的每笔交易都能够按时间顺序链式存储。这不仅大大提高了交易的效率，还降低了网络的验证成本。</p><h3 id="2-Proof-of-Stake-PoS"><a href="#2-Proof-of-Stake-PoS" class="headerlink" title="2. Proof of Stake (PoS)"></a>2. Proof of Stake (PoS)</h3><p>虽然 PoH 是 Solana 的核心技术之一，但它并不是唯一的共识机制。Solana 还采用了 Proof of Stake（PoS）共识机制。PoS 机制要求节点质押一定数量的代币来参与区块验证，这使得攻击者需要持有大量的代币才能控制网络，从而增强了网络的安全性。</p><p>与传统的 PoW 共识机制相比，PoS 不需要大量的计算资源和能源消耗，因此它在能源效率上要优越得多。此外，Solana 的 PoS 机制还通过优化了区块验证过程，提高了网络的吞吐量。</p><h3 id="3-并行处理与分片（Sharding）"><a href="#3-并行处理与分片（Sharding）" class="headerlink" title="3. 并行处理与分片（Sharding）"></a>3. <strong>并行处理与分片（Sharding）</strong></h3><p>Solana 采用了并行处理的技术，通过优化其区块链架构，实现了高效的并行交易处理。与传统的区块链需要依赖单线程处理交易不同，Solana 通过支持多线程并行执行，极大提高了其交易吞吐量。</p><p>Solana 还计划通过分片（Sharding）技术进一步提升网络的可扩展性。分片技术将区块链网络划分为多个独立的子链（Shards），每个子链能够独立处理一部分交易，从而实现交易负载的均匀分布。通过这种方式，Solana 可以在不牺牲去中心化的情况下，实现更多交易的并行处理，从而提高整体网络的性能。</p><h3 id="4-Turbine-协议"><a href="#4-Turbine-协议" class="headerlink" title="4. Turbine 协议"></a>4. <strong>Turbine 协议</strong></h3><p>Solana 的 Turbine 协议是其核心网络协议之一，它负责高效地传播区块信息。Turbine 使用一种类似比特币的“传播树”结构，将每个新区块的传播过程拆分成多个小的片段，并通过多层级的分发机制快速传播。这不仅减少了区块传播时的延迟，还优化了网络带宽的使用，使得 Solana 能够更快地处理大量交易。</p><p>Turbine 协议的设计使得即使在高负载的情况下，Solana 也能保持其低延迟和高吞吐量，确保交易能够迅速被验证并添加到区块链中。</p><h3 id="5-Gulf-Stream-网络优化"><a href="#5-Gulf-Stream-网络优化" class="headerlink" title="5. Gulf Stream 网络优化"></a>5. Gulf Stream 网络优化</h3><p>Gulf Stream 是 Solana 网络中的一种优化协议，旨在减少交易确认的延迟。它允许节点在交易尚未被完全确认时，就能开始处理这些交易，并在未来的区块中完成确认。通过这种方式，Solana 大大缩短了交易的确认时间，并提高了整体网络的响应速度。</p><p>此外，Gulf Stream 协议还减少了网络中的交易等待时间和网络拥堵的情况，从而帮助 Solana 更加高效地处理交易。</p><h3 id="6-SeaLevel-多线程执行"><a href="#6-SeaLevel-多线程执行" class="headerlink" title="6. SeaLevel 多线程执行"></a>6. SeaLevel 多线程执行</h3><p>Solana 的 SeaLevel 是其用于执行智能合约和交易的一种并行执行环境。与传统的区块链环境不同，Solana 能够在多个线程中并行执行智能合约。这种并行处理能力使得 Solana 能够同时处理多个交易和智能合约，而无需像其他区块链那样依赖于单个线程的顺序执行。</p><p>这种技术创新大大提高了 Solana 的交易吞吐量，使其能够在处理大规模 DApp 和复杂交易时，仍然保持高效的性能。</p><h2 id="三、Solana-的独特优势"><a href="#三、Solana-的独特优势" class="headerlink" title="三、Solana 的独特优势"></a>三、Solana 的独特优势</h2><h3 id="1-高吞吐量与低延迟"><a href="#1-高吞吐量与低延迟" class="headerlink" title="1. 高吞吐量与低延迟"></a>1. 高吞吐量与低延迟</h3><p>Solana 的另一个显著特点是其极高的交易吞吐量和低延迟。Solana 的设计目标是每秒处理超过 65,000 笔交易（TPS），并且能够在毫秒级别内确认交易。这比目前市场上大多数区块链平台（如比特币的 7 TPS 和以太坊的 30 TPS）要高出几个数量级。</p><p>为了实现这一目标，Solana 采用了多个创新技术，包括分片（Sharding）、优化的交易验证算法、以及高效的内存池（Mempool）设计。这些技术使得 Solana 能够在不牺牲去中心化的前提下，提供大规模的交易处理能力。</p><h3 id="2-可扩展性"><a href="#2-可扩展性" class="headerlink" title="2. 可扩展性"></a>2. 可扩展性</h3><p>Solana 的可扩展性不仅体现在交易吞吐量上，还体现在其能够支持复杂的去中心化应用和智能合约。Solana 使用的编程语言 Rust 和 C 语言使得开发者能够更高效地编写智能合约，而其高效的虚拟机（Solana VM）则确保了这些合约能够快速执行。</p><p>与以太坊相比，Solana 能够更好地处理高频交易和复杂应用，这使得它成为了去中心化金融、去中心化交易所（DEX）和其他应用的理想平台。</p><h3 id="3-低交易费用"><a href="#3-低交易费用" class="headerlink" title="3. 低交易费用"></a>3. 低交易费用</h3><p>Solana 提供极低的交易费用，这是它相较于其他区块链平台的另一个重要优势。每笔交易的费用通常低于 0.01 美元，这使得 Solana 成为适合小额支付、微支付和高频交易的理想选择。</p><p>这种低费用的优势在 DeFi 和 NFT 市场中尤为显著，Solana 能够让用户以几乎为零的成本进行交易和交互，这为平台的增长和用户的参与提供了巨大的推动力。</p><h2 id="四、Solana-与其他区块链的比较"><a href="#四、Solana-与其他区块链的比较" class="headerlink" title="四、Solana 与其他区块链的比较"></a>四、Solana 与其他区块链的比较</h2><h3 id="1-Solana-与以太坊"><a href="#1-Solana-与以太坊" class="headerlink" title="1. Solana 与以太坊"></a>1. Solana 与以太坊</h3><p>以太坊作为智能合约和去中心化应用的先驱，一直是区块链领域的重要平台。然而，随着使用者和应用的增长，以太坊在交易吞吐量和手续费方面出现了瓶颈，特别是在 DeFi 和 NFT 的高峰时期，网络拥堵严重，导致交易确认时间延长，手续费飙升。</p><p>与以太坊相比，Solana 的优势在于其更高的吞吐量、更低的交易费用以及更快的交易确认速度。Solana 能够支持更大规模的去中心化应用，同时保持网络的低成本和高效能，这使得它成为开发者和用户的热门选择。</p><h3 id="2-Solana-与比特币"><a href="#2-Solana-与比特币" class="headerlink" title="2. Solana 与比特币"></a>2. Solana 与比特币</h3><p>比特币是最早的区块链平台，主要用于数字货币交易和储值。然而，比特币的区块链相对较慢，交易吞吐量也有限，通常只有 7 笔交易每秒（TPS）。虽然比特币的安全性和去中心化程度无与伦比，但它并不适合大规模的去中心化应用和高频交易。</p><p>相比之下，Solana 在吞吐量、交易速度和低延迟方面拥有明显的优势。虽然比特币在区块链领域的地位难以撼动，但 Solana 在技术层面为更复杂的应用提供了更强大的支持。</p><h2 id="五、Solana-的应用场景"><a href="#五、Solana-的应用场景" class="headerlink" title="五、Solana 的应用场景"></a>五、Solana 的应用场景</h2><h3 id="1-去中心化金融（DeFi）"><a href="#1-去中心化金融（DeFi）" class="headerlink" title="1. 去中心化金融（DeFi）"></a>1. 去中心化金融（DeFi）</h3><p>Solana 已成为去中心化金融（DeFi）领域的领先平台之一。DeFi 通过去中心化的协议为用户提供金融服务，Solana 以其低延迟和高吞吐量，为 DeFi 提供了理想的基础设施。Solana 上的去中心化交易所（DEX）、借贷平台和稳定币协议，已经吸引了大量的用户和资金。</p><p>例如，Solana 上的 Serum 是一个去中心化交易所，它通过 Solana 高速区块链的特性，提供快速且低成本的交易体验。相比于以太坊上常见的高交易费用，Serum 让用户能够以更低的成本进行资产交换。</p><h3 id="2-非同质化代币（NFT）"><a href="#2-非同质化代币（NFT）" class="headerlink" title="2. 非同质化代币（NFT）"></a>2. 非同质化代币（NFT）</h3><p>Solana 还在非同质化代币（NFT）领域取得了显著的进展。Solana 的高吞吐量和低交易费用使得它成为了 NFT 项目的理想平台。Solana 上的 NFT 市场，如 Solanart 和 Magic Eden，已经吸引了大量的艺术家和收藏家。</p><p>与以太坊上的高交易费用不同，Solana 的低费用使得 NFT 创作者能够更频繁地进行交易，同时也降低了用户进入门槛。这种优势使得 Solana 在 NFT 领域成为了一个热门选择。</p><h3 id="3-物联网（IoT）与其他领域"><a href="#3-物联网（IoT）与其他领域" class="headerlink" title="3. 物联网（IoT）与其他领域"></a>3. 物联网（IoT）与其他领域</h3><p>除了 DeFi 和 NFT，Solana 还在物联网（IoT）、游戏、供应链管理等多个领域展现出潜力。由于 Solana 强大的扩展性和低交易费用，它能够为这些领域提供高效、去中心化的解决方案。</p><h2 id="三、Solana-面临的主要问题"><a href="#三、Solana-面临的主要问题" class="headerlink" title="三、Solana 面临的主要问题"></a>三、Solana 面临的主要问题</h2><p>尽管 Solana 拥有强大的技术优势，但它在快速发展的过程中也面临着一些挑战和问题：</p><h3 id="1-网络稳定性与宕机问题"><a href="#1-网络稳定性与宕机问题" class="headerlink" title="1. 网络稳定性与宕机问题"></a>1. 网络稳定性与宕机问题</h3><p>Solana 曾多次遭遇网络停运或宕机的情况，尤其是在网络流量激增时，导致交易拥堵或中断。这些问题对用户的信任和平台的稳定性产生了较大的影响。尽管 Solana 开发团队采取了一些修复措施，但频繁的网络宕机依然影响了平台的可靠性。</p><h3 id="2-去中心化和节点集中化问题"><a href="#2-去中心化和节点集中化问题" class="headerlink" title="2. 去中心化和节点集中化问题"></a>2. 去中心化和节点集中化问题</h3><p>Solana 的去中心化程度较低，节点集中度较高。尽管 Solana 采用了 PoS 共识机制，推动多个节点参与验证，但相较于比特币和以太坊，Solana 网络中少数大型资金和矿池主导了大部分验证工作。这可能影响网络的安全性和公平性，降低其去中心化的能力。</p><h3 id="3-生态系统的成熟度与开发者支持"><a href="#3-生态系统的成熟度与开发者支持" class="headerlink" title="3. 生态系统的成熟度与开发者支持"></a>3. 生态系统的成熟度与开发者支持</h3><p>Solana 的生态系统仍在扩展阶段，尽管其在 DeFi 和 NFT 等领域取得了一定成就，但与以太坊等老牌区块链相比，Solana 的应用数量和开发者支持还存在差距。Solana 需要更多的开发者参与和更完善的工具和文档，以促进生态系统的成熟。</p><h3 id="4-跨链兼容性与安全性问题"><a href="#4-跨链兼容性与安全性问题" class="headerlink" title="4. 跨链兼容性与安全性问题"></a>4. 跨链兼容性与安全性问题</h3><p>Solana 在与其他区块链的互操作性方面存在挑战。尽管通过协议如 Wormhole 实现了与以太坊等网络的跨链转移，但跨链操作的安全性和效率仍然是问题。同时，由于 Solana 网络的复杂性，网络安全和智能合约的漏洞也可能导致资金损失。如何在保证性能的同时增强跨链兼容性和网络安全，是 Solana 需要解决的关键问题。</p><h2 id="七、总结"><a href="#七、总结" class="headerlink" title="七、总结"></a>七、总结</h2><p>Solana 凭借其创新的技术架构和高性能特点，已经在区块链领域占据了一席之地。通过引入独特的 Proof of History（PoH）共识机制、高吞吐量、低延迟以及并行处理等技术，Solana 成为解决区块链扩展性问题的一个重要创新平台。尤其在 DeFi、NFT 和 Web3 等应用场景中，Solana 展现了强大的潜力，吸引了大量开发者和用户的关注。</p><p>然而，Solana 在快速发展的过程中，也面临着一些不可忽视的问题。网络稳定性、去中心化程度、生态系统的成熟度以及跨链兼容性等挑战，仍然是平台面临的主要瓶颈。尽管如此，Solana 的技术优势和高速发展使其成为区块链领域的重要竞争者，未来通过持续优化和解决这些问题，Solana 有望在区块链的竞争中稳固自己的位置，推动更多创新应用的落地和发展。</p><p>总之，Solana 是一款在技术上具有重大突破的区块链平台，虽然存在一些挑战，但其独特的设计理念和性能优势使得它在行业中占据了重要的地位。随着生态的不断成熟和技术的不断优化，Solana 有望继续引领区块链行业走向更高效、去中心化的未来。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Solana 是一个高性能的区块链平台，以其卓越的可扩展性和极快的交易速度吸引了全球开发者和加密爱好者的关注。作为一个相对较新的区块链项目，Solana 不仅在技术创新上突破重围，还在实际应用上展现出强大的潜力。本文将详细探讨 Solana 的背景、技术特点、与其他区块链的</summary>
      
    
    
    
    <category term="区块链" scheme="http://yaocl.cn/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    
    <category term="区块链" scheme="http://yaocl.cn/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    <category term="Solana" scheme="http://yaocl.cn/tags/Solana/"/>
    
  </entry>
  
  <entry>
    <title>InnoDB 存储引擎是如何管理和存储数据</title>
    <link href="http://yaocl.cn/2023/08/06/31innodb/"/>
    <id>http://yaocl.cn/2023/08/06/31innodb/</id>
    <published>2023-08-06T08:41:39.000Z</published>
    <updated>2023-08-22T02:00:49.378Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何连接-Mysql-？"><a href="#如何连接-Mysql-？" class="headerlink" title="如何连接 Mysql ？"></a>如何连接 Mysql ？</h2><p>在 Java 中，通常使用 JDBC（Java Database Connectivity）来连接数据库。JDBC 定义了一套用于访问数据库的 API，它提供了一种标准的接口，使得我们可以通过 Java 代码与各种数据库进行交互。</p><p>常见的 Java Web 系统是部署在 Tomcat 中的，那么 Tomcat 本身肯定是有多个线程来并发处理接收到的多个请求的，Mysql 是怎么处理的呢？</p><p>在 Mysql 中，引入了连接池，连接池会维护一组可重用的数据库连接，应用程序需要访问数据库时可以从连接池中获取一个可用连接，执行完毕后将连接归还给连接池。这样可以减少连接的频繁创建和销毁，提升性能。</p><p>如下所示：</p><p><img src="/2023/08/06/31innodb/1.png"></p><h2 id="Mysql-如何处理连接请求的？"><a href="#Mysql-如何处理连接请求的？" class="headerlink" title="Mysql 如何处理连接请求的？"></a>Mysql 如何处理连接请求的？</h2><p>当 Mysql 接收到一个网络连接请求后，它是如何去处理该请求的，如何执行 SQL 的，总体的步骤可以分为一下几步：</p><ol><li><p>开启一个端口监听的线程，用于网络连接以及读取请求。</p></li><li><p>Mysql 内部提供了一个 SQL 接口（SQL Interface）的组件，用来专门执行 SQL 语句的接口</p></li><li><p>通过<code>查询优化器</code>选择最优的查询路径来执行</p></li><li><p>调用执行器，根据执行计划调用存储引擎的接口</p></li><li><p>调用存储引擎接口，真正执行 SQL 语句</p></li><li><p>存储引擎管理和存储数据</p></li></ol><p>比如：InnoDB、MyISAM、Memory，我们可以自己选择使用哪种存储引擎来负责具体的 SQL 语句执行。<br>现在 MySQL 一般都是默认使用 InnoDB 存储引擎</p><p><img src="/2023/08/06/31innodb/2.png"></p><p>接着来分析 InnoDB 存储引擎是如何管理和存储我们的数据。</p><h2 id="InnoDB-的重要内存结构：缓冲池"><a href="#InnoDB-的重要内存结构：缓冲池" class="headerlink" title="InnoDB 的重要内存结构：缓冲池"></a>InnoDB 的重要内存结构：缓冲池</h2><p>InnoDB 存储引擎中有一个非常重要的组件：缓冲池（Buffer Pool）。 Buffer Pool 会将磁盘上的数据页缓存到内存中。</p><p><img src="/2023/08/06/31innodb/3.png"></p><p>Buffer Pool 使用 LRU（Least Recently Used，最近最少使用）算法来管理内存中的数据页。当查询需要访问数据时，InnoDB 首先检查缓冲池中是否存在相应的数据页。如果存在，它会直接从内存中获取数据，而不是从磁盘中读取，这大大提高了查询性能。如果数据页不在缓冲池中，InnoDB 会将其读取到缓冲池，并将其保留在内存中供后续查询使用。</p><p>比如 SQL 语句：<code>update user set name=&#39;xxx&#39; where id=1</code>，Mysql 会先从 Buffer Pool 中查询存不存在，存在直接操作缓存中的数据，如果不在的话，先从磁盘里加载到缓冲池里来。</p><p>默认配置下 Buffer Pool 只有 128MB ，可以通过配置<code>innodb_buffer_pool_size</code>调整 Buffer Pool 大小。 通过适当配置缓冲池的大小，可以使常用的数据页始终在内存中，提高查询效率。</p><h2 id="undo-日志文件：让更新的数据可以回滚"><a href="#undo-日志文件：让更新的数据可以回滚" class="headerlink" title="undo 日志文件：让更新的数据可以回滚"></a>undo 日志文件：让更新的数据可以回滚</h2><p>Undo 日志文件用于记录数据库中正在进行的事务操作，用于回滚数据。当有更新、删除或插入操作发生时，InnoDB 引擎会将相关信息记录到 Undo 日志文件中。</p><p>当需要回滚事务时，InnoDB 引擎使用 Undo 日志来还原到事务开始之前的数据状态。它通过逆向操作来撤销对数据的修改，并将数据还原为先前的状态。</p><p><img src="/2023/08/06/31innodb/4.png"></p><p>当要更新一条数据时，首先会从磁盘文件中加载数据到缓冲池，然后然后对这条数据加锁，接着把更新前的旧值写入 undo 日志文件。这时才开始更新这条记录更新的时候，先更新缓冲池中的记录，此时这条数据变成了脏数据。</p><p><img src="/2023/08/06/31innodb/5.png"></p><h2 id="redo-日志文件：保证数据的一致性和持久性"><a href="#redo-日志文件：保证数据的一致性和持久性" class="headerlink" title="redo 日志文件：保证数据的一致性和持久性"></a>redo 日志文件：保证数据的一致性和持久性</h2><p>如果修改操作已经写入缓存中，但是没有同步到磁盘进行持久化，此时，Mysql 的机器宕机了那么缓存中的数据也会丢失，那么本次更新的数据也就丢失了。</p><p>为了保障 Mysql 数据的一致性和持久性，InnoDB 引擎引入了 redo 日志文件。</p><blockquote><p>Redo Log 日志是一种物理日志，主要用于记录在事务提交前对数据库进行的修改操作。当数据库崩溃或发生故障时，通过 Redo Log 可以恢复到最后一次提交的状态，保证数据的持久性。</p></blockquote><p>Redo Log 的作用主要体现在以下两个方面：</p><p>数据恢复：当数据库发生故障时，通过 Redo Log 可以将未提交的修改操作重新应用到数据库中，从而恢复到最后一次提交的状态。</p><p>提高性能：通过将修改操作记录到 Redo Log 中，可以将磁盘 IO 操作转化为顺序写操作，大幅提高了数据库的写入性能。</p><p>因此，当更新操作执行后，Mysql 会把对内存所做的修改写入到一个 Redo Log Buffer 里去，这也是内存里的一个缓冲区，是用来存放 redo 日志的。如下图所示：</p><p><img src="/2023/08/06/31innodb/6.png"></p><p>可以配置<code>innodb_log_buffer_size</code>来指定 Redo Log 的缓冲区大小，默认为 8MB。较大的值可以减少频繁的刷新操作，提高性能，但同时也会占用更多的内存。</p><p>redo 日志写入磁盘有三种策略，可以通过 innodb_flush_log_at_trx_commit 来配置的：</p><p>① 参数值为 0，redo log 不进磁盘</p><p>表示不刷写 Redo Log 到磁盘，即异步写入策略。事务提交时，Redo Log 的修改操作只会写入到操作系统的页缓存中，并不会马上刷写到磁盘。这样可以提供最好的写入性能，但在数据库崩溃或发生故障时，可能会造成一定程度的数据丢失。</p><p>② 参数值为 1，redo log 进磁盘【默认值】</p><p>表示同步刷写 Redo Log 到磁盘。事务提交时，Redo Log 的修改操作会立即写入磁盘并等待 IO 操作完成。确保数据持久性的同时，也会对性能产生一定的影响。这是最常用的设置，适合大多数应用场景。</p><p><img src="/2023/08/06/31innodb/7.png"></p><p>③ 参数值为 2，redo log 进 os cache 缓存</p><p>表示每次事务提交时将 Redo Log 的修改操作写入磁盘，但不会等待 IO 操作完成。事务提交时，Redo Log 会先写入到操作系统的页缓存，然后由后台线程异步地将数据刷写到磁盘。这种设置可以提供较好的性能和一定程度的数据保护，但仍然存在一定的风险。</p><p><img src="/2023/08/06/31innodb/8.png"></p><p>选择适当的 innodb_flush_log_at_trx_commit 值取决于对数据的持久性和性能的需求。如果对数据的持久性要求非常高，可以将其设置为 1。如果对性能要求较高且可以接受一定程度的数据丢失，可以将其设置为 0。如果在保证一定程度的数据保护的同时追求更好的性能，可以选择设置为 2。</p><h2 id="binlog-到底是什么东西？"><a href="#binlog-到底是什么东西？" class="headerlink" title="binlog 到底是什么东西？"></a>binlog 到底是什么东西？</h2><p>binlog 不是 InnoDB 存储引擎特有的日志文件，是属于 mysql server 自己的日志文件。用于记录对 MySQL 数据库执行的更改操作，包括语句的发生时间、执行时长，主要用于数据库恢复和主从复制。</p><p>redo log 和 binlog 都是记录修改的日志，但是两者是有差别的。redo log 是一种偏向物理性质的重做日志，它里面记录的类似<code>对哪个数据页中的什么记录，做了个什么修改</code>，而 binlog 叫做归档日志，它里面记录的是偏向于逻辑性的日志，类似于<code>对 xxx 表中的 id=1 的一行数据做了更新操作，更新以后的值是什么</code>，</p><p>因此在提交事务的时候，同时也会写入 binlog：</p><p><img src="/2023/08/06/31innodb/9.png"></p><h3 id="binlog-日志的刷盘策略分析"><a href="#binlog-日志的刷盘策略分析" class="headerlink" title="binlog 日志的刷盘策略分析"></a>binlog 日志的刷盘策略分析</h3><p>对于 binlog 日志，有两种刷盘策略，可以通过 <code>sync_binlog</code> 设置：</p><p>① 参数值为 0，【默认值】</p><p>把 binlog 写入磁盘的时候，不是直接进入磁盘文件，而是进入 os cache 内存缓存。<br>所以跟之前分析的一样，如果此时机器宕机，那么在 os cache 里的 binlog 日志是会丢失的：</p><p><img src="/2023/08/06/31innodb/10.png"></p><p>② 参数值为 1</p><p>强制在提交事务的时候，把 binlog 直接写入到磁盘文件里去，那么这样提交事务之后，哪怕机器宕机，磁盘上的 binlog 是不会丢失的。</p><p>当把 binlog 写入磁盘文件之后，接着就会完成最终的事务提交，此时会把本次更新对应的 binlog 文件名称和本次更新的 binlog 日志在文件里的位置，都写入到 redo log 日志文件里去，同时在 redo log 日志文件里写入一个 commit 标记。</p><p>在完成这个事情之后，才算最终完成了事务的提交，我们看下图的示意：</p><p><img src="/2023/08/06/31innodb/11.png"></p><h2 id="后台-IO-线程随机将内存更新后的脏数据刷回磁盘"><a href="#后台-IO-线程随机将内存更新后的脏数据刷回磁盘" class="headerlink" title="后台 IO 线程随机将内存更新后的脏数据刷回磁盘"></a>后台 IO 线程随机将内存更新后的脏数据刷回磁盘</h2><p>MySQL 有一个后台的 IO 线程，会在之后某个时间里，随机的把内存 buffer pool 中的修改后的脏数据给刷回到磁盘上的数据文件里去，我们看下图：</p><p><img src="/2023/08/06/31innodb/12.png"></p><p>在 IO 线程把脏数据刷回磁盘之前，哪怕 mysql 宕机崩溃也没关系，因为重启之后，会根据 redo 日志恢复之前提交事务做过的修改到内存里去，然后等适当时机，IO 线程自然还是会把这个修改后的数据刷到磁盘上的数据文件里去的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>InnoDB 存储引擎主要就是包含了一些 Buffer Pool、redo log buffer 等内存里的缓存数据，同时还包含了一些 undo 日志文件，redo 日志文件等东西，同时 mysql server 自己还有 binlog 日志文件。</p><p>在执行更新的时候，每条 SQL 语句，都会对应修改 buffer pool 里的缓存数据、写 undo 日志、写 redo log buffer 几个步骤；当提交事务的时候，一定会把 redo log 刷入磁盘，binlog 刷入磁盘，完成 redo log 中的事务 commit 标记；最后后台的 IO 线程会随机的把 buffer pool 里的脏数据刷入磁盘里去。</p><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a href="https://developer.aliyun.com/article/1286718">https://developer.aliyun.com/article/1286718</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;如何连接-Mysql-？&quot;&gt;&lt;a href=&quot;#如何连接-Mysql-？&quot; class=&quot;headerlink&quot; title=&quot;如何连接 Mysql ？&quot;&gt;&lt;/a&gt;如何连接 Mysql ？&lt;/h2&gt;&lt;p&gt;在 Java 中，通常使用 JDBC（Java Databa</summary>
      
    
    
    
    <category term="MySql" scheme="http://yaocl.cn/categories/MySql/"/>
    
    
    <category term="MySql" scheme="http://yaocl.cn/tags/MySql/"/>
    
    <category term="InnoDB" scheme="http://yaocl.cn/tags/InnoDB/"/>
    
  </entry>
  
  <entry>
    <title>搞明白什么是零拷贝，就是这么简单</title>
    <link href="http://yaocl.cn/2023/07/26/28zerocopy/"/>
    <id>http://yaocl.cn/2023/07/26/28zerocopy/</id>
    <published>2023-07-26T14:09:23.000Z</published>
    <updated>2023-08-07T01:22:28.482Z</updated>
    
    <content type="html"><![CDATA[<p>我们总会在各种地方看到零拷贝，那零拷贝到底是个什么东西。接下来，让我们来理一理啊。拷贝说的是计算机里的 I/O 操作，也就是数据的读写操作。计算机可是一个复杂的家伙，包括软件和硬件两大部分，软件主要指操作系统、驱动程序和应用程序。硬件那就多了，CPU、内存、硬盘等等一大堆东西。这么复杂的设备要进行读写操作，其中繁琐和复杂程度可想而知。</p><h2 id="传统I-O的读写过程"><a href="#传统I-O的读写过程" class="headerlink" title="传统I/O的读写过程"></a>传统I/O的读写过程</h2><p>如果要了解零拷贝，那就必须要知道一般情况下，计算机是如何读写数据的，我把这种情况称为传统 I/O。数据读写的发起者是计算机中的应用程序，比如我们常用的浏览器、办公软件、音视频软件等。而数据的来源呢，一般是硬盘、外部存储设备或者是网络套接字（也就是网络上的数据通过网口+网卡的处理）。过程本来是很复杂的，所以大学课程里要通过《操作系统》、《计算机组成原理》来专门讲计算机的软硬件。</p><h3 id="简化版读操作流程"><a href="#简化版读操作流程" class="headerlink" title="简化版读操作流程"></a>简化版读操作流程</h3><p>那么细的没办法讲来，所以，我们把这个读写过程简化一下，忽略大多数细节，只讲流程。</p><p><img src="/2023/07/26/28zerocopy/1.png"></p><p>上图是应用程序进行一次读操作的过程。</p><ol><li> 应用程序先发起读操作，准备读取数据了；</li><li> 内核将数据从硬盘或外部存储读取到内核缓冲区；</li><li> 内核将数据从内核缓冲区拷贝到用户缓冲区；</li><li> 应用程序读取用户缓冲区的数据进行处理加工；</li></ol><h3 id="详细的读写操作流程"><a href="#详细的读写操作流程" class="headerlink" title="详细的读写操作流程"></a>详细的读写操作流程</h3><p>下面是一个更详细的 I/O 读写过程。这个图可好用极了，我会借助这个图来厘清 I/O 操作的一些基础但非常重要的概念。</p><p><img src="/2023/07/26/28zerocopy/2.png"></p><p>先看一下这个图，上面红粉色部分是读操作，下面蓝色部分是写操作。如果一下子看着有点儿迷糊的话，没关系，看看下面几个概念就清楚了。</p><h4 id="应用程序"><a href="#应用程序" class="headerlink" title="应用程序"></a>应用程序</h4><p>就是安装在操作系统上的各种应用。</p><h4 id="系统内核"><a href="#系统内核" class="headerlink" title="系统内核"></a>系统内核</h4><p>系统内核是一些列计算机的核心资源的集合，不仅包括CPU、总线这些硬件设备，也包括进程管理、文件管理、内存管理、设备驱动、系统调用等一些列功能。</p><h4 id="外部存储"><a href="#外部存储" class="headerlink" title="外部存储"></a>外部存储</h4><p>外部存储就是指硬盘、U盘等外部存储介质。</p><h4 id="内核态"><a href="#内核态" class="headerlink" title="内核态"></a>内核态</h4><ul><li>内核态是操作系统内核运行的模式，当操作系统内核执行特权指令时，处于内核态。</li><li>在内核态下，操作系统内核拥有最高权限，可以访问计算机的所有硬件资源和敏感数据，执行特权指令，控制系统的整体运行。</li><li>内核态提供了操作系统管理和控制计算机硬件的能力，它负责处理系统调用、中断、硬件异常等核心任务。</li></ul><h4 id="用户态"><a href="#用户态" class="headerlink" title="用户态"></a>用户态</h4><p>这里的用户可以理解为应用程序，这个用户是对于计算机的内核而言的，对于内核来说，系统上的各种应用程序会发出指令来调用内核的资源，这时候，应用程序就是内核的用户。</p><ul><li>用户态是应用程序运行的模式，当应用程序执行普通的指令时，处于用户态。</li><li>在用户态下，应用程序只能访问自己的内存空间和受限的硬件资源，无法直接访问操作系统的敏感数据或控制计算机的硬件设备。</li><li>用户态提供了一种安全的运行环境，确保应用程序之间相互隔离，防止恶意程序对系统造成影响。</li></ul><h4 id="模式切换"><a href="#模式切换" class="headerlink" title="模式切换"></a>模式切换</h4><p>计算机为了安全性考虑，区分了内核态和用户态，应用程序不能直接调用内核资源，必须要切换到内核态之后，让内核来调用，内核调用完资源，再返回给应用程序，这个时候，系统在切换会用户态，应用程序在用户态下才能处理数据。上述过程其实一次读和一次写都分别发生了两次模式切换。</p><p><img src="/2023/07/26/28zerocopy/3.png"></p><h4 id="内核缓冲区"><a href="#内核缓冲区" class="headerlink" title="内核缓冲区"></a>内核缓冲区</h4><p>内核缓冲区指内存中专门用来给内核直接使用的内存空间。可以把它理解为应用程序和外部存储进行数据交互的一个中间介质。应用程序想要读外部数据，要从这里读。应用程序想要写入外部存储，要通过内核缓冲区。</p><h4 id="用户缓冲区"><a href="#用户缓冲区" class="headerlink" title="用户缓冲区"></a>用户缓冲区</h4><p>用户缓冲区可以理解为应用程序可以直接读写的内存空间。因为应用程序没法直接到内核读写数据， 所以应用程序想要处理数据，必须先通过用户缓冲区。</p><h4 id="磁盘缓冲区"><a href="#磁盘缓冲区" class="headerlink" title="磁盘缓冲区"></a>磁盘缓冲区</h4><p>磁盘缓冲区是计算机内存中用于暂存从磁盘读取的数据或将数据写入磁盘之前的临时存储区域。它是一种优化磁盘 I/O 操作的机制，通过利用内存的快速访问速度，减少对慢速磁盘的频繁访问，提高数据读取和写入的性能和效率。</p><h4 id="PageCache"><a href="#PageCache" class="headerlink" title="PageCache"></a>PageCache</h4><ul><li>PageCache 是 Linux 内核对文件系统进行缓存的一种机制。它使用空闲内存来缓存从文件系统读取的数据块，加速文件的读取和写入操作。</li><li>当应用程序或进程读取文件时，数据会首先从文件系统读取到 PageCache 中。如果之后再次读取相同的数据，就可以直接从 PageCache 中获取，避免了再次访问文件系统。</li><li>同样，当应用程序或进程将数据写入文件时，数据会先暂存到 PageCache 中，然后由 Linux 内核异步地将数据写入磁盘，从而提高写入操作的效率。</li></ul><h4 id="再说数据读写操作流程"><a href="#再说数据读写操作流程" class="headerlink" title="再说数据读写操作流程"></a>再说数据读写操作流程</h4><p>上面弄明白了这几个概念后，再回过头看一下那个流程图，是不是就清楚多了。</p><h5 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h5><ol><li> 首先应用程序向内核发起读请求，这时候进行一次模式切换了，从用户态切换到内核态；</li><li> 内核向外部存储或网络套接字发起读操作；</li><li> 将数据写入磁盘缓冲区；</li><li> 系统内核将数据从磁盘缓冲区拷贝到内核缓冲区，顺便再将一份（或者一部分）拷贝到 PageCache；</li><li> 内核将数据拷贝到用户缓冲区，供应用程序处理。此时又进行一次模态切换，从内核态切换回用户态；</li></ol><h5 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h5><ol><li> 应用程序向内核发起写请求，这时候进行一次模式切换了，从用户态切换到内核态；</li><li> 内核将要写入的数据从用户缓冲区拷贝到 PageCache，同时将数据拷贝到内核缓冲区；</li><li> 然后内核将数据写入到磁盘缓冲区，从而写入磁盘，或者直接写入网络套接字。</li></ol><h2 id="瓶颈在哪里"><a href="#瓶颈在哪里" class="headerlink" title="瓶颈在哪里"></a>瓶颈在哪里</h2><p>但是传统I/O有它的瓶颈，这才是零拷贝技术出现的缘由。瓶颈是啥呢，当然是性能问题，太慢了。尤其是在高并发场景下，I/O性能经常会卡脖子。那是什么地方耗时了呢？</p><h3 id="数据拷贝"><a href="#数据拷贝" class="headerlink" title="数据拷贝"></a>数据拷贝</h3><p>在传统 I/O 中，数据的传输通常涉及多次数据拷贝。数据需要从应用程序的用户缓冲区复制到内核缓冲区，然后再从内核缓冲区复制到设备或网络缓冲区。这些数据拷贝过程导致了多次内存访问和数据复制，消耗了大量的 CPU 时间和内存带宽。</p><h3 id="用户态和内核态的切换"><a href="#用户态和内核态的切换" class="headerlink" title="用户态和内核态的切换"></a>用户态和内核态的切换</h3><p>由于数据要经过内核缓冲区，导致数据在用户态和内核态之间来回切换，切换过程中会有上下文的切换，如此一来，大大增加了处理数据的复杂性和时间开销。每一次操作耗费的时间虽然很小，但是当并发量高了以后，积少成多，也是不小的开销。所以要提高性能、减少开销就要从以上两个问题下手了。这时候，零拷贝技术就出来解决问题了。</p><h2 id="什么是零拷贝"><a href="#什么是零拷贝" class="headerlink" title="什么是零拷贝"></a>什么是零拷贝</h2><p>问题出来数据拷贝和模态切换上。但既然是 I/O 操作，不可能没有数据拷贝的，只能减少拷贝的次数，还有就是尽量将数据存储在离应用程序（用户缓冲区）更近的地方。而区分用户态和内核态有其他更重要的原因，不可能单纯为了 I/O 效率就改变这种设计吧。那也只能尽量减少切换的次数。零拷贝的理想状态就是操作数据不用拷贝，但是显示情况下并不一定真的就是一次复制操作都没有，而是尽量减少拷贝操作的次数。要实现零拷贝，应该从下面这三个方面入手：</p><ol><li> 尽量减少数据在各个存储区域的复制操作，例如从磁盘缓冲区到内核缓冲区等；</li><li> 尽量减少用户态和内核态的切换次数及上下文切换；</li><li> 使用一些优化手段，例如对需要操作的数据先缓存起来，内核中的 PageCache 就是这个作用；</li></ol><h2 id="实现零拷贝方案"><a href="#实现零拷贝方案" class="headerlink" title="实现零拷贝方案"></a>实现零拷贝方案</h2><h3 id="直接内存访问（DMA）"><a href="#直接内存访问（DMA）" class="headerlink" title="直接内存访问（DMA）"></a>直接内存访问（DMA）</h3><p>DMA 是一种硬件特性，允许外设（如网络适配器、磁盘控制器等）直接访问系统内存，而无需通过 CPU 的介入。在数据传输时，DMA 可以直接将数据从内存传输到外设，或者从外设传输数据到内存，避免了数据在用户态和内核态之间的多次拷贝。</p><p><img src="/2023/07/26/28zerocopy/4.png"></p><p>如上图所示，内核将数据读取的大部分数据读取操作都交个了 DMA 控制器，而空出来的资源就可以去处理其他的任务了。</p><h3 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h3><p>一些操作系统（例如 Linux）提供了特殊的系统调用，如 sendfile，在网络传输文件时实现零拷贝。通过 sendfile，应用程序可以直接将文件数据从文件系统传输到网络套接字或者目标文件，而无需经过用户缓冲区和内核缓冲区。如果不用sendfile，如果将A文件写入B文件。</p><ol><li> 需要先将A文件的数据拷贝到内核缓冲区，再从内核缓冲区拷贝到用户缓冲区；</li><li> 然后内核再将用户缓冲区的数据拷贝到内核缓冲区，之后才能写入到B文件；</li></ol><p>而用了sendfile，用户缓冲区和内核缓冲区的拷贝都不用了，节省了一大部分的开销。</p><h3 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h3><p>使用共享内存技术，应用程序和内核可以共享同一块内存区域，避免在用户态和内核态之间进行数据拷贝。应用程序可以直接将数据写入共享内存，然后内核可以直接从共享内存中读取数据进行传输，或者反之。</p><p><img src="/2023/07/26/28zerocopy/5.png"></p><p>通过共享一块儿内存区域，实现数据的共享。就像程序中的引用对象一样，实际上就是一个指针、一个地址。</p><h3 id="内存映射文件（Memory-mapped-Files）"><a href="#内存映射文件（Memory-mapped-Files）" class="headerlink" title="内存映射文件（Memory-mapped Files）"></a>内存映射文件（Memory-mapped Files）</h3><p>内存映射文件直接将磁盘文件映射到应用程序的地址空间，使得应用程序可以直接在内存中读取和写入文件数据，这样一来，对映射内容的修改就是直接的反应到实际的文件中。当文件数据需要传输时，内核可以直接从内存映射区域读取数据进行传输，避免了数据在用户态和内核态之间的额外拷贝。虽然看上去感觉和共享内存没什么差别，但是两者的实现方式完全不同，一个是共享地址，一个是映射文件内容。</p><h2 id="Java-实现零拷贝的方式"><a href="#Java-实现零拷贝的方式" class="headerlink" title="Java 实现零拷贝的方式"></a>Java 实现零拷贝的方式</h2><p>Java 标准的 IO 库是没有零拷贝方式的实现的，标准IO就相当于上面所说的传统模式。只是在 Java 推出的 NIO 中，才包含了一套新的 I/O 类，如 <code>ByteBuffer</code> 和 <code>Channel</code>，它们可以在一定程度上实现零拷贝。<code>ByteBuffer</code>：可以直接操作字节数据，避免了数据在用户态和内核态之间的复制。<code>Channel</code>：支持直接将数据从文件通道或网络通道传输到另一个通道，实现文件和网络的零拷贝传输。借助这两种对象，结合 NIO 中的API，我们就能在 Java 中实现零拷贝了。首先我们先用传统 IO 写一个方法，用来和后面的 NIO 作对比，这个程序的目的很简单，就是将一个100M左右的PDF文件从一个目录拷贝到另一个目录。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">ioCopy</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">try</span> &#123;  </span><br><span class="line">    File sourceFile = <span class="keyword">new</span> File(SOURCE_FILE_PATH);  </span><br><span class="line">    File targetFile = <span class="keyword">new</span> File(TARGET_FILE_PATH);  </span><br><span class="line">    <span class="keyword">try</span> (FileInputStream fis = <span class="keyword">new</span> FileInputStream(sourceFile);  </span><br><span class="line">         FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(targetFile)) &#123;  </span><br><span class="line">      <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];  </span><br><span class="line">      <span class="keyword">int</span> bytesRead;  </span><br><span class="line">      <span class="keyword">while</span> ((bytesRead = fis.read(buffer)) != -<span class="number">1</span>) &#123;  </span><br><span class="line">        fos.write(buffer, <span class="number">0</span>, bytesRead);  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    System.out.println(<span class="string">&quot;传输 &quot;</span> + formatFileSize(sourceFile.length()) + <span class="string">&quot; 字节到目标文件&quot;</span>);  </span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;  </span><br><span class="line">    e.printStackTrace();  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure><p>下面是这个拷贝程序的执行结果，109.92M，耗时1.29秒。</p><blockquote><p>“传输 109.92 M 字节到目标文件 耗时: 1.290 秒”</p></blockquote><h3 id="FileChannel-transferTo-和-transferFrom"><a href="#FileChannel-transferTo-和-transferFrom" class="headerlink" title="FileChannel.transferTo() 和 transferFrom()"></a>FileChannel.transferTo() 和 transferFrom()</h3><p>FileChannel 是一个用于文件读写、映射和操作的通道，同时它在并发环境下是线程安全的，基于 FileInputStream、FileOutputStream 或者 RandomAccessFile 的 getChannel() 方法可以创建并打开一个文件通道。FileChannel 定义了 transferFrom() 和 transferTo() 两个抽象方法，它通过在通道和通道之间建立连接实现数据传输的。这两个方法首选用 sendfile 方式，只要当前操作系统支持，就用 sendfile，例如Linux或MacOS。如果系统不支持，例如windows，则采用内存映射文件的方式实现。</p><h4 id="transferTo"><a href="#transferTo" class="headerlink" title="transferTo()"></a>transferTo()</h4><p>下面是一个 transferTo 的例子，仍然是拷贝那个100M左右的 PDF，我的系统是 MacOS。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">nioTransferTo</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">try</span> &#123;  </span><br><span class="line">    File sourceFile = <span class="keyword">new</span> File(SOURCE_FILE_PATH);  </span><br><span class="line">    File targetFile = <span class="keyword">new</span> File(TARGET_FILE_PATH);  </span><br><span class="line">    <span class="keyword">try</span> (FileChannel sourceChannel = <span class="keyword">new</span> RandomAccessFile(sourceFile, <span class="string">&quot;r&quot;</span>).getChannel();  </span><br><span class="line">         FileChannel targetChannel = <span class="keyword">new</span> RandomAccessFile(targetFile, <span class="string">&quot;rw&quot;</span>).getChannel()) &#123;  </span><br><span class="line">      <span class="keyword">long</span> transferredBytes = sourceChannel.transferTo(<span class="number">0</span>, sourceChannel.size(), targetChannel);  </span><br><span class="line">  </span><br><span class="line">      System.out.println(<span class="string">&quot;传输 &quot;</span> + formatFileSize(transferredBytes) + <span class="string">&quot; 字节到目标文件&quot;</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;  </span><br><span class="line">    e.printStackTrace();  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure><p>只耗时0.536秒，快了一倍。</p><blockquote><p>“传输 109.92 M 字节到目标文件 耗时: 0.536 秒”</p></blockquote><h4 id="transferFrom"><a href="#transferFrom" class="headerlink" title="transferFrom()"></a>transferFrom()</h4><p>下面是一个 transferFrom 的例子，仍然是拷贝那个100M左右的 PDF，我的系统是 MacOS。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">nioTransferFrom</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">try</span> &#123;  </span><br><span class="line">    File sourceFile = <span class="keyword">new</span> File(SOURCE_FILE_PATH);  </span><br><span class="line">    File targetFile = <span class="keyword">new</span> File(TARGET_FILE_PATH);  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">try</span> (FileChannel sourceChannel = <span class="keyword">new</span> RandomAccessFile(sourceFile, <span class="string">&quot;r&quot;</span>).getChannel();  </span><br><span class="line">         FileChannel targetChannel = <span class="keyword">new</span> RandomAccessFile(targetFile, <span class="string">&quot;rw&quot;</span>).getChannel()) &#123;  </span><br><span class="line">      <span class="keyword">long</span> transferredBytes = targetChannel.transferFrom(sourceChannel, <span class="number">0</span>, sourceChannel.size());  </span><br><span class="line">      System.out.println(<span class="string">&quot;传输 &quot;</span> + formatFileSize(transferredBytes) + <span class="string">&quot; 字节到目标文件&quot;</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;  </span><br><span class="line">    e.printStackTrace();  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure><p>执行时间：</p><blockquote><p>“传输 109.92 M 字节到目标文件 耗时: 0.603 秒”</p></blockquote><h3 id="Memory-Mapped-Files"><a href="#Memory-Mapped-Files" class="headerlink" title="Memory-Mapped Files"></a>Memory-Mapped Files</h3><p>Java 的 NIO 也支持内存映射文件（Memory-mapped Files），通过 <code>FileChannel.map()</code> 实现。下面是一个 <code>FileChannel.map()</code>的例子，仍然是拷贝那个100M左右的 PDF，我的系统是 MacOS。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">nioMap</span><span class="params">()</span></span>&#123;  </span><br><span class="line">        <span class="keyword">try</span> &#123;  </span><br><span class="line">            File sourceFile = <span class="keyword">new</span> File(SOURCE_FILE_PATH);  </span><br><span class="line">            File targetFile = <span class="keyword">new</span> File(TARGET_FILE_PATH);  </span><br><span class="line">  </span><br><span class="line">            <span class="keyword">try</span> (FileChannel sourceChannel = <span class="keyword">new</span> RandomAccessFile(sourceFile, <span class="string">&quot;r&quot;</span>).getChannel();  </span><br><span class="line">                 FileChannel targetChannel = <span class="keyword">new</span> RandomAccessFile(targetFile, <span class="string">&quot;rw&quot;</span>).getChannel()) &#123;  </span><br><span class="line">                <span class="keyword">long</span> fileSize = sourceChannel.size();  </span><br><span class="line">                MappedByteBuffer buffer = sourceChannel.map(FileChannel.MapMode.READ_ONLY, <span class="number">0</span>, fileSize);  </span><br><span class="line">                targetChannel.write(buffer);  </span><br><span class="line">                System.out.println(<span class="string">&quot;传输 &quot;</span> + formatFileSize(fileSize) + <span class="string">&quot; 字节到目标文件&quot;</span>);  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;  </span><br><span class="line">            e.printStackTrace();  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br></pre></td></tr></table></figure><p>执行时间：</p><blockquote><p>“传输 109.92 M 字节到目标文件 耗时: 0.663 秒”</p></blockquote><p>原文： <a href="https://mp.weixin.qq.com/s/ULVCvSLIGvj3VtY5prtxGw">https://mp.weixin.qq.com/s/ULVCvSLIGvj3VtY5prtxGw</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我们总会在各种地方看到零拷贝，那零拷贝到底是个什么东西。接下来，让我们来理一理啊。拷贝说的是计算机里的 I/O 操作，也就是数据的读写操作。计算机可是一个复杂的家伙，包括软件和硬件两大部分，软件主要指操作系统、驱动程序和应用程序。硬件那就多了，CPU、内存、硬盘等等一大堆东</summary>
      
    
    
    
    <category term="JAVA" scheme="http://yaocl.cn/categories/JAVA/"/>
    
    
    <category term="JAVA" scheme="http://yaocl.cn/tags/JAVA/"/>
    
    <category term="计算机" scheme="http://yaocl.cn/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>跨越性能瓶颈：Layer2技术为区块链解决可扩展性问题</title>
    <link href="http://yaocl.cn/2023/06/06/30layer2/"/>
    <id>http://yaocl.cn/2023/06/06/30layer2/</id>
    <published>2023-06-06T08:37:29.000Z</published>
    <updated>2025-01-09T08:10:53.700Z</updated>
    
    <content type="html"><![CDATA[<p>区块链有个著名的”不可能三角”问题，即一条区块链的发展很难兼顾安全、去中心化和可拓展性。</p><p><img src="/2023/06/06/30layer2/1.png"></p><p>以太坊举例，虽然在去中心化和安全方面做的已经足够好，但随着用户越来越多，其交易速度变慢、交易手续费高、用户体验恶化是一直以来有待解决的问题。尤其是在 17 年出现了一款非常火爆的 Dapp 应用叫加密猫，造成以太坊主网大规模的拥堵。造成拥堵的原因是以太坊当时的 TPS 只有 15，这意味着以太坊每秒只能处理 15 笔交易，如此低的 TPS 严重限制了区块链应用的大规模落地。</p><p>想提升公链的可扩展性，有两种方式：</p><p>1、链上扩容：</p><p>扩展主网本身（Layer 1）称为链上扩容方案。主要通过提高区块链本身的交易容量来实现扩容。比如早期对比特币进行区块大小调整，隔离见证的引入，以太坊 2.0 的转 POS 和分片机制。但是 Layer 1 的扩容要么进展缓慢，要么对性能的提升没有质的变化。</p><p>2、链下扩容：</p><p>链下扩容是在底层区块链 Layer 1 上构建一个扩展层 Layer 2，通过将一部分交易或计算迁移到区块链外的第二层网络来提高可扩展性和效率。  Layer1 来保证安全和去中心化，绝对可靠、可信；它能做到全球共识，并作为“加密法院”，通过智能合约设计的规则进行仲裁，以经济激励的形式将信任传递到 Layer2 上，而 Layer2 追求极致的性能，它只能做到局部共识，但是能够满足各类商业场景的需求。</p><p><img src="/2023/06/06/30layer2/2.png"></p><h2 id="常见的区块链-Layer-2-技术方案"><a href="#常见的区块链-Layer-2-技术方案" class="headerlink" title="常见的区块链 Layer 2 技术方案"></a>常见的区块链 Layer 2 技术方案</h2><h3 id="状态通道（State-Channels）"><a href="#状态通道（State-Channels）" class="headerlink" title="状态通道（State Channels）"></a>状态通道（State Channels）</h3><p>状态通道是一种基于区块链的链下交易方案，通过在链上锁定资金，交易双方在链下构建一个通道，实现链下的快速交易。其原理是将交易数据限制在链下的通道内，并只在必要时将最终结果提交到主链上。状态通道可以极大地提高交易吞吐量，并降低交易成本。</p><p>其实可以把状态通道理解成一个执行特殊操作的智能合约，一个专门建立双向通道，在一定条件下进行<code>状态保持</code>的智能合约。可以将状态通道中的执行过程作为<code>原子操作</code>，在执行完成这个原子操作后，将最终结果上链。</p><p><img src="/2023/06/06/30layer2/3.png"></p><p>比如建立价值为 100 美元的支付通道，首先进行资金锁定，一旦锁定完成，交易者双方可互相发送状态更新来实现转账，无需与主链进行交互，只要双方的余额都还为正值即可。一旦有一方想要停止使用支付通道，可以执行 “退出” 操作，将最后的状态更新提交至主链，结算下来的余额会退给发起支付通道的两方。主链可以通过核实签名和最后结余来验证状态更新的有效性，从而防止交易双方使用无效状态来退出支付通道,保证退出机制的安全性。</p><p>状态通道存在一些缺点：</p><ol><li>“退出” 模式存在一个问题，即主链无法验证支付通道是否提交了全部交易，也就是说，在提交了状态更新之后是否不再出现新的状态更新。</li><li>状态通道的第二个缺点就是低资金利用率。由于资金流动性无法扩容，当众多资金锁在一个状态通道里，只能用状态通道转发的话，这个效率是非常低下。</li></ol><p>应用代表：</p><ul><li>比特币中的闪电网络</li><li>以太坊中的的 Raiden Network。</li></ul><h3 id="侧链（Sidechains）"><a href="#侧链（Sidechains）" class="headerlink" title="侧链（Sidechains）"></a>侧链（Sidechains）</h3><p>侧链是一种独立于主链的区块链网络，通过与主链进行资产锁定和解锁的方式实现与主链的互操作性。它们通过“双向锚定” （Two-Way Pegging）来建立关联，实现主链与侧链之间价值的双向转移。侧链的思路可以简单的理解为在主链锁定资产，在侧链派生相应资产；当资产在侧链完成应用后要转回主链时，从侧链销毁资产，并在主链解锁。侧链可以承载大量的交易，并在需要时将交易结果提交到主链上。</p><p><img src="/2023/06/06/30layer2/4.png"></p><p>优点：</p><ul><li>不受主链 TPS 限制</li><li>侧链合约运行的手续费大大降低，对小金额玩家以及新玩家较友好</li></ul><p>缺点：</p><ul><li>中心化威胁：通过第三方公证人或中继者进行验证，牺牲了部分去中心化特性</li></ul><p>项目代表：</p><ul><li>Injective Protocol（注射协议）：首个 Layer 2 的衍生品 dex</li><li>Rootstock（RSK）（砧木）：第一条比特币侧链</li></ul><h3 id="等离子体（Plasma）"><a href="#等离子体（Plasma）" class="headerlink" title="等离子体（Plasma）"></a>等离子体（Plasma）</h3><p>Plasma 曾是 Vitalik 认为大有可为的一个解决方案，由 Vitalik Buterin 和 Joseph Poon 在 2017 年共同提出。可以将 Plasma 视为以太坊的原生侧链，使用智能合约和 Merkle 树的组合来创建无限的子链分支。这些子链是以太坊主链的较小副本，具有自己的共识机制。</p><p>Plasma 是一种设计模式，它允许链外消息驱动链上资产的转移。它通过将交易吞吐量转移到 Plasma 链来实现对根链的扩展。</p><p>Plasma 在一个树形结构上组装区块链。最底层的是根区块链，根区块链之上是第一级子链——Plasma 链。在第一级链上，可进一步分支出二级和三级 Plasma 链。上一级 Plasma 链称为下一级链的<code>父链</code>。</p><p>区块的承诺流向下，出口能被提交给任何父链，最终在根链上被执行。理解为子链的交易、状态等运算可以向下层层递交，最终在根链上落定和执行。</p><p><img src="/2023/06/06/30layer2/5.png"></p><p>优点：</p><ul><li>相对安全：即使链下环境崩塌，也能从主链上提取交易结果</li><li>操作快、交易费用低：因为与主链的交互较少</li></ul><p>缺点：</p><ul><li>不具备主链的数据可用性：给 Layer 1 返回的仅有交易结果的证明、没有详细的交易信息，主链无法还原交易</li><li>退出期长：用户需要从主链上提取资金，需要等待挑战期过去。</li><li>拓展困难：技术框架限定了子链的数据结构</li></ul><p>项目代表：</p><ul><li>Loom Network：第一个 Plasma 产品实现</li><li>Polygon</li></ul><h3 id="聚合链（Rollups）"><a href="#聚合链（Rollups）" class="headerlink" title="聚合链（Rollups）"></a>聚合链（Rollups）</h3><p>Rollups 是一种将大量交易聚合到单个链上进行处理的技术方案，其本质是将原本分布在区块中的大量交易数据，<code>打包成一笔集合的交易</code>，发布到链上。Roll Up 实际上是一条侧链，因此它会生成区块，并且将这些区块的快照发送到主链上。不过，Roll Up 上的运营者是无需信任的。也就是说，Roll Up 假定运营者可以在任何时候做出停止出块、生成无效块、隐瞒数据等恶意行为。</p><p>主流的 Rollup 技术可以分为两类：ZkRollup 和 Optimistic Rollup。</p><p><em><strong>ZkRollup</strong></em>：基于<a href="https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==&mid=2247484540&idx=1&sn=af2d2f3711b712952b8e4bb8278ff41f&chksm=fcafc1fecbd848e8673bd61edd693ad60f2bbd6334915e825d95551987b5df872cc4437edadb#rd">零知识证明</a>的 Layer2 扩容方案，采用有效性验证方法(VP)，默认所有交易都是不诚实的，只有通过有效性验证才会被接受。ZkRollup 在链下进行复杂的计算和证明的生成，链上进行证明的校验并存储部分数据保证数据可用性。</p><p>优点：</p><ul><li>安全性：牺牲了等待时间来换取较好的安全性</li><li>上链效率高：将多笔交易打包操作，节约时间和 gas fee</li></ul><p>缺点：</p><ul><li>验证效率低：较长的等待期，任何交易在等待期不会被确认，也无法从主链提取资金</li><li>交易压缩率相对较低</li></ul><p>项目代表：</p><ul><li>路印</li><li>ZKSync：旨在为以太坊带来 Visa 级别、每秒数千笔交易的吞吐量</li></ul><p><em><strong>Optimistic Rollup</strong></em>：采用的是欺诈性证明（Fraud Proof），它趋于相信操作者提交的数据都是真实的（乐观假设，大家都是好人）。但保险起见，需要操作者质押一定资产作为保证金，且在上链前留出两周的挑战期，任何人都可以在此期间挑战其真实性并发布欺诈证明，一旦挑战成功，质押金将会被没收，挑战者会获得奖励，且回滚交易细节。因此，从概率角度防止作恶行为。</p><p>优点：</p><ul><li>高度的去中心化</li><li>隐私性好：零知识证明不会透露任何交易细节</li><li>上链效率高：一次性提交多笔操作的结果，节约时间和 gas fee</li><li>验证效率高：无需等待期，快速完成资产取出动作</li><li>安全性极高：zk 技术保证了提交给主链的数据真实有效，同时主链可随时还原侧链发生的交易细节（即拥有主链的数据可用性），因此拥有以太坊级别的安全性</li></ul><p>缺点：</p><ul><li>技术开发难度大</li><li>难兼容不同智能合约</li><li>需要大量运算</li></ul><p>项目代表：</p><ul><li>Fuel：Optimistic Rollup（乐观汇总）概念提出者所在团队研发</li><li>Synthetix：DeFi 巨头的 Layer2 扩容选择</li></ul><h2 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h2><p>经过数年发展，Layer 2 扩容诞生了很多方案，在以太坊发展早期，以太坊创始人 V 神都曾认为侧链、Plasma 技术是解决区块链扩容问题的最佳方案。但时间和实践都证明，在 DeFi 大爆发的背景下，侧链、状态通道、Plasma 等 Layer 2 扩容方案都无法满足市场的要求，发展到现在，Rollup 成为了目前最有希望的方案。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;区块链有个著名的”不可能三角”问题，即一条区块链的发展很难兼顾安全、去中心化和可拓展性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2023/06/06/30layer2/1.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;以太坊举例，虽然在去中心化和安全方面做的已经足够好，但随着用户越来越多，其交易</summary>
      
    
    
    
    <category term="区块链" scheme="http://yaocl.cn/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    
    <category term="区块链" scheme="http://yaocl.cn/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    <category term="layer2" scheme="http://yaocl.cn/tags/layer2/"/>
    
  </entry>
  
  <entry>
    <title>MVCC如何应对MySQL并发问题</title>
    <link href="http://yaocl.cn/2023/05/28/29mvcc/"/>
    <id>http://yaocl.cn/2023/05/28/29mvcc/</id>
    <published>2023-05-28T11:43:33.000Z</published>
    <updated>2023-08-07T01:22:28.555Z</updated>
    
    <content type="html"><![CDATA[<p>数据库使用事务来保持数据最终一致性，但是在并发下执行事务，会引起脏读、不可重复读、幻读等问题。为了解决这些问题，设计了四种隔离级别：</p><ul><li>读未提交(Read uncommitted)</li><li>读已提交(Read committed)</li><li>可重复读(Repeatable read)</li><li>串行化(Serializable)</li></ul><p><img src="/2023/05/28/29mvcc/1.png"></p><p>不同的隔离级别，解决了不一样的并发问题，那么不同的隔离级别是怎么解决并发问题的呢？ 一个比较简单粗暴的方法是加锁，但是加锁必然会带来性能的降低。因此，数据库又引入了 MVCC（多版本并发控制）和锁配合使用，在读取数据不用加锁的情况下，实现读取数据的同时可以修改数据，修改数据时同时可以读取数据。</p><h2 id="什么是-MVCC"><a href="#什么是-MVCC" class="headerlink" title="什么是 MVCC"></a>什么是 MVCC</h2><blockquote><p>MVCC，全称 Multi-Version Concurrency Control，即多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。</p></blockquote><h3 id="数据库并发场景："><a href="#数据库并发场景：" class="headerlink" title="数据库并发场景："></a>数据库并发场景：</h3><ul><li>读-读：不存在任何问题，不需要并发控制。</li><li>读-写：有线程安全问题，可能会造成事务隔离性问题，可能会有脏读，幻读，不可重复读。</li><li>写-写：有线程安全问题，可能会存在更新丢失问题。</li></ul><p>MVCC 通过维护一个数据的多个版本，用来解决<code>读-写</code>冲突的无锁并发控制，可以解决以下问题：</p><ul><li><p>在并发读写数据时，可以做到在读操作时不用阻塞写操作，写操作不用阻塞读操作，提高数据库并发读写的性能。</p></li><li><p>可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决<code>写-写</code>引起的更新丢失问题。</p></li></ul><p>MVCC 只在读已提交(Read Committed )和可重复读(Repeatable Read) 两个隔离级别下起作用，因为读未提交(Read UnCommitted) 隔离级别下，读写都不加锁，串行化（Serializable） 隔离级别下，读写都加锁，也就不需要 MVCC 了。</p><p>MVCC 没有正式的标准，在不同的 DBMS 中 MVCC 的实现方式可能是不同的。本文讲解 InnoDB 中 MVCC 的实现机制（MySQL 其它的存储引擎并不支持它）。</p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><h3 id="隐式字段"><a href="#隐式字段" class="headerlink" title="隐式字段"></a>隐式字段</h3><p>在 InnoDB 存储引擎，针对每行记录都有固定的隐藏列：</p><ul><li>DB_ROW_ID</li></ul><p>6-byte，隐含的自增 ID（隐藏主键），如果表中没有主键和非 NULL 唯一键时，则会生成一个单调递增的行 ID 作为聚簇索引。</p><ul><li>DB_TRX_ID</li></ul><p>6-byte，操作这个数据的事务 ID，事务开启之前，从数据库获得一个自增长的事务 ID，用其判断事务的执行顺序。</p><ul><li>DB_ROLL_PTR</li></ul><p>7-byte，回滚指针，也就是指向这个记录的 Undo Log 信息。</p><p><img src="/2023/05/28/29mvcc/2.png"></p><blockquote><p>其实还有一个删除的 flag 字段，用来判断该行记录是否已经被删除。</p></blockquote><h3 id="Undo-Log-版本链"><a href="#Undo-Log-版本链" class="headerlink" title="Undo Log 版本链"></a>Undo Log 版本链</h3><p>InnoDB 把那些为了回滚而记录的东西称之为 Undo Log。在事务开始之前，会先将记录存放到 Undo Log 文件里备份起来，当事务回滚时或者数据库崩溃时用于回滚事务。</p><p>Undo Log 日志分为两种：</p><ul><li>insert undo log：</li></ul><p>事务在插入新记录产生的 Undo Log，当事务提交之后可以直接删除。</p><ul><li>update undo log：</li></ul><p>事务在进行 update 或者 delete 的时候产生的 Undo Log。不仅在事务回滚时需要，在快照读的时候还是需要的，所以不能直接删除，只有当系统没有比这个 log 更早的 Read View 了的时候才能删除。ps：所以长事务会产生很多老的视图导致 undo log 无法删除 大量占用存储空间。</p><p>MVCC 实际上是使用的<code>update undo log</code>。</p><p>每次更新记录时，旧值都会放入<code>Undo Log</code>中，形成该记录的旧版本，随着更新次数的增加，所有版本通过回滚指针（DB_ROLL_PTR）链接成一条链，我们称之为版本链。版本链的头节点是当前记录的最新值。</p><p><img src="/2023/05/28/29mvcc/3.png"></p><h3 id="当前读和快照读"><a href="#当前读和快照读" class="headerlink" title="当前读和快照读"></a>当前读和快照读</h3><ul><li>当前读</li></ul><p>读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。像下面这些语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span>  LOCK <span class="keyword">IN</span> SHARE MODE;  # 共享锁</span><br><span class="line"><span class="keyword">SELECT</span>  <span class="keyword">FOR</span> UPDATE; # 排他锁</span><br><span class="line"><span class="keyword">INSERT</span>   # 排他锁</span><br><span class="line"><span class="keyword">DELETE</span>  # 排他锁</span><br><span class="line">UPDATE   # 排他锁</span><br></pre></td></tr></table></figure><ul><li>快照读</li></ul><p>读取的是记录数据的可见版本，不加锁，不加锁的普通 <code>select</code> 语句都是快照读，即不加锁的非阻塞读。快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读。</p><p>快照读的执行方式是生成 ReadView，直接利用 MVCC 机制来进行读取，并不会对记录进行加锁。</p><h3 id="Read-View"><a href="#Read-View" class="headerlink" title="Read View"></a>Read View</h3><p>Read View 就是事务进行<code>快照读</code>操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的 ID(当每个事务开启时，都会被分配一个 ID, 这个 ID 是递增的，所以最新的事务，ID 值越大).</p><p>Read View 相当于某个时刻表记录的一个快照，在这个快照中我们能获取到与当前记录相关的事务中，哪些事务是已提交的稳定事务，哪些是正在活跃的事务，哪些是生成快照之后才开启的事务。</p><p>Read View 中有四个属性(基于 Mysql 5.7)</p><ul><li>creator_trx_id</li></ul><p>创建当前 Read View 的事务 ID</p><ul><li>m_ids</li></ul><p>当前系统中所有的活跃事务的 id，活跃事务指的是当前系统中开启了事务，但还没有提交的事务;</p><ul><li>m_low_limit_id</li></ul><p>表示在生成 Read View 时，当前系统中活跃的读写事务中最小的事务 id，即 m_ids 中的最小值。</p><ul><li>m_up_limit_id</li></ul><p>当前系统中事务的 id 值最大的那个事务 id 值再加 1，也就是系统中下一个要生成的事务 id。</p><p><code>Read View 会根据这 4 个属性，结合 undo log 版本链，来实现 MVCC 机制，决定一个事务能读取到那个版本的数据。</code></p><h2 id="实现过程–可见性比较算法"><a href="#实现过程–可见性比较算法" class="headerlink" title="实现过程–可见性比较算法"></a>实现过程–可见性比较算法</h2><p>当一个事务读取某条数据时，Read View 是如何判断版本链中的哪个版本是可用的呢？ 通过数据中的隐藏字段<code>DB_TRX_ID</code>进行可见性规则判断，如下：</p><p><img src="/2023/05/28/29mvcc/4.png"></p><p>① 当 <code>DB_TRX_ID &lt; m_low_limit_id</code>：</p><p>表示 DB_TRX_ID 对应这条数据是在当前事务【creator_trx_id】开启之前，其他的事务就已经将该条数据修改了并提交了事务，所以当前事务（开启 Read View 的事务）能读取到。</p><p>② 当 <code>DB_TRX_ID &gt;= m_up_limit_id</code>：</p><p>表示在当前事务【creator_trx_id】开启以后，有新的事务开启，并且新的事务修改了这行数据的值并提交了事务，因为这是【creator_trx_id】后面的事务修改提交的数据，所以当前事务是不能读取到的。</p><p>③ 当 <code>m_low_limit_id =&lt; DB_TRX_ID &lt; m_up_limit_id</code>：</p><p>1、如果 DB_TRX_ID 在 m_ids 数组中</p><ul><li><p><code>DB_TRX_ID 等于 creator_trx_id</code></p><p>表明数据是自己生成的，因此是可见的</p></li><li><p><code>DB_TRX_ID 不等于 creator_trx_id</code></p><p>DB_TRX_ID 事务修改了数据的值，并提交了事务，所以当前事务【creator_trx_id】不能读取到。</p></li></ul><p>2、如果 DB_TRX_ID 不在 m_ids 数组中</p><p>表示的是在当前事务【creator_trx_id】开启之前，其他事务【DB_TRX_ID】将数据修改后就已经提交了事务，所以当前事务能读取到。</p><h2 id="案例说明"><a href="#案例说明" class="headerlink" title="案例说明"></a>案例说明</h2><p>我们先准备一条数据</p><p><img src="/2023/05/28/29mvcc/5.png"></p><p>现在有两个事务同时执行， 事务 A 的<code>DB_TRX_ID=2</code>，事务 B 的<code>DB_TRX_ID=3</code>。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#事务A：</span><br><span class="line"><span class="keyword">select</span> name <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line">#事务B：</span><br><span class="line">update <span class="keyword">table</span> <span class="keyword">set</span> name <span class="operator">=</span> <span class="string">&#x27;Go&#x27;</span> <span class="keyword">where</span> id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>事物开始后分别生成 ReadView</p><p>事务 A 的 ReadView :</p><blockquote><p>m_ids=[2,3]，<br>m_low_limit_id=2，<br>m_up_limit_id=4，<br>creator_trx_id=2。</p></blockquote><p>事务 B 的 ReadView ：</p><blockquote><p>m_ids=[2,3]，<br>m_low_limit_id=2，<br>m_up_limit_id=4，<br>creator_trx_id=3。</p></blockquote><p>1、当事务 A 去查询时，发现数据的<code>DB_TRX_ID=1</code>，小于<code>m_low_limit_id</code>，说明这条数据是事物 A 开启之前就已经写入，并提交了事物，所以事物 A 可以读取到。</p><p>2、 事务 B 去更新数据，修改后写入 Undo Log 日志，此时还<code>没有提交事务B</code>。示意图如下：<br><img src="/2023/05/28/29mvcc/6.png"></p><p>3、此时事务 A 再去查询数据，发现数据<code>DB_TRX_ID=3</code>，并且在 m_ids 里，但是不等与<code>creator_trx_id</code>，说明这个版本的数据是和自己同一时刻启动的事务修改的，因此这个版本的数据，事务 A 读取不到。</p><p>此时需要沿着 undo log 的版本链向前找，接着会找到该行数据的上一个版本<code>DB_TRX_ID=1</code>，由于 DB_TRX_ID=1 小于 m_low_limit_id 的值，因此事务 A 能读取到该版本的值，</p><p>4、此时事务 B 提交事务，系统中活跃的事务只有事物 A，事物 A 第三次读取，读取到内容就有两种可能性：</p><ul><li>读已提交（RC）隔离级别：读取到是事物 B 提交的数据。</li><li>可重复读（RR）隔离级别：读取到是原始数据。</li></ul><h3 id="读已提交（RC）MVCC-实现"><a href="#读已提交（RC）MVCC-实现" class="headerlink" title="读已提交（RC）MVCC 实现"></a>读已提交（RC）MVCC 实现</h3><p>在读已提交(Read committed)的隔离级别下实现 MVCC，同一个事务里面，每一次查询都会产生一个<code>新的 Read View 副本</code>，这样可能造成同一个事务里前后读取数据可能不一致的问题（不可重复读并发问题）。</p><p>在事务 A 第一次读的时候生成的 Read View：</p><blockquote><p><code>m_ids=[2,3]</code>，<br>m_low_limit_id=2，<br>m_up_limit_id=4，<br>creator_trx_id=2。</p></blockquote><p>此时数据没有修改，<code>DB_TRX_ID=1</code>,小于 m_low_limit_id，事务 A 可以读取到数据。</p><p>当事务 B 提交后，事务 A 再去读时，又生成新的 Read View：</p><blockquote><p><code>m_ids=[2]</code>，<br>m_low_limit_id=2，<br>m_up_limit_id=4，<br>creator_trx_id=2。</p></blockquote><p>此时数据已经被修改，<code>DB_TRX_ID=3</code>，满足<code>m_low_limit_id =&lt; DB_TRX_ID &lt; m_up_limit_id</code>，DB_TRX_ID 不在 m_ids 数组中的情况，所以事务 A 可以读取到。</p><h3 id="可重复读（RR）MVCC-实现"><a href="#可重复读（RR）MVCC-实现" class="headerlink" title="可重复读（RR）MVCC 实现"></a>可重复读（RR）MVCC 实现</h3><p>在可重复读(Repeatable read)的隔离级别下实现 MVCC，同一个事务里面，多次查询，都<code>只会产生一个共用Read View</code>，从而保证每次查询的数据都是一样的。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="https://www.modb.pro/db/397162">https://www.modb.pro/db/397162</a></li><li><a href="https://heapdump.cn/article/4465449">https://heapdump.cn/article/4465449</a></li><li><a href="https://github.com/lifei6671/interview-go/blob/master/mysql/mysql-mvcc.md">https://github.com/lifei6671/interview-go/blob/master/mysql/mysql-mvcc.md</a></li><li><a href="https://www.6hu.cc/archives/86666.html">https://www.6hu.cc/archives/86666.html</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;数据库使用事务来保持数据最终一致性，但是在并发下执行事务，会引起脏读、不可重复读、幻读等问题。为了解决这些问题，设计了四种隔离级别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读未提交(Read uncommitted)&lt;/li&gt;
&lt;li&gt;读已提交(Read committed)&lt;/li&gt;</summary>
      
    
    
    
    <category term="MySql" scheme="http://yaocl.cn/categories/MySql/"/>
    
    
    <category term="MySql" scheme="http://yaocl.cn/tags/MySql/"/>
    
  </entry>
  
  <entry>
    <title>以太坊概述</title>
    <link href="http://yaocl.cn/2023/04/27/27Ethereum/"/>
    <id>http://yaocl.cn/2023/04/27/27Ethereum/</id>
    <published>2023-04-27T05:31:22.000Z</published>
    <updated>2023-08-07T01:22:28.482Z</updated>
    
    <content type="html"><![CDATA[<h1 id="以太坊基础知识"><a href="#以太坊基础知识" class="headerlink" title="以太坊基础知识"></a>以太坊基础知识</h1><h2 id="什么是以太坊"><a href="#什么是以太坊" class="headerlink" title="什么是以太坊"></a>什么是以太坊</h2><p>以太坊（Ethereum）是一个去中心化的开源的有智能合约功能的公共区块链平台。 以太坊的概念首次在 2013 至 2014 年间由程序员维塔利克·布特林（Vitalik Buterin）受比特币启发后提出，大意为“下一代加密货币与去中心化应用平台”，在 2014 年通过 ICO 众筹得以开始发展。以太坊亦被称为“第二代的区块链平台”，仅次于比特币。目前为止，以太坊是被使用最多的区块链平台。</p><p><img src="/2023/04/27/27Ethereum/1.png"></p><p>以太币（ETH 或 Ξ）是以太坊的原生加密货币，目前是市值第二高的加密货币，仅次于比特币。</p><h2 id="以太坊特点"><a href="#以太坊特点" class="headerlink" title="以太坊特点"></a>以太坊特点</h2><ol><li> 以太坊是 “世界计算机”，这代表它是一个开源的、全球分布的计算基础设施。</li><li> 执行称为智能合约（smart contract）的程序。</li><li> 使用区块链来同步和存储系统状态以及使用名为以太币（ether）的加密货币，以计量和约束执行资源成本。</li><li> 本质是一个基于交易的状态机 (transaction-based state machine)。</li><li> 以太坊平台使开发人员能够构建具有内置经济功能的强大去中心化应用程序（DApp）；在持续自我正常运行的同时，它还减少或消除了审查，第三方界面和交易对手风险。</li></ol><h2 id="以太坊的组成部分"><a href="#以太坊的组成部分" class="headerlink" title="以太坊的组成部分"></a>以太坊的组成部分</h2><p><img src="/2023/04/27/27Ethereum/2.png"></p><h3 id="P2P-网络"><a href="#P2P-网络" class="headerlink" title="P2P 网络"></a>P2P 网络</h3><p>以太坊在以太坊主网络上运行，该网络可在 TCP 端口 30303 上寻址，并运行一个名为 ÐΞVp2p 的协议。</p><h3 id="交易（Transaction）"><a href="#交易（Transaction）" class="headerlink" title="交易（Transaction）"></a>交易（Transaction）</h3><p>以太坊交易是网络消息，其中包括发送者（sender），接收者（receiver），值（value） 和数据的有效载荷（payload）。</p><h3 id="以太坊虚拟机（EVM）"><a href="#以太坊虚拟机（EVM）" class="headerlink" title="以太坊虚拟机（EVM）"></a>以太坊虚拟机（EVM）</h3><p>以太坊状态转换由以太坊虚拟机（EVM）处理，这是一个执行字节码（机器语言指令）的 基于堆栈的虚拟机。</p><h3 id="数据库（Blockchain）"><a href="#数据库（Blockchain）" class="headerlink" title="数据库（Blockchain）"></a>数据库（Blockchain）</h3><p>以太坊的区块链作为数据库（通常是 Google 的 LevelDB）本地存储在每个节点上，包含 序列化后的交易和系统状态。</p><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p>以太坊有几种可互操作的客户端软件实现，其中最突出的是 Go-Ethereum（Geth）和 Parity。</p><h2 id="以太坊中的重要概念"><a href="#以太坊中的重要概念" class="headerlink" title="以太坊中的重要概念"></a>以太坊中的重要概念</h2><h3 id="账户（Account）"><a href="#账户（Account）" class="headerlink" title="账户（Account）"></a>账户（Account）</h3><p>账户包含地址，余额和随机数，以及可选的存储和代码的对象。</p><ul><li>  普通账户（EOA），存储和代码均为空。</li><li>  合约账户（Contract），包含存储和代码。</li></ul><h3 id="地址（Address）"><a href="#地址（Address）" class="headerlink" title="地址（Address）"></a>地址（Address）</h3><p>一般来说，代表一个 EOA 或合约，它可以在区块链上接收或发送交易， 更具体地说，它是 ECDSA 公钥的 keccak 散列的最右边的 160 位</p><h3 id="交易（Transaction）-1"><a href="#交易（Transaction）-1" class="headerlink" title="交易（Transaction）"></a>交易（Transaction）</h3><ul><li>  可以发送以太币和信息。</li><li>  向合约发送的交易可以调用合约代码，并以信息数据为函数参数。</li><li>  向空用户发送信息，可以自动生成以信息为代码块的合约账户。</li></ul><h3 id="gas"><a href="#gas" class="headerlink" title="gas"></a>gas</h3><p>以太坊用于执行智能合约的虚拟燃料， 以太坊虚拟机使用核算机制来衡量 gas 的消耗量并限制计算资源的消耗</p><h2 id="以太坊的货币"><a href="#以太坊的货币" class="headerlink" title="以太坊的货币"></a>以太坊的货币</h2><p>以太坊的货币单位称为以太（ether），也可以表示为 ETH 或符号 Ξ</p><ul><li><p>以太币的发行规则：</p><p>  1 、挖矿前（Pre-mine，Genesis）</p><p>  2014 年 7 月 / 8 月间，为众筹大约发行了 7200 万以太币。这些币有的时候被称之为 “矿前”。众筹阶段之后，以太币每年的产量基本稳定，被限制不超过 7200 万的 25%。</p><p>  2、挖矿产出（Mining）</p><ul><li>  区块奖励（block reward）</li><li>  叔块奖励（uncle reward）</li><li>  叔块引用奖励（uncle referencing reward）</li></ul></li><li><p>以太币产量未来的变化</p><p>  以太坊出块机制从工作量证明（PoW）转换为股权证明（PoS）后，以太币的发行会有什么变化尚未有定论。股权证明机制将使用一个称为 Casper 的协议。在 Casper 协议下，以太币的发行率将大大低于工作量证明下幽灵（GHOST）协议下的发行率。</p></li></ul><h2 id="以太坊的挖矿产出"><a href="#以太坊的挖矿产出" class="headerlink" title="以太坊的挖矿产出"></a>以太坊的挖矿产出</h2><h3 id="区块奖励（Block-rewards）"><a href="#区块奖励（Block-rewards）" class="headerlink" title="区块奖励（Block rewards）"></a>区块奖励（Block rewards）</h3><p>每产生一个新区块就会有一笔固定的奖励给矿工，初始是 5 个以太币，现在是 3 个。</p><h3 id="叔块奖励（Uncle-rewards）"><a href="#叔块奖励（Uncle-rewards）" class="headerlink" title="叔块奖励（Uncle rewards）"></a>叔块奖励（Uncle rewards）</h3><p>有些区块被挖得稍晚一些，因此不能作为主区块链的组成部分。比特币称这类区块为 “孤块”，并且完全舍弃它们。但是，以太币称它们为 “叔块”（uncles），并且在之后的区块中，可以引用它们。如果叔块在之后的区块链中作为叔块被引用，每个叔块会为挖矿者产出区块奖励的 7/8。这被称之为叔块奖励。</p><h3 id="叔块引用奖励（Uncle-referencing-rewards）"><a href="#叔块引用奖励（Uncle-referencing-rewards）" class="headerlink" title="叔块引用奖励（Uncle referencing rewards）"></a>叔块引用奖励（Uncle referencing rewards）</h3><p>矿工每引用一个叔块，可以得到区块奖励的 1/32 作为奖励（最多引用两个叔块）。</p><h2 id="以太坊区块收入"><a href="#以太坊区块收入" class="headerlink" title="以太坊区块收入"></a>以太坊区块收入</h2><h3 id="普通区块收入"><a href="#普通区块收入" class="headerlink" title="普通区块收入"></a>普通区块收入</h3><ul><li>  固定奖励（挖矿奖励），每个普通区块都有。</li><li>  区块内包含的所有程序的 gas 花费的总和。</li><li>  如果普通区块引用了叔块，每引用一个叔块可以得到固定奖励的 1/32</li></ul><h3 id="叔块收入"><a href="#叔块收入" class="headerlink" title="叔块收入"></a>叔块收入</h3><p>叔块收入只有一项，就是叔块奖励，计算公式为： 叔块奖励 = (叔块高度 + 8 – 引用叔块的区块高度) * 普通区块奖励 / 8。</p><h2 id="以太坊和图灵完备"><a href="#以太坊和图灵完备" class="headerlink" title="以太坊和图灵完备"></a>以太坊和图灵完备</h2><p>1936 年，英国数学家艾伦 · 图灵（Alan Turing）创建了一个计算机的数学模型，它由一个控制器、一个读写头和一根无限长的工作带组成。纸带起着存储的作用，被分成一个个的小方格（可以看成磁带）；读写头能够读取纸带上的信息，以及将运算结果写进纸带；控制器则负责根据程序对搜集到的信息进行处理。在每个时刻，机器头都要从当前纸带上读入一个方格信息，然后结合自己的内部状态查找程序表，根据程序输出信息到纸带方格上，并转换自己的内部状态，然后进行移动纸带。这样的机器称为图灵机。</p><p><img src="/2023/04/27/27Ethereum/3.png"><br>如果一个系统可以模拟任何图灵机，它就被定义为 “图灵完备”（Turing Complete）的。 这种系统称为通用图灵机（UTM）</p><p>以太坊能够在称为以太坊虚拟机的状态机中执行存储程序，同时向内存读取和写入数据， 使其成为图灵完备系统，因此成为通用图灵机。考虑到有限存储器的限制，以太坊可以计 算任何可由任何图灵机计算的算法。简单来说，以太坊中支持循环语句，理论上可以运行 “无限循环” 的程序</p><h2 id="去中心化应用"><a href="#去中心化应用" class="headerlink" title="去中心化应用"></a>去中心化应用</h2><ul><li>  基于以太坊可以创建智能合约 (Smart Contract) 来构建去中心化应用 (Decentralized Application，简称为 DApp）</li><li>  以太坊的构想是成为 DApps 编程开发的平台</li><li>DApp 至少由以下组成：<ul><li>  区块链上的智能合约</li><li>  Web 前端用户界面</li></ul></li></ul><h2 id="以太坊应用"><a href="#以太坊应用" class="headerlink" title="以太坊应用"></a>以太坊应用</h2><ul><li>  基于以太坊创建新的加密货币（CryptoCurrency，这种能力是 2017 年各种 ICO 泛滥的技术动因）。</li><li>  基于以太坊创建域名注册系统、博彩系统。</li><li>  基于以太坊开发去中心化的游戏，比如 2017 年底红极一时的以太猫（CryptoKitties，最高单只猫售价高达 80W 美元)。</li></ul><h2 id="代币（Token）"><a href="#代币（Token）" class="headerlink" title="代币（Token）"></a>代币（Token）</h2><ul><li>  代币（token）也称作通证，本意为 “令牌”，代表有所有权的资产、货币、权限等在区块链上的抽象。</li><li>  可替代性通证（fungible token）：指的是基于区块链技术发行的，互相可以替代的，可以接近无限拆分的 token。</li><li>  非同质通证（non-fungible token）： 指的是基于区块链技术发行的，唯一的，不可替代的，大多数情况下不可拆分的 token，如加密猫（CryptoKitties）。</li></ul><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ul><li>  IP： Ethereum Improvement Proposals，以太坊改进建议。</li><li>  ERC：Ethereum Request for Comments 的缩写，以太坊征求意见。一些 EIP 被标记为 ERC，表示试图定义以太坊使用的特定标准的提议。</li><li>  EOA：External Owned Account，外部账户。由以太坊网络的人类用户创建的账户。</li><li>  Ethash：以太坊 1.0 的工作量证明算法。</li><li>  HD 钱包：使用分层确定性（HD protocol）密钥创建和转账协议（BIP32）的钱包。</li><li>  Keccak256：以太坊中使用的密码哈希函数。Keccak256 被标准化为 SHA-3。</li><li>  Nonce：在密码学中，术语 nonce 用于指代只能使用一次的值。以太坊使用两种类型的随机数，账户随机数和 POW 随机数。</li></ul><h1 id="以太坊客户端"><a href="#以太坊客户端" class="headerlink" title="以太坊客户端"></a>以太坊客户端</h1><h2 id="什么是以太坊客户端"><a href="#什么是以太坊客户端" class="headerlink" title="什么是以太坊客户端"></a>什么是以太坊客户端</h2><p>以太坊客户端是一个软件应用程序，它实现以太坊规范并通过 p2p 网络与其他以太坊客户端进行通信。如果不同的以太坊客户端符合参考规范和标准化通信协议，则可以进行相互操作。</p><p>以太坊是一个开源项目，由 “<a href="https://ethereum.github.io/yellowpaper/paper.pdf" title="以太坊黄皮书">以太坊黄皮书</a>” 正式规范定义。除了各种以太坊改进提案之外，此正式规范还定义了以太坊客户端的标准行为，因为有了明确的正式规范，以太网客户端有了许多独立开发的软件实现，它们之间又可以彼此交互。</p><p><img src="/2023/04/27/27Ethereum/4.png"></p><h2 id="基于以太坊规范的网络"><a href="#基于以太坊规范的网络" class="headerlink" title="基于以太坊规范的网络"></a>基于以太坊规范的网络</h2><p>存在各种基于以太坊规范的网络，这些网络基本符合 “以太坊黄皮书” 中定义的形式规范，但它们之间可能相互也可能不相互操作。</p><p>这些基于以太坊的网络中有：以太坊，以太坊经典，Ella，Expanse，Ubiq，Musicoin 等等。</p><p>虽然大多数在协议级别兼容，但这些网络通常具有特殊要求，以太坊客户端软件的维护人员、需要进行微小更改、以支持每个网络的功能或属性。</p><h2 id="以太坊的多种客户端"><a href="#以太坊的多种客户端" class="headerlink" title="以太坊的多种客户端"></a>以太坊的多种客户端</h2><ul><li>go-ethereum (Go)：<br>官方推荐，开发使用最多， Geth 是由以太坊基金会积极开发的 Go 语言实现，因此被认为是以太坊客户端的 “官方” 实现。通常，每个基于以太坊的区块链都有自己的 Geth 实现</li><li>parity (Rust)： 最轻便客户端，在历次以太坊网络攻击中表现卓越。</li><li>cpp-ethereum (C++)</li><li>pyethapp (python)</li><li>ethereumjs (javascript)</li><li>EthereumJ / Harmony (Java)</li></ul><h2 id="JSON-RPC"><a href="#JSON-RPC" class="headerlink" title="JSON-RPC"></a>JSON-RPC</h2><p>以太坊客户端提供了 API 和一组远程调用（RPC）命令，这些命令被编码为 JSON。这被称为 JSON-RPC API。本质上，JSON-RPC API 就是一个接口，允许编写的程序使用以太坊客户端作为网关，访问以太坊网络和链上数据。</p><p>通常，RPC 接口作为一个 HTTP 服务，端口设定为 8545。出于安全原因，默认情况下，它仅限于接受来自 localhost 的连接。</p><p>要访问 JSON-RPC API，可以使用编程语言编写的专用库，例如 JavaScript 的 web3.js，或者也可以手动构建 HTTP 请求并发送 / 接收 JSON 编码的请求。</p><h2 id="以太坊全节点"><a href="#以太坊全节点" class="headerlink" title="以太坊全节点"></a>以太坊全节点</h2><p>全节点是整个主链的一个副本，存储并维护链上的所有数据，可以随时验证新区块的合法性，运行全节点将耗费巨大的成本，包括硬件资源和带宽。</p><p>区块链的健康和扩展弹性，取决于具有许多独立操作和地理上分散的全节点。每个全节点都可以帮助其他新节点获取区块数据，并提供所有交易和合约的独立验证。</p><p>以太坊开发不需要在实时网络（主网）上运行的全节点。可以使用测试网络的节点来代替，也可以用本地私链，或者使用服务商提供的基于云的以太坊客户端，这些几乎都可以执行所有操作。</p><h2 id="远程客户端和轻节点"><a href="#远程客户端和轻节点" class="headerlink" title="远程客户端和轻节点"></a>远程客户端和轻节点</h2><p>远程客户端：<br>不存储区块链的本地副本或验证块和交易。这些客户端一般只提供钱包的功能，可以创建和广播交易。远程客户端可用于连接到现有网络，MetaMask 就是一个这样的客户端。</p><p>轻节点：<br>不保存链上的区块历史数据，只保存区块链当前的状态。轻节点可以对块和交易进行验证。</p><h3 id="全节点的优缺点"><a href="#全节点的优缺点" class="headerlink" title="全节点的优缺点"></a>全节点的优缺点</h3><ul><li>优点<ul><li>为以太坊网络的灵活性和抗审查性提供有力支持。</li><li>权威地验证所有交易。</li><li>可以直接与公共区块链上的任何合约交互。</li><li>可以离线查询区块链状态（帐户，合约等）。</li><li>可以直接把自己的合约部署到公共区块链中。</li></ul></li><li>缺点<ul><li>需要巨大的硬件和带宽资源，而且会不断增长。</li><li>第一次下载往往需要几天才能完全同步。</li><li>必须及时维护、升级并保持在线状态以同步区块。。</li></ul></li></ul><h3 id="公共测试网络节点的优缺点"><a href="#公共测试网络节点的优缺点" class="headerlink" title="公共测试网络节点的优缺点"></a>公共测试网络节点的优缺点</h3><ul><li>优点<ul><li>一个 testnet 节点需要同步和存储更少的数据，大约 10GB，具体取决于不同的网络</li><li>一个 testnet 节点一般可以在几个小时内完全同步</li><li>部署合约或进行交易只需要发送测试以太，可以从 “水龙头” 免费获得</li><li>测试网络是公共区块链，有许多其他用户和合约运行（区别于私链）</li></ul></li><li>缺点<ul><li>测试网络上使用测试以太，它没有价值。因此，无法测试交易对手的安全性，因为没有任何利害关系</li><li>测试网络上的测试无法涵盖所有的真实主网特性。例如，交易费用虽然是发送交易所必需的，但由于 gas 免费，因此 testnet 上往往不会考虑。而且一般来说，测试网络不会像主网那样经常拥堵</li></ul></li></ul><h3 id="本地私链的优缺点"><a href="#本地私链的优缺点" class="headerlink" title="本地私链的优缺点"></a>本地私链的优缺点</h3><ul><li>优点<ul><li>磁盘上几乎没有数据，也不同步别的数据，是一个完全 “干净” 的环境</li><li>无需获取测试以太，你可以任意分配以太，也可以随时自己挖矿获得</li><li>没有其他用户，也没有其他合约，没有任何外部干扰</li></ul></li><li>缺点<ul><li>没有其他用户意味与公链的行为不同。发送的交易并不存在空间或交易顺序的竞争</li><li>除自己之外没有矿工意味着挖矿更容易预测，因此无法测试公链上发生的某些情况</li><li>没有其他合约，意味着你必须部署要测试的所有内容</li></ul></li></ul><h2 id="用-Geth-搭建以太坊私链"><a href="#用-Geth-搭建以太坊私链" class="headerlink" title="用 Geth 搭建以太坊私链"></a>用 Geth 搭建以太坊私链</h2><p>一种是直接用源码安装，直接克隆 git 仓库，获取源代码的副本。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/ethereum/go-ethereum.git</span><br></pre></td></tr></table></figure><p>另一种是到官网直接下载对应系统的安装程序。</p><p>查看<code>geth version</code>，确保在真正运行之前安装正常。</p><h3 id="启动节点同步"><a href="#启动节点同步" class="headerlink" title="启动节点同步"></a>启动节点同步</h3><p>安装好了 Geth，可以尝试运行一下它。执行下面的命令，geth 就会开始同步区块，并存储在当前目录下。这里的<code>--syncmode fast</code>参数表示会以 “快速” 模式同步区块。在这种模式下，只会下载每个区块头和区块体，但不会执行验证所有的交易，直到所有区块同步完毕再去获取一个系统当前的状态。这样就节省了很多交易验证的时间。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">geth –datadir . --syncmode fast</span><br></pre></td></tr></table></figure><p>如果想同步测试网络的区块，可以用下面的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">geth --testnet --datadir . --syncmode fast</span><br></pre></td></tr></table></figure><p><code>--testnet</code>这个参数会告诉 geth 启动并连接到最新的测试网络，测试网络的区块和交易数量会明显少于主网，所以会更快一点。但即使是用快速模式同步测试网络，也会需要几个小时的时间。</p><h3 id="搭建自己的私链"><a href="#搭建自己的私链" class="headerlink" title="搭建自己的私链"></a>搭建自己的私链</h3><p>因为公共网络的区块数量太多，同步耗时太长，为了方便快速了解 Geth，可以试着用它来搭一个只属于自己的私链。</p><p>首先，需要创建网络的 “创世”（genesis）状态，这写在一个小小的 JSON 文件里（例如，将其命名为 genesis.json）：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;config&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;chainId&quot;</span>: <span class="number">15</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;difficulty&quot;</span>: <span class="string">&quot;2000&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;gasLimit&quot;</span>: <span class="string">&quot;2100000&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;alloc&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;7df9a875a174b3bc565e6424a0050ebc1b2d1d82&quot;</span>: &#123; <span class="attr">&quot;balance&quot;</span>: <span class="string">&quot;300000&quot;</span> &#125;,</span><br><span class="line">        <span class="attr">&quot;f41c74c9ae680c1aa78f42e5647a62f353b7bdde&quot;</span>: &#123; <span class="attr">&quot;balance&quot;</span>: <span class="string">&quot;400000&quot;</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>要创建一条以它作为创世块的区块链，可以使用下面的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">geth --datadir path/to/custom/data/folder init genesis.json</span><br></pre></td></tr></table></figure><p>在当前目录下运行 geth，就会启动这条私链，注意要将 networked 设置为与创世块配置里的 chainId 一致。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">geth --datadir path/to/custom/data/folder --networkid 15</span><br></pre></td></tr></table></figure><p>现在，节点正常启动，恭喜！已经成功启动了一条自己的私链。</p><h3 id="Geth-控制台命令"><a href="#Geth-控制台命令" class="headerlink" title="Geth 控制台命令"></a>Geth 控制台命令</h3><p>Geth Console 是一个交互式的 JavaScript 执行环境，里面内置了一些用来操作以太坊的 JavaScript 对象，可以直接调用这些对象来获取区块链上的相关信息。这些对象主要包括：</p><ul><li><p>eth：主要包含对区块链进行访问和交互相关的方法；</p></li><li><p>net：主要包含查看 p2p 网络状态的方法；</p></li><li><p>admin：主要包含与管理节点相关的方法；</p></li><li><p>miner：主要包含挖矿相关的一些方法；</p></li><li><p>personal：包含账户管理的方法；</p></li><li><p>txpool：包含查看交易内存池的方法；</p></li><li><p>web3：包含以上所有对象，还包含一些通用方法<br>常用命令有：</p></li><li><p>personal.newAccount()：创建账户；</p></li><li><p>personal.unlockAccount()：解锁账户；</p></li><li><p>eth.accounts：列出系统中的账户；</p></li><li><p>eth.getBalance()：查看账户余额，返回值的单位是 Wei；</p></li><li><p>eth.blockNumber：列出当前区块高度；</p></li><li><p>eth.getTransaction()：获取交易信息；</p></li><li><p>eth.getBlock()：获取区块信息；</p></li><li><p>miner.start()：开始挖矿；</p></li><li><p>miner.stop()：停止挖矿；</p></li><li><p>web3.fromWei()：Wei 换算成以太币；</p></li><li><p>web3.toWei()：以太币换算成 Wei；</p></li><li><p>txpool.status：交易池中的状态；</p></li></ul><h1 id="以太坊交易"><a href="#以太坊交易" class="headerlink" title="以太坊交易"></a>以太坊交易</h1><h2 id="以太币单位"><a href="#以太币单位" class="headerlink" title="以太币单位"></a>以太币单位</h2><p><img src="/2023/04/27/27Ethereum/5.png"></p><ul><li>  以太坊的货币单位称为以太，也称为 ETH 或符号 Ξ 。</li><li>  ether 被细分为更小的单位，直到可能的最小单位，称为 wei；1 ether = 10^18 wei 。</li><li>  以太的值总是在以太坊内部表示为以 wei 表示的无符号整数值。</li><li>  以太的各种单位都有一个使用国际单位制（SI）的科学名称，和一个口语名称。</li></ul><h2 id="以太坊账户"><a href="#以太坊账户" class="headerlink" title="以太坊账户"></a>以太坊账户</h2><h3 id="私钥、公钥和地址"><a href="#私钥、公钥和地址" class="headerlink" title="私钥、公钥和地址"></a>私钥、公钥和地址</h3><ul><li><p>  私钥（Private Key）：以太坊私钥是一个 256 位的随机数，用于发送以太的交易中创建签名来证明自己对资金的所有权</p></li><li><p>  公钥（Public Key）：公钥是由私钥通过椭圆曲线加密 secp256k1 算法单向生成的 512 位 （64 字节）数</p></li><li><p>  地址（Address）：地址是由公钥的 Keccak-256 单向哈希，取最后 20 个字节（160 位） 派生出来的标识符</p></li></ul><h3 id="以太坊账户类型"><a href="#以太坊账户类型" class="headerlink" title="以太坊账户类型"></a>以太坊账户类型</h3><p>以太坊账户分为外部账户 (Externally owned account, EOA)和 合约账户 (Contract accounts)。<br><img src="/2023/04/27/27Ethereum/6.png"></p><h4 id="EOA"><a href="#EOA" class="headerlink" title="EOA"></a>EOA</h4><p>外部账户：普通用户用私钥控制的账户</p><ul><li>  有对应的以太币余额</li><li>  可发送交易（转币或触发合约代码）</li><li>  由用户私钥控制</li><li>  没有关联代码</li></ul><h4 id="合约账户"><a href="#合约账户" class="headerlink" title="合约账户"></a>合约账户</h4><p>一种拥有合约代码的账户，它不属于任何人，也没有私钥与之对应。</p><ul><li>  有对应的以太币余额</li><li>  有关联代码</li><li>  由代码控制</li><li>  可通过交易或来自其它合约的调用消息来触发代码执行</li><li>  执行代码时可以操作自己的存储空间，也可以调用其它合约</li></ul><h2 id="以太坊钱包"><a href="#以太坊钱包" class="headerlink" title="以太坊钱包"></a>以太坊钱包</h2><p>以太坊钱包是我们进入以太坊系统的门户。它包含了私钥，可以代表我们创建和广播交易，常见得钱包有：</p><ul><li><p>  MetaMask：一个浏览器扩展钱包，可在浏览器中运行。下面例子中使用的是 MetaMask。</p></li><li><p>  Jaxx：一款多平台、多币种的钱包，可在各种操作系统上运行，包括 Android，iOS，Windows，Mac 和 Linux。</p></li><li><p>  MyEtherWallet（MEW）：一个基于 web 的钱包，可以在任何浏览器中运行。</p></li><li><p>  Emerald Wallet：旨在与 ETC 配合使用，但与其他基于以太坊的区块链兼容。</p></li></ul><h2 id="交易"><a href="#交易" class="headerlink" title="交易"></a>交易</h2><p>以太坊中的交易是一个签名的数据包，由 EOA 发送到另一个账户，由以太坊网络传输，并被序列化后记录在以太坊区块链上，并且以太坊是一个全局单例状态机，交易是唯一可以触发状态更改或导致合约在 EVM 中执行的事物。</p><p>数据包里包含：</p><ul><li>  nonce：由发起人 EOA 发出的序列号，用于防止交易消息重播</li><li>  gas price：交易发起人愿意支付的 gas 单价（wei）</li><li>  start gas：交易发起人愿意支付的最大 gas 量</li><li>  to：目的以太坊地址</li><li>  value：要发送到目的地的以太数量</li><li>  data：可变长度二进制数据负载（payload）</li><li>  v,r,s：发起人 EOA 的 ECDSA 签名的三个组成部分</li></ul><p>交易消息的结构使用递归长度前缀（RLP）编码方案进行序列化，该方案专为在以太坊中准确和字节完美的数据序列化而创建。</p><h3 id="nonce"><a href="#nonce" class="headerlink" title="nonce"></a>nonce</h3><p>对于 EOA 账户，nonce 等于从这个账户地址发送的交易数。 对于合约账户，nonce 等于这个这个账户中创建的合约数。</p><p>nonce 值还用于防止错误计算账户余额。nonce 强制来自任何地址的交易按顺序处理，没有间隔，无论节点接收它们的顺序如何。使用 nonce 确保所有节点计算相同的余额和正确的序列交易，等同于用于防止比特币 “双重支付”（“重放攻击”）的机制。</p><h3 id="gas-1"><a href="#gas-1" class="headerlink" title="gas"></a>gas</h3><p>当交易或消息触发 EVM 运行时，每个指令都会在网络的每个节点上执行。对于每个执行的操作，都存在固定的成本，这个成本用一定量的 gas 表示。发起交易时，需要从执行代码的矿工那里用以太币购买 gas。</p><p>gas 与消耗的系统资源对应，这是具有自然成本的。因此在设计上 gas 和 ether 有意地解耦，消耗的 gas 数量代表了对资源的占用，而对应的交易费用则还跟 gas 对以太的单价有关。这两者是由自由市场调节的：gas 的价格实际上是由矿工决定的，他们可以拒绝处理 gas 价格低于最低限额的交易。我们不需要专门购买 gas ，只需将以太币添加到帐户即可，客户端在发送交易时会自动用以太币购买 gas。而以太币本身的价格通常由于市场力量而波动。</p><h3 id="gas-的计算"><a href="#gas-的计算" class="headerlink" title="gas 的计算"></a>gas 的计算</h3><p>在发起交易时发起人会先设置一个<code>gas limit</code>，代表消耗 gas 得上限，相当于押金。 实际支付的 gas 数量是执行过程中消耗的 gas （gasUsed），<code>gas limit</code> 中剩余的部分会返回给发送人。最终支付的 gas 费用是 gasUsed 对应的以太币费用，单价由设定的 gasPrice 而定。</p><p>最终支付费用 <code>totalCost = gasPrice * gasUsed</code> totalCost 会作为交易手续费（Tx fee）支付给矿工</p><h3 id="交易的接收者：to"><a href="#交易的接收者：to" class="headerlink" title="交易的接收者：to"></a>交易的接收者：to</h3><p><code>to</code>字段是一个 20 字节的以太坊地址，可以是 EOA 也可以是合约地址。</p><p>在以太坊中，任何 20 字节的值都被认为是有效的，以太坊没有做验证。如果 20 字节值没有对应的地址或者是不存在的合约，交易也是有效的，但是以太坊会销毁发送的以太，使其永远无法访问。</p><h3 id="交易的-value-和-data"><a href="#交易的-value-和-data" class="headerlink" title="交易的 value 和 data"></a>交易的 value 和 data</h3><p><code>value</code> 和 <code>data</code>是交易主要的“有效负载”，它们可以有 4 中组合。</p><ul><li>  仅有 value： 表示一笔以太的付款。</li><li>  仅有 data： 一般表示合约调用。</li><li>  同时有 value 和 data： 进行合约调用，同时忘合约中发送以太。</li><li>  既没有 value 也没有 data： 只是在浪费 gas，但它是有效的。</li></ul><h2 id="特殊交易：创建（部署）合约"><a href="#特殊交易：创建（部署）合约" class="headerlink" title="特殊交易：创建（部署）合约"></a>特殊交易：创建（部署）合约</h2><p>有一种特殊的交易，具有数据负载且没有 value，那就是一个创建新合约的交易。这个交易的<code>to</code>地址是一个特殊的地址，即零地址： 0x0。该地址既不代表 EOA 也不代表合约。它永远不会花费以太或发起交易，它仅用作目的地，具有特殊含义 “创建合约”。</p><p>虽然零地址仅用于合同注册，但它有时会收到来自各种地址的付款。 这种情况要么是偶然误操作，导致失去以太；要么是故意销毁以太。</p><h1 id="以太坊虚拟机-EVM"><a href="#以太坊虚拟机-EVM" class="headerlink" title="以太坊虚拟机 (EVM)"></a>以太坊虚拟机 (EVM)</h1><h2 id="以太坊虚拟机-EVM-简介"><a href="#以太坊虚拟机-EVM-简介" class="headerlink" title="以太坊虚拟机 (EVM) 简介"></a>以太坊虚拟机 (EVM) 简介</h2><p>以太坊虚拟机（ EVM ）是<code>智能合约</code>的运行环境， 作为区块验证协议的一部分，参与网络的每个节点都会运行 EVM。他们会检查正在验证的块中列出的交易，并运行由 EVM 中的交易触发的代码。</p><p>EVM 不仅是沙盒封装的，而且是完全隔离的，也就是说在 EVM 中运行的代码是无法访问网络、文件系统和其他进程的， 甚至智能合约之间的访问也是受限的。</p><p>合约以字节码的格式（EVM bytecode）存在于区块链上， 合约通常以高级语言（solidity）编写，通过 EVM 编译器编译为字节码，最终通过客户端上载部署到区块链网络中。</p><h2 id="EVM的工作原理"><a href="#EVM的工作原理" class="headerlink" title="EVM的工作原理"></a>EVM的工作原理</h2><h3 id="代码编译和部署"><a href="#代码编译和部署" class="headerlink" title="代码编译和部署"></a>代码编译和部署</h3><p>在以太坊上开发智能合约时，开发者使用Solidity等高级编程语言编写合约代码，并通过编译器将其转换为EVM能够理解和执行的字节码。</p><p>编译得到的字节码会被写入以太坊区块链，并分配一个唯一的合约地址。合约地址用于唯一标识合约在区块链上的存储位置。</p><h3 id="交易执行"><a href="#交易执行" class="headerlink" title="交易执行"></a>交易执行</h3><p>当一个合约交易被广播到以太坊网络时，EVM的节点会接收到该交易，并进行验证。验证通过后，EVM开始执行交易中的智能合约代码。</p><h3 id="EVM执行环境"><a href="#EVM执行环境" class="headerlink" title="EVM执行环境"></a>EVM执行环境</h3><p>EVM提供了一个独立的执行环境，每个交易都在自己的环境中执行。EVM的执行环境由以下几个组成部分：</p><p><img src="/2023/04/27/27Ethereum/7.png"></p><ul><li><p>栈（Stack）</p><p>  EVM 使用栈来存储和处理数据。栈是一种后进先出（LIFO）结构，用于执行指令时的操作数栈和返回值栈。</p><p>  存放部分局部值类型变量，几乎免费使用的内存，但有数量限制。</p></li><li><p>内存（Memory）</p><p>  EVM 提供了一块可扩展的内存区域，用于临时存储和操作数据。智能合约可以通过读写内存来进行复杂的计算和数据处理。</p><p>  每一次消息调用，合约会临时获取一块干净的内存空间，生命周期仅为整个方法执行期间，函数调用后回收，因为仅保存临时变量，故读写 gas 开销较小。</p></li><li><p>存储（Storage）<br>  EVM 提供了持久化的存储空间，用于永久保存合约的状态和数据。这是一个将 256 位字映射到 256 位字的 key-value 存储区，可以理解为合约的数据库，每个合约都有自己的存储空间。</p><p>  由于会永久保存合约状态变量，所以读写的 gas 开销也最大。</p></li><li><p>指令集（Instruction Set）</p><p>  EVM 定义了一套指令集，用于执行智能合约的操作和功能。指令集包括基本的算术运算、逻辑运算、存储读写操作等，也可以做到有条件和无条件跳转。所有的指令都是针对 “256 位的字（word）“这个基本的数据类型来进行操作。</p></li></ul><h3 id="执行过程"><a href="#执行过程" class="headerlink" title="执行过程"></a>执行过程</h3><p>EVM的执行过程可以简单概括为以下几个步骤：</p><p>解析交易：EVM首先解析交易数据，提取出合约地址、调用参数等信息。</p><p>创建执行环境：EVM为该交易创建一个独立的执行环境，包括栈、存储和内存空间。</p><p>执行合约代码：EVM按照合约代码的指令顺序逐条执行，通过操作码来执行各种操作，如计算、存储、跳转等。</p><p>栈操作：EVM使用栈来保存和处理数据。在执行过程中，可以将数据压入栈顶、从栈顶弹出数据，进行栈上计算操作。</p><p>存储操作：EVM提供了持久化的存储空间Storage，可以读取和写入合约的状态和数据。通过存储操作码，可以将数据存储到存储空间或从存储空间中读取数据。</p><p>内存操作：EVM的临时内存空间可用于临时存储数据。通过内存操作码，可以将数据加载到内存中或从内存中读取数据。</p><p>跳转操作：EVM支持跳转操作，可以根据条件或无条件地改变代码执行的流程，实现条件判断、循环等控制结构。</p><p>异常处理：在执行过程中，如果遇到错误或异常情况，EVM会停止执行并回滚状态，确保合约的执行不会导致不一致的状态。</p><p>结束执行：当合约代码执行完毕或遇到返回指令时，EVM将结束执行，并将执行结果返回给调用者。</p><h1 id="编写智能合约"><a href="#编写智能合约" class="headerlink" title="编写智能合约"></a>编写智能合约</h1><h2 id="MetaMask-钱包"><a href="#MetaMask-钱包" class="headerlink" title="MetaMask 钱包"></a>MetaMask 钱包</h2><p>以太坊钱包是我们进入以太坊系统的门户。它包含了私钥，可以代表我们创建和广播交易。本文我们使用 MetaMask 钱包。 MetaMask 钱包可以在谷歌浏览器插件中安装。</p><h3 id="添加测试地址"><a href="#添加测试地址" class="headerlink" title="添加测试地址"></a>添加测试地址</h3><p>在以太坊主网上进行交易和执行智能合约需要支付 gas 费用，这些费用在开发和测试阶段可能会累积成相当大的开销。 因此，在开发和测试阶段一般都是使用太坊测试网络。这些测试网络通常提供免费的测试以太币。</p><p>这里有一些以太坊测试地址：<a href="https://talk.comunion.org/d/650-comunion-rpc-erc-20">https://talk.comunion.org/d/650-comunion-rpc-erc-20</a></p><p>本文选择 Avalanch 测试链：</p><pre><code>Avalanch Avalanch - Avalanch Testent网络名称：Avalanche Fuji Testnet新增 RPC URL：https://api.avax-test.network/ext/bc/C/rpcChain ID：43113货币符号：AVAX区块链浏览器 URL：https://cchain.explorer.avax-test.network水龙头地址：https://faucet.avax.network/</code></pre><h3 id="领取测试币"><a href="#领取测试币" class="headerlink" title="领取测试币"></a>领取测试币</h3><p>进入测试网络的水龙头地址<code>https://faucet.avax.network/</code>中，连接 MetaMask</p><p><img src="/2023/04/27/27Ethereum/8.png"></p><p>连接到 MetaMask 后，地址栏中会显示钱包的地址，点击<code>Request 2 AVAX</code>，等待交易完成，钱包地址中会有 2 AVAX 代币。<br><img src="/2023/04/27/27Ethereum/9.png"></p><h3 id="MateMask-中添加测试网络。"><a href="#MateMask-中添加测试网络。" class="headerlink" title="MateMask 中添加测试网络。"></a>MateMask 中添加测试网络。</h3><p>点击下面的<code>将子网添加到钱包</code>，并将钱包切换到测试网络。<br><img src="/2023/04/27/27Ethereum/10.png"></p><p>完成后，可以在钱包查看测试网中的账户信息<br><img src="/2023/04/27/27Ethereum/11.png"></p><h2 id="在-Remix-上构建简单的水龙头合约"><a href="#在-Remix-上构建简单的水龙头合约" class="headerlink" title="在 Remix 上构建简单的水龙头合约"></a>在 Remix 上构建简单的水龙头合约</h2><p>Remix 是一个在线用于构建和部署以太坊智能合约的开发工具和平台。它提供了一个用户友好的界面和功能强大的集成开发环境（IDE），帮助开发者更轻松地编写、测试和部署智能合约。</p><p>Remix 集成了 Solidity 编译器，可以将 Solidity 合约代码编译成 EVM（以太坊虚拟机）字节码。开发者可以使用 Remix 提供的编译器生成合约的字节码和 ABI（应用二进制接口），以便在以太坊上部署和调用合约。</p><p>Remix 的地址：<a href="https://remix.ethereum.org/">https://remix.ethereum.org</a></p><p><img src="/2023/04/27/27Ethereum/12.png"></p><h3 id="编写水龙头合约"><a href="#编写水龙头合约" class="headerlink" title="编写水龙头合约"></a>编写水龙头合约</h3><p>水龙头是一件相对简单的事情：它会向任何要求的地址发出以太。</p><p>在<code>contracts</code>目录下，新建一个<code>Faucet.sol</code>文件</p><p><img src="/2023/04/27/27Ethereum/13.png"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Version of Solidity compiler this program was written for</span></span><br><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.19</span>;</span><br><span class="line"><span class="comment">// Our first contract is a faucet!</span></span><br><span class="line">contract Faucet &#123;</span><br><span class="line">    <span class="comment">// Give out ether to anyone who asks</span></span><br><span class="line">    <span class="function">function <span class="title">withdraw</span><span class="params">(uint withdraw_amount)</span> <span class="keyword">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// Limit withdrawal amount</span></span><br><span class="line">        require(withdraw_amount &lt;= <span class="number">100000000000000000</span>);</span><br><span class="line">        <span class="comment">// Send the amount to the address that requested it</span></span><br><span class="line">        msg.sender.transfer(withdraw_amount);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Accept any incoming amount</span></span><br><span class="line">    function () <span class="keyword">public</span> payable &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>contract Faucet &#123;</code> ： 该行声明了一个合约对象，类似于其他面向对象语言中的类声明</p><p><code>function withdraw(uint withdraw_amount) public &#123;</code>： 该函数名为 withdraw，它接受一个名为 withdraw_amount 的无符号整数（uint）参数。它被声明为公共函数，这意味着它可以被其他合约调用</p><p><code>require(withdraw_amount &lt;= 100000000000000000);</code>： 该行设定提款限额。</p><p>使用内置的 Solidity 函数 require 来测试一个前提条件，即 withdraw_amount 小于或等于 100000000000000000 wei，这是 ether 的 基本单位，相当于 0.1 ether。</p><p>如果使用大于该数量的 withdraw_amount 调用 withdraw 函数，则此处的 require 函数将导致合约执行停止并因异常而失败</p><p><code>msg.sender.transfer(withdraw_amount);</code>： 该行是实际提现。</p><ul><li>  msg 对象：所有合约都可以访问的输入之一，它表示触发此合约执行的交易</li><li>  sender 属性：交易的发件人地址</li><li>  transfer 函数：是一个内置函数，它将以太从合约传递到调用它的地址。向后读，这意味着将以太转移到触发此合约执行的 msg 的发送者</li><li>  transfer 函数将金额作为其唯一参数。我们将 withdraw_amount 值作为参数传递给上面几行声明的 withdraw 函数</li></ul><p><code>function () public payable &#123;&#125;</code>： 此函数是所谓的 “回退” 或默认函数，如果触发合约的交易未命名合约中的任何已声明函数或任何函数或未包含数据，则调用此函数</p><h3 id="编译水龙头合约"><a href="#编译水龙头合约" class="headerlink" title="编译水龙头合约"></a>编译水龙头合约</h3><p>现在我们有了第一个示例合约，需要使用 Solidity 编译器将 Solidity 代码转换为 EVM 字节码，以便它可以由 EVM 执行。</p><p>在编译页面，首先要选择与代码中<code>pragma solidity ^0.4.19</code>相同的 solidity 版本。然后点击<code>Compile Faucet.sol</code>编译程序。</p><p><img src="/2023/04/27/27Ethereum/14.png"></p><h3 id="在区块链上创建合约"><a href="#在区块链上创建合约" class="headerlink" title="在区块链上创建合约"></a>在区块链上创建合约</h3><p>我们写了合约并把它编译成字节码。现在，我们需要在以太坊区块链上 “注册” 合约。我们将使用测试网来测试我们的合约。</p><p>在区块链上注册合约涉及创建一个特殊交易，其目的地是一个 “零地址”，也就是地址为：<code>0x0000000000000000000000000000000000000000</code>。零地址是一个特殊地址，告诉以太坊区块链我们想要注册合约。不过我们不需要手动输入这么多个 0，Remix IDE 将为我们处理所有这些，并将交易发送到 MetaMask，由钱包账户确认提交。</p><p>将运行环境关联到 MetaMask 上的测试链，然后点击 <code>Deploy</code>部署合约<br><img src="/2023/04/27/27Ethereum/15.png"></p><p>部署完成后会生成一个合约地址。同时包含了一些合约的其他信息，像合约地址的余额：<code>balance</code>，调用方法名<code>withdraw</code>等。<br><img src="/2023/04/27/27Ethereum/16.png"></p><h2 id="与合约交互"><a href="#与合约交互" class="headerlink" title="与合约交互"></a>与合约交互</h2><p>以太坊合约是控制资金的程序，它在称为 EVM 的虚拟机内运行。它们由特殊交易创建，该交易提交其字节码以记录在区块链上。一旦他们在区块链上创建，他们就有了一个以太坊地址，就像钱包一样。只要有人将某个交易发送到合约地址，就会导致合约在 EVM 中运行，并将该合约作为其输入。</p><p>发送到合约地址的交易可能包含 ether 或数据或两者。如果它们含有 ether，则将其 “存入” 合约余额。如果它们包含数据，则数据可以在合约中指定命名函数并调用它，将参数传递给函数</p><h3 id="资助合约"><a href="#资助合约" class="headerlink" title="资助合约"></a>资助合约</h3><p>目前，合约在其历史记录中只有一个交易：合约创建交易。</p><p>合约也还没有以太（零余额）。那是因为我们没有在创建交易中向合约发送任何以太。</p><p>我们可以给合约发一些以太，打开 MetaMask，给合约的地址发送以太，就像发送给其他任何以太坊地址一样。</p><p><img src="/2023/04/27/27Ethereum/17.png"></p><p>当交易完成后，再看合约的余额。</p><p><img src="/2023/04/27/27Ethereum/18.png"></p><h3 id="调用合约"><a href="#调用合约" class="headerlink" title="调用合约"></a>调用合约</h3><p>接下来，让我们从水龙头中提取一些资金。要提现，我们必须构造一个调用 <code>withdraw</code> 函数的交易，并将 withdraw_amount 参数传递给它。为了使事情变得简单，Remix 将为我们构建该交易，并由MetaMask发送交易。</p><p>我们输入要体现的金额，然后点击<code>withdraw</code>，表示调用withdraw方法。<br><img src="/2023/04/27/27Ethereum/19.png"></p><p>该交易导致合约在 EVM 内部运行，当 EVM 运行水龙头合约的提现功能时，首先它调用 require 函数并验证我们的金额小于或等于允许的最大提现 0.1 以太；然后它调用 transfer 函数向我们发送以太，运行转账功能会产生一个内部交易，从合约的余额中withdraw_amount的以太币存入我们的钱包地址；</p><p>当交易完成后，可以看到合约中的余额减少了。并且钱包中会多一条交易记录</p><p><img src="/2023/04/27/27Ethereum/20.png"></p><p><img src="/2023/04/27/27Ethereum/21.png"></p><p>我们可以点击<code>在区块浏览器上查看</code>，查看这条交易的详细信息。</p><p><img src="/2023/04/27/27Ethereum/22.png">迟到</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;以太坊基础知识&quot;&gt;&lt;a href=&quot;#以太坊基础知识&quot; class=&quot;headerlink&quot; title=&quot;以太坊基础知识&quot;&gt;&lt;/a&gt;以太坊基础知识&lt;/h1&gt;&lt;h2 id=&quot;什么是以太坊&quot;&gt;&lt;a href=&quot;#什么是以太坊&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    <category term="以太坊" scheme="http://yaocl.cn/categories/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
    
    <category term="web3" scheme="http://yaocl.cn/tags/web3/"/>
    
    <category term="以太坊" scheme="http://yaocl.cn/tags/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
  </entry>
  
  <entry>
    <title>从CPU聊到Java内存模型</title>
    <link href="http://yaocl.cn/2023/03/30/jmm/"/>
    <id>http://yaocl.cn/2023/03/30/jmm/</id>
    <published>2023-03-30T13:06:41.000Z</published>
    <updated>2023-08-07T01:22:28.572Z</updated>
    
    <content type="html"><![CDATA[<p>当谈到<code>并发编程</code>时，Java 内存模型（Java Memory Model，简称 JMM）是一个关键概念。它定义了线程如何与主内存交互以及如何在自己的工作内存中存储数据。理解和遵守 Java 内存模型对于编写正确且高效的多线程程序至关重要。</p><p><code>注意：</code>Java 内存模型并不是 JVM 内存模型。JVM 内存模型指的是 JVM 内存是如何划分的，比如我们平常所说的堆、栈、方法区等。而 Java 内存模型定义了 Java 语言如何与内存进行交互，具体地说是 Java 语言运行时的变量，如何与我们的硬件内存进行交互。</p><h2 id="从-CPU-说起"><a href="#从-CPU-说起" class="headerlink" title="从 CPU 说起"></a>从 CPU 说起</h2><h3 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h3><p>在计算机中 CPU 负责计算，内存负责存储，每次运算 CPU 需要从内存中获取数据。但是 CUP 的运算速度远远大于内存的速度，这样会出现每次计算时 CPU 等待内存的情况。</p><p>为了弥补 CPU 和内存之间存在的速度差异，因此引入了 CPU 高速缓存，CPU 高速缓存介于 CPU 和内存之间。每次运算先从内存读取到 CPU 高速缓存中，CPU 再从 CPU 高速缓存中读取。</p><p>下面是我现在的使用的电脑，有三级缓存。<br><img src="/2023/03/30/jmm/1.png"></p><p>随着技术的发展，出现了多核 CPU，进一步提升了 CPU 的计算能力，但同时也引入了新的问题：缓存一致性。在多 CPU 下，每个 CPU 共享内存，同时每个 CPU 又有自己的高速缓存，如果多个 CPU 同时处理一块主内存区域的数据时，那该如何保证数据的正确。比如下面这段代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">i = i + <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>假设 i 初始值为 0，按照正常的逻辑 ，2 个 CPU 运算完成后 i 的值会是 2，但是因为高速缓存的存在，会有下面的运算过程。</p><ul><li>CPU1 读取 i 的初始值放到 CPU1 高速缓存中，</li><li>CPU2 读取 i 的初始值放到 CPU2 高速缓存中，</li><li>CPU1 进行运算，得出结果 1，运算结束，写回内存，此时内存 i 的值为 1。</li><li>CPU2 进行运算，得出结果 1，运算结束，写回内存，此时内存 i 的值为 1。</li></ul><p>那么，如何保证数据的一致性呢？答案是：缓存一致性协议。在多 CPU 系统中，一种用来保持多个高速缓存之间，以及高速缓存与主存储器之间数据一致的机制。</p><p><img src="/2023/03/30/jmm/2.png"></p><p>在不同的 CPU 中，会使用不同的缓存一致性协议。例如 奔腾系列的 CPU 中使用的是 MESI 协议， AMD 系列 CPU 中使用的是 MOSEI 协议，Intel 的 core i7 使用 MESIF 协议。</p><h3 id="处理器优化和指令重排序"><a href="#处理器优化和指令重排序" class="headerlink" title="处理器优化和指令重排序"></a>处理器优化和指令重排序</h3><p>为了使 CPU 内部运算单元被充分利用，CPU 会对输入的代码进行乱序执行（Out-Of-Order Execution）优化，CPU 会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，<code>但不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致</code>。</p><p><img src="/2023/03/30/jmm/3.png"></p><p>如果是在单核处理器上运行，这是没有问题的。但是在多核处理器下，如果存在一个核的计算任务依赖另一个核的计算任务的中间结果，而且对相关数据读写没做任何防护措施，那么其顺序性并不能靠代码的先后顺序来保证。</p><p><img src="/2023/03/30/jmm/4.png"></p><p>除了 CPU 会对代码进行优化处理，很多现代编程语言的编译器也会做类似的优化，比如像 Java 的即时编译器(JIT)会做<code>指令重排序</code>。</p><p>处理器优化其实也是重排序的一种类型，重排序可以分为三种类型：</p><ul><li>编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。</li><li>指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</li><li>内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</li></ul><p><img src="/2023/03/30/jmm/5.png"></p><h2 id="并发编程的问题"><a href="#并发编程的问题" class="headerlink" title="并发编程的问题"></a>并发编程的问题</h2><p>并发编程的三个特点：<code>可见性</code>、<code>有序性</code>、<code>原子性</code>。如果从更深层次看这三个问题，其实就是上面讲的<code>缓存一致性</code>、<code>处理器优化</code>、<code>指令重排序</code>造成的。</p><p>缓存一致性问题其实就是可见性问题，处理器优化可能会造成原子性问题，指令重排序会造成有序性问题。</p><p>了解过 JVM 得都清楚，JVM 运行时内存区域是分片的，分为栈、堆等，其实这些都是 JVM 定义的逻辑概念。在传统的硬件内存架构中是没有栈和堆这种概念。从下图中可以看出栈和堆既存在于高速缓存中又存在于主内存中。</p><p><img src="/2023/03/30/jmm/6.png"></p><p>Java 一直秉持着「Write Once, Run Anywhere」，即一次编译哪里都可以运行的理念。为了达到这个目地必须要解决上面这些问题，Java 定义出了一套内存模型， 规范内存的读写操作。</p><h2 id="Java-内存模型"><a href="#Java-内存模型" class="headerlink" title="Java 内存模型"></a>Java 内存模型</h2><p>Java 内存模型用于屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台都能达到一致的内存访问效果。</p><p>Java 内存模型定义了程序中各个变量的访问规则，即在 Java 虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。这里说的变量包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数。因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。</p><h3 id="主内存和工作内存"><a href="#主内存和工作内存" class="headerlink" title="主内存和工作内存"></a>主内存和工作内存</h3><p>Java 内存模型规定所有的变量都存储在主内存（Main Memory）中。每条线程还有自己的工作内存（Working Memory），工作内存中保留了该线程使用到的变量的主内存的副本。</p><p>工作内存是 JMM 的一个抽象概念，并不真实存在，它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。</p><p>线程对变量的操作必须是在工作内存中，不能直接操作主内存。不同的线程间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。</p><p><img src="/2023/03/30/jmm/7.png"></p><h3 id="内存间的交互"><a href="#内存间的交互" class="headerlink" title="内存间的交互"></a>内存间的交互</h3><p>关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存，以及如何从工作内存同步回主内存的细节，Java 内存模型定义了 8 种操作来完成。Java 虚拟机实现的时候必须保证下面提及的每一种操作都是原子的、不可再分的。</p><ul><li><code>lock</code>（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。</li><li><code>unlock</code>（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。</li><li><code>read</code>（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的 load 动作使用。</li><li><code>load</code>（载入）：作用于工作内存的变量，它把 read 操作从主内存中得到的变量值放入工作内存的变量副本中。</li><li><code>use</code>（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。</li><li><code>assign</code>（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。</li><li><code>store</code>（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的 write 操作使用。</li><li><code>write</code>（写入）：作用于主内存的变量，它把 store 操作从工作内存中得到的变量的值放入主内存的变量中。</li></ul><p>JMM 还规定了上述 8 种基本操作，需要满足以下规则：</p><p>有关变量拷贝过程的规则:</p><ul><li>read 和 load 必须成对出现；store 和 write 必须成对出现。即不允许一个变量从主内存读取了但工作内存不接受，或从工作内存发起回写了但主内存不接受的情况出现。</li><li>不允许一个线程丢弃它的最近 assign 的操作，即变量在工作内存中改变了之后必须把变化同步到主内存中。</li><li>不允许一个线程无原因的（没有发生过任何 assign 操作）把数据从工作内存同步回主内存中。</li><li>一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load 或 assign ）的变量。换句话说，就是对一个变量实施 use 和 store 操作之前，必须先执行过了 load 或 assign 操作。</li></ul><p>有关加锁的规则:</p><ul><li>一个变量在同一个时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一条线程重复执行多次，多次执行 lock 后，只有执行相同次数的 unlock 操作，变量才会被解锁。所以 lock 和 unlock 必须成对出现。</li><li>如果对一个变量执行 lock 操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行 load 或 assign 操作初始化变量的值。</li><li>如果一个变量事先没有被 lock 操作锁定，则不允许对它执行 unlock 操作，也不允许去 unlock 一个被其他线程锁定的变量。</li><li>对一个变量执行 unlock 操作之前，必须先把此变量同步到主内存中（执行 store 和 write 操作）</li></ul><p><img src="/2023/03/30/jmm/8.png"></p><p>一个变量从主内存拷贝到工作内存，再从工作内存同步回主内存的流程为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">|主内存| -&gt; read -&gt; load -&gt; |工作内存| -&gt; use -&gt; |Java线程| -&gt; assign -&gt; |工作内存| -&gt; store -&gt; write -&gt; |主内存|</span><br></pre></td></tr></table></figure><h3 id="可见性和有序性问题"><a href="#可见性和有序性问题" class="headerlink" title="可见性和有序性问题"></a>可见性和有序性问题</h3><p>在上图中，Java 中每个线程只能操作自己得工作内存，这样就有可能产生可见性问题。</p><p>对于在主内存中的变量 A，不同线程中的工作内存中有着不同得副本 A1,A2,A3。不同线程的<code>read</code>和<code>load</code>、<code>store</code>和<code>write</code>不一定是连续的，中间可以插入其他命令，Java 只能保证 read 和 load、store 和 write 的执行<code>对于一个线程而言是连续的，但是并不保证不同线程的 read 和 load、store 和 write 的执行是连续的</code>。</p><p>比如下图中：</p><p><img src="/2023/03/30/jmm/9.png"></p><p>两个线程 A、B，其中 A 写入共享变量，B 读取变量。 假设 A 先写。B 再读取，按照正常得逻辑应该是<code>storeA -&gt; writeA -&gt; readB -&gt; loadB</code>。但是 Java 并不能保证不同线程的执行是连续的，可能得会有这样的顺序<code>storeA -&gt; readB -&gt; writeA -&gt; load</code>，在 A 还没写完时，B 已经读取了共享变量得旧值。</p><p>通过上述的分析可以发现，<code>可见性问题的本身，也是由于不同线程之间的执行顺序得不到保证导致的</code>，因此可以将它的解决和有序性合并，即对 Java 一些指令的操作顺序进行限制，这样既保证了有序性，又解决了可见性。</p><h3 id="Happens-Before-原则"><a href="#Happens-Before-原则" class="headerlink" title="Happens-Before 原则"></a>Happens-Before 原则</h3><p>Happens-Before 规则保证：<code>前面的操作的结果对后面的操作一定是可见的</code>。</p><p>Happens-Before 规则本质上是一种顺序约束规范，用来约束编译器的优化行为。就是说，为了执行效率，我们允许编译器的优化行为，但是为了保证程序运行的正确性，我们要求编译器优化后需要满足 Happens-Before 规则。</p><p>根据类别，可以将 Happens-Before 规则分为了以下 4 类：</p><p>操作的顺序：</p><ul><li>程序顺序规则： 如果代码中操作 A 在操作 B 之前，那么同一个线程中 A 操作一定在 B 操作前执行，即在本线程内观察，所有操作都是有序的。</li><li>传递性： 在同一个线程中，如果 A 先于 B ，B 先于 C 那么 A 必然先于 C。</li></ul><p>锁和 volatile：</p><ul><li>监视器锁规则： 监视器锁的解锁操作必须在同一个监视器锁的加锁操作前执行。</li><li>volatile 变量规则： 对 volatile 变量的写操作必须在对该变量的读操作前执行，保证时刻读取到这个变量的最新值。</li></ul><p>线程和中断：</p><ul><li>线程启动规则： Thread#start() 方法一定先于该线程中执行的操作。</li><li>线程结束规则： 线程的所有操作先于线程的终结。</li><li>中断规则： 假设有线程 A，其他线程 interrupt A 的操作先于检测 A 线程是否中断的操作，即对一个线程的 interrupt() 操作和 interrupted() 等检测中断的操作同时发生，那么 interrupt() 先执行。</li></ul><p>对象生命周期相关：</p><ul><li>终结器规则： 对象的构造函数执行先于 finalize() 方法。</li></ul><p>根据 Happens-Before 原则，要确保上图中得问题能够正常运行，只要在共享变量上加个<code>volatile</code>即可。</p><h3 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h3><p>Java 底层是怎么实现这些规则来保证有序性和可见性？ 通过内存屏障（memory barrier）。</p><p>内存屏障是一种 CPU 指令，用来禁止处理器指令发生重排序。常见有 4 种屏障：</p><ul><li>LoadLoad 屏障 - 对于这样的语句<code>Load1; LoadLoad; Load2</code>，在 Load2 及后续读取操作要读取的数据被访问前，保证 Load1 要读取的数据被读取完毕。</li><li>StoreStore 屏障 - 对于这样的语句 <code>Store1; StoreStore; Store2</code>，在 Store2 及后续写入操作执行前，保证 Store1 的写入操作对其它处理器可见。</li><li>LoadStore 屏障 - 对于这样的语句 <code>Load1; LoadStore; Store2</code>，在 Store2 及后续写入操作被执行前，保证 Load1 要读取的数据被读取完毕。</li><li>StoreLoad 屏障 - 对于这样的语句 <code>Store1; StoreLoad; Load2</code>，在 Load2 及后续所有读取操作执行前，保证 Store1 的写入对所有处理器可见。它的开销是四种屏障中最大的（冲刷写缓冲器，清空无效化队列）。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。</li></ul><p>比如下面这段代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileTest</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> <span class="keyword">boolean</span> flag = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> i = <span class="number">0L</span>;</span><br><span class="line">        flag = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">while</span> (!flag) &#123;</span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;count = &quot;</span> + i);</span><br><span class="line">        flag = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>编译成 CPU 汇编指令后，被<code>volatile</code>修饰得flag变量在进行写操作时会有一个<code>lock</code>指令</p><p><img src="/2023/03/30/jmm/10.png"></p><p>在 Intel CPU 中<code>lock</code>指令功能如下：</p><ul><li>被修饰的汇编指令成为“原子的”</li><li>与被修饰的汇编指令一起提供<code>内存屏障</code>效果</li></ul><h3 id="Java-语言级别的处理"><a href="#Java-语言级别的处理" class="headerlink" title="Java 语言级别的处理"></a>Java 语言级别的处理</h3><p>上面说的这些都是 Java 底层的处理逻辑，我们真正在使用 Java 时，并不需要关心底层的编译器优化、缓存一致性等问题，Java 已经提供了关键字来处理并发安全问题。。所以，<code>Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用</code>。</p><p>Java 语言级别中来解决要解决原子性、有序性和一致性的问题的方法。</p><h4 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h4><p>使用<code>synchronized</code>来保证方法和代码块内的操作是原子性的。</p><h4 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h4><p><code>volatile</code>关键字其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在<code>每次是用之前都从主内存刷新</code>。因此，可以使用 volatile 来保证多线程操作时变量的可见性。</p><p>另外，synchronized 和 final 两个关键字也可以实现可见性。只不过实现方式不同。</p><h4 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h4><p><code>volatile</code> 关键字会禁止指令重排。<code>synchronized</code> 关键字保证同一时刻只允许一条线程操作。</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul><li><a href="https://dunwu.github.io/javacore/pages/d4e06f">https://dunwu.github.io/javacore/pages/d4e06f</a></li><li><a href="https://bbs.huaweicloud.com/blogs/338476">https://bbs.huaweicloud.com/blogs/338476</a></li><li><a href="https://github.com/TangBean/Java-Concurrency-in-Practice/blob/master/Ch0-Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/00-Java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B.md">https://github.com/TangBean/Java-Concurrency-in-Practice/blob/master/Ch0-Java并发编程基础/00-Java内存模型.md</a></li></ul>]]></content>
    
    
    <summary type="html">Java 内存模型用于屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台都能达到一致的内存访问效果。</summary>
    
    
    
    <category term="JAVA" scheme="http://yaocl.cn/categories/JAVA/"/>
    
    
    <category term="JAVA" scheme="http://yaocl.cn/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>SkyWalking，分布式链路追踪</title>
    <link href="http://yaocl.cn/2023/02/25/26SkyWalking/"/>
    <id>http://yaocl.cn/2023/02/25/26SkyWalking/</id>
    <published>2023-02-25T09:36:06.000Z</published>
    <updated>2023-05-22T01:00:59.056Z</updated>
    
    <content type="html"><![CDATA[<p>随着业务的发展，软件架构也越来越复杂，为了适应海量用户高并发请求，系统中的组件也逐渐的变为分布式，单体服务变为微服务、缓存变为分布式缓存、组件通信变为分布式消息。</p><p>系统进行交互时，一个请求往往需要调用多个服务，当需要排查问题时，搞清楚服务之间的调用关系，服务与服务的调用顺序就变得重要起来。</p><p><img src="/2023/02/25/26SkyWalking/1.png"></p><h2 id="什么是分布式链路追踪"><a href="#什么是分布式链路追踪" class="headerlink" title="什么是分布式链路追踪"></a>什么是分布式链路追踪</h2><p>分布式链路追踪就是将一次分布式请求还原成调用链路，将一次分布式请求的调用情况集中展示，比如各个服务节点上的耗时、请求具体到达哪台机器上、每个服务节点的请求状态等等。</p><p><img src="/2023/02/25/26SkyWalking/2.png"></p><p>链路追踪最早可以追溯到谷歌的 Dapper 系统，但是 Dapper 链路追踪系统并没有开源，不过谷歌发表了一篇论文：《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》，讲述了分布式链路追踪的理论和 Dapper 的设计思想，特别是微服务架构中链路追踪的概念、数据表示、埋点、传递、收集、存储与展示等技术细节。</p><p>Dapper 中有几个关键的技术点来表示链路的信息：Trace、Span、Annotations。</p><h3 id="Trace"><a href="#Trace" class="headerlink" title="Trace"></a>Trace</h3><p>Trace 表示一次请求经过所有服务的路径。用一个全局唯一的 traceid 来标识。</p><h3 id="Span"><a href="#Span" class="headerlink" title="Span"></a>Span</h3><p>Span 用来表示父子关系，同一层级 parent id 相同，span id 不同，span id 从小到大表示请求的顺序。</p><h3 id="Annotations"><a href="#Annotations" class="headerlink" title="Annotations"></a>Annotations</h3><p>Annotations 用于用户自定义事件，用来辅助定位问题。<br>通常包含四个注解信息：</p><p>cs：Client Start，表示客户端发起请求；</p><p>sr：ServerReceived，表示服务端收到请求；</p><p>ss：Server Send，表示服务端完成处理，并将结果发送给客户端；</p><p>cr：ClientReceived，表示客户端获取到服务端返回信息；</p><p><img src="/2023/02/25/26SkyWalking/3.png"></p><h3 id="采样和存储"><a href="#采样和存储" class="headerlink" title="采样和存储"></a>采样和存储</h3><p>为了减少性能消耗，避免存储资源的浪费，dapper 并不会上报所有的 span 数据，而是使用采样的方式。举个例子，每秒有 1000 个请求访问系统，如果设置采样率为 1/1000，那么只会上报一个请求到存储端。</p><p>链路中的 span 数据经过收集和上报后会集中存储在一个地方，Dapper 使用了 BigTable 数据仓库，常用的存储还有 ElasticSearch, HBase, In-memory DB 等。</p><p>目前业界的链路追踪系统，如 Twitter 的 Zipkin，Uber 的 Jaeger，阿里的鹰眼，美团的 Mtrace 以及本文介绍的 SkyWalking，大多数都是受谷歌 Dapper 的启发。</p><h2 id="SkyWalking"><a href="#SkyWalking" class="headerlink" title="SkyWalking"></a>SkyWalking</h2><p>SkyWalking 是一个优秀的国产开源 APM（Application Performance Management） 组件，是一个对分布式应用程序集群的业务运行情况进行追踪、告警和分析的系统。2015 年由个人吴晟开源 ， 2017 年加入 Apache 孵化器。</p><p>SkyWalking 支持 SpringBoot、SpringCloud、dubbo 集成，代码无侵入，通信方式采用 GRPC，性能较好，实现方式是 探针，支持告警，支持 JVM 监控，支持全局调用统计等等，功能较完善。</p><p>SkyWalking 的核心是数据分析和度量结果的存储平台，通过 HTTP 或 gRPC 方式向 SkyWalking Collecter 提交分析和度量数据。</p><h3 id="SkyWalking-架构"><a href="#SkyWalking-架构" class="headerlink" title="SkyWalking 架构"></a>SkyWalking 架构</h3><p><img src="/2023/02/25/26SkyWalking/4.png"></p><p>SkyWalking Collecter 对数据进行分析和聚合，存储到 Elasticsearch、H2、MySQL、TiDB 等其一即可，最后可以通过 SkyWalking UI 的可视化界面对最终的结果进行查看。</p><p>Skywalking 支持从多个来源和多种格式收集数据：多种语言的 Skywalking Agent 、Zipkin v1/v2 、Istio 勘测、Envoy 度量等数据格式。</p><p>在上面的架构图中我们需要关注的只有 SkyWalking Collecter、SkyWalking UI 和 存储设备，SkyWalking Collecter、SkyWalking UI 官方下载安装包内已包含，最终我们只需考虑存储设备即可。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>本文以 SkyWalking9.4.0 演示，SkyWalking 下载地址：<a href="http://skywalking.apache.org/downloads/">http://skywalking.apache.org/downloads/</a></p><p><img src="/2023/02/25/26SkyWalking/5.png"></p><p>以 Linux 为例。启动脚本在 bin/startup.sh。会启动两个服务:</p><p>1、 skywalking-oap-server 服务</p><p>skywalking-oap-server 服务启动后会暴露 11800 和 12800 两个端口，分别为收集监控数据的端口 11800 和接受前端请求的端口 12800，可以在 config/applicaiton.yml 修改端口，数据库存储等。默认使用 H2 数据库存储。</p><p><img src="/2023/02/25/26SkyWalking/6.png"></p><p>2、 skywalking-web-ui 服务</p><p>SkyWalking UI 界面的数据是通过请求 SkyWalking OAP 服务来获得。</p><p>skywalking-web-ui 服务会占用 8080 端口， 可以在 webapp/applicaiton.yml 修改端口。</p><p><img src="/2023/02/25/26SkyWalking/7.png"></p><p>启动成功之后，访问 Skywalking UI 界面：<a href="http://127.0.0.1:8080/">http://127.0.0.1:8080/</a></p><h3 id="项目集成"><a href="#项目集成" class="headerlink" title="项目集成"></a>项目集成</h3><p>监控 Java 项目，需要下载 Java 所需的探针 Skywalking Agent。</p><p><img src="/2023/02/25/26SkyWalking/8.png"></p><p>在 IDEA 中使用 SkyWalking， 配置 java 启动参数</p><p><img src="/2023/02/25/26SkyWalking/9.png"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 探针的位置</span></span><br><span class="line">-javaagent:/kywalking-agent所在目录/skywalking-agent/skywalking-agent.jar</span><br><span class="line"><span class="comment">//服务名称</span></span><br><span class="line">-Dskywalking.agent.service_name=system</span><br><span class="line"><span class="comment">//skywalking collector的地址</span></span><br><span class="line">-Dskywalking.collector.backend_service=<span class="number">192.168</span><span class="number">.68</span><span class="number">.28</span>:<span class="number">11800</span></span><br></pre></td></tr></table></figure><p>配置完，启动 Java 项目。</p><p><img src="/2023/02/25/26SkyWalking/10.png"></p><h3 id="展示效果"><a href="#展示效果" class="headerlink" title="展示效果"></a>展示效果</h3><p>链路拓扑</p><p><img src="/2023/02/25/26SkyWalking/11.png"></p><p>每个请求的调用链路</p><p><img src="/2023/02/25/26SkyWalking/12.png"></p><p>概览全局页</p><p><img src="/2023/02/25/26SkyWalking/13.png"></p>]]></content>
    
    
    <summary type="html">分布式链路追踪就是将一次分布式请求还原成调用链路，将一次分布式请求的调用情况集中展示，比如各个服务节点上的耗时、请求具体到达哪台机器上、每个服务节点的请求状态等等。</summary>
    
    
    
    <category term="分布式链路追踪" scheme="http://yaocl.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"/>
    
    
    <category term="分布式链路追踪" scheme="http://yaocl.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"/>
    
  </entry>
  
  <entry>
    <title>什么是DAPP</title>
    <link href="http://yaocl.cn/2023/01/13/25dapp/"/>
    <id>http://yaocl.cn/2023/01/13/25dapp/</id>
    <published>2023-01-13T07:36:06.000Z</published>
    <updated>2023-05-22T01:00:59.053Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DAPP（分布式应用），区块链新物种，去中心化-App"><a href="#DAPP（分布式应用），区块链新物种，去中心化-App" class="headerlink" title="DAPP（分布式应用），区块链新物种，去中心化 App"></a>DAPP（分布式应用），区块链新物种，去中心化 App</h2><p>简单来说，DAPP 和普通的 App 原理一样，除了他们是完全去中心化的，由类似以太坊网络本身自己的节点来运作的 DAPP，不依赖于任何中心化的服务器，DAPP 是去中心化的，可以完全自动地运行。</p><h3 id="1、DAPP（分布式应用）是什么"><a href="#1、DAPP（分布式应用）是什么" class="headerlink" title="1、DAPP（分布式应用）是什么"></a>1、DAPP（分布式应用）是什么</h3><p>DAPP 是 Decentralized Application 的缩写，中文叫分布式应用/去中心化应用，通常来说，不同的 DAPP 会采用不同的底层区块链开发平台和共识机制，或者自行发布代币（也可以使用基于相同区块链平台的通用代币）。</p><p><img src="/2023/01/13/25dapp/1.png"></p><p>符合以下 3 个条件的应用可以认为是一个 DAPP（分布式应用）：</p><p>运行在分布式网络上；</p><p>参与者信息被安全存储，隐私得到很好的保护；</p><p>通过网络节点去中心化操作。</p><p><img src="/2023/01/13/25dapp/2.png"></p><h3 id="2、DAPP-的四个特征"><a href="#2、DAPP-的四个特征" class="headerlink" title="2、DAPP 的四个特征"></a>2、DAPP 的四个特征</h3><p>DAPP 不同的底层区块链开发平台就好比手机的 IOS 系统和 Android 系统，是各 DAPP 的底层生态环境，DAPP 就是底层区块链平台生态上衍生的各种分布式应用，也是区块链世界中的基础服务提供方，DAPP 于区块链，就好比 APP 之于 IOS 和 Android。</p><p><img src="/2023/01/13/25dapp/3.png"></p><p>一个真正的 DAPP 应用，需要同时满足一下几个条件：</p><p>应用必须完全开源、自治，且没有一个实体控制着该应用超 51%Token。该应用必须能够根据用户的反馈及技术要求进行升级，且应用升级必须由大部分用户达成共识之后方可进行；</p><p>应用的数据必须加密后存储在公开的区块链上；</p><p>应用必须拥有 Token 机制（可用基于相同底层区块链平台的通用代币或自行发行新币），矿工或应用维护节点需要得到代币奖励；</p><p>应用代币的产生必须依据标准的加密算法，有价值的节点可以根据该算法获取应用的代币奖励。</p><h3 id="3、DAPP-应该制定类似宪法章程的智能合约"><a href="#3、DAPP-应该制定类似宪法章程的智能合约" class="headerlink" title="3、DAPP 应该制定类似宪法章程的智能合约"></a>3、DAPP 应该制定类似宪法章程的智能合约</h3><p>区块链的早期应用是货币交易、金融交易，随后是智能资产，包括房产、汽车等实物资产和知识产权、司法认证、公共档案等虚拟资产。</p><p>未来随着智能合约的发展，智能合约构建的组织如同现实商业社会一样的运行，这样形成的去中心化组织网络会变得极其复杂和自治，会出现各种形态：</p><p>Dapp（去中心化应用）<br>DAO（去中心化自治组织）<br>DAC（去中心化自治公司）<br>DAS（去中心化自治社会）<br>在没有人类干预的前提下，通过预先设定的业务规则自动运行。</p><p>一个简单的智能合约例子：2 个人打赌一场球赛，筹码会暂时保存到网络，球赛结束后，网络中预先设定的智能合约会校验在线结果，然后把钱打到赢家账户。</p><p><img src="/2023/01/13/25dapp/4.png"></p><h2 id="DAPP-优势"><a href="#DAPP-优势" class="headerlink" title="DAPP 优势"></a>DAPP 优势</h2><p>DAPP 用户体验由于区块链特有的数据确权、价值传递功能，可以消除很多影响用户体验、提升开发难度的因素：</p><p>（1）用户实名认证流程变更</p><p>DAPP 场景下，如果公链内支持数据共享，那么开发者只需要完成数据匹配，就可以从其他生态内的开发者处共享到用户实名资料，同时只需要支付 Token 即可；同时对用户而言，这也算是 POD（Proof of Data）挖矿模式，同样有收益，算是合作共赢；比如公信宝“布洛克城”。</p><p>（2）交易安全性提升</p><p>随着交易大爆炸的出现，交易效率的需求日渐提升；原来基于金融中介（例如银行、VISA 等）的交易处理方式效率低，信用生产成本高，为了降低这种风险，现在需要投入大量的风控成本进行审核但收效甚微。而基于 UTXO（Unspent Transaction Output）的区块链技术可以简单解决这个问题，而不需要对现有业务流程做任何变动升级，比如央行“数字票据交易平台”。</p><p>（3）行业生产关系的变更</p><p>区块链的数据确权、价值网络的两个属性可以变更现在的互联网生产关系，促使行业类应用出现，用户不用再为选择焦虑症发愁，典型的例子就是互联网视频；版权成本高昂导致腾讯、爱奇艺、搜狐只能付出极高的成本打击盗版、而用户追剧则需要在不同的平台购买 VIP 账号，如果基于区块链技术，剧集可以被版权方确权，用户不管通过任何渠道观看剧集，其支付的费用都可以 Token 化，然后由区块链基于价值网络分配给版权方、渠道方。在此生态内，盗版的问题被解决（比如 B 站 UGC 上传等），版权争夺成本下降，开发者专注于用户体验的提升，获取用户的方式也从版权壁垒变成社群运营，体验比拼，真正的互联网运营时代将会到来。例如当年的“火花电视”将各个平台的电视剧做到一站式观看，但是私自添加广告，影响版权方利益，最后被禁就是例子。</p><p>（4）项目运维成本降低</p><p>项目的运维成本往往高于开发成本，我们评估资源阈值的依据是预计最大流量，如果评估太低，则容易宕机，太高则浪费严重，例如：大多数产品应该都面临过运营活动带来的高并发问题，一次营销爆服务器的现象屡见不鲜，而添置服务器所带来的成本浪费则令人头疼，目前几个开发中的底层链（例如 EOS、Elastos）的资源分配模型基于用户持有 Token 的数量，这就意味着我们可以在某个活动开始前临时性购买 Token（资源），并在日常运维中将其释放（卖出），极大减少了运维成本。</p><p>（5）技术开发成本降低</p><p>目前项目开发通常会评估四个版本：iOS、Android、小程序、Web，理论上 DAPP 类似小程序，设计思想是无需安装，用完即走，所有的计算都在线上完成，本地禁止创建进程，系统自动创建或查找本地、周边、链内的其他微服务。</p><h2 id="DAPP-的劣势"><a href="#DAPP-的劣势" class="headerlink" title="DAPP 的劣势"></a>DAPP 的劣势</h2><p>（1）产品设计思路的颠覆</p><p>目前互联网产品设计思路是“小步快跑、高速迭代”，这个方式在纯 DAPP 应用中应该会出现较大问题。简单来说，现有的 APP 都基于自有服务器，重大问题迭代强行刷新版本即可，但 DAPP 基于分布式的区块链网络，一旦提交上线出现核心 bug 很难迭代。</p><p>拿 The DAO 来举个例子，The DAO 的核心漏洞如果是中心化处理，只需要下线更改 Bug 即可，但是以太坊却只能以硬分叉解决，这就是 DAPP 与现有 APP 设计思想的不同，在 MVP1.0 的调研阶段，一定要确认核心机制不出意外。</p><p>（2）公链处理效率低</p><p>目前成功落地的底层链都存在效率低、资源占用不合理问题，比特币的 5TPS、以太坊的 25TPS 跟 VISA 的 1300TPS 几乎没有可对比性。所以，目前公链并不适合商业化应用开发，如果借用其中几个技术（不涉及实时交易）倒是没有问题，比如积分交易、版权分享等。</p><p>（3）研发风险大</p><p>现在尚未出现普适性质的公链，就好像 PC 时代的 Windows、Mac OS；智能机时代的 iOS、Android。所以，基于某条公链的开发就要承担如果该公链被淘汰后血本无归的风险，好比当年的塞班开发者，或许跨链技术可以解决，但谁知道呢？综上所述，从互联网生态意义上来说，区块链技术是其底层结构的重要部分，未来所有的应用都需要考虑与其结合，也可能会有更多的全新应用模式出现。</p><h2 id="底线"><a href="#底线" class="headerlink" title="底线"></a>底线</h2><p>网上看到一句话说：DAPP 是技术进化的下一个合乎逻辑的步骤。我觉得有道理，区块链带来的人们的共识和数据的公开不可篡改，在这个基础上不依赖于人来执行的智能合约成为了可能，于是一切 App 的底层规则也就变了。</p>]]></content>
    
    
    <summary type="html">DAPP 和普通的 App 原理一样，除了他们是完全去中心化的，由类似以太坊网络本身自己的节点来运作的 DAPP，不依赖于任何中心化的服务器，DAPP 是去中心化的，可以完全自动地运行。</summary>
    
    
    
    <category term="web3" scheme="http://yaocl.cn/categories/web3/"/>
    
    
    <category term="web3" scheme="http://yaocl.cn/tags/web3/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务框架Seata</title>
    <link href="http://yaocl.cn/2022/12/19/24seata/"/>
    <id>http://yaocl.cn/2022/12/19/24seata/</id>
    <published>2022-12-19T06:33:18.000Z</published>
    <updated>2023-05-22T01:00:59.053Z</updated>
    
    <content type="html"><![CDATA[<p>分布式事务基础</p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==&mid=2247484102&idx=1&sn=58aca57cc3c96f64af6c68e9944918d7&chksm=fcafc744cbd84e52da07629c679a9915ee9cb7ba5698aee5934429b19a95ce2a402c07dca756&token=1611733318&lang=zh_CN#rd">&lt;&lt;分布式事务基础理论&gt;&gt;</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==&mid=2247484148&idx=1&sn=2e5395cf06ce1fcf5fd52b1c4381ea49&chksm=fcafc776cbd84e600b244ba4040f1cdd8b4845bb3a1ec144497a41e4b65652468c621f9be8dd&token=1611733318&lang=zh_CN#rd">&lt;&lt;分布式事务解决方案&gt;&gt;</a></p><p>Seata 一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。</p><h2 id="Seata-全局框架"><a href="#Seata-全局框架" class="headerlink" title="Seata 全局框架"></a>Seata 全局框架</h2><p>Seata 的设计思路是将一个分布式事务理解成一个全局事务下面挂了多个分支事务，而一个分支事务是一个满足 ACID 的本地事务，因此我们可以操作分布式事务像操作本地事务一样。</p><p>在 Seata 内部定义了三个模块来处理全局事务和分支事务：</p><ul><li>  Transaction Coordinator（TC) - 事务协调者: 维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。</li><li>  Transaction Manager (TM)-  事务管理器： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。</li><li>  Resource Manager (RM)  - 资源管理器： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。</li></ul><p>Seata 提供的 AT、TCC、SAGA 和 XA 事务模式，都是基于这三个模块进行的。Seata 整体的执行步骤为：</p><ol><li> TM 向 TC 申请开启一个全局事务，TC 创建全局事务并返回一个唯一的 XID，XID 会在全局事务的上下文中传播。</li><li> RM 向 TC 注册分支事务，该分支事务归属于拥有相同 XID 的全局事务。</li><li> TM 向 TC 发起全局的提交或回滚。</li><li> TC 调度 XID 下的所有分支事务提交或回滚。</li></ol><p><img src="/2022/12/19/24seata/1.png"></p><h3 id="AT-模式"><a href="#AT-模式" class="headerlink" title="AT 模式"></a>AT 模式</h3><p>在<a href="https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==&mid=2247484148&idx=1&sn=2e5395cf06ce1fcf5fd52b1c4381ea49&chksm=fcafc776cbd84e600b244ba4040f1cdd8b4845bb3a1ec144497a41e4b65652468c621f9be8dd&token=1611733318&lang=zh_CN#rd">《分布式事务解决方案》</a>中介绍了常见的几种方案，总的来说主要分为两类：对业务无入侵和有入侵的方案。无入侵方案主要有基于数据库 XA 协议，虽然 XA 协议与业务代码解耦，但是它必须要求数据库对 XA 协议的支持，且 XA 协议会造成事务资源长时间得不到释放，锁定周期长，性能很差。有入侵的方案都需要通过在应用层做手脚，比如很出名的 TCC 方案，基于 TCC 也有很多成熟的框架，如 ByteTCC、tcc-transaction 等。</p><p>针对以上事务解决方案的痛点，Seata 提出了 AT 模式，<code>也是Seata默认的事务模式</code>。</p><p>AT 模式的实现原理是在数据源做了一层代理(DataSourceProxy)，在代理层中 Seata 加入了一些额外的逻辑，包括解析 SQL，把业务数据在更新前后的数据镜像组织成回滚日志，并将 undo log 日志插入 undo_log 表中，保证每条更新数据的业务 sql 都有对应的回滚日志存在。</p><p>AT 模式的执行过程</p><ul><li>  一阶段：</li></ul><p>Seata 拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成<code>before image</code>，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成<code>after image</code>，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。最后生成的<code>before image</code>和<code>after image</code>会保存到 undo log 表中</p><p><img src="/2022/12/19/24seata/2.png"></p><ul><li>  二阶段：</li></ul><p>如果是提交，因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。</p><p><img src="/2022/12/19/24seata/3.png"></p><p>如果是回滚，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用<code>before image</code>还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。</p><p><img src="/2022/12/19/24seata/4.png"></p><p>AT 模式的一阶段、二阶段提交和回滚均由 Seata 框架自动生成，用户只需编写业务 SQL，便能轻松使用分布式事务，AT 模式是一种对业务无任何侵入的分布式事务解决方案。</p><h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p>Seata 分 TC、TM 和 RM 三个角色，TC（Server 端）为单独服务端部署，TM 和 RM（Client 端）由业务系统集成。</p><h3 id="服务端部署"><a href="#服务端部署" class="headerlink" title="服务端部署"></a>服务端部署</h3><ol><li> 下载启动包：<a href="https://github.com/seata/seata/releases">https://github.com/seata/seata/releases</a></li><li> 建表，主要的表有三个：</li></ol><ul><li><p>  全局事务：global_table</p></li><li><p>  分支事务：branch_table</p></li><li><p>全局锁：lock_table</p><p>  在 MySQL 中，创建一个名为 seata 的数据库实例。创建相关表的脚本在 <code>seata--&gt;script--&gt;server--&gt;db</code>目录下</p></li></ul><ol><li> 设置配置中心和注册中心</li></ol><ul><li><p>  搭建 nacos，具体的搭建过程自行查资料</p></li><li><p>配置中心： <code>seata--&gt;conf--&gt;application.yml</code> 修改 seata.config.type=”nacos”,在 <code>seata--&gt;conf--&gt;application.example.yml</code> 中 seata.config.nacos 下有相关的 nacos 配置，将其复制到 application.yml 下，并将 nacos 相关的数据配置完整。</p><p>  设置配置中心可以参考官网：<a href="https://seata.io/zh-cn/docs/user/configuration/nacos.html">https://seata.io/zh-cn/docs/user/configuration/nacos.html</a></p></li><li><p>  注册中心： <code>seata--&gt;conf--&gt;application.yml</code> 修改 seata.registry.type=”nacos”,在 <code>seata--&gt;conf--&gt;application.example.yml</code> 中 seata.registry.nacos 下有相关的 nacos 配置，将其复制到 application.yml 下，并将 nacos 相关的数据配置完整。</p></li></ul><ol><li><p>修改存储模式 store.mode<br> Server 端存储模式（store.mode）现有 file、db、redis 三种，file 模式无需改动，直接启动即可，下面专门讲下 db，因为 db 模式为高可用模式，全局事务会话信息通过 db 共享。<br> <code>seata--&gt;conf--&gt;application.yml</code>，修改 store.mode=”db”</p></li><li><p>修改数据库连接<br> <code>seata--&gt;conf--&gt;application.example.yml</code> 中附带额外配置，将其 db 相关配置复制至 application.yml，修改 store.db 相关属性。</p></li><li><p> 启动</p></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">seata-server.sh -h 127.0.0.1 -p 8091 -m db</span><br></pre></td></tr></table></figure><h3 id="业务系统集成"><a href="#业务系统集成" class="headerlink" title="业务系统集成"></a>业务系统集成</h3><ol><li> 添加依赖，Seata 提供了不同的依赖包。可以根据项目自行选择，建议单选。</li></ol><ul><li>  依赖 seata-all</li><li>  依赖 seata-spring-boot-starter，支持 yml、properties 配置(.conf 可删除)，内部已依赖 seata-all</li><li>  依赖 spring-cloud-alibaba-seata，内部集成了 seata，并实现了 xid 传递</li></ul><ol><li> 在涉及到的服务的数据库中创建<code>undo_log</code>表</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `undo_log` (</span><br><span class="line">  `id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `branch_id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `xid` <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `context` <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `rollback_info` longblob <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `log_status` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `log_created` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `log_modified` datetime <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `ext` <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`),</span><br><span class="line">  <span class="keyword">UNIQUE</span> KEY `ux_undo_log` (`xid`,`branch_id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB AUTO_INCREMENT<span class="operator">=</span><span class="number">1</span> <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4;</span><br></pre></td></tr></table></figure><ol><li> 初始化 GlobalTransactionScanner，如果引入<code>seata-spring-boot-starter</code>、<code>spring-cloud-starter-alibaba-seata</code>等 jar 会自动初始化，否则需要手动初始化。</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> GlobalTransactionScanner <span class="title">globalTransactionScanner</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    String applicationName = <span class="keyword">this</span>.applicationContext.getEnvironment().getProperty(<span class="string">&quot;spring.application.name&quot;</span>);</span><br><span class="line">    String txServiceGroup = <span class="keyword">this</span>.seataProperties.getTxServiceGroup();</span><br><span class="line">    <span class="keyword">if</span> (StringUtils.isEmpty(txServiceGroup)) &#123;</span><br><span class="line">        txServiceGroup = applicationName + <span class="string">&quot;-fescar-service-group&quot;</span>;</span><br><span class="line">        <span class="keyword">this</span>.seataProperties.setTxServiceGroup(txServiceGroup);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> GlobalTransactionScanner(applicationName, txServiceGroup);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li> 实现 xid 跨服务传递，如果是 Spring Cloud 项目，并引用了<code>spring-cloud-starter-alibaba-seata</code>jar，则已经自动实现了，否则需要参考源码 integration 文件夹下的各种 rpc 实现 module</li></ol><h4 id="业务使用"><a href="#业务使用" class="headerlink" title="业务使用"></a>业务使用</h4><p>1、以一个 Spring Cloud 项目为例，项目中有两个服务：订单服务和 库存服务。业务场景为创建订单的同时减库存。</p><p>在两个服务中添加依赖</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-alibaba-seata<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.nacos<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nacos-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2、在每个业务服务下的数据库里添加<code>undo_log</code>表。</p><p>3、在每个业务服务下的配置文件中添加 seata 配置</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">seata:</span></span><br><span class="line">  <span class="attr">tx-service-group:</span> <span class="string">default_tx_group</span></span><br><span class="line">  <span class="attr">registry:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">nacos</span></span><br><span class="line">    <span class="attr">nacos:</span></span><br><span class="line">      <span class="attr">application:</span> <span class="string">seata-server</span> <span class="comment"># seata server 的服务名seata-server ，如果没有修改可以不配</span></span><br><span class="line">      <span class="attr">server-addr:</span>  <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:8848</span> <span class="comment"># seata server 所在的nacos服务地址</span></span><br><span class="line">      <span class="attr">group :</span> <span class="string">DEFAULT_GROUP</span>  <span class="comment"># seata server 所在的组，默认就是SEATA_GROUP，没有改也可以不配</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">0d876b7d-4cfd-4860-bf81-8e5266c9375c</span> <span class="comment"># 自己seata注册中心namespace</span></span><br><span class="line">      <span class="attr">username:</span> <span class="string">nacos</span></span><br><span class="line">      <span class="attr">password:</span> <span class="string">nacos</span></span><br><span class="line">  <span class="attr">config:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">nacos</span></span><br><span class="line">    <span class="attr">nacos:</span></span><br><span class="line">      <span class="attr">server-addr:</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">:8848</span> <span class="comment"># seata server 所在的nacos服务地址</span></span><br><span class="line">      <span class="attr">username:</span> <span class="string">nacos</span></span><br><span class="line">      <span class="attr">password:</span> <span class="string">nacos</span></span><br><span class="line">      <span class="attr">group:</span> <span class="string">DEFAULT_GROUP</span></span><br><span class="line">      <span class="attr">namespace:</span> <span class="string">0d876b7d-4cfd-4860-bf81-8e5266c9375c</span> <span class="comment"># 自己seata注册中心namespace</span></span><br><span class="line">  <span class="attr">application-id:</span> <span class="string">seata-demo</span> <span class="comment">#</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p><code>注意</code>：</p><ol><li> 这里的 group 要与 server 端配置的保持一致</li><li> tx-service-group 为事务群组，要部署同一套分布式事务的微服务要求事务群组要一致。可以在 nacos 的配置中查询 ：service.vgroupMapping.xxx。</li></ol><p><img src="/2022/12/19/24seata/5.png"></p><ol><li> 库存服务 <code>StockController</code></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PostMapping(value = &quot;/reduct&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduct</span><span class="params">(String productId)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//去库存</span></span><br><span class="line">    stockService.reduct(order.getProductId());</span><br><span class="line">    <span class="comment">// 异常</span></span><br><span class="line">    <span class="keyword">int</span> a=<span class="number">1</span>/<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> order;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在减库存的方法中模拟了一个业务异常<code>int a=1/0</code>，表示服务调用发生异常。</p><ol><li> 订单服务中创建调用库存服务的 Feign</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FeignClient(value = &quot;stock-service&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">StockApi</span> </span>&#123;</span><br><span class="line">    <span class="meta">@PostMapping(value = &quot;/reduct&quot;)</span></span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">reduct</span><span class="params">(String productId)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>订单服务<code>OrderService</code>，在需要开启全局事务的方法上添加<code>@GlobalTransactional</code>注解</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Autowired</span><br><span class="line"><span class="keyword">private</span> StockApi stockApi;</span><br><span class="line"></span><br><span class="line"><span class="meta">@GlobalTransactional</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Order <span class="title">create</span><span class="params">(Order order)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 插入</span></span><br><span class="line">    orderMapper.insert(order);</span><br><span class="line">    <span class="comment">// 减库存</span></span><br><span class="line">    stockApi.reduct(order.getProductId());</span><br><span class="line">    <span class="keyword">return</span> order;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当调用订单服务时，库存服务发生异常，可以判断发生异常后两个数据库中的数据是否回滚。</p><p>参考： <a href="https://seata.io/zh-cn/blog/seata-at-tcc-saga.html">https://seata.io/zh-cn/blog/seata-at-tcc-saga.html</a></p>]]></content>
    
    
    <summary type="html">Seata 的设计思路是将一个分布式事务理解成一个全局事务下面挂了多个分支事务，而一个分支事务是一个满足 ACID 的本地事务，因此我们可以操作分布式事务像操作本地事务一样。</summary>
    
    
    
    <category term="分布式事务" scheme="http://yaocl.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    
    
    <category term="分布式事务" scheme="http://yaocl.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务基础</title>
    <link href="http://yaocl.cn/2022/11/23/23distributedTransaction/"/>
    <id>http://yaocl.cn/2022/11/23/23distributedTransaction/</id>
    <published>2022-11-23T02:27:40.000Z</published>
    <updated>2023-05-22T01:00:59.043Z</updated>
    
    <content type="html"><![CDATA[<p>事务是数据库执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。<br>事务有四个特性，习惯上被称为 ACID 特性：</p><ul><li>Atomicity(原子性)</li><li>Consistency(一致性)</li><li>Isolation(隔离性)</li><li>Durability(持久性)</li></ul><h2 id="本地事物"><a href="#本地事物" class="headerlink" title="本地事物"></a>本地事物</h2><p>在系统发展初期，单体应用对应一个数据库，整个服务操作只涉及一个数据库资源，通过数据库自带的事务很容易实现 ACID，这类基于单个服务单一数据库资源访问的事务，被称为本地事务(Local Transaction)。</p><p><img src="/2022/11/23/23distributedTransaction/1.png"></p><h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2><p>随着互联网的发展，微服务架构大规模的普及，软件系统由原来的单体应用转变为分布式应用。分布式系统一般由多个独立的子系统组成，多个子系统通过网络通信互相协作配合完成各个功能。</p><p>分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。比如在一个电商系统中，一条订单的生成涉及库存、订单、支付等不同的服务，不同的服务之间要么全成功、要么全失败，保证事务的 ACID 特性。</p><p><img src="/2022/11/23/23distributedTransaction/2.png"></p><p>本质上来说，分布式事务就是为了保证不同数据库的数据一致性。</p><p>在分布式系统中数据一致性又可以划分出多个一致性模型</p><ul><li><p>强一致性：任何一次读都能读到某个数据的最近一次写的数据。系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致。简言之，在任意时刻，所有节点中的数据是一样的。</p></li><li><p>弱一致性：数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。</p></li><li><p>最终一致性：不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。简单说，就是在一段时间后，节点间的数据会最终达到一致状态。</p></li></ul><p>在解决分布式事物的数据一致性问题上，产生了多个相关的理论。</p><h2 id="CAP-理论"><a href="#CAP-理论" class="headerlink" title="CAP 理论"></a>CAP 理论</h2><p>CAP 定理又被称作布鲁尔定理，是加州大学的计算机科学家布鲁尔在 2000 年提出的一个猜想。2002 年，麻省理工学院的赛斯·吉尔伯特和南希·林奇发表了布鲁尔猜想的证明，使之成为分布式计算领域公认的一个定理。</p><ul><li>C : Consistency 一致性 , 所有实例节点同一时间看到是相同的数据</li><li>A : Availability 可用性 , 不管是否成功，确保每一个请求都能接收到响应</li><li>P : Partition tolerance 分区容错性 , 系统任意分区后，在网络故障时，仍能操作</li></ul><p>CAP 理论是指在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性、可用性、分区容错性者中的两个，另外一个必须被牺牲。</p><p>在真实的分布式环境下，如果我们选择了 CA（一致性 + 可用性） 而放弃了 P（分区容错性），那么当发生分区现象时，为了保证 C（一致性），系统需要禁止写入，当有写入请求时，系统返回 error（例如，当前系统不允许写入），这又和 A(可用性) 冲突了，因为 A（可用性）要求返回 no error 和 no timeout。因此虽然在 CAP 理论定义是三个要素中只能取两个，但放到分布式环境下来，必须选择 P（分区容错）要素，因为网络本身无法做到 100% 可靠，有可能出故障，所以分区是一个必然的现象。<br>也就说在真是环境下我们只能选择 CP（一致性 + 分区容错性） 或者 AP （可用性 + 分区容错性）架构，在一致性和可用性做折中选择。</p><p>虽然 CAP 理论告诉我们分布式系统只能选择 AP 或者 CP，但实际上并不是说整个系统只能选择 AP 或者 CP，在 CAP 理论落地实践时，我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP 还是 AP），而不是直接限定整个系统所有数据都是同一策略。</p><h2 id="BASE-理论–CAP-理论的延伸"><a href="#BASE-理论–CAP-理论的延伸" class="headerlink" title="BASE 理论–CAP 理论的延伸"></a>BASE 理论–CAP 理论的延伸</h2><p>由于在分布式系统中 C、A、P 三者都无法抛弃，但 CAP 定理限制三者无法同时满足，这种情况，我们会选择尽量靠近 CAP 定理，即尽量让 C、A、P 都满足，在此所趋下，出现了 BASE 定理。</p><p>BASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent （最终一致性）三个短语的缩写。核心思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。</p><ul><li>BA：Basically Available 基本可用，分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。<br>电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。</li><li>S：Soft State 软状态，允许系统存在中间状态，而该中间状态不会影响系统整体可用性。<br>分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication 的异步复制也是一种体现。</li><li>E: Eventual Consistency 最终一致性， 系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。</li></ul><p>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。</p><p>BASE和ACID的区别与联系</p><ul><li>ACID是传统数据库常用的设计理念, 追求强一致性模型。</li><li>BASE支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性</li></ul><p>ACID和BASE代表了两种截然相反的设计哲学。<br>总的来说，BASE 理论面向大型高可用可扩展的分布式系统，与ACID这种强一致性模型不同，常常是牺牲强一致性来获得可用性，并允许数据在一段时间是不一致的。虽然两者处于（一致性-可用性）分布图的两级，但两者并不是孤立的，对于分布式系统来说，往往依据业务的不同和使用的系统组件不同，而需要灵活的调整一致性要求，也因此，常常会组合使用ACID和BASE。</p><h2 id="柔性事务"><a href="#柔性事务" class="headerlink" title="柔性事务"></a>柔性事务</h2><p>不同于 ACID 的刚性事务，在分布式场景下基于 BASE 理论，就出现了柔性事务的概念。柔性事务下，在不影响系统整体可用性的情况下(Basically Available 基本可用)，允许系统存在数据不一致的中间状态(Soft State 软状态)，在经过数据同步的延时之后，最终数据能够达到一致。并不是完全放弃了 ACID，而是通过放宽一致性要求，借助本地事务来实现最终分布式事务一致性的同时也保证系统的吞吐。</p><h2 id="XA-–强一致性"><a href="#XA-–强一致性" class="headerlink" title="XA –强一致性"></a>XA –强一致性</h2><p>由 Tuxedo 提出的 XA 是一个分布式事务协议，规定了事务管理器和资源管理器接口。XA 协议可以分为两部分，即事务管理器和本地资源管理器。</p><ul><li>事务管理器作为<code>协调者</code>，负责各个本地资源的提交和回滚。</li><li>资源管理器就是分布式事务的<code>参与者</code>.其中资源管理通常是数据库。</li></ul><p>基于 XA 协议的，发展出了二阶段提交协议（The two-phase commit protocol，2PC）和三阶段提交协议（Three-phase commit protocol，3PC）。</p><h3 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h3><p>二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。</p><p>将事务的提交过程分为两个阶段来进行处理：准备阶段和提交阶段。</p><p>0x1 准备阶段</p><ol><li> 协调者向所有参与者发送 CanCommit 操作请求，并等待参与者的响应。</li><li>参与者接收到请求后，会执行请求中的事务操作，将 undo 和 redo 信息记入事务日志中，但是这时并不提交事务。<br> <img src="/2022/11/23/23distributedTransaction/3.png"><br> 若不成功，则发送“No”消息，表示终止操作。当所有的参与者都返回了操作结果（Yes 或 No 消息）后，系统进入了提交阶段。<br> <img src="/2022/11/23/23distributedTransaction/4.png"></li></ol><p>0x2 提交阶段</p><p>协调者会根据所有参与者返回的信息向参与者发送 DoCommit 或 DoAbort 指令</p><ol><li><p>若协调者收到的都是“Yes”消息，则向参与者发送“DoCommit”消息，参与者会提交事务并释放资源，然后向协调者返回“Ack”消息。<br><img src="/2022/11/23/23distributedTransaction/5.png"></p></li><li><p>如果协调者收到的消息中包含“No”消息，则向所有参与者发送“DoAbort”消息，此时发送“Yes”的参与者会根据之前执行操作时的回滚日志对操作进行回滚，然后所有参与者会向协调者发送“Ack”消息；<br><img src="/2022/11/23/23distributedTransaction/6.png"></p></li></ol><ol start="3"><li>协调者接收到所有参与者的“Ack”消息，就意味着整个事务结束了。</li></ol><p>2PC 实现起来比较简单，但是实际项目中使用比较少，主要因为以下问题：</p><p>性能问题：所有参与节点都是事务阻塞型的，占用系统资源，容易导致性能瓶颈。</p><p>可靠性问题：如果协调者出现故障，参与者将一直处于锁定状态。</p><p>数据一致性问题：在提交阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。</p><h3 id="3PC"><a href="#3PC" class="headerlink" title="3PC"></a>3PC</h3><p>基于 2PC 基础上，3PC 对 2PC 进行了改进，引入了超时机制。同时将准备阶段拆分为 2 个阶段，多了一个 PreCommit 阶段。</p><p>3PC 可以划分为 CanCommit 阶段、PreCommit 阶段、DoCommit 阶段。</p><p>0x1 CanCommit 阶段</p><ol><li>协调者向所有参与者发送 “CanCommit” 请求，询问是否可以提交事务，并等待所有参与者答复。</li><li>参与者收到 “CanCommit” 请求之后，回复 “Yes”，表示可以顺利执行事务；否则回复 “No”。</li></ol><p><img src="/2022/11/23/23distributedTransaction/7.png"></p><p>0x2 PreCommit 阶段</p><p>协调者根据参与者的回复情况，来决定是否可以进行 PreCommit 操作或中断事务。</p><p>如果参与者返回的回复情况全部是 Yes</p><ol><li>协调者向所有参与者发送 “PreCommit” 请求，参与者进入到预提交阶段。</li><li>参与者收到 “PreCommit” 请求后，执行事务操作，并将 undo 和 redo 信息记入事务日志中，但这时并不提交事务。</li><li>参与者向协调者反馈执行成功 “Yes” 或失败响应 “No”。</li></ol><p><img src="/2022/11/23/23distributedTransaction/8.png"></p><p>如果参与者返回的回复情况中包含 No，说明有一个事务执行失败。</p><ol><li>协调者向所有参与者发送 “Abort”请求</li><li>参与者收到“Abort”消息之后，或超时后仍未收到协调者的消息，执行事务的中断操作。</li></ol><p>0x3 DoCommit 阶段</p><p>协调者根据参与者的回复情况，来决定是否可以进行 DoCommit 操作 或 中断事务。</p><p>如果参与者返回的回复情况全部是 YES</p><ol><li>协调者向所有参与者发送 “DoCommit” 消息。</li><li>参与者接收到 “DoCommit” 消息之后，正式提交事务。完成事务提交之后，释放所有锁住的资源。</li><li>参与者提交完事务之后，向协调者发送 “Ack” 响应</li><li>协调者接收到所有参与者的 “Ack” 响应之后，完成事务。</li></ol><p><img src="/2022/11/23/23distributedTransaction/9.png"></p><p>如果参与者返回的回复情况中包含 No，说明有一个事务执行失败。</p><ol><li>协调者向所有参与者发送 “Abort” 请求。</li><li>参与者接收到 “Abort” 消息之后，利用其在 “PreCommit” 阶段记录的 undo 信息执行事务的回滚操作，并释放所有锁住的资源。</li><li>参与者完成事务回滚之后，向协调者发送 “Ack” 消息。</li><li>协调者接收到参与者反馈的 “Ack” 消息之后，执行事务的中断，并结束事务。</li></ol><p>相比二阶段提交，三阶段降低了阻塞范围，在等待超时后协调者或参与者会中断事务，避免了协调者单点问题。DoCommit 阶段中协调者出现问题时，参与者会继续提交事务。</p><p>但是数据不一致问题依然存在，当在参与者收到 preCommit 请求后等待 DoCommit 指令时，此时如果协调者请求中断事务，而协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。</p><h2 id="TCC-–最终一致性"><a href="#TCC-–最终一致性" class="headerlink" title="TCC –最终一致性"></a>TCC –最终一致性</h2><p>TCC（Try-Confirm-Cancel）的概念，最早是由 Pat Helland 于 2007 年发表的一篇名为《Life beyond Distributed Transactions:an Apostate’s Opinion》的论文提出。</p><p>TCC 是服务化的二阶段编程模型， 针对每个操作，都要实现对应的确认和补偿操作，也就是业务逻辑的每个服务都需要实现 Try、Confirm、Cancel 三个操作，第一阶段由业务代码编排来调用 Try 接口进行资源预留，当所有参与者的 Try 接口都成功了，事务协调者提交事务，并调用参与者的 Confirm 接口真正提交业务操作，否则调用每个参与者的 Cancel 接口回滚事务，并且由于 Confirm 或者 Cancel 有可能会重试，因此对应的部分需要支持幂等。</p><ul><li>Try 阶段：尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性）</li><li>Confirm 阶段： 确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作满足幂等性</li><li>Cancel 阶段： 取消执行，释放 Try 阶段预留的业务资源 Cancel 操作满足幂等性 Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致。</li></ul><p><img src="/2022/11/23/23distributedTransaction/10.png"></p><p>TCC 事务机制相比于上面介绍的 XA，解决了其几个缺点：</p><ol><li>解决了协调者单点，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。</li><li>同步阻塞：引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。</li><li>数据一致性，有了补偿机制之后，由业务活动管理器控制一致性</li></ol><p>但是TCC中Try、Confirm、Cancel 的操作需要业务来实现，耦合度过高。</p><h2 id="本地消息表-–最终一致性"><a href="#本地消息表-–最终一致性" class="headerlink" title="本地消息表 –最终一致性"></a>本地消息表 –最终一致性</h2><p>本地消息表这个方案最初是 ebay 架构师 Dan Pritchett 在 2008 年发表给 ACM 的文章。核心思路是将分布式事务拆分成本地事务进行处理。 本地事物表方案可以将事务分为事务主动方和事物被动方。</p><ul><li>事务主动方: 分布式事务最先开始处理的事务方</li><li>事务被动方: 在事务主动方之后处理的业务内的其他事务</li></ul><p>事务的主动方需要<code>额外新建事务消息表</code>，用于记录分布式事务的消息的发生、处理状态。整个业务流程：</p><ol><li>事务主动方在本地事务中处理业务更新操作和写消息表操作。</li><li>事务主动方通过消息中间件，通知事务被动方处理事务。</li><li>事务被动方通过消息中间件，通知事务主动方事务已处理的消息</li></ol><p><img src="/2022/11/23/23distributedTransaction/11.png"></p><p>本地消息表实现的条件：</p><ul><li>消费者与生成者的接口都要支持幂等</li><li>生产者需要额外的创建消息表</li><li>需要提供补偿逻辑，如果消费者业务失败，需要生产者支持回滚操作</li></ul><p>容错机制：</p><ul><li>步骤 1 失败时，事务直接回滚</li><li>步骤 2、3 写 mq 与消费 mq 失败会进行重试</li><li>步骤 3 业务失败事务被动方向事务主动方发起事务回滚操作</li></ul><h2 id="MQ-事务-–最终一致性"><a href="#MQ-事务-–最终一致性" class="headerlink" title="MQ 事务 –最终一致性"></a>MQ 事务 –最终一致性</h2><p>有些 MQ 的实现支持事务，比如 RocketMQ ，基于 MQ 的分布式事务方案其实是对本地消息表的封装。以 RocketMQ 为例介绍 MQ 的分布式事务方案。</p><ol><li>发送方向 MQ 服务端(MQ Server)发送 half 消息。这个 half 消息与普通消息的区别在于，在事物提交之前，这个消息对订阅方来说是不可见的，订阅方不会消费这个消息。</li><li>MQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功。</li><li>发送方开始执行本地事务逻辑。</li><li>如果事务提交成功，将会发送确认消息（commit 或是 rollback）至 MQ Server。</li><li>MQ Server 收到 commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 rollback 状态则删除half消息，订阅方将不会接受该消息。</li></ol><p><img src="/2022/11/23/23distributedTransaction/12.png"></p><p>异常情况 1：如果发送方发送 commit 或 rollback 消息失败，未到达消息集群</p><ul><li>MQ Server 会发起消息回查</li><li>发送方收到回查消息后，会检查本地事务的执行结果</li><li>根据本地事务的执行结果重新发送 commit 或 rollback 消息</li><li>MQ Server 根据接收到的消息（commit 或 rollback）判断消息是否可消费或直接删除</li></ul><p>异常情况 2：接收方消费失败或消费超时</p><ul><li>一直重试消费，直到事务订阅方消费消息成功，整个过程可能会导致重复消费问题，所以业务逻辑需要保证幂等性</li></ul><p>异常情况 3：消息已消费，但接收方业务处理失败</p><ul><li>通过 MQ Server 通知发送方进行补偿或事务回滚</li></ul><h2 id="Saga-事务-–最终一致性"><a href="#Saga-事务-–最终一致性" class="headerlink" title="Saga 事务 –最终一致性"></a>Saga 事务 –最终一致性</h2><p>Saga 事务源于 1987 年普林斯顿大学的 Hecto 和 Kenneth 发表的如何处理 long lived transaction（长活事务）论文，Saga 事务核心思想是将长事务拆分为多个本地短事务，由 Saga 事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。</p><p>Saga 事务基本协议如下：</p><p>每个 Saga 事务由一系列幂等的有序子事务(sub-transaction) Ti 组成。<br>每个 Ti 都有对应的幂等补偿动作 Ci，补偿动作用于撤销 Ti 造成的结果。</p><p>Saga 的执行顺序有两种：</p><ul><li>T1, T2, T3, …, Tn</li><li>T1, T2, …, Tj, Cj,…, C2, C1，其中 0 &lt; j &lt; n</li></ul><p>Saga 定义了两种恢复策略：</p><ul><li>向前恢复(forward recovery)<br>适用于必须要成功的场景，发生失败进行重试，执行顺序是类似于这样的：T1, T2, …, Tj(失败), Tj(重试),…, Tn，其中 j 是发生错误的子事务(sub-transaction)。该情况下不需要 Ci。</li></ul><p><img src="/2022/11/23/23distributedTransaction/13.png"></p><ul><li>向后恢复(backward recovery)<br>如果任一子事务失败，补偿所有已完成的事务。即上面提到的第二种执行顺序，其中 j 是发生错误的 sub-transaction，这种做法的效果是撤销掉之前所有成功的 sub-transation，使得整个 Saga 的执行结果撤销。</li></ul><p><img src="/2022/11/23/23distributedTransaction/14.png"></p><p>Saga 事务常见的有两种不同的实现方式：</p><ol><li>命令协调(Order Orchestrator)：中央协调器负责集中处理事件的决策和业务逻辑排序</li></ol><p><img src="/2022/11/23/23distributedTransaction/15.png"></p><ol start="2"><li>事件编排 (Event Choreography)：没有中央协调器（没有单点风险）时，每个服务产生并观察其他服务的事件，并决定是否应采取行动。<br>在事件编排方法中，第一个服务执行一个事务，然后发布一个事件。该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布（或不发布）新的事件。<br>当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何 Saga 参与者听到都意味着事务结束。</li></ol><p><img src="/2022/11/23/23distributedTransaction/16.png"></p>]]></content>
    
    
    <summary type="html">分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。</summary>
    
    
    
    <category term="分布式事务" scheme="http://yaocl.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    
    
    <category term="分布式事务" scheme="http://yaocl.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>智能合约</title>
    <link href="http://yaocl.cn/2022/10/10/22smartContract/"/>
    <id>http://yaocl.cn/2022/10/10/22smartContract/</id>
    <published>2022-10-10T09:25:14.000Z</published>
    <updated>2023-05-22T01:00:59.043Z</updated>
    
    <content type="html"><![CDATA[<p>接触区块链的，经常会听到智能合约这个词，那什么是智能合约？今天就来了解了解。</p><h2 id="比特币引领区块链，以太坊复活智能合约"><a href="#比特币引领区块链，以太坊复活智能合约" class="headerlink" title="比特币引领区块链，以太坊复活智能合约"></a>比特币引领区块链，以太坊复活智能合约</h2><p>1994 年，计算机科学家和密码学家 Nick Szabo 首次提出“智能合约”概念，它早于区块链概念的诞生，几乎与互联网同龄。</p><p><img src="/2022/10/10/22smartContract/1.png"></p><p>Szabo 描述了什么是“以数字形式指定的一系列承诺，包括各方履行这些承诺的协议”。虽然有它的好处，但智能合约的想法一直未取得进展——一个重要原因是因为缺乏能够支持可编程合约的数字系统和技术。</p><p>直到 2008 年，第一个加密货币比特币出现，同时引入了现代区块链技术。区块链最初是以比特币的底层技术出现的，但是智能合约在 2008 年依然无法融入比特币区块链网络。五年后，以太坊创始人 Vitalik Buterin 发布了白皮书《以太坊：下一代智能合约和去中心化应用平台》， 作为首个支持“图灵完备”智能合约的区块链网络，以太坊掀开了以智能合约为代表的区块链 2.0 时代的序章。从此，涌现出了各种不同形式的智能合约，其中以太坊智能合约使用最广。</p><p><img src="/2022/10/10/22smartContract/2.png"></p><h2 id="智能合约是什么"><a href="#智能合约是什么" class="headerlink" title="智能合约是什么"></a>智能合约是什么</h2><blockquote><p>智能合约是一种特殊协议，旨在提供、验证及执行合约。</p></blockquote><p>智能合约的英文是 <code>Smart Contract</code>，这里的智能 Smart 不等同于人工智能的 Artificial Intelligence。Smart 的意思是聪明的、灵活的，还远远未达到 Intelligence 的级别。中文的翻译有点误导的意思。</p><p>智能合约本质上是一个数字协议，数字协议在我们日常生活很常见，比如信用卡自动还款服务就是一个数字协议，在某一个时间（还款日），条件满足（储蓄卡余额比信用卡还款金额要多）的情况下，计算机系统会自动完成这笔交易。自动售货机也是一个数字协议，当选择商品，付钱后，如果付的钱足以支付该商品，那么售货机会弹出想要的商品，如果钱不够则运行另一套逻辑。</p><p>所以，智能合约就是一段计算机程序，程序中预先设定好了合约双方的职责和要执行的条件，一旦满足条约中的条款，程序会自动执行。只是与传统数字协议不同的是，智能合约是运行在区块链上的。</p><p>站在程序员的角度去理解智能合约，可以类比为一个类实例化对象，唯一的区别是这个对象永远存在区块链网络中（除非程序进行自毁）。</p><h2 id="智能合约是怎么运行的"><a href="#智能合约是怎么运行的" class="headerlink" title="智能合约是怎么运行的"></a>智能合约是怎么运行的</h2><p>智能合约一定要在区块链上么？ 并不是，就像上面说的信用卡自动还款、自动售货机的例子。但是运行在传统的计算机方式中存在合约被恶意篡改之类风险，还有一个重要的信任问题。在信用卡自动还款的例子中，因为是银行的服务，有银行背书，许多人相信银行。如果把这个服务放在淘宝、京东这类网店上，还会有人相信么？ 即使从技术角度来说实现这种服务也并不难。</p><p>所以相对于传统的方式，区块链去中心化、不可篡改、过程透明可追踪、去信任等优点，天然适合于智能合约。智能合约也是区块链被称之为“去中心化的”重要原因，它允许我们在不需要第三方的情况下，执行可追溯、不可逆转和安全的交易。</p><p>基于区块链的智能合约构建及执行主要分为如下几步：</p><p><code>构建 → 存储 → 执行</code></p><ol><li>多方共同制定合约内容，将编写好的智能合约代码上传到区块链上，全网的验证节点都会收到编写好的合约。</li><li>智能合约会定期检查是否存在相关事件和触发条件，满足条件的事件将会推送到待验证的队列中。比如每月10号信用卡还款日，这个事件就是智能合约的触发条件。</li><li>区块链上的验证节点先对该事件进行签名验证，以确保其有效，等大多数验证节点对该事件达成共识后，智能合约将成功执行，并通知用户。</li><li>合约成功执行后将移出区块，未执行的合约则继续等待下一轮处理，直至成功执行。</li></ol><p>智能合约的代码是具体如何运行的，不同区块链运行的方式不同，像以太坊是运行在以太坊的 EVM 中，超级账本 Fabric 是运行在 dcoker 中。</p><p>基于区块链乌托邦式的智能合约虽然能够解决当前传统计算机合约下的许多问题，但是现阶区块链段智能合约仍然有一些缺点。</p><ul><li>区块链不可篡改的特性，智能合约一旦上链就不容易修改，这使得修改代码变得困难。</li><li>区块链公开透明的特性，使得所有的私人信息都进入了公共领域。对于想要完全隐私的企业和个人来说，缺乏保密性是使用智能合约的一大缺点。</li><li>区块链上的智能合约只是将信任问题进行了转移并没有得到解决，比如房产交易合约，房屋归属权上链的首要条件是现实生活中房产交付确认同样是必须的输入信息。也就是，区块链无法解决外部虚假信息的录入。</li></ul><p>互联网从诞生到成熟这条路走了有三十年，对于仅活跃几年的区块链智能合约，未来的路依旧会很漫长。</p><p><img src="https://img.soogif.com/zr4XXRlsRpSDwFA4N1wNkrWM923md01V.gif?scope=mdnice"></p>]]></content>
    
    
    <summary type="html">Szabo 描述了什么是“以数字形式指定的一系列承诺，包括各方履行这些承诺的协议”。虽然有它的好处，但智能合约的想法一直未取得进展——一个重要原因是因为缺乏能够支持可编程合约的数字系统和技术。</summary>
    
    
    
    <category term="web3" scheme="http://yaocl.cn/categories/web3/"/>
    
    
    <category term="web3" scheme="http://yaocl.cn/tags/web3/"/>
    
  </entry>
  
  <entry>
    <title>编译器对代码做了哪些工作</title>
    <link href="http://yaocl.cn/2022/09/15/21compile/"/>
    <id>http://yaocl.cn/2022/09/15/21compile/</id>
    <published>2022-09-15T06:21:36.000Z</published>
    <updated>2023-05-22T01:00:59.043Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>知乎上有一种说法是「编译器、图形学、操作系统是程序员的三大浪漫」。</p></blockquote><p>计算机很笨，它只认识 0 和 1,也只会运行最简单的机器指令，而我们平时写的代码大多都属于高级语言。高级语言编写的指令要想在计算机上执行，需要将高级语言转换成计算机识别的机器语言。编译器就是将高级语言转换成机器语言的一款软件。</p><p>一个完整的编译器将源码编译成目标机器指令主要包含以下几个步骤。</p><p><img src="/2022/09/15/21compile/1.png"></p><h2 id="词法分析"><a href="#词法分析" class="headerlink" title="词法分析"></a>词法分析</h2><p>词法分析从左到右扫描源程序的字符，识别出每个单词，并组成<code>词素</code>（源代码中的一个字符串，比如一个变量名，一个运算符，都会被识别为一个词素。）。对于每个词素，词法分析会把它解析成一个词法单元。这个词法单元被称为 Token。Token 的形式一般为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">〈token-name, attribute-value〉</span><br></pre></td></tr></table></figure><ul><li>token-name: 单词的类别</li></ul><p>程序中的单词大体可以分成五类：</p><p><img src="/2022/09/15/21compile/2.png"></p><ul><li>attribute-value： 指向符号表中关于这个词法单元的条目。符号表条目的信息会被语义分析和代码生成步骤使用</li></ul><p>什么是符号表？</p><p>编译器的重要功能之一是记录源程序中使用的变量的名字，并收集和每个名字的各种属性有关的信息。这些属性可以提供一个名字的存储分配、类型、作用域等信息。对于过程名字，这些信息还包括：它的参数数量和类型、每个参数的传递方法及返回类型。</p><p>符号表数据结构为每个变量名字创建了一个记录条目。记录的字段就是名字的各个属性。这个数据结构应该允许编译器迅速查找到每个名字的记录，并向记录中快速存放和获取记录中的数据。</p><p>比如，对于赋值语句<code>position = initial + 2 * 60</code></p><p><code>position</code>是一个词素，被映射成词法单元<code>&lt;id, 1&gt;</code>，其中 id 是表示标识符（identifier）的抽象符号，而 1 指向符号表中 position 对应的条目。</p><p>赋值符号<code>=</code>是一个词素，被映射成词法单元<code>&lt;=&gt;</code>，因为这个词法单元不需要属性值，所以省略了第二个分量。</p><p>整条语句被词法分析后的结果可以表示为<br><code>&lt;id, 1&gt; &lt;=&gt; &lt;id, 2&gt; &lt;+&gt; &lt;2&gt; &lt;*&gt; &lt;60&gt;</code></p><h2 id="语法分析"><a href="#语法分析" class="headerlink" title="语法分析"></a>语法分析</h2><p>语法分析对词法分析中扫描的 Token 进行分析，并产生语法树，这棵树被称为 AST 抽象语法树。整个分析过程采用的是上下文无关语法（Context-free Grammar）。</p><p>简单来说，语法分析生成的树是以表达式为节点的树。</p><p>比如，对于赋值语句<code>position = initial + 2 * 60</code>，经过语法分析后生成的数</p><p><img src="/2022/09/15/21compile/3.png"></p><h2 id="语义分析"><a href="#语义分析" class="headerlink" title="语义分析"></a>语义分析</h2><p>语义分析利用前面生成的语法树和符号表来检查源程序是否符合语言定义。同时收集类型信息，以便在代码生成过程中使用。</p><p>语义分析的一个重要作用就是类型检查，编译器检查每一个运算符是否具有合法的运算分量。另外对于某些语言允许自动类型转换，编译器需要根据自动类型转换规则，对数据类型进行转换。</p><p>语义分析结束以后，整个语法树的表达式都被标识了类型，如果有些类型需要做隐式转换的，在分析完后会在语法书树上插入相应的转换节点。</p><p>比如<code>position = initial + 2 * 60</code> 经过语义分析后</p><p><img src="/2022/09/15/21compile/4.png"></p><p>语义分析同时还会对更新符号表里的符号类型。</p><h2 id="中间语言生成"><a href="#中间语言生成" class="headerlink" title="中间语言生成"></a>中间语言生成</h2><p>在经过语义分析后。大多数的编译器不会直接生成目标代码，一般会生成一个抽象于平台的中间语言(Intermediate Representation，简称 IR )，该中间语言与机器无关。</p><p>先生成中间代码一方面可以增加编译器的模块化、可移植性和可扩展性。中间代码既独立于任何高级语言，也独立于任何目标机器架构，这样可以开发出适应广泛高级语言的编译器。</p><p><img src="/2022/09/15/21compile/5.png"></p><p>另一方面，也可以做一些与机器无关的优化操作。</p><p>中间语言有很多种，在不同的编译器中可能也会有不同的表达形式。常用的方式有三地址码、P-代码等。</p><p>拿三地址码来举例，基本的三地址码是这样的<code>x = y op z</code>，表示将变量y和z操作后赋值给x，op既可以是算术运算也可以是其他的操作。 <code>position = initial + 2 * 60</code> 被三地址成三地址码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t1 = 2 * 60</span><br><span class="line">t2 = initial + t1</span><br><span class="line">position  = t2</span><br></pre></td></tr></table></figure><h2 id="中间代码优化"><a href="#中间代码优化" class="headerlink" title="中间代码优化"></a>中间代码优化</h2><p>中间代码优化的主要是做一些于底层机器无关的优化，比如消除死代码，函数内联优化，for 循环展开等优化。这一步输入的是中间代码IR,输出的也是中间代码IR。</p><p><code>position = initial + 2 * 60</code> 被翻译成中间语言后，<code>t1 = 2 * 60</code> 是可以在生成目标代码之前计算出来的，<code>t2 = initial + t1</code> 中的t1也是可以直接被替换成值的。 经过优化后的中间代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2 = initial + 120</span><br><span class="line">position  = t2</span><br></pre></td></tr></table></figure><h2 id="目标代码生成"><a href="#目标代码生成" class="headerlink" title="目标代码生成"></a>目标代码生成</h2><p>目标代码生成的工作是将中间代码转换成目标机器代码，这个过程十分依赖目标机器，因为不同的机器有着不同的字长、寄存器、数据类型等等，需要生成不同的机器代码。</p><p>现在编译器有着异常复杂的机构，因为现代高级语言本身非常的复杂，像C++编译器，至今也没有一个编译器能够完整的支持C++标准所规定的所有语言特性。 那么作为一个高级语言的使用者，为什么要学习编译原理呢？这里引用《三体》中的一段话结束。</p><blockquote><p>成吉思汗的骑兵，攻击速度与二十世纪的装甲部队相当;北宋的床弩，射程达一千五百米，与二十世纪的狙击步枪差不多;但这些仍不过是古代的骑兵与弓弩而已，不可能与现代力量抗衡。<code>基础理论决定一切</code>，未来史学派清楚地看到了这一点。而你们，却被回光返照的低级技术蒙住了眼睛。</p></blockquote>]]></content>
    
    
    <summary type="html">计算机很笨，它只认识 0 和 1,也只会运行最简单的机器指令，而我们平时写的代码大多都属于高级语言。高级语言编写的指令要想在计算机上执行，</summary>
    
    
    
    <category term="编译原理" scheme="http://yaocl.cn/categories/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
    
    <category term="编译原理" scheme="http://yaocl.cn/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Java8中的Stream流</title>
    <link href="http://yaocl.cn/2022/08/20/20stream/"/>
    <id>http://yaocl.cn/2022/08/20/20stream/</id>
    <published>2022-08-20T06:15:48.000Z</published>
    <updated>2023-05-22T01:00:59.040Z</updated>
    
    <content type="html"><![CDATA[<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>什么是Stream流，Java doc中是这样写的</p><blockquote><p>A sequence of elements supporting sequential and parallel aggregate operations</p></blockquote><p>翻译一下就是一个支持顺序和并行聚合操作的元素序列。<br>可以把它理解成一个迭代器，但是只能遍历一次，就像是流水一样，要处理的元素在流中传输，并且可以在流中设置多个处理节点，元素在经过每个节点后会被节点的逻辑所处理。比如可以进行过滤、排序、转换等操作。</p><p>Stream流的使用可以分为三个步骤：</p><ul><li>数据源，创建流</li><li>中间操作，可以有多个，生成一个新的流</li><li>终端操作，只能有一个，放在最后，代表流中止。</li></ul><p>Stream流有几个特点：<br>1、Stream流一般不会改变数据源，只会生成一个新的数据流。<br>2、Stream流不会存储数据，只会根据设置的操作节点处理数据。<br>3、Stream流是延迟执行的，只有在调用终端操作后才会进行流转。</p><p>看一下Stream的结构<br><img src="/2022/08/20/20stream/1.png" alt="stream"></p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h3 id="数据源生成流"><a href="#数据源生成流" class="headerlink" title="数据源生成流"></a>数据源生成流</h3><ul><li>如果是集合的话，可以直接使用<code>stream()</code>创建流。</li><li>如果是数组的话，可以使用<code>Arrays.stream()</code>或<code>Stream.of()</code>来创建流。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 集合生成流</span></span><br><span class="line">List&lt;String&gt; strList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">Stream&lt;String&gt; stream = strList.stream();</span><br><span class="line"></span><br><span class="line"><span class="comment">//数据生成流</span></span><br><span class="line">String[] strs = <span class="keyword">new</span> String[]&#123;<span class="string">&quot;1&quot;</span>,<span class="string">&quot;2&quot;</span>,<span class="string">&quot;3&quot;</span>&#125;;</span><br><span class="line">Stream&lt;String&gt; stream1 = Arrays.stream(strs);</span><br><span class="line">Stream&lt;String&gt; stream2 = Stream.of(strs);</span><br></pre></td></tr></table></figure><h3 id="中间操作"><a href="#中间操作" class="headerlink" title="中间操作"></a>中间操作</h3>在上边Stream定义中，返回是<code>Stream</code>类型的大多数都是中间操作，入参大多数都是函数式编程，不熟悉的可以看看这篇&lt;Java函数式编程&gt;。常用的中间操作有</li><li>过滤操作 <code>filter()</code><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Arrays.stream(strs).filter(s -&gt; s.equals(<span class="string">&quot;1&quot;</span>));</span><br></pre></td></tr></table></figure></li><li>排序操作 <code>sorted()</code><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Arrays.stream(strs).sorted();</span><br></pre></td></tr></table></figure></li><li>去重操作 <code>distinct()</code><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Arrays.stream(strs).distinct();</span><br></pre></td></tr></table></figure></li><li>映射操作，将流中元素转换成新的元素<ul><li><code>mapToInt()</code>转换成Integer类型</li><li><code>mapToLong()</code>转换成Long类型</li><li><code>mapToDouble()</code>转换成Double类型</li><li><code>map()</code> 自定义转换类型，这是一个使用频率非常高的方法。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//将字符串转换成Integer</span></span><br><span class="line">Arrays.stream(strs).mapToInt(s -&gt; Integer.valueOf(s));</span><br><span class="line"><span class="comment">//将字符串转换成Long</span></span><br><span class="line">Arrays.stream(strs).mapToLong(s -&gt; Long.valueOf(s));</span><br><span class="line"><span class="comment">//将字符串转换成Doublde</span></span><br><span class="line">Arrays.stream(strs).mapToDouble(s -&gt; Double.valueOf(s));</span><br><span class="line"><span class="comment">//自定义转换的类型</span></span><br><span class="line">Arrays.stream(strs).map(s -&gt; <span class="keyword">new</span> BigDecimal(s));</span><br></pre></td></tr></table></figure>中间操作是可以有多个的，我们可以根据业务功能组合多个中间操作，比如求数组中字符串包含s的字符串长度排序<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Arrays.stream(strs).filter(e-&gt;e.contains(<span class="string">&quot;s&quot;</span>)).map(String::length).sorted();</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="终端操作"><a href="#终端操作" class="headerlink" title="终端操作"></a>终端操作</h3><p>终端操作，表示结束流操作，是在流的最后，常用的有</p><ul><li>统计 <code>count()</code><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> count = Arrays.stream(strs).count();</span><br><span class="line"><span class="comment">// count=3</span></span><br></pre></td></tr></table></figure></li><li>获取最小值 <code>min()</code><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将字符串转换成Interger类型再比较大小</span></span><br><span class="line"> OptionalInt min = Arrays.stream(strs).mapToInt(Integer::valueOf).min();</span><br><span class="line"> System.out.println(min.getAsInt());</span><br><span class="line"> <span class="comment">// 1</span></span><br></pre></td></tr></table></figure></li><li>获取最大值 <code>max()</code><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">OptionalInt max = Arrays.stream(strs).mapToInt(Integer::valueOf).max();</span><br><span class="line">System.out.println(max.getAsInt());</span><br><span class="line"><span class="comment">// 3</span></span><br></pre></td></tr></table></figure></li><li>匹配<ul><li><code>anyMatch()</code>，只要有一个匹配就返回<code>true</code></li><li><code>allMatch()</code>，只有全部匹配才返回<code>true</code></li><li><code>noneMatch()</code>，只要有一个匹配就返回 <code>false</code><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">boolean</span> all = Arrays.stream(strs).allMatch(s -&gt; s.equals(<span class="string">&quot;2&quot;</span>));</span><br><span class="line"><span class="keyword">boolean</span> any = Arrays.stream(strs).anyMatch(s -&gt; s.equals(<span class="string">&quot;2&quot;</span>));</span><br><span class="line"><span class="keyword">boolean</span> none = Arrays.stream(strs).noneMatch(s -&gt; s.equals(<span class="string">&quot;2&quot;</span>));</span><br><span class="line"><span class="comment">// all = false</span></span><br><span class="line"><span class="comment">// any = true</span></span><br><span class="line"><span class="comment">// none = false</span></span><br></pre></td></tr></table></figure></li></ul></li><li>组合 <code>reduce()</code>将Stream 中的元素组合起来，有两种用法<ul><li><code>Optional reduce(BinaryOperator accumulator)</code> 没有起始值只有运算规则</li><li><code>T reduce(T identity, BinaryOperator accumulator)</code>，有运算起始值和运算规则、返回的是和起始值一样的类型</li></ul></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Integer[] integers = <span class="keyword">new</span> Integer[]&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line">Optional&lt;Integer&gt; reduce1 = Arrays.stream(integers).reduce((i1, i2) -&gt; i1 + i2);</span><br><span class="line">Integer reduce2 = Arrays.stream(integers).reduce(<span class="number">100</span>, (i1, i2) -&gt; i1 + i2);</span><br><span class="line"><span class="comment">// reduce1.get() = 6</span></span><br><span class="line"><span class="comment">// reduce2 = 106</span></span><br></pre></td></tr></table></figure><ul><li>转换 <code>collect()</code>，转换作用是将流再转换成集合或数组，这也是一个使用频率非常高的方法。<br><code>collect()</code>一般配合<code>Collectors</code>使用，<code>Collectors</code> 是一个收集器的工具类，内置了一系列收集器实现，比如<code>toList()</code> 转换成list集合，<code>toMap()</code>转换成Map,<code>toSet()</code>转换成Set集合,<code>joining()</code> 将元素收集到一个可以用分隔符指定的字符串中。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">String[] strs = <span class="keyword">new</span> String[]&#123;<span class="string">&quot;11111&quot;</span>, <span class="string">&quot;222&quot;</span>, <span class="string">&quot;3&quot;</span>&#125;;</span><br><span class="line"><span class="comment">//统计每个字符串的长度</span></span><br><span class="line">List&lt;Integer&gt; lengths = Arrays.stream(strs).map(String::length).collect(Collectors.toList());</span><br><span class="line">String s = Arrays.stream(strs).collect(Collectors.joining(<span class="string">&quot;,&quot;</span>));</span><br><span class="line"><span class="comment">// lengths=[5,3,1]</span></span><br><span class="line"><span class="comment">// s = 11111,222,3</span></span><br></pre></td></tr></table></figure>合理的组合Steam操作，可以很大的提升生产力</li></ul><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><img src="/2022/08/20/20stream/2.png"><br>Stream的实现类中，将Stream划分成了<code>Head</code>、<code>StatelessOp</code>和<code>StatefulOp</code>，<code>Head</code>控制数据流入，中间操作分为了<code>StatelessOp</code>和<code>StatefulOp</code>。</p><p>StatelessOp代表无状态操作：每个数据的处理是独立的，不会影响或依赖之前的数据。像<code>filter()</code>、<code>map()</code>等。</p><p>StatefulOp代表有状态操作：：处理时会记录状态，比如后面元素的处理会依赖前面记录的状态，或者拿到所有元素才能继续下去等这样有状态的操作，像<code>sorted()</code>。</p><p>现在已下面代码为例，分析一下Stream的原理</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">list.stream()</span><br><span class="line">    .filter(e -&gt; e.length() &gt; <span class="number">1</span>)</span><br><span class="line">    .sorted()</span><br><span class="line">    .filter(e -&gt; e.equals(<span class="string">&quot;333&quot;</span>))</span><br><span class="line">    .collect(Collectors.toList());</span><br></pre></td></tr></table></figure><h3 id="数据源生成流-1"><a href="#数据源生成流-1" class="headerlink" title="数据源生成流"></a>数据源生成流</h3><p>首先，进入到<code>list.stream()</code>里</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Collection#stream</span></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">default</span> Stream&lt;E&gt; <span class="title">stream</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> StreamSupport.stream(spliterator(), <span class="keyword">false</span>);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">default</span> Spliterator&lt;E&gt; <span class="title">spliterator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Spliterators.spliterator(<span class="keyword">this</span>, <span class="number">0</span>);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//StreamSupport#stream</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">Stream&lt;T&gt; <span class="title">stream</span><span class="params">(Spliterator&lt;T&gt; spliterator, <span class="keyword">boolean</span> parallel)</span> </span>&#123;</span><br><span class="line">    Objects.requireNonNull(spliterator);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ReferencePipeline.Head&lt;&gt;(spliterator,</span><br><span class="line">                                        StreamOpFlag.fromCharacteristics(spliterator),</span><br><span class="line">                                        parallel);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将原数据封装成<code>Spliterator</code>，同时生成一个<code>Head</code>，将<code>Spliterator</code>放到<code>Head</code>中。</p><p><img src="/2022/08/20/20stream/3.png"></p><h3 id="中间操作-1"><a href="#中间操作-1" class="headerlink" title="中间操作"></a>中间操作</h3><p>接着分析中间操作<code>.filter(e -&gt; e.length() &gt; 1)</code>的代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//ReferencePipeline#filter</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Stream&lt;P_OUT&gt; <span class="title">filter</span><span class="params">(Predicate&lt;? <span class="keyword">super</span> P_OUT&gt; predicate)</span> </span>&#123;</span><br><span class="line">    Objects.requireNonNull(predicate);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> StatelessOp&lt;P_OUT, P_OUT&gt;(<span class="keyword">this</span>, StreamShape.REFERENCE,</span><br><span class="line">                                  StreamOpFlag.NOT_SIZED) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function">Sink&lt;P_OUT&gt; <span class="title">opWrapSink</span><span class="params">(<span class="keyword">int</span> flags, Sink&lt;P_OUT&gt; sink)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Sink.ChainedReference&lt;P_OUT, P_OUT&gt;(sink) &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">begin</span><span class="params">(<span class="keyword">long</span> size)</span> </span>&#123;</span><br><span class="line">                    downstream.begin(-<span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(P_OUT u)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span> (predicate.test(u))</span><br><span class="line">                        downstream.accept(u);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回的是一个无状态操作<code>StatelessOp</code>，查看<code>StatelessOp</code>的构造函数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// AbstractPipeline#AbstractPipeline</span></span><br><span class="line">  AbstractPipeline(AbstractPipeline&lt;?, E_IN, ?&gt; previousStage, <span class="keyword">int</span> opFlags) &#123;</span><br><span class="line">      <span class="keyword">if</span> (previousStage.linkedOrConsumed)</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(MSG_STREAM_LINKED);</span><br><span class="line">      previousStage.linkedOrConsumed = <span class="keyword">true</span>;</span><br><span class="line">      previousStage.nextStage = <span class="keyword">this</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">this</span>.previousStage = previousStage;</span><br><span class="line">      <span class="keyword">this</span>.sourceOrOpFlags = opFlags &amp; StreamOpFlag.OP_MASK;</span><br><span class="line">      <span class="keyword">this</span>.combinedFlags = StreamOpFlag.combineOpFlags(opFlags, previousStage.combinedFlags);</span><br><span class="line">      <span class="keyword">this</span>.sourceStage = previousStage.sourceStage;</span><br><span class="line">      <span class="keyword">if</span> (opIsStateful())</span><br><span class="line">          sourceStage.sourceAnyStateful = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">this</span>.depth = previousStage.depth + <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>构造函数中有<code>previousStage.nextStage = this;</code>和<code>this.previousStage = previousStage;</code>，相当于将当前的<code>StatelessOp</code>操作拼接到<code>Head</code>后面，构成了一条双向链表。</p><p><img src="/2022/08/20/20stream/4.png"></p><p>再看后面的<code>.sorted().filter(e -&gt; e.equals(&quot;333&quot;)).limit(10)</code>，也会将操作添加到了双向链表后面。<code>.sorted()</code>在链表后面添加的是<code>StatefulOp</code>有状态操作。</p><p><img src="/2022/08/20/20stream/5.png"></p><h3 id="终端操作-1"><a href="#终端操作-1" class="headerlink" title="终端操作"></a>终端操作</h3><p>最后走到终端操作<code>.collect(Collectors.toList())</code>。进入到<code>collect()</code> 中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//ReferencePipeline#collect</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> &lt;R, A&gt; <span class="function">R <span class="title">collect</span><span class="params">(Collector&lt;? <span class="keyword">super</span> P_OUT, A, R&gt; collector)</span> </span>&#123;</span><br><span class="line">    A container;</span><br><span class="line">    <span class="keyword">if</span> (isParallel()</span><br><span class="line">            &amp;&amp; (collector.characteristics().contains(Collector.Characteristics.CONCURRENT))</span><br><span class="line">            &amp;&amp; (!isOrdered() || collector.characteristics().contains(Collector.Characteristics.UNORDERED))) &#123;</span><br><span class="line">        container = collector.supplier().get();</span><br><span class="line">        BiConsumer&lt;A, ? <span class="keyword">super</span> P_OUT&gt; accumulator = collector.accumulator();</span><br><span class="line">        forEach(u -&gt; accumulator.accept(container, u));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        container = evaluate(ReduceOps.makeRef(collector));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> collector.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)</span><br><span class="line">            ? (R) container</span><br><span class="line">            : collector.finisher().apply(container);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>并发操作先不看，直接看<code>container = evaluate(ReduceOps.makeRef(collector));</code>，<code>ReduceOps.makeRef()</code>返回是<code>TerminalOp</code>，代表的是终端操作。</p><p><img src="/2022/08/20/20stream/6.png"></p><p>进<code>evaluate()</code>中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//AbstractPipeline#evaluate</span></span><br><span class="line"><span class="keyword">final</span> &lt;R&gt; <span class="function">R <span class="title">evaluate</span><span class="params">(TerminalOp&lt;E_OUT, R&gt; terminalOp)</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">assert</span> <span class="title">getOutputShape</span><span class="params">()</span> </span>== terminalOp.inputShape();</span><br><span class="line">    <span class="keyword">if</span> (linkedOrConsumed)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(MSG_STREAM_LINKED);</span><br><span class="line">    linkedOrConsumed = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> isParallel()</span><br><span class="line">            ? terminalOp.evaluateParallel(<span class="keyword">this</span>, sourceSpliterator(terminalOp.getOpFlags()))</span><br><span class="line">            : terminalOp.evaluateSequential(<span class="keyword">this</span>, sourceSpliterator(terminalOp.getOpFlags()));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>先不管并行，进串行入<code>evaluateSequential()</code>中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//ReduceOps#evaluateSequential</span></span><br><span class="line"><span class="keyword">public</span> &lt;P_IN&gt; <span class="function">R <span class="title">evaluateSequential</span><span class="params">(PipelineHelper&lt;T&gt; helper,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    Spliterator&lt;P_IN&gt; spliterator)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> helper.wrapAndCopyInto(makeSink(), spliterator).get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>makeSink()</code>将返回一个<code>Sink</code>实例，并作为参数和 spliterator 一起传入最后一个节点(terminalOp)的 wrapAndCopyInto() 方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//AbstractPipeline#wrapAndCopyInto</span></span><br><span class="line"><span class="keyword">final</span> &lt;P_IN, S extends Sink&lt;E_OUT&gt;&gt; <span class="function">S <span class="title">wrapAndCopyInto</span><span class="params">(S sink, Spliterator&lt;P_IN&gt; spliterator)</span> </span>&#123;</span><br><span class="line">    copyInto(wrapSink(Objects.requireNonNull(sink)), spliterator);</span><br><span class="line">    <span class="keyword">return</span> sink;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> &lt;P_IN&gt; <span class="function">Sink&lt;P_IN&gt; <span class="title">wrapSink</span><span class="params">(Sink&lt;E_OUT&gt; sink)</span> </span>&#123;</span><br><span class="line">     Objects.requireNonNull(sink);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ( <span class="meta">@SuppressWarnings(&quot;rawtypes&quot;)</span> AbstractPipeline p=AbstractPipeline.<span class="keyword">this</span>; p.depth &gt; <span class="number">0</span>; p=p.previousStage) &#123;</span><br><span class="line">        sink = p.opWrapSink(p.previousStage.combinedFlags, sink);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (Sink&lt;P_IN&gt;) sink;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>wrapSink()</code>将最后一个节点创建的 Sink 传入，并且看到里面有个 for 循环。这个 for 循环是从最后一个节点开始，到第二个节点结束。每一次循环都是将上一节点的 combinedFlags 和当前的 Sink 包起来生成一个新的 Sink 。这和前面拼接各个操作很类似，只不过拼接的是 Sink 的实现类的实例，方向相反。</p><p><img src="/2022/08/20/20stream/7.png"></p><p>到现在整个流水已经拼接完成。真正的数据处理在<code>copyInto()</code>中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//AbstractPipeline#copyInto</span></span><br><span class="line"><span class="keyword">final</span> &lt;P_IN&gt; <span class="function"><span class="keyword">void</span> <span class="title">copyInto</span><span class="params">(Sink&lt;P_IN&gt; wrappedSink, Spliterator&lt;P_IN&gt; spliterator)</span> </span>&#123;</span><br><span class="line">    Objects.requireNonNull(wrappedSink);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) &#123;</span><br><span class="line">        wrappedSink.begin(spliterator.getExactSizeIfKnown());</span><br><span class="line">        spliterator.forEachRemaining(wrappedSink);</span><br><span class="line">        wrappedSink.end();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        copyIntoWithCancel(wrappedSink, spliterator);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>Sink</code>中有三个方法：</p><ul><li><code>begin</code>：节点开始准备</li><li><code>accept</code>: 节点处理数据</li><li><code>end</code>： 节点处理结束</li></ul><p><code>Sink</code>与操作是相关的，不同的<code>Sink</code>有不同的职责，无状态操作的 Sink 接收到通知或者数据，处理完了会马上通知自己的下游。有状态操作的 Sink 则像有一个缓冲区一样，它会等要处理的数据处理完了才开始通知下游，并将自己处理的结果传递给下游。</p><p>比如<code>filter</code>这种无状态的操作，处理完数据会直接交给下游，而像<code>sorted</code>这种无有状态的操作在<code>begin</code>阶段会先创建一个容器，<code>accept</code>会将流转过来的数据保存起来，最后在执行 <code>end</code>方法时才正在开始排序。排序之后再将数据，采用同样的方式依次传递给下游节点。<br><img src="/2022/08/20/20stream/8.png"></p><p>wrapAndCopyInto() 返回了 TerminalOps 创建的 Sink，这时候它里面已经包含了最终处理的结果。调用它的 get() 方法就获得了最终的结果。</p><p><code>Steam</code>还可以支持并行流，把<code>list.stream()</code>换成<code>list.parallelStream()</code>即可使用并行操作。</p><p>并行过程中，构建操作链的双向链表是不变的，区别实在构建完后的操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//AbstractPipeline#evaluate</span></span><br><span class="line"><span class="keyword">final</span> &lt;R&gt; <span class="function">R <span class="title">evaluate</span><span class="params">(TerminalOp&lt;E_OUT, R&gt; terminalOp)</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">assert</span> <span class="title">getOutputShape</span><span class="params">()</span> </span>== terminalOp.inputShape();</span><br><span class="line">    <span class="keyword">if</span> (linkedOrConsumed)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(MSG_STREAM_LINKED);</span><br><span class="line">    linkedOrConsumed = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> isParallel()</span><br><span class="line">            ? terminalOp.evaluateParallel(<span class="keyword">this</span>, sourceSpliterator(terminalOp.getOpFlags()))</span><br><span class="line">            : terminalOp.evaluateSequential(<span class="keyword">this</span>, sourceSpliterator(terminalOp.getOpFlags()));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这次进入到 <code>evaluateParallel()</code>中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//ReduceOps#evaluateSequential</span></span><br><span class="line"><span class="keyword">public</span> &lt;P_IN&gt; <span class="function">R <span class="title">evaluateParallel</span><span class="params">(PipelineHelper&lt;T&gt; helper,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         Spliterator&lt;P_IN&gt; spliterator)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ReduceTask&lt;&gt;(<span class="keyword">this</span>, helper, spliterator).invoke().get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>ReduceTask</code>继承自<code>ForkJoinTask</code>，<code>Steam</code>的并行底层用的是ForkJoin框架。</p>]]></content>
    
    
    <summary type="html">可以把它理解成一个迭代器，但是只能遍历一次，就像是流水一样，要处理的元素在流中传输，并且可以在流中设置多个处理节点，元素在经过每个节点后会被节点的逻辑所处理。比如可以进行过滤、排序、转换等操作。</summary>
    
    
    
    <category term="JAVA" scheme="http://yaocl.cn/categories/JAVA/"/>
    
    
    <category term="JAVA" scheme="http://yaocl.cn/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>区块链的灵魂-共识机制</title>
    <link href="http://yaocl.cn/2022/07/15/19consensus/"/>
    <id>http://yaocl.cn/2022/07/15/19consensus/</id>
    <published>2022-07-15T06:11:40.000Z</published>
    <updated>2023-05-22T01:00:59.033Z</updated>
    
    <content type="html"><![CDATA[<p>区块链是去中心化、分布式的，每个人都可以自由的参与进来，共同处理区块链中的数据。所谓绝对的自由必然带来绝对的混乱，作为一个巨大的分布式计算网络，必然有一个绕不开的问题–拜占庭将军问题</p><h3 id="拜占庭将军问题"><a href="#拜占庭将军问题" class="headerlink" title="拜占庭将军问题"></a>拜占庭将军问题</h3><p>拜占庭将军问题（Byzantine failures），是由计算机科学史上的传奇人物莱斯利·兰伯特（Leslie Lamport）提出的。</p><p>拜占庭帝国派出10个将军去攻击敌人，这支敌人可以同时抵御5支拜占庭军队的同时袭击。而这10个拜占庭将军在分开的状态下包围了敌人，并且只能依靠通信兵骑马相互通信来协商进攻意向及进攻时间。但是这些将军们不能确定他们的通信兵中是否有叛徒，叛徒可能擅自改变进攻意向及进攻时间。在这种情况下怎样才能保证同时有多于5支军队攻击，来赢得胜利？</p><p><img src="/2022/07/15/19consensus/1.png"></p><p>放到区块链中，拜占庭将军问题主要针对点对点通信中的分布式系统一致性问题。可以简单的概括为为 <code>在整个网络中的任意节点都无法信任与之通信的对方时，如何能创造出共识基础来进行安全信息的交互而无需担心数据被篡改。</code></p><p>区块链四大核心技术之一的共识机制就是为了解决这个问题。</p><h3 id="什么是共识机制？"><a href="#什么是共识机制？" class="headerlink" title="什么是共识机制？"></a>什么是共识机制？</h3><p>共识，对特定事务具有相同的认识或态度。 共识在我们的生活中无处不在，说一个场景<br>中午你和同事一起吃午饭，你们在讨论怎么吃，然后你出来提议一起点外卖。其他人对你的提议进行投票，如果没有异议那么这就达成了共识。</p><p><img src="/2022/07/15/19consensus/2.png"></p><p>区块链是一个点对点的分布式数据库结构的网络账本。这个账本与传统账本不同，不是由会计或少数几个人来记账，而是人人都可以参与记账。在没有中心机构的情况下，怎么确保别人的数据是正确的？</p><p>这就需要一套规则来规定<code>怎样记账才是有效的</code>，而这一套规则就是共识机制。</p><p>这一套规则主要有两点功能：</p><ul><li>如何记账</li><li>怎样达成共识</li></ul><p>按照这套规则来决定区块链中谁取得区块链中的记账权，也就决定着由谁来产生新的区块。</p><p>共识机制的作用非常大，直接关系到记账权和相关收益的分配。如果把区块链比作一个社会，那共识机制就是这个社会的法律。不夸张地说，共识机制就是区块链的灵魂。</p><p>区块链发展到现在，已经有了多种共识机制，这里主要介绍三种被提及最多的共识机制。</p><p><img src="/2022/07/15/19consensus/3.jpg"></p><h2 id="POW-工作量证明"><a href="#POW-工作量证明" class="headerlink" title="POW 工作量证明"></a>POW 工作量证明</h2><p>POW(Proof of Work)，工作量证明，闻名于比特币，经常提到的<code>挖矿</code>一词也是起源于POW。</p><p><img src="/2022/07/15/19consensus/4.png"></p><p>POW的设计思想是计算一道数学难题，这道题计算过程是复杂的，但是验证过程是简单的。这种特性称之为计算不对称特性。</p><p>比如在比特币中选定为以SHA256算法计算一个目标哈希，使得这个哈希值符合前N位全是0。 举个例子,给出一个字符串”Blockchain”，要求计算一个数字，与给出的字符串拼接起来，进行SHA256后，得到的结果前4位是0，这个数字称作nonce。比如字符串”Blockchain1234”，nonce就是1234。由于结果只能暴力搜索，而且搜索空间非常巨大，作弊几乎不可能。</p><p>只要计算出目标值nonce就会获得记账权，距离上一次打包到现在未确认的交易，就可以一次性将未确认的交易打包并广播了。其他节点在接收到消息后，可以对nonce进行验证。</p><p>简单来说POW就是谁的计算能力越强，计算的越快，获得记账权的概率就越高。每个节点都在同时解题，一旦有一个节点解出来，其余节点解题的过程也就白费了，只能解下一个节点。所以这种证明方式需要消耗大量能源(电力及计算硬件损耗)。</p><p>并且理论上，在POW共识机制保护下，如果一个节点的计算力超过区块链全网的51%，即可对区块链网络进行有效攻击。因此许多基于比特币代码产生的、市值较小的山寨币很容易遭受攻击。这个51%攻击法在「矽谷」这个美剧第四季上曾经上演过这个情节。</p><h2 id="POS-权益证明"><a href="#POS-权益证明" class="headerlink" title="POS 权益证明"></a>POS 权益证明</h2><p>POS(Proof of Stake), 权益证明，最早出现在点点币的创始人Sunny King的白皮书中，它出现的目地就是为了解决POW挖矿出现大量资源浪费的问题。</p><p>在POS中个有<code>币龄</code>的概念，它指的是持币数量乘以持币天数。<br>相较与POW中人人都可以参与，人人都可以计算，POW更像是一种选举机制。节点需要抵押一定的代币，区块链网络会根据抵押代币的币龄，随机选取一个节点，由该节点进行打包区块。 抵押代币的多少，影响着被选中的概率。</p><p><img src="/2022/07/15/19consensus/5.png"></p><p>这种方式不需要每个节点都进行大量的运算，节省了能源。但它同样也有一些缺点。比如，PoS机制中初始的代币分发比较模糊，如果初始代币分发不下去，就很难形成之后的权益证明。并且POS也存在51%的问题，理论上谁能掌握51%的代币，谁就能掌控整个网络，所以，它的去中心化程度要弱一些。</p><h2 id="DPOS-代理权益证明"><a href="#DPOS-代理权益证明" class="headerlink" title="DPOS 代理权益证明"></a>DPOS 代理权益证明</h2><p>DPOS(Delegated Proof of Stake),代理权益证明。最初由Bitshares、Steemit以及 EOS 的创办人Dan Larimer提出，他在区块链项目Bitshares中实现了 DPoS 共识机制。DPOS与POS类似也是一种选举机制，它有点像民主大会。</p><p>其过程是每一个持币人进行投票，选举出一定数量的代表，并由这些代表来打包区块和验证。这些代表节点的权利是相等的。比如，EOS将产生21个主节点，以及100个备用节点。如果有些代表节点不称职，就随时有可能被投票出局。</p><p><img src="/2022/07/15/19consensus/6.png"></p><p>DPOS就像董事会投票，持币者投出一定数量的节点 （董事）。代表按照既定时间表，轮流产生区块，如果代表没能很好的行使权力（比如产生区块），他们会被除名，网络会选出新的代表节点来取代他们。</p><p>DPOS通过选举少数节点来出块记账，确实从网络传输和确认时间上看，大幅提升了性能。但是只有少数的节点出块记账的理念，牺牲了部分去中心化。因为DPOS机制的设计并不能保证一定有足额的真实的区块生产者，因为一个人或一个实体，可能控制着多个节点。如果节点的持有人相互串通，将进一步形成巨头垄断，这和区块链思想更是南辕北辙。这也是为什么V神怒怼DPOS的原因。</p>]]></content>
    
    
    <summary type="html">区块链是去中心化、分布式的，每个人都可以自由的参与进来，共同处理区块链中的数据。所谓绝对的自由必然带来绝对的混乱，作为一个巨大的分布式计算网络，</summary>
    
    
    
    <category term="web3" scheme="http://yaocl.cn/categories/web3/"/>
    
    
    <category term="web3" scheme="http://yaocl.cn/tags/web3/"/>
    
  </entry>
  
  <entry>
    <title>认识区块链和web3.0</title>
    <link href="http://yaocl.cn/2022/06/19/18web3/"/>
    <id>http://yaocl.cn/2022/06/19/18web3/</id>
    <published>2022-06-19T03:55:17.000Z</published>
    <updated>2023-05-22T01:00:59.030Z</updated>
    
    <content type="html"><![CDATA[<p>2017-2018年期间，伴随着比特币的又一轮牛市，第一次认识和了解了区块链。<br>2019年，高层大佬们集体学习区块链，也跟着重新关注起了区块链。也是因为区块链，去年第一次接触到了Web3.0，给我的第一印象是这东西太过超前了，如果真的能落地，那真的又是一场技术革命了，从那以后陆陆续续的关注着。<br>今年下半年换了份工作，发现公司做区块链的大牛也在关注Web3.0，也跟着学习长进了不少。<br>这篇文章主要介绍一些区块链和Web3.0的基本知识，可以对区块链和Web3.0有个大概的了解。</p><h2 id="区块链"><a href="#区块链" class="headerlink" title="区块链"></a>区块链</h2><p><img src="/2022/06/19/18web3/web31.png"></p><p>2008年，全球金融危机，全世界掀起了反思传统金融制度的思潮，一个叫中本聪的人在P2P foundation网站上发布了比特币白皮书<a href="https://bitcoin.org/bitcoin.pdf">《比特币：一种点对点的电子现金系统》</a>。</p><p><img src="/2022/06/19/18web3/web32.png"></p><p>在书里提出了一种无须可信第三方的电子支付系统——比特币，通过整合非对称加密技术、工作量证明机制（Proof of Work，简称PoW）、点对点技术（Peer-to-Peer，简称P2P）等来保障个人对资产的所有权和匿名性，彻底颠覆了对于货币需要依赖中心化机构发行的传统认知。</p><p>区块链和比特币由此诞生，那区块链到底是什么呢？。<br>可以把区块链理解成一个数据库，这个数据库有几个重要的特点：</p><ul><li>  去中心化</li><li>  不可篡改</li><li>  透明性</li></ul><p>区块链是怎么做到这些的呢？先看一下区块链的大致结构。</p><p><img src="/2022/06/19/18web3/web33.png"></p><p>区块链可以大致理解为： 由一笔一笔的交易组成一个区块，一个一个的区块组成的一条链。这里的交易不单单指的双方买卖，双方发生的任何业务都可以称为交易。</p><p>整个区块链是由所有参与节点共同维护的，每个节点都可以保存区块链的全部数据。</p><p>在区块链系统里，每当发生一个交易，交易都是双方是直接进行的。交易的双方会把交易信息广播到整个交易系统里，系统中的一些节点会将这些交易打包成区块，并广播到整个区块链系统中，这些节点就可以称为矿工，而打包的过程就是挖矿。系统中的节点会对矿工打包的区块进行验证，验证通过则放到区块链中。</p><p>在每个区块的头部包含了上一个区块的哈希值，这个哈希值是由上个区块中的内容生成的，如果某个节点想要修改某个区块中的内容，那么该区块的哈希值也会改变，该区块以后所有的区块也都需要改变。这就相当与以一己之力对抗系统中的所有人，当系统中的节点多的时候，这种操作可以说是几乎不可能的。</p><p>区块链从诞生到现在，整个发展过程可以简单的划分为3个阶段：</p><h3 id="1、-区块链1-0-以比特币为代表的数字货币阶段"><a href="#1、-区块链1-0-以比特币为代表的数字货币阶段" class="headerlink" title="1、 区块链1.0 以比特币为代表的数字货币阶段"></a>1、 区块链1.0 以比特币为代表的数字货币阶段</h3><p><img src="/2022/06/19/18web3/web34.png"></p><p>比特币的出现，催生出了区块链，但是比特币区块链，所有规则是事先写好的，没有人可以在比特币区块链上修改任何规则，你只能用它，而不能在它的基础上再去发展。也就是说这一时期的区块链，只是为了服务与特定的业务，并不能作为一个通用的平台。以太坊对于区块链技术而言，是一次飞跃性的突破，它让区块链商业应用变得可能。</p><h3 id="2、-区块链2-0-以太坊为代表的智能合约阶段"><a href="#2、-区块链2-0-以太坊为代表的智能合约阶段" class="headerlink" title="2、 区块链2.0 以太坊为代表的智能合约阶段"></a>2、 区块链2.0 以太坊为代表的智能合约阶段</h3><p><img src="/2022/06/19/18web3/web35.png"></p><p>2015年，一个新的公链出现，叫做以太坊。并将智能合约带到了区块链中。以太坊可以被看作是一台<code>全球计算机</code>，它允许所有人在以太坊区块链的基础上做其他的应用开发。</p><h3 id="3、-区块链3-0-开始超出金融行业，为各行各业提供解决方案，为新的互联网理念web3-0提供支持。"><a href="#3、-区块链3-0-开始超出金融行业，为各行各业提供解决方案，为新的互联网理念web3-0提供支持。" class="headerlink" title="3、 区块链3.0 开始超出金融行业，为各行各业提供解决方案，为新的互联网理念web3.0提供支持。"></a>3、 区块链3.0 开始超出金融行业，为各行各业提供解决方案，为新的互联网理念web3.0提供支持。</h3><p><img src="/2022/06/19/18web3/web36.png"></p><h2 id="Web3-0"><a href="#Web3-0" class="headerlink" title="Web3.0"></a>Web3.0</h2><p><img src="/2022/06/19/18web3/web37.png"></p><p>说起Web3.0,先要从Web1.0和Web2.0说起。</p><h3 id="1、Web1-0-静态互联网"><a href="#1、Web1-0-静态互联网" class="headerlink" title="1、Web1.0 静态互联网"></a>1、Web1.0 静态互联网</h3><p>Web1.0时期，也称为静态互联网时期，是互联网发展的第一个阶段，这一阶段互联网上的内容是由平台提供，用户只能<code>读取信息</code>而不能写入信息。最典型的互联网产品是门户网站、搜索引擎等工具。代表性的有搜狐、新浪和网易三大门户网站。</p><h3 id="2、Web2-0-平台互联网"><a href="#2、Web2-0-平台互联网" class="headerlink" title="2、Web2.0 平台互联网"></a>2、Web2.0 平台互联网</h3><p>Web2.0时期，也就是我们现在所处的时期，被称为平台互联网时期。Web2.0的概念在2004年始于出版社经营者O’Reilly和Media Live International之间的一场头脑风暴论坛。当时对Web2.0的讨论也像今天我们讨论Web3.0一样激烈。</p><p>Web2.0相比于Web1.0更加注重用户的交互，用户既可以是网站内容的浏览者也可以是内容的创造者，由以前的只能<code>读</code>向<code>写</code>和<code>共同建设</code>发展。用户也参与到互联网的发展。开始慢慢全面移动化，同时平台经济崛起，比如百度、阿里、腾讯、字节。</p><p>但是随着Web2.0的发展，平台互联网的弊端也越来越让人难以接受，所谓天下苦平台互联网时代久矣。当下的平台互联网：用户创造、平台所有、平台控制、平台分配、平台垄断、隐私泄漏等问题，形成了平台吞噬一切的现象。</p><p>2019年，《纽约时报》发布了一篇名为《减少互联网是唯一的答案》（The Only Answer Is Less Internet）的文章，对Web2.0时代的平台垄断、数据隐私、假新闻等问题进行了严厉批评。随着各国监管机构逐渐加强对互联网行业的监管，赢家通吃不再是互联网的铁律，合规化运营与寻找新增量成了行业发展的迫切需求，这也为Web3.0的到来埋下了伏笔。</p><h3 id="3、Web3-0-价值互联网"><a href="#3、Web3-0-价值互联网" class="headerlink" title="3、Web3.0 价值互联网"></a>3、Web3.0 价值互联网</h3><p>那里有压迫，那里就有反抗。在经历了一系列Web2.0弊端后，区块链时代的Web3.0出现了。</p><p>其实Web3.0一直是一个动态变化的过程，在区块链技术没有诞生之前，Web3.0通常意味这是一个更加智能的互联网，能够理解语义进行判断。在区块链诞生之后，Web3.0一般指建立在区块链技术之上的去中心化、去信任、无须许可的下一代互联网。</p><p>Web3.0有一下主要几个特点：</p><ul><li><p>  去中心化、去信任，不依赖第三方机构运作，避免平台吞噬一切</p></li><li><p>  可拥有，用户可以掌握自己在互联网上的数据和数字资产</p></li><li><p>  无须许可，代码开源、抗审查、可自由接入</p></li><li><p>全球化，资产在全球自由流动<br>  ……</p></li></ul><p>Web3.0的核心理念为数据的所有权归用户所有，每个人都可以控制自己的身份、数据和资产。</p><p>比如，我写了一篇文章，我授权给了某个平台，平台展示我的文章，并在文章下产生了一些评论。如果有一天我觉着这个平台不靠谱，我可以取消授权，同时将文章和评论授权给别的平台。实现真正的我的数据归我所有。</p><p>从2008年中本聪发布比特币白皮书，到2021年NFT和元宇宙的爆发，Web3.0已经从一小撮极客圈子，逐渐发展成为了一个庞大的科技产业，并且在多个方面带来了技术和应用</p><ul><li><p>去中心化金融(Defi)</p><p>  无须中心化的金融机构，即可实现传统金融中的贷款、保险、理财、股票等服务。比如Maker、Compound用于借贷的平台</p></li><li><p>非同质化代币(NFT)</p><p>  NFT有可验证、唯一、不可分割和可追溯的特性，可以用来标记特定资产，在数字货币中是重要的工具。比如著名球星库里花18万美元买一个NFT数字头像、游戏方面的GameFi、国内阿里，腾讯等推出的数字藏品等。</p></li><li><p>分布式自治组织(Dao)</p><p>  没有公司章程、没有层级制度、没有董事会，完全依靠民主治理、由参与者共同投票决定。比如Aragon、Moloch等Dao操作系统</p></li><li><p>  元宇宙</p></li></ul><p>可能大家还是觉着Web3.0现在还只是概念居多，但是在资本市场上Web3.0早已成为投资人眼里的香饽饽。</p><ul><li>  全球最大的风险投资公司之一的红杉资本一口气投资了20多家Web3.0公司。</li></ul><p>在政府层面上，也是同样在你追我敢</p><ul><li><p>  美国出台支持性政策，要保证Web3.0革命发生在美国。</p></li><li><p>  今年中国证监会科技监管局局长在《中国金融》杂志上撰文指出，“如今互联网正处在Web2.0向Web3.0演进的重要时点，加强Web3.0前瞻研究和战略预判，对我国未来互联网基础设施建设无疑具有重要意义。”</p></li><li><p>  10月31号，香港财政司正式发布《有关香港虚拟资产发展的政策宣言》，迎接Web3.0。</p></li></ul><p>处在风口的Web3.0到底是资本炒作的工具，还是一场真正的技术革命？</p><p>屠龙少年会不会终成恶龙？</p><p>让我们拭目以待。</p>]]></content>
    
    
    <summary type="html">Web3.0的核心理念为数据的所有权归用户所有，每个人都可以控制自己的身份、数据和资产。</summary>
    
    
    
    <category term="web3" scheme="http://yaocl.cn/categories/web3/"/>
    
    
    <category term="web3" scheme="http://yaocl.cn/tags/web3/"/>
    
  </entry>
  
</feed>
