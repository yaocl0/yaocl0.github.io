[{"title":"SkyWalking，分布式链路追踪","url":"/2023/02/25/26SkyWalking/","content":"随着业务的发展，软件架构也越来越复杂，为了适应海量用户高并发请求，系统中的组件也逐渐的变为分布式，单体服务变为微服务、缓存变为分布式缓存、组件通信变为分布式消息。\n\n系统进行交互时，一个请求往往需要调用多个服务，当需要排查问题时，搞清楚服务之间的调用关系，服务与服务的调用顺序就变得重要起来。\n\n![](1.png)\n\n\n## 什么是分布式链路追踪\n\n分布式链路追踪就是将一次分布式请求还原成调用链路，将一次分布式请求的调用情况集中展示，比如各个服务节点上的耗时、请求具体到达哪台机器上、每个服务节点的请求状态等等。\n\n\n![](2.png)\n\n\n链路追踪最早可以追溯到谷歌的 Dapper 系统，但是 Dapper 链路追踪系统并没有开源，不过谷歌发表了一篇论文：《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》，讲述了分布式链路追踪的理论和 Dapper 的设计思想，特别是微服务架构中链路追踪的概念、数据表示、埋点、传递、收集、存储与展示等技术细节。\n\nDapper 中有几个关键的技术点来表示链路的信息：Trace、Span、Annotations。\n\n### Trace\n\nTrace 表示一次请求经过所有服务的路径。用一个全局唯一的 traceid 来标识。\n\n### Span\n\nSpan 用来表示父子关系，同一层级 parent id 相同，span id 不同，span id 从小到大表示请求的顺序。\n\n### Annotations\n\nAnnotations 用于用户自定义事件，用来辅助定位问题。\n通常包含四个注解信息：\n\ncs：Client Start，表示客户端发起请求；\n\nsr：ServerReceived，表示服务端收到请求；\n\nss：Server Send，表示服务端完成处理，并将结果发送给客户端；\n\ncr：ClientReceived，表示客户端获取到服务端返回信息；\n\n![](3.png)\n\n### 采样和存储\n\n为了减少性能消耗，避免存储资源的浪费，dapper 并不会上报所有的 span 数据，而是使用采样的方式。举个例子，每秒有 1000 个请求访问系统，如果设置采样率为 1/1000，那么只会上报一个请求到存储端。\n\n链路中的 span 数据经过收集和上报后会集中存储在一个地方，Dapper 使用了 BigTable 数据仓库，常用的存储还有 ElasticSearch, HBase, In-memory DB 等。\n\n目前业界的链路追踪系统，如 Twitter 的 Zipkin，Uber 的 Jaeger，阿里的鹰眼，美团的 Mtrace 以及本文介绍的 SkyWalking，大多数都是受谷歌 Dapper 的启发。\n\n## SkyWalking\n\nSkyWalking 是一个优秀的国产开源 APM（Application Performance Management） 组件，是一个对分布式应用程序集群的业务运行情况进行追踪、告警和分析的系统。2015 年由个人吴晟开源 ， 2017 年加入 Apache 孵化器。\n\nSkyWalking 支持 SpringBoot、SpringCloud、dubbo 集成，代码无侵入，通信方式采用 GRPC，性能较好，实现方式是 探针，支持告警，支持 JVM 监控，支持全局调用统计等等，功能较完善。\n\nSkyWalking 的核心是数据分析和度量结果的存储平台，通过 HTTP 或 gRPC 方式向 SkyWalking Collecter 提交分析和度量数据。\n\n### SkyWalking 架构\n\n![](4.png)\n\nSkyWalking Collecter 对数据进行分析和聚合，存储到 Elasticsearch、H2、MySQL、TiDB 等其一即可，最后可以通过 SkyWalking UI 的可视化界面对最终的结果进行查看。\n\nSkywalking 支持从多个来源和多种格式收集数据：多种语言的 Skywalking Agent 、Zipkin v1/v2 、Istio 勘测、Envoy 度量等数据格式。\n\n在上面的架构图中我们需要关注的只有 SkyWalking Collecter、SkyWalking UI 和 存储设备，SkyWalking Collecter、SkyWalking UI 官方下载安装包内已包含，最终我们只需考虑存储设备即可。\n\n### 安装\n\n本文以 SkyWalking9.4.0 演示，SkyWalking 下载地址：http://skywalking.apache.org/downloads/\n\n![](5.png)\n\n以 Linux 为例。启动脚本在 bin/startup.sh。会启动两个服务:\n\n1、 skywalking-oap-server 服务\n\nskywalking-oap-server 服务启动后会暴露 11800 和 12800 两个端口，分别为收集监控数据的端口 11800 和接受前端请求的端口 12800，可以在 config/applicaiton.yml 修改端口，数据库存储等。默认使用 H2 数据库存储。\n\n![](6.png)\n\n2、 skywalking-web-ui 服务\n\nSkyWalking UI 界面的数据是通过请求 SkyWalking OAP 服务来获得。\n\nskywalking-web-ui 服务会占用 8080 端口， 可以在 webapp/applicaiton.yml 修改端口。\n\n![](7.png)\n\n启动成功之后，访问 Skywalking UI 界面：http://127.0.0.1:8080/\n\n### 项目集成\n\n监控 Java 项目，需要下载 Java 所需的探针 Skywalking Agent。\n\n![](8.png)\n\n在 IDEA 中使用 SkyWalking， 配置 java 启动参数\n\n![](9.png)\n\n```java\n// 探针的位置\n-javaagent:/kywalking-agent所在目录/skywalking-agent/skywalking-agent.jar\n//服务名称\n-Dskywalking.agent.service_name=system\n//skywalking collector的地址\n-Dskywalking.collector.backend_service=192.168.68.28:11800\n```\n\n配置完，启动 Java 项目。\n\n![](10.png)\n\n### 展示效果\n\n链路拓扑\n\n![](11.png)\n\n每个请求的调用链路\n\n![](12.png)\n\n\n概览全局页\n\n![](13.png)\n\n","tags":["分布式链路追踪"],"categories":["分布式链路追踪"]},{"title":"什么是DAPP","url":"/2023/01/13/25dapp/","content":"## DAPP（分布式应用），区块链新物种，去中心化 App\n\n简单来说，DAPP 和普通的 App 原理一样，除了他们是完全去中心化的，由类似以太坊网络本身自己的节点来运作的 DAPP，不依赖于任何中心化的服务器，DAPP 是去中心化的，可以完全自动地运行。\n\n### 1、DAPP（分布式应用）是什么\n\nDAPP 是 Decentralized Application 的缩写，中文叫分布式应用/去中心化应用，通常来说，不同的 DAPP 会采用不同的底层区块链开发平台和共识机制，或者自行发布代币（也可以使用基于相同区块链平台的通用代币）。\n\n![](1.png)\n\n符合以下 3 个条件的应用可以认为是一个 DAPP（分布式应用）：\n\n运行在分布式网络上；\n\n参与者信息被安全存储，隐私得到很好的保护；\n\n通过网络节点去中心化操作。\n\n![](2.png)\n\n### 2、DAPP 的四个特征\n\nDAPP 不同的底层区块链开发平台就好比手机的 IOS 系统和 Android 系统，是各 DAPP 的底层生态环境，DAPP 就是底层区块链平台生态上衍生的各种分布式应用，也是区块链世界中的基础服务提供方，DAPP 于区块链，就好比 APP 之于 IOS 和 Android。\n\n![](3.png)\n\n一个真正的 DAPP 应用，需要同时满足一下几个条件：\n\n应用必须完全开源、自治，且没有一个实体控制着该应用超 51%Token。该应用必须能够根据用户的反馈及技术要求进行升级，且应用升级必须由大部分用户达成共识之后方可进行；\n\n应用的数据必须加密后存储在公开的区块链上；\n\n应用必须拥有 Token 机制（可用基于相同底层区块链平台的通用代币或自行发行新币），矿工或应用维护节点需要得到代币奖励；\n\n应用代币的产生必须依据标准的加密算法，有价值的节点可以根据该算法获取应用的代币奖励。\n\n### 3、DAPP 应该制定类似宪法章程的智能合约\n\n区块链的早期应用是货币交易、金融交易，随后是智能资产，包括房产、汽车等实物资产和知识产权、司法认证、公共档案等虚拟资产。\n\n未来随着智能合约的发展，智能合约构建的组织如同现实商业社会一样的运行，这样形成的去中心化组织网络会变得极其复杂和自治，会出现各种形态：\n\nDapp（去中心化应用）  \nDAO（去中心化自治组织）  \nDAC（去中心化自治公司）  \nDAS（去中心化自治社会）  \n在没有人类干预的前提下，通过预先设定的业务规则自动运行。\n\n一个简单的智能合约例子：2 个人打赌一场球赛，筹码会暂时保存到网络，球赛结束后，网络中预先设定的智能合约会校验在线结果，然后把钱打到赢家账户。\n\n![](4.png)\n\n## DAPP 优势\n\nDAPP 用户体验由于区块链特有的数据确权、价值传递功能，可以消除很多影响用户体验、提升开发难度的因素：\n\n（1）用户实名认证流程变更\n\nDAPP 场景下，如果公链内支持数据共享，那么开发者只需要完成数据匹配，就可以从其他生态内的开发者处共享到用户实名资料，同时只需要支付 Token 即可；同时对用户而言，这也算是 POD（Proof of Data）挖矿模式，同样有收益，算是合作共赢；比如公信宝“布洛克城”。\n\n（2）交易安全性提升\n\n随着交易大爆炸的出现，交易效率的需求日渐提升；原来基于金融中介（例如银行、VISA 等）的交易处理方式效率低，信用生产成本高，为了降低这种风险，现在需要投入大量的风控成本进行审核但收效甚微。而基于 UTXO（Unspent Transaction Output）的区块链技术可以简单解决这个问题，而不需要对现有业务流程做任何变动升级，比如央行“数字票据交易平台”。\n\n（3）行业生产关系的变更\n\n区块链的数据确权、价值网络的两个属性可以变更现在的互联网生产关系，促使行业类应用出现，用户不用再为选择焦虑症发愁，典型的例子就是互联网视频；版权成本高昂导致腾讯、爱奇艺、搜狐只能付出极高的成本打击盗版、而用户追剧则需要在不同的平台购买 VIP 账号，如果基于区块链技术，剧集可以被版权方确权，用户不管通过任何渠道观看剧集，其支付的费用都可以 Token 化，然后由区块链基于价值网络分配给版权方、渠道方。在此生态内，盗版的问题被解决（比如 B 站 UGC 上传等），版权争夺成本下降，开发者专注于用户体验的提升，获取用户的方式也从版权壁垒变成社群运营，体验比拼，真正的互联网运营时代将会到来。例如当年的“火花电视”将各个平台的电视剧做到一站式观看，但是私自添加广告，影响版权方利益，最后被禁就是例子。\n\n（4）项目运维成本降低\n\n项目的运维成本往往高于开发成本，我们评估资源阈值的依据是预计最大流量，如果评估太低，则容易宕机，太高则浪费严重，例如：大多数产品应该都面临过运营活动带来的高并发问题，一次营销爆服务器的现象屡见不鲜，而添置服务器所带来的成本浪费则令人头疼，目前几个开发中的底层链（例如 EOS、Elastos）的资源分配模型基于用户持有 Token 的数量，这就意味着我们可以在某个活动开始前临时性购买 Token（资源），并在日常运维中将其释放（卖出），极大减少了运维成本。\n\n（5）技术开发成本降低\n\n目前项目开发通常会评估四个版本：iOS、Android、小程序、Web，理论上 DAPP 类似小程序，设计思想是无需安装，用完即走，所有的计算都在线上完成，本地禁止创建进程，系统自动创建或查找本地、周边、链内的其他微服务。\n\n## DAPP 的劣势\n\n（1）产品设计思路的颠覆\n\n目前互联网产品设计思路是“小步快跑、高速迭代”，这个方式在纯 DAPP 应用中应该会出现较大问题。简单来说，现有的 APP 都基于自有服务器，重大问题迭代强行刷新版本即可，但 DAPP 基于分布式的区块链网络，一旦提交上线出现核心 bug 很难迭代。\n\n拿 The DAO 来举个例子，The DAO 的核心漏洞如果是中心化处理，只需要下线更改 Bug 即可，但是以太坊却只能以硬分叉解决，这就是 DAPP 与现有 APP 设计思想的不同，在 MVP1.0 的调研阶段，一定要确认核心机制不出意外。\n\n（2）公链处理效率低\n\n目前成功落地的底层链都存在效率低、资源占用不合理问题，比特币的 5TPS、以太坊的 25TPS 跟 VISA 的 1300TPS 几乎没有可对比性。所以，目前公链并不适合商业化应用开发，如果借用其中几个技术（不涉及实时交易）倒是没有问题，比如积分交易、版权分享等。\n\n（3）研发风险大\n\n现在尚未出现普适性质的公链，就好像 PC 时代的 Windows、Mac OS；智能机时代的 iOS、Android。所以，基于某条公链的开发就要承担如果该公链被淘汰后血本无归的风险，好比当年的塞班开发者，或许跨链技术可以解决，但谁知道呢？综上所述，从互联网生态意义上来说，区块链技术是其底层结构的重要部分，未来所有的应用都需要考虑与其结合，也可能会有更多的全新应用模式出现。\n\n## 底线\n\n网上看到一句话说：DAPP 是技术进化的下一个合乎逻辑的步骤。我觉得有道理，区块链带来的人们的共识和数据的公开不可篡改，在这个基础上不依赖于人来执行的智能合约成为了可能，于是一切 App 的底层规则也就变了。\n\n","tags":["web3"],"categories":["web3"]},{"title":"分布式事务框架Seata","url":"/2022/12/19/24seata/","content":"分布式事务基础\n\n[<<分布式事务基础理论>>](https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==\\&mid=2247484102\\&idx=1\\&sn=58aca57cc3c96f64af6c68e9944918d7\\&chksm=fcafc744cbd84e52da07629c679a9915ee9cb7ba5698aee5934429b19a95ce2a402c07dca756\\&token=1611733318\\&lang=zh_CN#rd)\n\n[<<分布式事务解决方案>>](https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==\\&mid=2247484148\\&idx=1\\&sn=2e5395cf06ce1fcf5fd52b1c4381ea49\\&chksm=fcafc776cbd84e600b244ba4040f1cdd8b4845bb3a1ec144497a41e4b65652468c621f9be8dd\\&token=1611733318\\&lang=zh_CN#rd)\n\nSeata 一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。\n\n## Seata 全局框架\n\nSeata 的设计思路是将一个分布式事务理解成一个全局事务下面挂了多个分支事务，而一个分支事务是一个满足 ACID 的本地事务，因此我们可以操作分布式事务像操作本地事务一样。\n\n在 Seata 内部定义了三个模块来处理全局事务和分支事务：\n\n*   Transaction Coordinator（TC) - 事务协调者: 维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。\n*   Transaction Manager (TM)-  事务管理器： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。\n*   Resource Manager (RM)  - 资源管理器： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。\n\nSeata 提供的 AT、TCC、SAGA 和 XA 事务模式，都是基于这三个模块进行的。Seata 整体的执行步骤为：\n\n1.  TM 向 TC 申请开启一个全局事务，TC 创建全局事务并返回一个唯一的 XID，XID 会在全局事务的上下文中传播。\n2.  RM 向 TC 注册分支事务，该分支事务归属于拥有相同 XID 的全局事务。\n3.  TM 向 TC 发起全局的提交或回滚。\n4.  TC 调度 XID 下的所有分支事务提交或回滚。\n\n![](1.png)\n\n### AT 模式\n\n在[《分布式事务解决方案》](https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==\\&mid=2247484148\\&idx=1\\&sn=2e5395cf06ce1fcf5fd52b1c4381ea49\\&chksm=fcafc776cbd84e600b244ba4040f1cdd8b4845bb3a1ec144497a41e4b65652468c621f9be8dd\\&token=1611733318\\&lang=zh_CN#rd)中介绍了常见的几种方案，总的来说主要分为两类：对业务无入侵和有入侵的方案。无入侵方案主要有基于数据库 XA 协议，虽然 XA 协议与业务代码解耦，但是它必须要求数据库对 XA 协议的支持，且 XA 协议会造成事务资源长时间得不到释放，锁定周期长，性能很差。有入侵的方案都需要通过在应用层做手脚，比如很出名的 TCC 方案，基于 TCC 也有很多成熟的框架，如 ByteTCC、tcc-transaction 等。\n\n针对以上事务解决方案的痛点，Seata 提出了 AT 模式，`也是Seata默认的事务模式`。\n\nAT 模式的实现原理是在数据源做了一层代理(DataSourceProxy)，在代理层中 Seata 加入了一些额外的逻辑，包括解析 SQL，把业务数据在更新前后的数据镜像组织成回滚日志，并将 undo log 日志插入 undo\\_log 表中，保证每条更新数据的业务 sql 都有对应的回滚日志存在。\n\nAT 模式的执行过程\n\n*   一阶段：\n\nSeata 拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成`before image`，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成`after image`，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。最后生成的`before image`和`after image`会保存到 undo log 表中\n\n![](2.png)\n\n*   二阶段：\n\n如果是提交，因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。\n\n![](3.png)\n\n如果是回滚，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用`before image`还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。\n\n![](4.png)\n\nAT 模式的一阶段、二阶段提交和回滚均由 Seata 框架自动生成，用户只需编写业务 SQL，便能轻松使用分布式事务，AT 模式是一种对业务无任何侵入的分布式事务解决方案。\n\n## 环境搭建\n\nSeata 分 TC、TM 和 RM 三个角色，TC（Server 端）为单独服务端部署，TM 和 RM（Client 端）由业务系统集成。\n\n### 服务端部署\n\n1.  下载启动包：<https://github.com/seata/seata/releases>\n2.  建表，主要的表有三个：\n\n*   全局事务：global\\_table\n*   分支事务：branch\\_table\n*   全局锁：lock\\_table\n\n    在 MySQL 中，创建一个名为 seata 的数据库实例。创建相关表的脚本在 `seata-->script-->server-->db`目录下\n\n1.  设置配置中心和注册中心\n\n*   搭建 nacos，具体的搭建过程自行查资料\n\n*   配置中心： `seata-->conf-->application.yml` 修改 seata.config.type=\"nacos\",在 `seata-->conf-->application.example.yml` 中 seata.config.nacos 下有相关的 nacos 配置，将其复制到 application.yml 下，并将 nacos 相关的数据配置完整。\n\n    设置配置中心可以参考官网：<https://seata.io/zh-cn/docs/user/configuration/nacos.html>\n\n*   注册中心： `seata-->conf-->application.yml` 修改 seata.registry.type=\"nacos\",在 `seata-->conf-->application.example.yml` 中 seata.registry.nacos 下有相关的 nacos 配置，将其复制到 application.yml 下，并将 nacos 相关的数据配置完整。\n\n1.  修改存储模式 store.mode\\\n    Server 端存储模式（store.mode）现有 file、db、redis 三种，file 模式无需改动，直接启动即可，下面专门讲下 db，因为 db 模式为高可用模式，全局事务会话信息通过 db 共享。\n    `seata-->conf-->application.yml`，修改 store.mode=\"db\"\n\n2.  修改数据库连接\\\n    `seata-->conf-->application.example.yml` 中附带额外配置，将其 db 相关配置复制至 application.yml，修改 store.db 相关属性。\n\n3.  启动\n\n```shell\nseata-server.sh -h 127.0.0.1 -p 8091 -m db\n```\n\n### 业务系统集成\n\n1.  添加依赖，Seata 提供了不同的依赖包。可以根据项目自行选择，建议单选。\n\n*   依赖 seata-all\n*   依赖 seata-spring-boot-starter，支持 yml、properties 配置(.conf 可删除)，内部已依赖 seata-all\n*   依赖 spring-cloud-alibaba-seata，内部集成了 seata，并实现了 xid 传递\n\n1.  在涉及到的服务的数据库中创建`undo_log`表\n\n```sql\nCREATE TABLE `undo_log` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT,\n  `branch_id` bigint(20) NOT NULL,\n  `xid` varchar(100) NOT NULL,\n  `context` varchar(128) NOT NULL,\n  `rollback_info` longblob NOT NULL,\n  `log_status` int(11) NOT NULL,\n  `log_created` datetime NOT NULL,\n  `log_modified` datetime NOT NULL,\n  `ext` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;\n```\n\n1.  初始化 GlobalTransactionScanner，如果引入`seata-spring-boot-starter`、`spring-cloud-starter-alibaba-seata`等 jar 会自动初始化，否则需要手动初始化。\n\n```java\n@Bean\npublic GlobalTransactionScanner globalTransactionScanner() {\n    String applicationName = this.applicationContext.getEnvironment().getProperty(\"spring.application.name\");\n    String txServiceGroup = this.seataProperties.getTxServiceGroup();\n    if (StringUtils.isEmpty(txServiceGroup)) {\n        txServiceGroup = applicationName + \"-fescar-service-group\";\n        this.seataProperties.setTxServiceGroup(txServiceGroup);\n    }\n\n    return new GlobalTransactionScanner(applicationName, txServiceGroup);\n}\n```\n\n1.  实现 xid 跨服务传递，如果是 Spring Cloud 项目，并引用了`spring-cloud-starter-alibaba-seata`jar，则已经自动实现了，否则需要参考源码 integration 文件夹下的各种 rpc 实现 module\n\n#### 业务使用\n\n1、以一个 Spring Cloud 项目为例，项目中有两个服务：订单服务和 库存服务。业务场景为创建订单的同时减库存。\n\n在两个服务中添加依赖\n\n```xml\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-seata</artifactId>\n</dependency>\n<dependency>\n    <groupId>com.alibaba.nacos</groupId>\n    <artifactId>nacos-client</artifactId>\n</dependency>\n```\n\n2、在每个业务服务下的数据库里添加`undo_log`表。\n\n3、在每个业务服务下的配置文件中添加 seata 配置\n\n```yml\nseata:\n  tx-service-group: default_tx_group\n  registry:\n    type: nacos\n    nacos:\n      application: seata-server # seata server 的服务名seata-server ，如果没有修改可以不配\n      server-addr:  127.0.0.1:8848 # seata server 所在的nacos服务地址\n      group : DEFAULT_GROUP  # seata server 所在的组，默认就是SEATA_GROUP，没有改也可以不配\n      namespace: 0d876b7d-4cfd-4860-bf81-8e5266c9375c # 自己seata注册中心namespace\n      username: nacos\n      password: nacos\n  config:\n    type: nacos\n    nacos:\n      server-addr: 127.0.0.1:8848 # seata server 所在的nacos服务地址\n      username: nacos\n      password: nacos\n      group: DEFAULT_GROUP\n      namespace: 0d876b7d-4cfd-4860-bf81-8e5266c9375c # 自己seata注册中心namespace\n  application-id: seata-demo #\n  enabled: true\n```\n\n`注意`：\n\n1.  这里的 group 要与 server 端配置的保持一致\n2.  tx-service-group 为事务群组，要部署同一套分布式事务的微服务要求事务群组要一致。可以在 nacos 的配置中查询 ：service.vgroupMapping.xxx。\n\n![](5.png)\n\n1.  库存服务 `StockController`\n\n```java\n@PostMapping(value = \"/reduct\")\npublic void reduct(String productId) {\n    //去库存\n    stockService.reduct(order.getProductId());\n    // 异常\n    int a=1/0;\n    return order;\n}\n```\n\n在减库存的方法中模拟了一个业务异常`int a=1/0`，表示服务调用发生异常。\n\n1.  订单服务中创建调用库存服务的 Feign\n\n```java\n@FeignClient(value = \"stock-service\")\npublic interface StockApi {\n    @PostMapping(value = \"/reduct\")\n   void reduct(String productId);\n}\n\n```\n\n订单服务`OrderService`，在需要开启全局事务的方法上添加`@GlobalTransactional`注解\n\n```java\nAutowired\nprivate StockApi stockApi;\n\n@GlobalTransactional\npublic Order create(Order order) {\n    // 插入\n    orderMapper.insert(order);\n    // 减库存\n    stockApi.reduct(order.getProductId());\n    return order;\n}\n```\n\n当调用订单服务时，库存服务发生异常，可以判断发生异常后两个数据库中的数据是否回滚。\n\n参考： <https://seata.io/zh-cn/blog/seata-at-tcc-saga.html>\n","tags":["分布式事务"],"categories":["分布式事务"]},{"title":"分布式事务基础","url":"/2022/11/23/23distributedTransaction/","content":"事务是数据库执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。\n事务有四个特性，习惯上被称为 ACID 特性：\n\n- Atomicity(原子性)\n- Consistency(一致性)\n- Isolation(隔离性)\n- Durability(持久性)\n\n## 本地事物\n\n在系统发展初期，单体应用对应一个数据库，整个服务操作只涉及一个数据库资源，通过数据库自带的事务很容易实现 ACID，这类基于单个服务单一数据库资源访问的事务，被称为本地事务(Local Transaction)。\n\n![](1.png)\n\n## 分布式事务\n\n随着互联网的发展，微服务架构大规模的普及，软件系统由原来的单体应用转变为分布式应用。分布式系统一般由多个独立的子系统组成，多个子系统通过网络通信互相协作配合完成各个功能。\n\n分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。比如在一个电商系统中，一条订单的生成涉及库存、订单、支付等不同的服务，不同的服务之间要么全成功、要么全失败，保证事务的 ACID 特性。\n\n![](2.png)\n\n本质上来说，分布式事务就是为了保证不同数据库的数据一致性。\n\n在分布式系统中数据一致性又可以划分出多个一致性模型\n\n- 强一致性：任何一次读都能读到某个数据的最近一次写的数据。系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致。简言之，在任意时刻，所有节点中的数据是一样的。\n\n- 弱一致性：数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。\n\n- 最终一致性：不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。简单说，就是在一段时间后，节点间的数据会最终达到一致状态。\n\n在解决分布式事物的数据一致性问题上，产生了多个相关的理论。\n\n## CAP 理论\n\nCAP 定理又被称作布鲁尔定理，是加州大学的计算机科学家布鲁尔在 2000 年提出的一个猜想。2002 年，麻省理工学院的赛斯·吉尔伯特和南希·林奇发表了布鲁尔猜想的证明，使之成为分布式计算领域公认的一个定理。\n\n- C : Consistency 一致性 , 所有实例节点同一时间看到是相同的数据\n- A : Availability 可用性 , 不管是否成功，确保每一个请求都能接收到响应\n- P : Partition tolerance 分区容错性 , 系统任意分区后，在网络故障时，仍能操作\n\nCAP 理论是指在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性、可用性、分区容错性者中的两个，另外一个必须被牺牲。\n\n在真实的分布式环境下，如果我们选择了 CA（一致性 + 可用性） 而放弃了 P（分区容错性），那么当发生分区现象时，为了保证 C（一致性），系统需要禁止写入，当有写入请求时，系统返回 error（例如，当前系统不允许写入），这又和 A(可用性) 冲突了，因为 A（可用性）要求返回 no error 和 no timeout。因此虽然在 CAP 理论定义是三个要素中只能取两个，但放到分布式环境下来，必须选择 P（分区容错）要素，因为网络本身无法做到 100% 可靠，有可能出故障，所以分区是一个必然的现象。\n也就说在真是环境下我们只能选择 CP（一致性 + 分区容错性） 或者 AP （可用性 + 分区容错性）架构，在一致性和可用性做折中选择。\n\n虽然 CAP 理论告诉我们分布式系统只能选择 AP 或者 CP，但实际上并不是说整个系统只能选择 AP 或者 CP，在 CAP 理论落地实践时，我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP 还是 AP），而不是直接限定整个系统所有数据都是同一策略。\n\n## BASE 理论--CAP 理论的延伸\n\n由于在分布式系统中 C、A、P 三者都无法抛弃，但 CAP 定理限制三者无法同时满足，这种情况，我们会选择尽量靠近 CAP 定理，即尽量让 C、A、P 都满足，在此所趋下，出现了 BASE 定理。\n\nBASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent （最终一致性）三个短语的缩写。核心思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。\n\n- BA：Basically Available 基本可用，分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。  \n  电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。\n- S：Soft State 软状态，允许系统存在中间状态，而该中间状态不会影响系统整体可用性。  \n  分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication 的异步复制也是一种体现。\n- E: Eventual Consistency 最终一致性， 系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。\n\nBASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。\n\nBASE和ACID的区别与联系\n\n- ACID是传统数据库常用的设计理念, 追求强一致性模型。\n- BASE支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性\n\nACID和BASE代表了两种截然相反的设计哲学。  \n总的来说，BASE 理论面向大型高可用可扩展的分布式系统，与ACID这种强一致性模型不同，常常是牺牲强一致性来获得可用性，并允许数据在一段时间是不一致的。虽然两者处于（一致性-可用性）分布图的两级，但两者并不是孤立的，对于分布式系统来说，往往依据业务的不同和使用的系统组件不同，而需要灵活的调整一致性要求，也因此，常常会组合使用ACID和BASE。\n\n## 柔性事务\n\n不同于 ACID 的刚性事务，在分布式场景下基于 BASE 理论，就出现了柔性事务的概念。柔性事务下，在不影响系统整体可用性的情况下(Basically Available 基本可用)，允许系统存在数据不一致的中间状态(Soft State 软状态)，在经过数据同步的延时之后，最终数据能够达到一致。并不是完全放弃了 ACID，而是通过放宽一致性要求，借助本地事务来实现最终分布式事务一致性的同时也保证系统的吞吐。\n\n## XA --强一致性\n\n由 Tuxedo 提出的 XA 是一个分布式事务协议，规定了事务管理器和资源管理器接口。XA 协议可以分为两部分，即事务管理器和本地资源管理器。\n\n- 事务管理器作为`协调者`，负责各个本地资源的提交和回滚。\n- 资源管理器就是分布式事务的`参与者`.其中资源管理通常是数据库。\n\n基于 XA 协议的，发展出了二阶段提交协议（The two-phase commit protocol，2PC）和三阶段提交协议（Three-phase commit protocol，3PC）。\n\n### 2PC\n\n二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。\n\n将事务的提交过程分为两个阶段来进行处理：准备阶段和提交阶段。\n\n0x1 准备阶段\n\n1.  协调者向所有参与者发送 CanCommit 操作请求，并等待参与者的响应。\n2.  参与者接收到请求后，会执行请求中的事务操作，将 undo 和 redo 信息记入事务日志中，但是这时并不提交事务。\n    ![](3.png)\n    若不成功，则发送“No”消息，表示终止操作。当所有的参与者都返回了操作结果（Yes 或 No 消息）后，系统进入了提交阶段。  \n    ![](4.png)\n\n0x2 提交阶段\n\n协调者会根据所有参与者返回的信息向参与者发送 DoCommit 或 DoAbort 指令\n\n1. 若协调者收到的都是“Yes”消息，则向参与者发送“DoCommit”消息，参与者会提交事务并释放资源，然后向协调者返回“Ack”消息。\n   ![](5.png)\n\n2. 如果协调者收到的消息中包含“No”消息，则向所有参与者发送“DoAbort”消息，此时发送“Yes”的参与者会根据之前执行操作时的回滚日志对操作进行回滚，然后所有参与者会向协调者发送“Ack”消息；\n   ![](6.png)\n\n3) 协调者接收到所有参与者的“Ack”消息，就意味着整个事务结束了。\n\n2PC 实现起来比较简单，但是实际项目中使用比较少，主要因为以下问题：\n\n性能问题：所有参与节点都是事务阻塞型的，占用系统资源，容易导致性能瓶颈。\n\n可靠性问题：如果协调者出现故障，参与者将一直处于锁定状态。\n\n数据一致性问题：在提交阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。\n\n### 3PC\n\n基于 2PC 基础上，3PC 对 2PC 进行了改进，引入了超时机制。同时将准备阶段拆分为 2 个阶段，多了一个 PreCommit 阶段。\n\n3PC 可以划分为 CanCommit 阶段、PreCommit 阶段、DoCommit 阶段。\n\n0x1 CanCommit 阶段\n\n1. 协调者向所有参与者发送 \"CanCommit\" 请求，询问是否可以提交事务，并等待所有参与者答复。\n2. 参与者收到 \"CanCommit\" 请求之后，回复 \"Yes\"，表示可以顺利执行事务；否则回复 \"No\"。\n\n![](7.png)\n\n0x2 PreCommit 阶段\n\n协调者根据参与者的回复情况，来决定是否可以进行 PreCommit 操作或中断事务。\n\n如果参与者返回的回复情况全部是 Yes\n\n1. 协调者向所有参与者发送 \"PreCommit\" 请求，参与者进入到预提交阶段。\n2. 参与者收到 \"PreCommit\" 请求后，执行事务操作，并将 undo 和 redo 信息记入事务日志中，但这时并不提交事务。\n3. 参与者向协调者反馈执行成功 \"Yes\" 或失败响应 \"No\"。\n\n![](8.png)\n\n如果参与者返回的回复情况中包含 No，说明有一个事务执行失败。\n\n1. 协调者向所有参与者发送 “Abort”请求\n2. 参与者收到“Abort”消息之后，或超时后仍未收到协调者的消息，执行事务的中断操作。\n\n0x3 DoCommit 阶段\n\n协调者根据参与者的回复情况，来决定是否可以进行 DoCommit 操作 或 中断事务。\n\n如果参与者返回的回复情况全部是 YES\n\n1. 协调者向所有参与者发送 \"DoCommit\" 消息。\n2. 参与者接收到 \"DoCommit\" 消息之后，正式提交事务。完成事务提交之后，释放所有锁住的资源。\n3. 参与者提交完事务之后，向协调者发送 \"Ack\" 响应\n4. 协调者接收到所有参与者的 \"Ack\" 响应之后，完成事务。\n\n![](9.png)\n\n如果参与者返回的回复情况中包含 No，说明有一个事务执行失败。\n\n1. 协调者向所有参与者发送 \"Abort\" 请求。\n2. 参与者接收到 \"Abort\" 消息之后，利用其在 \"PreCommit\" 阶段记录的 undo 信息执行事务的回滚操作，并释放所有锁住的资源。\n3. 参与者完成事务回滚之后，向协调者发送 \"Ack\" 消息。\n4. 协调者接收到参与者反馈的 \"Ack\" 消息之后，执行事务的中断，并结束事务。\n\n相比二阶段提交，三阶段降低了阻塞范围，在等待超时后协调者或参与者会中断事务，避免了协调者单点问题。DoCommit 阶段中协调者出现问题时，参与者会继续提交事务。\n\n但是数据不一致问题依然存在，当在参与者收到 preCommit 请求后等待 DoCommit 指令时，此时如果协调者请求中断事务，而协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。\n\n## TCC --最终一致性\n\nTCC（Try-Confirm-Cancel）的概念，最早是由 Pat Helland 于 2007 年发表的一篇名为《Life beyond Distributed Transactions:an Apostate’s Opinion》的论文提出。\n\nTCC 是服务化的二阶段编程模型， 针对每个操作，都要实现对应的确认和补偿操作，也就是业务逻辑的每个服务都需要实现 Try、Confirm、Cancel 三个操作，第一阶段由业务代码编排来调用 Try 接口进行资源预留，当所有参与者的 Try 接口都成功了，事务协调者提交事务，并调用参与者的 Confirm 接口真正提交业务操作，否则调用每个参与者的 Cancel 接口回滚事务，并且由于 Confirm 或者 Cancel 有可能会重试，因此对应的部分需要支持幂等。\n\n- Try 阶段：尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性）\n- Confirm 阶段： 确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作满足幂等性\n- Cancel 阶段： 取消执行，释放 Try 阶段预留的业务资源 Cancel 操作满足幂等性 Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致。\n\n![](10.png)\n\nTCC 事务机制相比于上面介绍的 XA，解决了其几个缺点：\n\n1. 解决了协调者单点，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。\n2. 同步阻塞：引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。\n3. 数据一致性，有了补偿机制之后，由业务活动管理器控制一致性\n\n但是TCC中Try、Confirm、Cancel 的操作需要业务来实现，耦合度过高。\n\n## 本地消息表 --最终一致性\n\n本地消息表这个方案最初是 ebay 架构师 Dan Pritchett 在 2008 年发表给 ACM 的文章。核心思路是将分布式事务拆分成本地事务进行处理。 本地事物表方案可以将事务分为事务主动方和事物被动方。\n\n- 事务主动方: 分布式事务最先开始处理的事务方\n- 事务被动方: 在事务主动方之后处理的业务内的其他事务\n\n事务的主动方需要`额外新建事务消息表`，用于记录分布式事务的消息的发生、处理状态。整个业务流程：\n\n1. 事务主动方在本地事务中处理业务更新操作和写消息表操作。\n2. 事务主动方通过消息中间件，通知事务被动方处理事务。\n3. 事务被动方通过消息中间件，通知事务主动方事务已处理的消息\n\n![](11.png)\n\n本地消息表实现的条件：\n\n- 消费者与生成者的接口都要支持幂等\n- 生产者需要额外的创建消息表\n- 需要提供补偿逻辑，如果消费者业务失败，需要生产者支持回滚操作\n\n容错机制：\n\n- 步骤 1 失败时，事务直接回滚\n- 步骤 2、3 写 mq 与消费 mq 失败会进行重试\n- 步骤 3 业务失败事务被动方向事务主动方发起事务回滚操作\n\n## MQ 事务 --最终一致性\n\n有些 MQ 的实现支持事务，比如 RocketMQ ，基于 MQ 的分布式事务方案其实是对本地消息表的封装。以 RocketMQ 为例介绍 MQ 的分布式事务方案。\n\n1. 发送方向 MQ 服务端(MQ Server)发送 half 消息。这个 half 消息与普通消息的区别在于，在事物提交之前，这个消息对订阅方来说是不可见的，订阅方不会消费这个消息。\n2. MQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功。\n3. 发送方开始执行本地事务逻辑。\n4. 如果事务提交成功，将会发送确认消息（commit 或是 rollback）至 MQ Server。\n5. MQ Server 收到 commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 rollback 状态则删除half消息，订阅方将不会接受该消息。\n\n![](12.png)\n\n异常情况 1：如果发送方发送 commit 或 rollback 消息失败，未到达消息集群\n\n- MQ Server 会发起消息回查\n- 发送方收到回查消息后，会检查本地事务的执行结果\n- 根据本地事务的执行结果重新发送 commit 或 rollback 消息\n- MQ Server 根据接收到的消息（commit 或 rollback）判断消息是否可消费或直接删除\n\n异常情况 2：接收方消费失败或消费超时\n\n- 一直重试消费，直到事务订阅方消费消息成功，整个过程可能会导致重复消费问题，所以业务逻辑需要保证幂等性\n\n异常情况 3：消息已消费，但接收方业务处理失败\n\n- 通过 MQ Server 通知发送方进行补偿或事务回滚\n\n## Saga 事务 --最终一致性\n\nSaga 事务源于 1987 年普林斯顿大学的 Hecto 和 Kenneth 发表的如何处理 long lived transaction（长活事务）论文，Saga 事务核心思想是将长事务拆分为多个本地短事务，由 Saga 事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。\n\nSaga 事务基本协议如下：\n\n每个 Saga 事务由一系列幂等的有序子事务(sub-transaction) Ti 组成。  \n每个 Ti 都有对应的幂等补偿动作 Ci，补偿动作用于撤销 Ti 造成的结果。\n\nSaga 的执行顺序有两种：\n\n- T1, T2, T3, ..., Tn\n- T1, T2, ..., Tj, Cj,..., C2, C1，其中 0 < j < n\n\nSaga 定义了两种恢复策略：\n\n- 向前恢复(forward recovery)\n  适用于必须要成功的场景，发生失败进行重试，执行顺序是类似于这样的：T1, T2, ..., Tj(失败), Tj(重试),..., Tn，其中 j 是发生错误的子事务(sub-transaction)。该情况下不需要 Ci。\n\n![](13.png)\n\n- 向后恢复(backward recovery)\n  如果任一子事务失败，补偿所有已完成的事务。即上面提到的第二种执行顺序，其中 j 是发生错误的 sub-transaction，这种做法的效果是撤销掉之前所有成功的 sub-transation，使得整个 Saga 的执行结果撤销。\n\n![](14.png)\n\nSaga 事务常见的有两种不同的实现方式：\n\n1. 命令协调(Order Orchestrator)：中央协调器负责集中处理事件的决策和业务逻辑排序\n\n![](15.png)\n\n2. 事件编排 (Event Choreography)：没有中央协调器（没有单点风险）时，每个服务产生并观察其他服务的事件，并决定是否应采取行动。\n   在事件编排方法中，第一个服务执行一个事务，然后发布一个事件。该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布（或不发布）新的事件。\n   当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何 Saga 参与者听到都意味着事务结束。\n\n\n![](16.png)\n\n\n","tags":["分布式事务"],"categories":["分布式事务"]},{"title":"智能合约","url":"/2022/10/10/22smartContract/","content":"\n接触区块链的，经常会听到智能合约这个词，那什么是智能合约？今天就来了解了解。\n\n## 比特币引领区块链，以太坊复活智能合约\n\n1994 年，计算机科学家和密码学家 Nick Szabo 首次提出“智能合约”概念，它早于区块链概念的诞生，几乎与互联网同龄。\n\n![](1.png)\n\nSzabo 描述了什么是“以数字形式指定的一系列承诺，包括各方履行这些承诺的协议”。虽然有它的好处，但智能合约的想法一直未取得进展——一个重要原因是因为缺乏能够支持可编程合约的数字系统和技术。\n\n直到 2008 年，第一个加密货币比特币出现，同时引入了现代区块链技术。区块链最初是以比特币的底层技术出现的，但是智能合约在 2008 年依然无法融入比特币区块链网络。五年后，以太坊创始人 Vitalik Buterin 发布了白皮书《以太坊：下一代智能合约和去中心化应用平台》， 作为首个支持“图灵完备”智能合约的区块链网络，以太坊掀开了以智能合约为代表的区块链 2.0 时代的序章。从此，涌现出了各种不同形式的智能合约，其中以太坊智能合约使用最广。\n\n![](2.png)\n\n## 智能合约是什么\n\n> 智能合约是一种特殊协议，旨在提供、验证及执行合约。\n\n智能合约的英文是 `Smart Contract`，这里的智能 Smart 不等同于人工智能的 Artificial Intelligence。Smart 的意思是聪明的、灵活的，还远远未达到 Intelligence 的级别。中文的翻译有点误导的意思。\n\n智能合约本质上是一个数字协议，数字协议在我们日常生活很常见，比如信用卡自动还款服务就是一个数字协议，在某一个时间（还款日），条件满足（储蓄卡余额比信用卡还款金额要多）的情况下，计算机系统会自动完成这笔交易。自动售货机也是一个数字协议，当选择商品，付钱后，如果付的钱足以支付该商品，那么售货机会弹出想要的商品，如果钱不够则运行另一套逻辑。\n\n所以，智能合约就是一段计算机程序，程序中预先设定好了合约双方的职责和要执行的条件，一旦满足条约中的条款，程序会自动执行。只是与传统数字协议不同的是，智能合约是运行在区块链上的。\n\n站在程序员的角度去理解智能合约，可以类比为一个类实例化对象，唯一的区别是这个对象永远存在区块链网络中（除非程序进行自毁）。\n\n## 智能合约是怎么运行的\n\n智能合约一定要在区块链上么？ 并不是，就像上面说的信用卡自动还款、自动售货机的例子。但是运行在传统的计算机方式中存在合约被恶意篡改之类风险，还有一个重要的信任问题。在信用卡自动还款的例子中，因为是银行的服务，有银行背书，许多人相信银行。如果把这个服务放在淘宝、京东这类网店上，还会有人相信么？ 即使从技术角度来说实现这种服务也并不难。\n\n所以相对于传统的方式，区块链去中心化、不可篡改、过程透明可追踪、去信任等优点，天然适合于智能合约。智能合约也是区块链被称之为“去中心化的”重要原因，它允许我们在不需要第三方的情况下，执行可追溯、不可逆转和安全的交易。\n\n基于区块链的智能合约构建及执行主要分为如下几步：\n\n`构建 → 存储 → 执行`\n\n1. 多方共同制定合约内容，将编写好的智能合约代码上传到区块链上，全网的验证节点都会收到编写好的合约。\n2. 智能合约会定期检查是否存在相关事件和触发条件，满足条件的事件将会推送到待验证的队列中。比如每月10号信用卡还款日，这个事件就是智能合约的触发条件。\n3. 区块链上的验证节点先对该事件进行签名验证，以确保其有效，等大多数验证节点对该事件达成共识后，智能合约将成功执行，并通知用户。\n4. 合约成功执行后将移出区块，未执行的合约则继续等待下一轮处理，直至成功执行。\n\n智能合约的代码是具体如何运行的，不同区块链运行的方式不同，像以太坊是运行在以太坊的 EVM 中，超级账本 Fabric 是运行在 dcoker 中。\n\n基于区块链乌托邦式的智能合约虽然能够解决当前传统计算机合约下的许多问题，但是现阶区块链段智能合约仍然有一些缺点。\n\n- 区块链不可篡改的特性，智能合约一旦上链就不容易修改，这使得修改代码变得困难。\n- 区块链公开透明的特性，使得所有的私人信息都进入了公共领域。对于想要完全隐私的企业和个人来说，缺乏保密性是使用智能合约的一大缺点。\n- 区块链上的智能合约只是将信任问题进行了转移并没有得到解决，比如房产交易合约，房屋归属权上链的首要条件是现实生活中房产交付确认同样是必须的输入信息。也就是，区块链无法解决外部虚假信息的录入。\n\n互联网从诞生到成熟这条路走了有三十年，对于仅活跃几年的区块链智能合约，未来的路依旧会很漫长。\n\n![](https://img.soogif.com/zr4XXRlsRpSDwFA4N1wNkrWM923md01V.gif?scope=mdnice)\n","tags":["web3"],"categories":["web3"]},{"title":"编译器对代码做了哪些工作","url":"/2022/09/15/21compile/","content":"> 知乎上有一种说法是「编译器、图形学、操作系统是程序员的三大浪漫」。\n\n计算机很笨，它只认识 0 和 1,也只会运行最简单的机器指令，而我们平时写的代码大多都属于高级语言。高级语言编写的指令要想在计算机上执行，需要将高级语言转换成计算机识别的机器语言。编译器就是将高级语言转换成机器语言的一款软件。\n\n一个完整的编译器将源码编译成目标机器指令主要包含以下几个步骤。\n\n![](1.png)\n\n\n## 词法分析\n\n词法分析从左到右扫描源程序的字符，识别出每个单词，并组成`词素`（源代码中的一个字符串，比如一个变量名，一个运算符，都会被识别为一个词素。）。对于每个词素，词法分析会把它解析成一个词法单元。这个词法单元被称为 Token。Token 的形式一般为\n\n```\n〈token-name, attribute-value〉\n```\n\n- token-name: 单词的类别\n\n程序中的单词大体可以分成五类：\n\n![](2.png)\n\n- attribute-value： 指向符号表中关于这个词法单元的条目。符号表条目的信息会被语义分析和代码生成步骤使用\n\n什么是符号表？\n\n编译器的重要功能之一是记录源程序中使用的变量的名字，并收集和每个名字的各种属性有关的信息。这些属性可以提供一个名字的存储分配、类型、作用域等信息。对于过程名字，这些信息还包括：它的参数数量和类型、每个参数的传递方法及返回类型。\n\n符号表数据结构为每个变量名字创建了一个记录条目。记录的字段就是名字的各个属性。这个数据结构应该允许编译器迅速查找到每个名字的记录，并向记录中快速存放和获取记录中的数据。\n\n比如，对于赋值语句`position = initial + 2 * 60`\n\n`position`是一个词素，被映射成词法单元`<id, 1>`，其中 id 是表示标识符（identifier）的抽象符号，而 1 指向符号表中 position 对应的条目。\n\n赋值符号`=`是一个词素，被映射成词法单元`<=>`，因为这个词法单元不需要属性值，所以省略了第二个分量。\n\n整条语句被词法分析后的结果可以表示为   \n`<id, 1> <=> <id, 2> <+> <2> <*> <60>`\n\n\n\n## 语法分析\n\n语法分析对词法分析中扫描的 Token 进行分析，并产生语法树，这棵树被称为 AST 抽象语法树。整个分析过程采用的是上下文无关语法（Context-free Grammar）。\n\n简单来说，语法分析生成的树是以表达式为节点的树。\n\n比如，对于赋值语句`position = initial + 2 * 60`，经过语法分析后生成的数\n\n\n![](3.png)\n\n\n## 语义分析\n\n语义分析利用前面生成的语法树和符号表来检查源程序是否符合语言定义。同时收集类型信息，以便在代码生成过程中使用。\n\n语义分析的一个重要作用就是类型检查，编译器检查每一个运算符是否具有合法的运算分量。另外对于某些语言允许自动类型转换，编译器需要根据自动类型转换规则，对数据类型进行转换。\n\n语义分析结束以后，整个语法树的表达式都被标识了类型，如果有些类型需要做隐式转换的，在分析完后会在语法书树上插入相应的转换节点。\n\n比如`position = initial + 2 * 60` 经过语义分析后\n\n![](4.png)\n\n语义分析同时还会对更新符号表里的符号类型。\n\n## 中间语言生成\n\n在经过语义分析后。大多数的编译器不会直接生成目标代码，一般会生成一个抽象于平台的中间语言(Intermediate Representation，简称 IR )，该中间语言与机器无关。\n\n先生成中间代码一方面可以增加编译器的模块化、可移植性和可扩展性。中间代码既独立于任何高级语言，也独立于任何目标机器架构，这样可以开发出适应广泛高级语言的编译器。\n\n![](5.png)\n\n另一方面，也可以做一些与机器无关的优化操作。\n\n中间语言有很多种，在不同的编译器中可能也会有不同的表达形式。常用的方式有三地址码、P-代码等。\n\n拿三地址码来举例，基本的三地址码是这样的`x = y op z`，表示将变量y和z操作后赋值给x，op既可以是算术运算也可以是其他的操作。 `position = initial + 2 * 60` 被三地址成三地址码\n```\nt1 = 2 * 60\nt2 = initial + t1\nposition  = t2\n```\n\n## 中间代码优化\n\n中间代码优化的主要是做一些于底层机器无关的优化，比如消除死代码，函数内联优化，for 循环展开等优化。这一步输入的是中间代码IR,输出的也是中间代码IR。\n\n`position = initial + 2 * 60` 被翻译成中间语言后，`t1 = 2 * 60` 是可以在生成目标代码之前计算出来的，`t2 = initial + t1` 中的t1也是可以直接被替换成值的。 经过优化后的中间代码\n```\nt2 = initial + 120\nposition  = t2\n```\n\n## 目标代码生成\n\n目标代码生成的工作是将中间代码转换成目标机器代码，这个过程十分依赖目标机器，因为不同的机器有着不同的字长、寄存器、数据类型等等，需要生成不同的机器代码。\n\n现在编译器有着异常复杂的机构，因为现代高级语言本身非常的复杂，像C++编译器，至今也没有一个编译器能够完整的支持C++标准所规定的所有语言特性。 那么作为一个高级语言的使用者，为什么要学习编译原理呢？这里引用《三体》中的一段话结束。\n\n> 成吉思汗的骑兵，攻击速度与二十世纪的装甲部队相当;北宋的床弩，射程达一千五百米，与二十世纪的狙击步枪差不多;但这些仍不过是古代的骑兵与弓弩而已，不可能与现代力量抗衡。`基础理论决定一切`，未来史学派清楚地看到了这一点。而你们，却被回光返照的低级技术蒙住了眼睛。\n","tags":["编译原理"],"categories":["编译原理"]},{"title":"Java8中的Stream流","url":"/2022/08/20/20stream/","content":"## 定义\n什么是Stream流，Java doc中是这样写的\n\n> A sequence of elements supporting sequential and parallel aggregate operations\n\n翻译一下就是一个支持顺序和并行聚合操作的元素序列。  \n可以把它理解成一个迭代器，但是只能遍历一次，就像是流水一样，要处理的元素在流中传输，并且可以在流中设置多个处理节点，元素在经过每个节点后会被节点的逻辑所处理。比如可以进行过滤、排序、转换等操作。\n\nStream流的使用可以分为三个步骤：\n- 数据源，创建流\n- 中间操作，可以有多个，生成一个新的流\n- 终端操作，只能有一个，放在最后，代表流中止。\n\nStream流有几个特点：  \n1、Stream流一般不会改变数据源，只会生成一个新的数据流。  \n2、Stream流不会存储数据，只会根据设置的操作节点处理数据。  \n3、Stream流是延迟执行的，只有在调用终端操作后才会进行流转。\n\n看一下Stream的结构\n![stream](1.png)\n\n\n\n## 使用\n\n### 数据源生成流\n- 如果是集合的话，可以直接使用`stream()`创建流。\n- 如果是数组的话，可以使用`Arrays.stream()`或`Stream.of()`来创建流。\n```java\n// 集合生成流\nList<String> strList = new ArrayList<>();\nStream<String> stream = strList.stream();\n\n//数据生成流\nString[] strs = new String[]{\"1\",\"2\",\"3\"};\nStream<String> stream1 = Arrays.stream(strs);\nStream<String> stream2 = Stream.of(strs);\n```\n### 中间操作\n在上边Stream定义中，返回是`Stream`类型的大多数都是中间操作，入参大多数都是函数式编程，不熟悉的可以看看这篇<Java函数式编程>。常用的中间操作有\n- 过滤操作 `filter()`\n```java\nArrays.stream(strs).filter(s -> s.equals(\"1\"));\n```\n- 排序操作 `sorted()`\n```java\nArrays.stream(strs).sorted();\n```\n- 去重操作 `distinct()`\n```java\nArrays.stream(strs).distinct();\n```\n- 映射操作，将流中元素转换成新的元素\n    - `mapToInt()`转换成Integer类型\n    - `mapToLong()`转换成Long类型\n    - `mapToDouble()`转换成Double类型\n    - `map()` 自定义转换类型，这是一个使用频率非常高的方法。\n```java\n//将字符串转换成Integer\nArrays.stream(strs).mapToInt(s -> Integer.valueOf(s));\n//将字符串转换成Long\nArrays.stream(strs).mapToLong(s -> Long.valueOf(s));\n//将字符串转换成Doublde\nArrays.stream(strs).mapToDouble(s -> Double.valueOf(s));\n//自定义转换的类型\nArrays.stream(strs).map(s -> new BigDecimal(s));\n```\n中间操作是可以有多个的，我们可以根据业务功能组合多个中间操作，比如求数组中字符串包含s的字符串长度排序\n```java\nArrays.stream(strs).filter(e->e.contains(\"s\")).map(String::length).sorted();\n```\n\n### 终端操作\n终端操作，表示结束流操作，是在流的最后，常用的有\n- 统计 `count()`\n```java\nlong count = Arrays.stream(strs).count();\n// count=3\n```\n- 获取最小值 `min()`\n```java\n// 将字符串转换成Interger类型再比较大小\n OptionalInt min = Arrays.stream(strs).mapToInt(Integer::valueOf).min();\n System.out.println(min.getAsInt());\n // 1\n```\n- 获取最大值 `max()`\n```java\n OptionalInt max = Arrays.stream(strs).mapToInt(Integer::valueOf).max();\n System.out.println(max.getAsInt());\n // 3\n```\n- 匹配\n    - `anyMatch()`，只要有一个匹配就返回`true`\n    - `allMatch()`，只有全部匹配才返回`true`\n    - `noneMatch()`，只要有一个匹配就返回 `false`\n```java\nboolean all = Arrays.stream(strs).allMatch(s -> s.equals(\"2\"));\nboolean any = Arrays.stream(strs).anyMatch(s -> s.equals(\"2\"));\nboolean none = Arrays.stream(strs).noneMatch(s -> s.equals(\"2\"));\n// all = false\n// any = true\n// none = false\n```\n- 组合 `reduce()`将Stream 中的元素组合起来，有两种用法\n    - `Optional reduce(BinaryOperator accumulator)` 没有起始值只有运算规则\n    - `T reduce(T identity, BinaryOperator accumulator)`，有运算起始值和运算规则、返回的是和起始值一样的类型\n\n```java\nInteger[] integers = new Integer[]{1,2,3};\nOptional<Integer> reduce1 = Arrays.stream(integers).reduce((i1, i2) -> i1 + i2);\nInteger reduce2 = Arrays.stream(integers).reduce(100, (i1, i2) -> i1 + i2);\n// reduce1.get() = 6\n// reduce2 = 106\n```\n- 转换 `collect()`，转换作用是将流再转换成集合或数组，这也是一个使用频率非常高的方法。  \n  `collect()`一般配合`Collectors`使用，`Collectors` 是一个收集器的工具类，内置了一系列收集器实现，比如`toList()` 转换成list集合，`toMap()`转换成Map,`toSet()`转换成Set集合,`joining()` 将元素收集到一个可以用分隔符指定的字符串中。\n```java\nString[] strs = new String[]{\"11111\", \"222\", \"3\"};\n//统计每个字符串的长度\nList<Integer> lengths = Arrays.stream(strs).map(String::length).collect(Collectors.toList());\nString s = Arrays.stream(strs).collect(Collectors.joining(\",\"));\n// lengths=[5,3,1]\n// s = 11111,222,3\n```\n合理的组合Steam操作，可以很大的提升生产力\n\n## 原理\n![](2.png)\nStream的实现类中，将Stream划分成了`Head`、`StatelessOp`和`StatefulOp`，`Head`控制数据流入，中间操作分为了`StatelessOp`和`StatefulOp`。\n\nStatelessOp代表无状态操作：每个数据的处理是独立的，不会影响或依赖之前的数据。像`filter()`、`map()`等。\n\nStatefulOp代表有状态操作：：处理时会记录状态，比如后面元素的处理会依赖前面记录的状态，或者拿到所有元素才能继续下去等这样有状态的操作，像`sorted()`。\n\n现在已下面代码为例，分析一下Stream的原理\n```java\n list.stream()\n     .filter(e -> e.length() > 1)\n     .sorted()\n     .filter(e -> e.equals(\"333\"))\n     .collect(Collectors.toList());\n```\n### 数据源生成流\n首先，进入到`list.stream()`里\n```java\n//Collection#stream\n\n default Stream<E> stream() {\n    return StreamSupport.stream(spliterator(), false);\n }\n\ndefault Spliterator<E> spliterator() {\n    return Spliterators.spliterator(this, 0);\n }\n\n```\n```java\n//StreamSupport#stream\npublic static <T> Stream<T> stream(Spliterator<T> spliterator, boolean parallel) {\n    Objects.requireNonNull(spliterator);\n    return new ReferencePipeline.Head<>(spliterator,\n                                        StreamOpFlag.fromCharacteristics(spliterator),\n                                        parallel);\n}\n```\n将原数据封装成`Spliterator`，同时生成一个`Head`，将`Spliterator`放到`Head`中。\n\n![](3.png)\n\n### 中间操作\n接着分析中间操作`.filter(e -> e.length() > 1)`的代码\n\n```java\n//ReferencePipeline#filter\npublic final Stream<P_OUT> filter(Predicate<? super P_OUT> predicate) {\n    Objects.requireNonNull(predicate);\n    return new StatelessOp<P_OUT, P_OUT>(this, StreamShape.REFERENCE,\n                                  StreamOpFlag.NOT_SIZED) {\n        @Override\n        Sink<P_OUT> opWrapSink(int flags, Sink<P_OUT> sink) {\n            return new Sink.ChainedReference<P_OUT, P_OUT>(sink) {\n                @Override\n                public void begin(long size) {\n                    downstream.begin(-1);\n                }\n\n                @Override\n                public void accept(P_OUT u) {\n                    if (predicate.test(u))\n                        downstream.accept(u);\n                }\n            };\n        }\n    };\n}\n```\n返回的是一个无状态操作`StatelessOp`，查看`StatelessOp`的构造函数\n\n```java\n// AbstractPipeline#AbstractPipeline\n  AbstractPipeline(AbstractPipeline<?, E_IN, ?> previousStage, int opFlags) {\n      if (previousStage.linkedOrConsumed)\n          throw new IllegalStateException(MSG_STREAM_LINKED);\n      previousStage.linkedOrConsumed = true;\n      previousStage.nextStage = this;\n\n      this.previousStage = previousStage;\n      this.sourceOrOpFlags = opFlags & StreamOpFlag.OP_MASK;\n      this.combinedFlags = StreamOpFlag.combineOpFlags(opFlags, previousStage.combinedFlags);\n      this.sourceStage = previousStage.sourceStage;\n      if (opIsStateful())\n          sourceStage.sourceAnyStateful = true;\n      this.depth = previousStage.depth + 1;\n  }\n```\n构造函数中有`previousStage.nextStage = this;`和`this.previousStage = previousStage;`，相当于将当前的`StatelessOp`操作拼接到`Head`后面，构成了一条双向链表。\n\n![](4.png)\n\n再看后面的`.sorted().filter(e -> e.equals(\"333\")).limit(10)`，也会将操作添加到了双向链表后面。`.sorted()`在链表后面添加的是`StatefulOp`有状态操作。\n\n![](5.png)\n\n### 终端操作\n最后走到终端操作`.collect(Collectors.toList())`。进入到`collect()` 中\n```java\n//ReferencePipeline#collect\npublic final <R, A> R collect(Collector<? super P_OUT, A, R> collector) {\n    A container;\n    if (isParallel()\n            && (collector.characteristics().contains(Collector.Characteristics.CONCURRENT))\n            && (!isOrdered() || collector.characteristics().contains(Collector.Characteristics.UNORDERED))) {\n        container = collector.supplier().get();\n        BiConsumer<A, ? super P_OUT> accumulator = collector.accumulator();\n        forEach(u -> accumulator.accept(container, u));\n    }\n    else {\n        container = evaluate(ReduceOps.makeRef(collector));\n    }\n    return collector.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)\n            ? (R) container\n            : collector.finisher().apply(container);\n}\n```\n\n并发操作先不看，直接看`container = evaluate(ReduceOps.makeRef(collector));`，`ReduceOps.makeRef()`返回是`TerminalOp`，代表的是终端操作。\n\n![](6.png)\n\n\n进`evaluate()`中\n```java\n//AbstractPipeline#evaluate\nfinal <R> R evaluate(TerminalOp<E_OUT, R> terminalOp) {\n  assert getOutputShape() == terminalOp.inputShape();\n    if (linkedOrConsumed)\n        throw new IllegalStateException(MSG_STREAM_LINKED);\n    linkedOrConsumed = true;\n\n    return isParallel()\n            ? terminalOp.evaluateParallel(this, sourceSpliterator(terminalOp.getOpFlags()))\n            : terminalOp.evaluateSequential(this, sourceSpliterator(terminalOp.getOpFlags()));\n    }\n```\n\n先不管并行，进串行入`evaluateSequential()`中\n```java\n//ReduceOps#evaluateSequential\npublic <P_IN> R evaluateSequential(PipelineHelper<T> helper,\n                                    Spliterator<P_IN> spliterator) {\n    return helper.wrapAndCopyInto(makeSink(), spliterator).get();\n}\n```\n`makeSink()`将返回一个`Sink`实例，并作为参数和 spliterator 一起传入最后一个节点(terminalOp)的 wrapAndCopyInto() 方法\n```java\n//AbstractPipeline#wrapAndCopyInto\nfinal <P_IN, S extends Sink<E_OUT>> S wrapAndCopyInto(S sink, Spliterator<P_IN> spliterator) {\n    copyInto(wrapSink(Objects.requireNonNull(sink)), spliterator);\n    return sink;\n}\n\nfinal <P_IN> Sink<P_IN> wrapSink(Sink<E_OUT> sink) {\n     Objects.requireNonNull(sink);\n\n    for ( @SuppressWarnings(\"rawtypes\") AbstractPipeline p=AbstractPipeline.this; p.depth > 0; p=p.previousStage) {\n        sink = p.opWrapSink(p.previousStage.combinedFlags, sink);\n    }\n    return (Sink<P_IN>) sink;\n}\n```\n`wrapSink()`将最后一个节点创建的 Sink 传入，并且看到里面有个 for 循环。这个 for 循环是从最后一个节点开始，到第二个节点结束。每一次循环都是将上一节点的 combinedFlags 和当前的 Sink 包起来生成一个新的 Sink 。这和前面拼接各个操作很类似，只不过拼接的是 Sink 的实现类的实例，方向相反。\n\n![](7.png)\n\n\n到现在整个流水已经拼接完成。真正的数据处理在`copyInto()`中。\n```java\n//AbstractPipeline#copyInto\nfinal <P_IN> void copyInto(Sink<P_IN> wrappedSink, Spliterator<P_IN> spliterator) {\n    Objects.requireNonNull(wrappedSink);\n\n    if (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) {\n        wrappedSink.begin(spliterator.getExactSizeIfKnown());\n        spliterator.forEachRemaining(wrappedSink);\n        wrappedSink.end();\n    }\n    else {\n        copyIntoWithCancel(wrappedSink, spliterator);\n    }\n}\n```\n`Sink`中有三个方法：\n- `begin`：节点开始准备\n- `accept`: 节点处理数据\n- `end`： 节点处理结束\n\n`Sink`与操作是相关的，不同的`Sink`有不同的职责，无状态操作的 Sink 接收到通知或者数据，处理完了会马上通知自己的下游。有状态操作的 Sink 则像有一个缓冲区一样，它会等要处理的数据处理完了才开始通知下游，并将自己处理的结果传递给下游。\n\n比如`filter`这种无状态的操作，处理完数据会直接交给下游，而像`sorted`这种无有状态的操作在`begin`阶段会先创建一个容器，`accept`会将流转过来的数据保存起来，最后在执行 `end`方法时才正在开始排序。排序之后再将数据，采用同样的方式依次传递给下游节点。  \n![](8.png)\n\nwrapAndCopyInto() 返回了 TerminalOps 创建的 Sink，这时候它里面已经包含了最终处理的结果。调用它的 get() 方法就获得了最终的结果。\n\n\n`Steam`还可以支持并行流，把`list.stream()`换成`list.parallelStream()`即可使用并行操作。\n\n并行过程中，构建操作链的双向链表是不变的，区别实在构建完后的操作\n```java\n//AbstractPipeline#evaluate\nfinal <R> R evaluate(TerminalOp<E_OUT, R> terminalOp) {\n  assert getOutputShape() == terminalOp.inputShape();\n    if (linkedOrConsumed)\n        throw new IllegalStateException(MSG_STREAM_LINKED);\n    linkedOrConsumed = true;\n\n    return isParallel()\n            ? terminalOp.evaluateParallel(this, sourceSpliterator(terminalOp.getOpFlags()))\n            : terminalOp.evaluateSequential(this, sourceSpliterator(terminalOp.getOpFlags()));\n    }\n```\n这次进入到 `evaluateParallel()`中\n\n```java\n//ReduceOps#evaluateSequential\npublic <P_IN> R evaluateParallel(PipelineHelper<T> helper,\n                                         Spliterator<P_IN> spliterator) {\n    return new ReduceTask<>(this, helper, spliterator).invoke().get();\n}\n```\n`ReduceTask`继承自`ForkJoinTask`，`Steam`的并行底层用的是ForkJoin框架。\n\n\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"区块链的灵魂-共识机制","url":"/2022/07/15/19consensus/","content":"区块链是去中心化、分布式的，每个人都可以自由的参与进来，共同处理区块链中的数据。所谓绝对的自由必然带来绝对的混乱，作为一个巨大的分布式计算网络，必然有一个绕不开的问题--拜占庭将军问题\n\n### 拜占庭将军问题\n拜占庭将军问题（Byzantine failures），是由计算机科学史上的传奇人物莱斯利·兰伯特（Leslie Lamport）提出的。\n\n拜占庭帝国派出10个将军去攻击敌人，这支敌人可以同时抵御5支拜占庭军队的同时袭击。而这10个拜占庭将军在分开的状态下包围了敌人，并且只能依靠通信兵骑马相互通信来协商进攻意向及进攻时间。但是这些将军们不能确定他们的通信兵中是否有叛徒，叛徒可能擅自改变进攻意向及进攻时间。在这种情况下怎样才能保证同时有多于5支军队攻击，来赢得胜利？\n\n![](1.png)\n\n放到区块链中，拜占庭将军问题主要针对点对点通信中的分布式系统一致性问题。可以简单的概括为为 `在整个网络中的任意节点都无法信任与之通信的对方时，如何能创造出共识基础来进行安全信息的交互而无需担心数据被篡改。`\n\n区块链四大核心技术之一的共识机制就是为了解决这个问题。\n\n### 什么是共识机制？\n共识，对特定事务具有相同的认识或态度。 共识在我们的生活中无处不在，说一个场景  \n中午你和同事一起吃午饭，你们在讨论怎么吃，然后你出来提议一起点外卖。其他人对你的提议进行投票，如果没有异议那么这就达成了共识。\n\n![](2.png)\n\n区块链是一个点对点的分布式数据库结构的网络账本。这个账本与传统账本不同，不是由会计或少数几个人来记账，而是人人都可以参与记账。在没有中心机构的情况下，怎么确保别人的数据是正确的？\n\n这就需要一套规则来规定`怎样记账才是有效的`，而这一套规则就是共识机制。\n\n这一套规则主要有两点功能：\n\n- 如何记账\n- 怎样达成共识\n\n按照这套规则来决定区块链中谁取得区块链中的记账权，也就决定着由谁来产生新的区块。\n\n共识机制的作用非常大，直接关系到记账权和相关收益的分配。如果把区块链比作一个社会，那共识机制就是这个社会的法律。不夸张地说，共识机制就是区块链的灵魂。\n\n区块链发展到现在，已经有了多种共识机制，这里主要介绍三种被提及最多的共识机制。\n\n![](3.jpg)\n\n## POW 工作量证明\nPOW(Proof of Work)，工作量证明，闻名于比特币，经常提到的`挖矿`一词也是起源于POW。\n\n![](4.png)\n\nPOW的设计思想是计算一道数学难题，这道题计算过程是复杂的，但是验证过程是简单的。这种特性称之为计算不对称特性。\n\n比如在比特币中选定为以SHA256算法计算一个目标哈希，使得这个哈希值符合前N位全是0。 举个例子,给出一个字符串\"Blockchain\"，要求计算一个数字，与给出的字符串拼接起来，进行SHA256后，得到的结果前4位是0，这个数字称作nonce。比如字符串\"Blockchain1234\"，nonce就是1234。由于结果只能暴力搜索，而且搜索空间非常巨大，作弊几乎不可能。\n\n只要计算出目标值nonce就会获得记账权，距离上一次打包到现在未确认的交易，就可以一次性将未确认的交易打包并广播了。其他节点在接收到消息后，可以对nonce进行验证。\n\n简单来说POW就是谁的计算能力越强，计算的越快，获得记账权的概率就越高。每个节点都在同时解题，一旦有一个节点解出来，其余节点解题的过程也就白费了，只能解下一个节点。所以这种证明方式需要消耗大量能源(电力及计算硬件损耗)。\n\n并且理论上，在POW共识机制保护下，如果一个节点的计算力超过区块链全网的51%，即可对区块链网络进行有效攻击。因此许多基于比特币代码产生的、市值较小的山寨币很容易遭受攻击。这个51%攻击法在「矽谷」这个美剧第四季上曾经上演过这个情节。\n\n## POS 权益证明\nPOS(Proof of Stake), 权益证明，最早出现在点点币的创始人Sunny King的白皮书中，它出现的目地就是为了解决POW挖矿出现大量资源浪费的问题。\n\n在POS中个有`币龄`的概念，它指的是持币数量乘以持币天数。  \n相较与POW中人人都可以参与，人人都可以计算，POW更像是一种选举机制。节点需要抵押一定的代币，区块链网络会根据抵押代币的币龄，随机选取一个节点，由该节点进行打包区块。 抵押代币的多少，影响着被选中的概率。\n\n![](5.png)\n\n\n这种方式不需要每个节点都进行大量的运算，节省了能源。但它同样也有一些缺点。比如，PoS机制中初始的代币分发比较模糊，如果初始代币分发不下去，就很难形成之后的权益证明。并且POS也存在51%的问题，理论上谁能掌握51%的代币，谁就能掌控整个网络，所以，它的去中心化程度要弱一些。\n\n\n## DPOS 代理权益证明\nDPOS(Delegated Proof of Stake),代理权益证明。最初由Bitshares、Steemit以及 EOS 的创办人Dan Larimer提出，他在区块链项目Bitshares中实现了 DPoS 共识机制。DPOS与POS类似也是一种选举机制，它有点像民主大会。\n\n其过程是每一个持币人进行投票，选举出一定数量的代表，并由这些代表来打包区块和验证。这些代表节点的权利是相等的。比如，EOS将产生21个主节点，以及100个备用节点。如果有些代表节点不称职，就随时有可能被投票出局。\n\n![](6.png)\n\nDPOS就像董事会投票，持币者投出一定数量的节点 （董事）。代表按照既定时间表，轮流产生区块，如果代表没能很好的行使权力（比如产生区块），他们会被除名，网络会选出新的代表节点来取代他们。\n\nDPOS通过选举少数节点来出块记账，确实从网络传输和确认时间上看，大幅提升了性能。但是只有少数的节点出块记账的理念，牺牲了部分去中心化。因为DPOS机制的设计并不能保证一定有足额的真实的区块生产者，因为一个人或一个实体，可能控制着多个节点。如果节点的持有人相互串通，将进一步形成巨头垄断，这和区块链思想更是南辕北辙。这也是为什么V神怒怼DPOS的原因。\n\n\n\n","tags":["web3"],"categories":["web3"]},{"title":"认识区块链和web3.0","url":"/2022/06/19/18web3/","content":"\n2017-2018年期间，伴随着比特币的又一轮牛市，第一次认识和了解了区块链。\\\n2019年，高层大佬们集体学习区块链，也跟着重新关注起了区块链。也是因为区块链，去年第一次接触到了Web3.0，给我的第一印象是这东西太过超前了，如果真的能落地，那真的又是一场技术革命了，从那以后陆陆续续的关注着。\\\n今年下半年换了份工作，发现公司做区块链的大牛也在关注Web3.0，也跟着学习长进了不少。\\\n这篇文章主要介绍一些区块链和Web3.0的基本知识，可以对区块链和Web3.0有个大概的了解。\n\n## 区块链\n\n![](web31.png)\n\n2008年，全球金融危机，全世界掀起了反思传统金融制度的思潮，一个叫中本聪的人在P2P foundation网站上发布了比特币白皮书[《比特币：一种点对点的电子现金系统》](https://bitcoin.org/bitcoin.pdf)。\n\n![](web32.png)\n\n在书里提出了一种无须可信第三方的电子支付系统——比特币，通过整合非对称加密技术、工作量证明机制（Proof of Work，简称PoW）、点对点技术（Peer-to-Peer，简称P2P）等来保障个人对资产的所有权和匿名性，彻底颠覆了对于货币需要依赖中心化机构发行的传统认知。\n\n区块链和比特币由此诞生，那区块链到底是什么呢？。\\\n可以把区块链理解成一个数据库，这个数据库有几个重要的特点：\n\n*   去中心化\n*   不可篡改\n*   透明性\n\n区块链是怎么做到这些的呢？先看一下区块链的大致结构。\n\n![](web33.png)\n\n区块链可以大致理解为： 由一笔一笔的交易组成一个区块，一个一个的区块组成的一条链。这里的交易不单单指的双方买卖，双方发生的任何业务都可以称为交易。\n\n整个区块链是由所有参与节点共同维护的，每个节点都可以保存区块链的全部数据。\n\n在区块链系统里，每当发生一个交易，交易都是双方是直接进行的。交易的双方会把交易信息广播到整个交易系统里，系统中的一些节点会将这些交易打包成区块，并广播到整个区块链系统中，这些节点就可以称为矿工，而打包的过程就是挖矿。系统中的节点会对矿工打包的区块进行验证，验证通过则放到区块链中。\n\n在每个区块的头部包含了上一个区块的哈希值，这个哈希值是由上个区块中的内容生成的，如果某个节点想要修改某个区块中的内容，那么该区块的哈希值也会改变，该区块以后所有的区块也都需要改变。这就相当与以一己之力对抗系统中的所有人，当系统中的节点多的时候，这种操作可以说是几乎不可能的。\n\n区块链从诞生到现在，整个发展过程可以简单的划分为3个阶段：\n\n### 1、 区块链1.0 以比特币为代表的数字货币阶段\n\n![](web34.png)\n\n比特币的出现，催生出了区块链，但是比特币区块链，所有规则是事先写好的，没有人可以在比特币区块链上修改任何规则，你只能用它，而不能在它的基础上再去发展。也就是说这一时期的区块链，只是为了服务与特定的业务，并不能作为一个通用的平台。以太坊对于区块链技术而言，是一次飞跃性的突破，它让区块链商业应用变得可能。\n\n### 2、 区块链2.0 以太坊为代表的智能合约阶段\n\n![](web35.png)\n\n2015年，一个新的公链出现，叫做以太坊。并将智能合约带到了区块链中。以太坊可以被看作是一台`全球计算机`，它允许所有人在以太坊区块链的基础上做其他的应用开发。\n\n### 3、 区块链3.0 开始超出金融行业，为各行各业提供解决方案，为新的互联网理念web3.0提供支持。\n\n![](web36.png)\n\n## Web3.0\n\n![](web37.png)\n\n说起Web3.0,先要从Web1.0和Web2.0说起。\n\n### 1、Web1.0 静态互联网\n\nWeb1.0时期，也称为静态互联网时期，是互联网发展的第一个阶段，这一阶段互联网上的内容是由平台提供，用户只能`读取信息`而不能写入信息。最典型的互联网产品是门户网站、搜索引擎等工具。代表性的有搜狐、新浪和网易三大门户网站。\n\n### 2、Web2.0 平台互联网\n\nWeb2.0时期，也就是我们现在所处的时期，被称为平台互联网时期。Web2.0的概念在2004年始于出版社经营者O'Reilly和Media Live International之间的一场头脑风暴论坛。当时对Web2.0的讨论也像今天我们讨论Web3.0一样激烈。\n\nWeb2.0相比于Web1.0更加注重用户的交互，用户既可以是网站内容的浏览者也可以是内容的创造者，由以前的只能`读`向`写`和`共同建设`发展。用户也参与到互联网的发展。开始慢慢全面移动化，同时平台经济崛起，比如百度、阿里、腾讯、字节。\n\n但是随着Web2.0的发展，平台互联网的弊端也越来越让人难以接受，所谓天下苦平台互联网时代久矣。当下的平台互联网：用户创造、平台所有、平台控制、平台分配、平台垄断、隐私泄漏等问题，形成了平台吞噬一切的现象。\n\n2019年，《纽约时报》发布了一篇名为《减少互联网是唯一的答案》（The Only Answer Is Less Internet）的文章，对Web2.0时代的平台垄断、数据隐私、假新闻等问题进行了严厉批评。随着各国监管机构逐渐加强对互联网行业的监管，赢家通吃不再是互联网的铁律，合规化运营与寻找新增量成了行业发展的迫切需求，这也为Web3.0的到来埋下了伏笔。\n\n### 3、Web3.0 价值互联网\n\n那里有压迫，那里就有反抗。在经历了一系列Web2.0弊端后，区块链时代的Web3.0出现了。\n\n其实Web3.0一直是一个动态变化的过程，在区块链技术没有诞生之前，Web3.0通常意味这是一个更加智能的互联网，能够理解语义进行判断。在区块链诞生之后，Web3.0一般指建立在区块链技术之上的去中心化、去信任、无须许可的下一代互联网。\n\nWeb3.0有一下主要几个特点：\n\n*   去中心化、去信任，不依赖第三方机构运作，避免平台吞噬一切\n\n*   可拥有，用户可以掌握自己在互联网上的数据和数字资产\n\n*   无须许可，代码开源、抗审查、可自由接入\n\n*   全球化，资产在全球自由流动\\\n    ......\n\nWeb3.0的核心理念为数据的所有权归用户所有，每个人都可以控制自己的身份、数据和资产。\n\n比如，我写了一篇文章，我授权给了某个平台，平台展示我的文章，并在文章下产生了一些评论。如果有一天我觉着这个平台不靠谱，我可以取消授权，同时将文章和评论授权给别的平台。实现真正的我的数据归我所有。\n\n从2008年中本聪发布比特币白皮书，到2021年NFT和元宇宙的爆发，Web3.0已经从一小撮极客圈子，逐渐发展成为了一个庞大的科技产业，并且在多个方面带来了技术和应用\n\n*   去中心化金融(Defi)\n\n    无须中心化的金融机构，即可实现传统金融中的贷款、保险、理财、股票等服务。比如Maker、Compound用于借贷的平台\n*   非同质化代币(NFT)\n\n    NFT有可验证、唯一、不可分割和可追溯的特性，可以用来标记特定资产，在数字货币中是重要的工具。比如著名球星库里花18万美元买一个NFT数字头像、游戏方面的GameFi、国内阿里，腾讯等推出的数字藏品等。\n*   分布式自治组织(Dao)\n\n    没有公司章程、没有层级制度、没有董事会，完全依靠民主治理、由参与者共同投票决定。比如Aragon、Moloch等Dao操作系统\n*   元宇宙\n\n可能大家还是觉着Web3.0现在还只是概念居多，但是在资本市场上Web3.0早已成为投资人眼里的香饽饽。\n\n*   全球最大的风险投资公司之一的红杉资本一口气投资了20多家Web3.0公司。\n\n在政府层面上，也是同样在你追我敢\n\n*   美国出台支持性政策，要保证Web3.0革命发生在美国。\n\n*   今年中国证监会科技监管局局长在《中国金融》杂志上撰文指出，“如今互联网正处在Web2.0向Web3.0演进的重要时点，加强Web3.0前瞻研究和战略预判，对我国未来互联网基础设施建设无疑具有重要意义。”\n\n*   10月31号，香港财政司正式发布《有关香港虚拟资产发展的政策宣言》，迎接Web3.0。\n\n处在风口的Web3.0到底是资本炒作的工具，还是一场真正的技术革命？\n\n屠龙少年会不会终成恶龙？\n\n让我们拭目以待。\n\n","tags":["web3"],"categories":["web3"]},{"title":"Java类加载器","url":"/2022/05/27/classload/","content":"### 类加载器\n我们写的每一个Java文件，首先通过编译器编译成class文件，然后经过类加载器加载到jdk运行时内存中生成一个class类，才会被程序使用。而类加载器就是加载字节码(.class)文件的类--`java.lang.ClassLoader`。\n### 类加载器的分类\nJava默认设置了三个类加载器。\n- BootstrapClassloader\n- ExtClassloader\n- AppClassloader  \n\nBootstrapClassloader 叫做启用类加载器，用于加载JRE核心类库，使用C++实现。加载路径%JAVA_HOME%/lib下的所有类库。  \n\nExtClassloader 扩展类加载器，加载%JAVA_HOME%/lib/ext中的所有类库。  \n\nAppClassloader 应用类加载器也叫系统类加载器System Classloader，加载%CLASSPATH%路径下的所有类库。\n\nJava 也提供了扩展，可以让我们自己实现类加载的功能。类加载器在Java中是`java.lang.ClassLoader`这个类，如果要自定义类加载器，只要实现这个类，重写加载方法就好了。\n\n在Java中，由不同的类加载器加载的两个相同的类在Java虚拟机里是两个不同的类，那么Java是怎么确保一个类不会被多个类加载器重复加载，并且保证核心API不会被篡改的呢？  \n\n这就需要Java的双亲委派机制。\n\n### 双亲委派机制\n\n![](classload.png)\n\n1、当一个类加载器接到加载类的请求后，首先会交给父类去加载，如果所有父类都无法加载，自己加载，并将被加载的类缓存起来。。\n\n2、每加载一个类，所有的类加载器都会判断是否可以加载，最终会委托到启动类加载器来首先加载。所有的类的加载都尽可能由顶层的类加载器加载，这样就保证了加载的类的唯一性。  \n\n3、启动类加载器、扩展类加载器、应用程序类加载器，都有自己加载的类的范围，因此并不是所有的类父类都可以加载。\n\nJava 类加载器中还有一个全盘委托机制，当指定一个`ClassLoader`加载一个类时，该类所依赖或者引用的类也会由这个类加载器来加载，除非显示的用别的类加载器加载\n\n比如：程序入口默认用的是`AppClassloader`，那么以后创建出来的类也是用`AppClassloader`来加载，除非自己显示的用别的类加载器去加载。(classX引用了classY，那么ClassX的类加载器就会去加载classY(前提是classY尚未被加载))\n\n### 线程上下文加载器\n因为双亲委派机制的存在，每个类加载器都有自己的加载范围。但是在JDK中提供了很多服务提供者接口（Service Provider Interface，SPI），他们允许第三方来实现接口，比如常见的JDBC、JNDI、JAXP等。  \n\n 这些接口是由Java核心库提供的，并由启用类加载器(BootstrapClassloader)加载，而实现确是在Java应用所依赖的第三方Jar包里的，默认是由应用类加载器(AppClassloader)加载。 \n \nJava引入了线程上下文加载器的概念来打破双亲委派机制。 通过线程`Thread`类的`getContextClassLoader()`和 `setContextClassLoader(ClassLoader cl)`来设置线程上下文加载器。如果没有通过`setContextClassLoader(ClassLoader cl)`进行设置的话，线程将继承其父线程的上下文类加载器。\n\n线程上下文加载器并不是一个真实存在的类，而是一个概念。它是Thread类里的一个成员变量。\n```java\npublic class Thread implements Runnable {\n\n   private ClassLoader contextClassLoader;\n\n   public void setContextClassLoader(ClassLoader cl) {\n       SecurityManager sm = System.getSecurityManager();\n       if (sm != null) {\n           sm.checkPermission(new RuntimePermission(\"setContextClassLoader\"));\n       }\n       contextClassLoader = cl;\n   }\n\n\n\n   public ClassLoader getContextClassLoader() {\n       if (contextClassLoader == null)\n           return null;\n       SecurityManager sm = System.getSecurityManager();\n       if (sm != null) {\n           ClassLoader.checkClassLoaderPermission(contextClassLoader,\n                                                  Reflection.getCallerClass());\n       }\n       return contextClassLoader;\n   }\n}\n```\n \n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"Java工具 Jstack 的使用","url":"/2022/04/27/jstack/","content":"\n> jstack - Prints Java thread stack traces for a Java process, core file, or remote debug server.\n\n\nJstack主要的作用是生成当前进程中所有线程的信息，也就是当前时刻JVM的线程快照，通过线程的信息我们可以定位到程序中出现长时间停顿、CPU占用率过高等问题。\n\n线程快照中的信息是当前java虚拟机内每一条线程正在执行的方法的堆栈集合，有了堆栈信息我们就可以分析出我们的程序问题出现在哪，比如线程间死锁、外部资源请求时间过长、死循环等。\n\n\n\n使用：\n\n```\njstack [ options ] pid\n\njstack [ options ] executable core\n\njstack [ options ] [ server-id@ ] remote-hostname-or-IP\n\n\nOPTIONS\n       -F\n              Force a stack dump when jstack [-l] pid does not respond.\n\n       -l\n              Long listing. Prints additional information about locks such as a list of owned java.util.concurrent ownable synchronizers. See the\n              AbstractOwnableSynchronizer class description at\n              http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/AbstractOwnableSynchronizer.html\n\n       -m\n              Prints a mixed mode stack trace that has both Java and native C/C++ frames.\n```\n\n- -F  当正常的请求不被响应时，强制输出堆栈信息。\n- -l  额外打印锁的信息，当发生死锁时可以查看锁的信息\n- -m 如果调用本地方法栈的信息，可以打印C/C++的堆栈\n\n\n\n以一个发生死锁的例子来看一下使用Jstack查看到的信息\n\n```java\npublic class Jstack {\n\n    private static Object obj1 = new Object();\n    private static Object obj2 = new Object();\n\n    public static void main(String[] args) {\n\n        new Thread(() -> {\n            synchronized (obj1) {\n                try {\n                    Thread.sleep(2000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                synchronized (obj2) {\n                }\n            }\n        }).start();\n        new Thread(() -> {\n            synchronized (obj2) {\n                try {\n                    Thread.sleep(2000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                synchronized (obj1) {\n                }\n            }\n        }).start();\n    }\n}\n```\n\n上面代码中，第一个线程拿到obj1的锁，等待obj2的锁，第二个线程拿到obj2的锁，等待obj1的锁，这样就会发生死锁。\n\n\n\n先通过`jps`命令获取到先拿到当前的进程pid，然后通过jstack获取线程的信息。可以看到有两个线程都处于阻塞状态。\n\n```\n\"Thread-1\" #12 prio=5 os_prio=0 tid=0x00007fdff871c800 nid=0x3cc2 waiting for monitor entry [0x00007fdfce0fc000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat com.example.demo.jstack.Jstack.lambda$main$1(Jstack.java:36)\n\t- waiting to lock <0x000000076e925a90> (a java.lang.Object)\n\t- locked <0x000000076e925aa0> (a java.lang.Object)\n\tat com.example.demo.jstack.Jstack$$Lambda$2/2052001577.run(Unknown Source)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\"Thread-0\" #11 prio=5 os_prio=0 tid=0x00007fdff871a800 nid=0x3cc1 waiting for monitor entry [0x00007fdfce1fc000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat com.example.demo.jstack.Jstack.lambda$main$0(Jstack.java:25)\n\t- waiting to lock <0x000000076e925aa0> (a java.lang.Object)\n\t- locked <0x000000076e925a90> (a java.lang.Object)\n\tat com.example.demo.jstack.Jstack$$Lambda$1/1174361318.run(Unknown Source)\n\tat java.lang.Thread.run(Thread.java:748)\n```\n\n第一行显示线程名、线程优先级、线程id、线程状态描述等信息\n\n第二行显示的是当前线程的状态\n\n​      Java中线程的状态分为NEW、RUNNABLE、BLOCKED、WATING、TIMED_WATING、TERMINATED，但是在快照中NEW状态是不会出现的。\n\n再下面的就是当前线程的调用栈的信息。调用栈中包含了锁的信息。\n\n​     `locked    `   表示使用synchronized申请对象锁成功,监视器的拥有者\n\n​     `waiting to lock `  表示使用synchronized申请对象锁未成功,进入等待区。\n\n​\t `waiting on`    表示用synchronized申请对象锁成功后,调用了wait方法,进入对象的等待区等待。\n\n​    `parking to wait for`  park是基本的线程阻塞原语,不通过监视器在对象上阻塞。随concurrent包会出现的新的机制,与synchronized体系不同。\n\n\n\n在最后也显示出了代码中出现死锁的信息\n\n```\nFound one Java-level deadlock:\n=============================\n\"Thread-1\":\n  waiting to lock monitor 0x00007fdfac006638 (object 0x000000076e925a90, a java.lang.Object),\n  which is held by \"Thread-0\"\n\"Thread-0\":\n  waiting to lock monitor 0x00007fdfac003da8 (object 0x000000076e925aa0, a java.lang.Object),\n  which is held by \"Thread-1\"\n\nJava stack information for the threads listed above:\n===================================================\n\"Thread-1\":\n\tat com.example.demo.jstack.Jstack.lambda$main$1(Jstack.java:36)\n\t- waiting to lock <0x000000076e925a90> (a java.lang.Object)\n\t- locked <0x000000076e925aa0> (a java.lang.Object)\n\tat com.example.demo.jstack.Jstack$$Lambda$2/2052001577.run(Unknown Source)\n\tat java.lang.Thread.run(Thread.java:748)\n\"Thread-0\":\n\tat com.example.demo.jstack.Jstack.lambda$main$0(Jstack.java:25)\n\t- waiting to lock <0x000000076e925aa0> (a java.lang.Object)\n\t- locked <0x000000076e925a90> (a java.lang.Object)\n\tat com.example.demo.jstack.Jstack$$Lambda$1/1174361318.run(Unknown Source)\n\tat java.lang.Thread.run(Thread.java:748)\n\nFound 1 deadlock.\n```\n\n\n\n好了，熟悉了Jstack，我们用一段死循环的代码，通过Jstack来定位到使CPU占用100%的代码行\n\n```java\npublic class JstackDemo {\n    public static Executor executor = Executors.newFixedThreadPool(3);\n    private static Object lock = new Object();\n\n    public static void main(String[] args) {\n        Task task1 = new Task();\n        Task task2 = new Task();\n        executor.execute(task1);\n        executor.execute(task2);\n    }\n\n    public static class Task implements Runnable {\n\n        @Override\n        public void run() {\n            synchronized (lock) {\n                run0();\n            }\n        }\n\n        private void run0() {\n            int i = 0;\n            while (true) {\n                i++;\n            }\n        }\n    }\n}\n\n```\n\n\n\n1、首先通过`top`查看到使CPU占用到100%的进程id\n\n  ![](top.png)\n\n2、使用`top -Hp 进程id` 查看占用CPU最多的线程id\n\n![](top-Hp.png)\n\n3、将线程id转换为16进制\n\n 17997 -> 464d\n\n4、使用Jstack查看Java所在的进程，并找到相应的线程\n\n![](run0.png)\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"ThreadLocal 内存泄露问题","url":"/2022/04/06/threadlocal/","content":"\n\n> 内存泄漏（Memory Leak）是指程序中已动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。  ——百度百科\n\n\n上述的意思用在java中就是存在已经没有任何引用的对象，但是GC又不能把对象所在的内存回收掉，所以就造成了内存泄漏。\n\nThreadLocal主要解决的是对象不能被多个线程同时访问的问题。根据ThreadLocal的源码看看它是怎么实现的。\n\nThreadLocal设置数据的`set()`方法\n\n```java\n  public void set(T value) {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null)\n            map.set(this, value);\n        else\n            createMap(t, value);\n    }\n\n    ThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }\n\n    void createMap(Thread t, T firstValue) {\n        t.threadLocals = new ThreadLocalMap(this, firstValue);\n    }\n```\n\n\n\n可以看到在使用ThreadLocal设置数据时，其实设置到的是当前线程的threadLocals字段里，去Thread里看一看threadLocals变量\n\n```java\n  ThreadLocal.ThreadLocalMap threadLocals = null;\n```\n\nthreadLocals的类型是ThreadLocal里的内部类ThreadLocalMap，ThreadLocalMap的中用来存储数据的又是一个内部类是`Entry`\n\n```java\n static class Entry extends WeakReference<ThreadLocal<?>> {\n        Object value;\n\n        Entry(ThreadLocal<?> k, Object v) {\n             super(k);\n             value = v;\n         }\n   }\n```\n\n`Entry`的key是当前ThreadLocal，value值是我们要设置的数据。\n\n`WeakReference`表示的是弱引用，当JVM进行GC时，一旦发现了只具有弱引用的对象，不管当前内存空间是否足够，都会回收它的内存。\n\n因为`WeakReference<ThreadLocal<?>>`，所以在`Entry`中`ThreadLocal`是弱引用，一旦发生GC，`ThreadLocal`会被GC回收掉，但是`value`是强引用，它不会被回收掉。用一张图来表示一下\n\n![ThreadLocal](ThreadLocal.png)\n\n\n\n图中实线表示的是强引用，虚线表示的是弱引用。\n\n当JVM发生GC后，虚线会断开应用，也就是key会变为null，value是强引用不会为null，整个Entry也不为null，它依然在ThreadLocalMap中，并占据着内存，\n\n我们获取数据时，使用ThreadLocal的`get()`方法，ThreadLocal并不为null，所以我们无法通过一个key为null去访问到该entry的value。这就造成了内存泄漏。\n\n\n\n既然用弱引用会造成内存泄漏，直接用强引用可以么？\n\n答案是不行。如果是强引用的话，看看下面代码\n\n```java\n ThreadLocal threadLocal = new ThreadLocal();\n threadLocal.set(new Object());\n threadLocal = null;\n```\n\n我们在设置完数据后，直接将threadLocal设为null，这时栈中`ThreadLocal Ref` 到堆中`ThreadLocal`断开了，但是`key`到`ThreadLocal`的引用依然存在，GC依旧没法回收，同样会造成内存泄漏。\n\n\n\n那弱引用比强引用好在哪？\n\n当key为弱引用时，同样是上面代码，当threadLocal设为null时，栈中`ThreadLocal Ref` 到堆中`ThreadLoacl`断开了，`key`到`ThreadLoacl`也因为GC断开了，这时`ThreadLocal`就可以被回收了。\n\n同时,ThreadLocal也可以根据`key.get() == null` 来判断key是否已经被回收，因此ThreadLocal可以自己清理这些过期的节点来避免内存泄漏。\n\n\n\n其实，ThreadLocal做了很大的工作清除过期的key来避免发生内存泄漏\n\n1. 在调用`set（）`方法时，会进行清理\n\n   ```java\n    private void set(ThreadLocal<?> key, Object value) {\n   \n        Entry[] tab = table;\n        int len = tab.length;\n        int i = key.threadLocalHashCode & (len-1);\n   \n        for (Entry e = tab[i];\n             e != null;\n             e = tab[i = nextIndex(i, len)]) {\n             ThreadLocal<?> k = e.get();\n   \n             if (k == key) {\n                 e.value = value;\n                 return;\n              }\n   \t\t\t// 当key为null时，替换掉\n              if (k == null) {\n                  replaceStaleEntry(key, value, i);\n                  return;\n              }\n        }\n   \n        tab[i] = new Entry(key, value);\n        int sz = ++size;\n        // 清理一些槽位，清理过期key\n        if (!cleanSomeSlots(i, sz) && sz >= threshold)\n            rehash();\n    }\n   \n   ```\n\n   1、 当key为null时，说明该位置被GC回收了，会将当前位置覆盖掉。\n\n   2、 在`set()`方法最后调用了`cleanSomeSlots()`中还会有清理的操作。看一看`cleanSomeSlots()`\n\n   ```java\n    private boolean cleanSomeSlots(int i, int n) {\n        boolean removed = false;\n        Entry[] tab = table;\n        int len = tab.length;\n        do {\n            i = nextIndex(i, len);\n            Entry e = tab[i];\n            if (e != null && e.get() == null) {\n                n = len;\n                removed = true;\n                // 真正的清理工作\n                i = expungeStaleEntry(i);\n             }\n         } while ( (n >>>= 1) != 0);\n         return removed;\n    }\n   \n   ```\n\n   `cleanSomeSlots()`中当判断`e != null && e.get() == null`为true时，说明已经被GC回收了，会调用`expungeStaleEntry()`进行清理工作，具体的逻辑就不再看了。\n\n   \n\n2. 在调用`get()`方法时，如果没有命中，会向后查找，也会进行清理操作\n\n   ```java\n    \n   private Entry getEntry(ThreadLocal<?> key) {\n        int i = key.threadLocalHashCode & (table.length - 1);\n        Entry e = table[i];\n        if (e != null && e.get() == key)\n            return e;\n        else\n            // 没有命中向后查找\n           return getEntryAfterMiss(key, i, e);\n    }\n    private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {\n        Entry[] tab = table;\n        int len = tab.length;\n   \n        while (e != null) {\n            ThreadLocal<?> k = e.get();\n            if (k == key)\n                return e;\n            if (k == null)\n                // 当key为null，说明被GC回收了，进行清理的操作\n                expungeStaleEntry(i);\n            else\n                i = nextIndex(i, len);\n            e = tab[i];\n        }\n        return null;\n    }\n   ```\n\n   \n\n3. 调用`remove()`时，除了清理当前节点，还会向后进行清理操作\n\n   ```java\n    private void remove(ThreadLocal<?> key) {\n        Entry[] tab = table;\n        int len = tab.length;\n        int i = key.threadLocalHashCode & (len-1);\n        for (Entry e = tab[i];\n             e != null;\n             e = tab[i = nextIndex(i, len)]) {\n             if (e.get() == key) {\n                 e.clear();\n                 // 向后查找，进行清理操作\n                 expungeStaleEntry(i);\n                 return;\n              }\n         }\n    }\n   ```\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"Spring Boot 打包成Jar包运行的原理","url":"/2022/04/05/springbootjar/","content":"\n相比于传统的Java打包方式，使用SpringBoot打包插件打包成jar包后，可以直接使用`java -jar` 运行SpringBoot项目，本篇就来分析一下运行的原理。\n\nSpringBoot打包插件\n\n```xml\n<plugin>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-maven-plugin</artifactId>\n</plugin>\n```\n\n\n\n打包完后会生成两个文件，一个`***.jar`和`***.jar.original`\n\n`.jar`文件是SpringBoot打包后生成的文件，`.jar.original`是用原生方式打包生成的文件，对比一下两个的区别\n\n\n\n`.jar.original`文件\n\n![original](jar.png)\n\n`.jar`文件\n\n![jar](springbootjar.png)\n\n\n\n\n\n`.jar.original`就是普通的jar打包的结构，这里主要看`.jar`文件的结构：\n\n- META-INFO目录：META-INFO/MANIFEST.MF里包含了jar包的元数据，包含了项目的启动类等信息.\n\n- org目录：该目录下包含的是启动项目的一些类，启动的过程就在这个包里。\n\n- BOOT-INFO目录：本地项目的代码（BOOT-INF/classes），以及所需的依赖（BOOT-INFO/lib）\n\n  \n\n重点在META-INFO/MANIFEST.MF里：\n\n```\nManifest-Version: 1.0\nSpring-Boot-Classpath-Index: BOOT-INF/classpath.idx\nImplementation-Title: demo\nImplementation-Version: 0.0.1-SNAPSHOT\nSpring-Boot-Layers-Index: BOOT-INF/layers.idx\nStart-Class: com.example.demo.DemoApplication\nSpring-Boot-Classes: BOOT-INF/classes/\nSpring-Boot-Lib: BOOT-INF/lib/\nBuild-Jdk-Spec: 1.8\nSpring-Boot-Version: 2.4.5\nCreated-By: Maven Jar Plugin 3.2.0\nMain-Class: org.springframework.boot.loader.JarLauncher\n```\n\n这里有几个重点的字段\n\n- Main-Class ：jar包启动类，这是java规定的字段，存在这个字段的情况下， 在`java -jar`时，jar包才会运行起来\n- Start-Class：本地项目的启动类\n- Spring-Boot-Classes：加载应用类的入口\n- Spring-Boot-Lib：项目所需的依赖\n\n\n\n有了Main-Class启动类，那就直接进入到`JarLauncher`里查看运行的过程\n\n```java\n    public static void main(String[] args) throws Exception {\n        (new JarLauncher()).launch(args);\n    }\n```\n\n在`JarLauncher`的`main`方法里调用了`launch`方法，`launch`方法的具体实现在`JarLauncher`的抽象父类`Launcher`中实现\n\n```java\n    protected void launch(String[] args) throws Exception {\n        if (!this.isExploded()) {\n            JarFile.registerUrlProtocolHandler();\n        }\n\n        ClassLoader classLoader = this.createClassLoader(this.getClassPathArchivesIterator());\n        String jarMode = System.getProperty(\"jarmode\");\n        String launchClass = jarMode != null && !jarMode.isEmpty() ? \"org.springframework.boot.loader.jarmode.JarModeLauncher\" : this.getMainClass();\n        this.launch(args, launchClass, classLoader);\n    }\n\n```\n\n- 首先获取了类加载器。\n- 然后获取jarMode，再根据jarMode获取launchClass，如果没有设置jarMode，则根据`getMainClass`方法获取，`getMainClass`的具体实现在`ExecutableArchiveLauncher`中实现\n\n   ```java\n    protected String getMainClass() throws Exception {\n           Manifest manifest = this.archive.getManifest();\n           String mainClass = null;\n           if (manifest != null) {\n               mainClass = manifest.getMainAttributes().getValue(\"Start-Class\");\n           }\n   \n           if (mainClass == null) {\n               throw new IllegalStateException(\"No 'Start-Class' manifest entry specified in \" + this);\n           } else {\n               return mainClass;\n           }\n       }\n   ```\n\n​     在`getMainClass`里获取了`MANIFEST.MF`文件里`Start-Class`字段的值，也就是本地项目的启动类。\n\n- 最后调用`this.launch(args, launchClass, classLoader);`\n\n    ```java\n        protected void launch(String[] args, String launchClass, ClassLoader classLoader) throws Exception {\n            Thread.currentThread().setContextClassLoader(classLoader);\n            this.createMainMethodRunner(launchClass, args, classLoader).run();\n        }\n    ```\n\n   调用`MainMethodRunner`的`run()`方法\n\n```java\n\n    public void run() throws Exception {\n        Class<?> mainClass = Class.forName(this.mainClassName, false, Thread.currentThread().getContextClassLoader());\n        Method mainMethod = mainClass.getDeclaredMethod(\"main\", String[].class);\n        mainMethod.setAccessible(true);\n        mainMethod.invoke((Object)null, this.args);\n    }\n\n```\n\n在`run()`方法里通过反射拿到了项目的启动类的`main`方法，从而启动本地项目。","tags":["Spring Boot"],"categories":["JAVA"]},{"title":"设计一个支持热加载的Java应用启动器","url":"/2021/12/29/hot-loading/","content":"热加载是指在不重启服务的情况下使更改的代码生效。注意和热部署的区别，热加载主要是在开发环境下使用。\n\n首先要知道Java程序是怎么运行起来的，Java类加载分为其7个阶段。\n\n![phase](phase.png)\n\n其中加载阶段是用户可以自定义，而验证阶段、准备阶段、解析阶段、初始化阶段都是用 JVM 来处理的。  \n整个类加载是在Java 中一个叫做类加载器上进行的，如果我们能程序更改后，让程序所在的进程能够实时的获取到编译后的Class类字节码信息，然后重新加载的话，那么就可以实现热加载功能。\n\n### Java 类加载器\n类加载器，顾名思义就是加载Java类的工具，Java默认设置了三个类加载器。\n- BootstrapClassloader\n- ExtClassloader\n- AppClassloader  \n\nBootstrapClassloader 叫做启用类加载器，用于加载JRE核心类库，使用C++实现。加载路径%JAVA_HOME%/lib下的所有类库。  \n\nExtClassloader 扩展类加载器，加载%JAVA_HOME%/lib/ext中的所有类库。  \n\nAppClassloader 应用类加载器也叫系统类加载器System Classloader，加载%CLASSPATH%路径下的所有类库。\n\nJava 也提供了扩展，可以让我们自己实现类加载的功能。类加载器在Java中是`java.lang.ClassLoader`这个类，如果要自定义类加载器，只要实现这个类，重写加载方法就好了。\n\n在Java中，由不同的类加载器加载的两个相同的类在Java虚拟机里是两个不同的类，那么Java是怎么确保一个类不会被多个类加载器重复加载，并且保证核心API不会被篡改的呢？  \n\n这就需要Java的双亲委派机制。\n\n### 双亲委派机制\n\n![classloader](classloader.png)\n\n当一个类加载器接到加载类的请求后，首先会交给父类去加载，如果所有父类都无法加载，自己加载，并将被加载的类缓存起来。。\n\n每加载一个类，所有的类加载器都会判断是否可以加载，最终会委托到启动类加载器来首先加载。所有的类的加载都尽可能由顶层的类加载器加载，这样就保证了加载的类的唯一性。  \n\n启动类加载器、扩展类加载器、应用程序类加载器，都有自己加载的类的范围，因此并不是所有的类父类都可以加载。\n\n\n\nJava 类加载器中还有一个全盘委托机制，当指定一个`ClassLoader`加载一个类时，该类所依赖或者引用的类也会由这个类加载器来加载，除非显示的用别的类加载器加载。\n\n比如：程序入口默认用的是`AppClassloader`，那么以后创建出来的类也是用`AppClassloader`来加载，除非自己显示的用别的类加载器去加载。\n\n### 热加载\nOK，有了以上铺垫，现在可以来实现热加载的功能了，怎么实现呢？  \n\n1、首先要实现自己的类加载器，破坏双亲委派机制。  \n2、通过自定义的类加载器加载所需的类。  \n3、不断的轮询判断类是否有变化，如果有变化重新加载。\n\n\n自定义类加载器\n```java\npublic class MyClassLoader extends ClassLoader {\n\n\n    private static final String SUFFIX = \".class\";\n\n    private String rootPath;\n\n    public MyClassLoader(String rootPath) {\n        this.rootPath = rootPath;\n    }\n\n    /**\n     * 破坏双亲委派机制,自定义类加载方式\n     * @param name\n     * @return\n     * @throws ClassNotFoundException\n     */\n    @Override\n    public Class<?> loadClass(String name) throws ClassNotFoundException {\n        Class<?> loadedClass = findLoadedClass(name);\n        if (null == loadedClass) {\n            try {\n                return findClass(name);\n            } catch (ClassNotFoundException e) {\n                return super.loadClass(name);\n            }\n        }\n\n        return loadedClass;\n    }\n\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        String path = rootPath + name.replace(\".\", \"/\") + SUFFIX;\n        File file = new File(path);\n        byte[] classBytes = null;\n        try {\n            classBytes = getClassBytes(file);\n        } catch (Exception e) {\n        }\n        if (null != classBytes) {\n            if (null != super.findLoadedClass(name)) {\n                return super.findLoadedClass(name);\n            }\n            Class<?> aClass = defineClass(name, classBytes, 0, classBytes.length);\n            if (null != aClass) {\n                return aClass;\n            }\n        }\n        return super.findClass(name);\n    }\n\n    /**\n     * 加载类\n     * @param file\n     * @return\n     * @throws Exception\n     */\n    private byte[] getClassBytes(File file) throws Exception {\n        FileInputStream fileInputStream = new FileInputStream(file);\n        FileChannel fc = fileInputStream.getChannel();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        WritableByteChannel writableByteChannel = Channels.newChannel(baos);\n        ByteBuffer by = ByteBuffer.allocate(1024);\n        while (true) {\n            int read = fc.read(by);\n            if (read == 0 || read == -1) {\n                break;\n            }\n            by.flip();\n            writableByteChannel.write(by);\n            by.clear();\n        }\n        fileInputStream.close();\n        return baos.toByteArray();\n    }\n}\n```\n自定义类加载器重写了`loadClass()`方法和`findClass`方法，破坏了Java的双亲委派机制，先通过自定义的类加载所需的类，如果加载不到，再交给父类加载。  \n\n接下来，写启动器\n```java\npublic class Run {\n\n    public static String rootPath;\n\n    public static void run(Class cl) {\n        rootPath = cl.getClass().getResource(\"/\").getPath();\n        MyClassLoader myClassLoader = new MyClassLoader(rootPath);\n        startFileListener(rootPath);\n        start0(myClassLoader);\n    }\n\n    public static void startFileListener(String rootPath) {\n        FileAlterationObserver fileAlterationObserver = new FileAlterationObserver(rootPath);\n        fileAlterationObserver.addListener(new FileListener());\n        FileAlterationMonitor fileAlterationMonitor = new FileAlterationMonitor(5);\n        fileAlterationMonitor.addObserver(fileAlterationObserver);\n        try {\n            fileAlterationMonitor.start();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n\n    public static void start0(MyClassLoader classLoader) {\n        Class<?> clazz = null;\n        try {\n            clazz = classLoader.findClass(\"com.example.Run\");\n            clazz.getMethod(\"start\").invoke(clazz.newInstance());\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 模拟启动应用程序\n     */\n    public static void start() {\n        Application application = new Application();\n        application.printApplicationName();\n    }\n}\n```\n`run()` 方法是入口，首先自定义了加载器，然后设置了文件监听，这个文件监听用的是`commons-io`\n```\n<dependency>\n    <groupId>commons-io</groupId>\n    <artifactId>commons-io</artifactId>\n    <version>2.4</version>\n</dependency>\n```\n最后调用`start0`来启动项目，在`start0`里通过自定义的类加载器又重新加载了`Run`本身，然后通过反射调用`start()`方法，`start()`方法里启动真正的项目。这样的目的是因为类加载器中的全盘委托机制。Java 默认用的是`AppClassloader`，所以只能显示的通过自定义的类加载器来加载启动类，再启动真正的项目。\n\n文件的监听，使用`commons-io`\n```java\npublic class FileListener extends FileAlterationListenerAdaptor {\n\n    @Override\n    public void onFileCreate(File file) {\n        System.out.println(file.getName());\n        if (file.getName().indexOf(\".class\") != -1) {\n\n            try {\n                MyClassLoader myClassLoader = new MyClassLoader(Run.rootPath);\n                Run.start0(myClassLoader);\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n        super.onFileCreate(file);\n    }\n\n\n    @Override\n    public void onFileChange(File file) {\n        System.out.println(file.getName());\n        if (file.getName().indexOf(\".class\") != -1) {\n\n            try {\n                MyClassLoader myClassLoader = new MyClassLoader(Run.rootPath);\n                Run.start0(myClassLoader);\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n通过监听文件的创建和修改，如果文件有变化，定义一个新的类加载器，重新运行项目。\n\n模拟的真正项目\n```java\npublic class Application {\n\n    public void printApplicationName() {\n        System.out.println(\"应用程序777\");\n    }\n}\n\n```\n\n好了，现在来测试一下项目\n```java\npublic class Main {\n\n    public static void main(String[] args) {\n        Run.run(Main.class);\n    }\n}\n```\n设置一下idea，让编译器可以自动编译\n![idea](classloader.png)\n\n现在修改`Application`里`printApplicationName`输出的内容，等编译器编译完后，可以看到修改的内容了。\n\n\n本文只是一个供学习使用的简单小小的例子，项目github地址：[https://github.com/yaocl0/hot-loading](https://github.com/yaocl0/hot-loading)\n\n\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"聊一聊Tomcat 系统架构设计","url":"/2021/12/22/tomcat-arch/","content":"### 总体架构\n\n\nTomcat 是一个应用服务器，那么要开发一个应用服务器，首先捋一捋它的需求，要实现那些功能。\n\n\n1、 首先可以和客户端建立连接，并且能够处理客户端的连接\n\n2、 其次还要解析处理我们写的 Servlet\n\n3、 最后能够根据客户端的请求找到相应的 Servlet。\n\n在 Tomcat 中将这些需求分为了两大功能\n\n- 处理 Socket 连接，并将网络字节流转换成 Request 对象和 Response 对象\n- 解析、加载和管理 Servlet，处理请求并返回响应数据\n\nTomcat 将这两大功能，设计成了两个主要的组件\n\n- 连接器（Connector）\n- 容器（Container）\n\n来看一下 Tomcat 的总体架构\n\n![all](all.png)\n\n上图中是 Tomcat 的整体架构，一个 Tomcat 代表一个 Server，一个 Server 下包含对个 Service，每个 Service 下包含多个连接器和一个容器。\n\nService 本身没有什么重要的作用，它只是把连接器和容器组装在一起了，但是 Tomcat 可以同时设置多个 Service，也就可以部署多个服务。比如有两个相同的项目，可以把这两个项目放到两个 Service 里，那这两个相同的项目就可以在一个 Tomcat 里运行了，不用担心冲突的问题。\n\n这些配置可以在 conf/server.xml 中查看。\n\n接下来重点关注一下连接器和容器，这是 Tomcat 工作的核心。\n\n#### 连接器（Connector）\n\n在分析连接器之前，先了解一下 Tomcat 支持的 I/O 模型和应用层协议。\n\nI/O 模型：\n\n- NIO：非阻塞 I/O， Java NIO 类库实现。\n- NIO2：异步 I/O， JDK 7 最新的 NIO2 类库实现。\n- APR： Apache 可移植运行库实现，是 C/C++ 编写的本地库。\n\n应用层协议：\n\n- HTTP/1.1\n- AJP：用于和 Web 服务器集成（如 Apache）。\n- HTTP/2：HTTP 2.0 大幅度的提升了 Web 性能。\n\nService 中存在多个连接器就是为了支持 Tomcat 的多个 I/O 模型和应用层协议。\n\nOK，现在来分析连接器。\n\n首先可以先看一看 Tomcat 中连接器的配置\n\n```xml\n    <Connector port=\"24100\" protocol=\"HTTP/1.1\"\n               connectionTimeout=\"20000\"\n               compression=\"on\"\n               compressionMinSize=\"2048\"\n               noCompressionUserAgents=\"gozilla, traviata\"\n               compressableMimeType=\"text/html,text/xml,text/javascript,text/css,text/plain,image/jpeg,image/gif\" />\n```\n\n连接器中配置了监听的端口和使用的应用层协议等信息。\n\n在上面说了，连接器的主要作用是处理 Socket 连接，并将网络字节流转换成 Request 对象和 Response 对象。那么我可以再试着捋一捋连接器的需求\n\n1、 监听端口\n\n2、 建立连接\n\n3、 获取客户端传输的字节流\n\n4、 根据应用层协议解析字节流，将解析的数据交给容器处理\n\n5、 容器返回响应\n\n6、 将响应转换成字节流返回给客户端\n\n根据以上的需求，Tomcat 将整个连接器分为了三部分\n\n- 网络通信\n- 解析应用层协议\n- 与容器进行交互\n\nTomcat 将这三个功能分成了三个模块：Endpoint、Processor 和 Adapter，三个模块只通过抽象接口进行交互，封装了变化，降低了耦合度。\n\n三个模块的处理逻辑为：  \n\n1、Endpoint 接收字节流，并交给 Processor。  \n\n2、Processor 拿到字节流后，将字节流解析成 Tomcat Request 对象并交给 Adapter。  \n\n3、Adapter 拿到 Tomcat Request 对象再解析成 ServletRequest 交给容器。  \n\nTomcat 并没有直接将字节流解析成 ServletRequest 而是先解析成了 Tomcat Request，再通过 Adapter 进行转换，这样做的好处可以使连接器和容器接偶，我们可以自己实现 Adapter 的功能，来对接我们自己实现的类似容器的功能。\n\n由于 Tocmat 支持多种 I/O 模型和应用层协议，并且这些 I/O 模型和应用层协议可以自由组合，比如 NIO + HTTP 或者 NIO2 + AJP。Tomcat 设计了一个 ProtocolHandler，将网络通信和解析应用层协议放到了一起，来封装这两点的变化。\n\n来看一下连接器的结构图\n\n![connector](connector.png)\n\n来看一下连接器各个组件的代码结构\n\n##### Endpoint\n\nEndpoint 不是一个接口，只有对应的实现类 AbstractEndpoint\n\n![Endpoint](Endpoint.png)\n\nAbstractEndpoint 的实现类中包含了 Tomcat 支持的 I/O 模型。\n\n##### Processor\n\n![Processor](Processor.png)\n\nProcessor 的实现类是包含了 Tomcat 支持的所有应用协议。\n\n##### ProtocolHandler\n\n![ProtocolHandler](ProtocolHandler.png)\n\nProtocolHandler 的实现类里包含了每一种 I/O 模型和协议的组合。\n\n##### Adapter\n\nAdapter 只有一个实现类 CoyoteAdapter，CoyoteAdapter 是一个典型的适配器模式的使用，ProtocolHandler 中将不同的 IO 模式和不同的应用层协议通过 Endpoint 和 Processor 封装成 Tomcat Request，这个 Request 在 Adapter 中转换成标准的 ServletRequest。这其实也是一个扩展点，我们可以实现自己的 Adapter，拿到 Request 进行自己的业务处理，甚至可以不用 Servlet 那一套，自己定义一套新的应用处理模式。\n\n#### 容器（Container）\n\n容器的作用是解析、加载和管理 Servlet，处理请求并返回响应数据。在 Tomcat 中设计了四种容器 Engine、Host、Context 和 Wrapper，这四种容器是父子关系。\n\n- Engine 表示引擎，用来管理多个虚拟站点\n\n- Host 代表的是一个虚拟主机，或者说一个站点，可以给 Tomcat 配置多个虚拟主机地址\n\n- Context 表示一个 Web 应用程序，也是就我们写的一个项目\n\n- Wrapper 表示一个 Servlet\n\n一个 Service 最多只能有一个 Engine，一个 Engine 中可以包含多个 Host，一个 Host 中可以包含多个个 Context，一个 Context 可以包含多个 Wrapper\n\n看一下它的结构图\n\n![Container](Container.png)\n\n\n可以结合 conf/server.xml 配置文件来理解容器的设计\n\n```xml\n<Server port=\"8005\" shutdown=\"SHUTDOWN\">\n  <Service name=\"Catalina\">\n\n    <!--连接器-->\n    <Connector port=\"8080\" protocol=\"HTTP/1.1\"\n               connectionTimeout=\"20000\"\n               redirectPort=\"8443\" />\n\n    <!--容器-->\n    <Engine name=\"Catalina\" defaultHost=\"localhost\">\n      <Host name=\"localhost\"  appBase=\"webapps\"\n            unpackWARs=\"true\" autoDeploy=\"true\">\n      </Host>\n    </Engine>\n  </Service>\n</Server>\n```\n\nTomcat 容器是怎么确定请求的是那个 Servlet 的呢？\n\n通过一个例子来说明一下，图片是盗来的，哈哈哈哈。\n\n![demo](demo.png)\n\n上面这个例子中，要访问 `http://user.shopping.com:8080/order/buy`。  Tomcat通过连接器解析数据后，交给容器，\n\n1、 根据域名找到对应的 Host，也就是在 conf/server.xml 中配置的和 Host 的 name 相同的 Host\n\n2、根据 URL 找到 Context\n\n3、根据 URL 找到 Wrapper（Servlet）\n\n当连接器将数据给到容器后，并不是直到找到 Servlet 才开始处理数据，容器的每一层都会对数据进行一些处理。Tomcat 用了一个叫做 Pipeline-Valve 管道的方式来对数据进行处理。\n\n##### Pipeline-Valve 管道\n\nPipeline-Valve 管道是一种责任链模式，其中 Valve 表示一个处理点，Pipeline 中包含多个 Valve，每个容器中包含一个 Pipeline，每个容器中的 Pipeline 必须包含一个 BasicValve，处于调用的最末端，负责调用下个容器的 Value。\n\n用一张图来解释一下\n\n![Pipeline-Valve](Pipeline-Valve.png)\n\nWrapper 容器的最后一个 Valve 会创建一个 Filter 链，并调用 doFilter 方法，最终会调到 Servlet 的 service 方法。\n\n来看一下容器的代码结构\n\nTomcat 设计了一个顶层的容器接口\n\n```java\npublic interface Container extends Lifecycle {\n\n     public Container getParent();\n\n     public void setParent(Container container);\n\n     public void addChild(Container child);\n\n   // ....省略\n}\n```\n\n各个容器继承了这个顶层的容器\n\n![ContainerClass](ContainerClass.png)\n\n`Container`中定义了操作父容器和子容器的方法，很明显的组合模式。\n\n再来看看每个实现类的结构\n\n![standContainerClass](standContainerClass.png)\n\n每个类同时又继承了一个 Container 的实现抽象类`ContainerBase`，看一下这个类\n\n```java\npublic abstract class ContainerBase extends LifecycleMBeanBase\n        implements Container {\n\n    protected final Pipeline pipeline = new StandardPipeline(this);\n\n    // ....省略\n}\n```\n\n在 ContainerBase 中有`Pipeline`的属性，这就是 Pipeline-Valve 管道。\n\n\nOK，最后结合Java类来看看Tomcat组件的总体结构。  \n\n![class](class.png)\n","tags":["Tomcat"],"categories":["JAVA"]},{"title":"Java泛型中的类型擦除以及Type接口","url":"/2021/11/15/type-erasure/","content":"\n> Java 泛型（generics）是JDK1.5中引入的一个新特性，其本质是参数化类型，解决不确定具体对象类型的问题;其所操作的数据类型被指定为一个参数（type parameter）这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口、泛型方法。  \n\n但是在Java中并不是真正的泛型，实际上是“伪泛型”\n\n### 类型擦除（type Erasure）\n为了与之前的版本兼容，JDK1.5中通过类型擦除来增加的泛型功能。Java泛型只是在编译器层次上，在编译后生成的字节码中是不包含泛型中类型的信息的。  \n通过一个例子来证明类型擦除\n```java\npublic class main {\n\n    public static void main(String[] args) {\n        ArrayList<String> sList = new ArrayList<String>();\n        ArrayList<Integer> iList = new ArrayList<Integer>();\n        System.out.println(sList.getClass() == iList.getClass());\n    }\n}\n```\n上面定义了两个ArrayList，一个是ArrayList\\<String>泛型类型的,一个是ArrayList\\<Integer>类型的，但是最后打印的是`true`，说明两个类型相同。  \n用`javap -c`看一下生成的生成的字节码\n\n![1](1.png)\n\n可以看到在字节码中，ArrayList\\<String>和ArrayList\\<Integer>都被编译成了ArrayList类型，可见编译后发生了类型擦除。\n\n1. 既然编译后发生了类型擦除，那么虚拟机解析、反射等场景是怎么获取到正确的类型的？   \n\n在JDk1.5中增加泛型的同时，JCP组织修改了虚拟机规范，增加了`Signature`、`LocalVariableTypeTable`新属性。  \n用`javap -v`查看一下字节码，在`main`方法中包含一段\n ```\nLocalVariableTypeTable:\n  Start  Length  Slot  Name   Signature\n    8      31     1 sList   Ljava/util/ArrayList<Ljava/lang/String;>;\n    16      23     2 iList   Ljava/util/ArrayList<Ljava/lang/Integer;>;\n```\n `LocalVariableTypeTable`是一个可选属性，如果存在泛型，则会出现这个属性。在`Signature`下包含了泛型的信息。\n\n2. 接下来，看这段代码\n\n```java\nArrayList<String> sList = new ArrayList<String>();\nsList.add(\"111\");\nString s = sList.get(0);\n```\n类型擦除之后，当调用`sList.get(0)`是如何确保返回的值不会和String不匹配呢？  \n用`javap -c`查看一下字节码\n```\npublic class com.example.demo.test.main {\n       // .....省略\n  public static void main(java.lang.String[]) throws java.lang.NoSuchFieldException;\n    Code:\n       0: new           #2                  // class java/util/ArrayList\n       3: dup\n       4: invokespecial #3                  // Method java/util/ArrayList.\"<init>\":()V\n       7: astore_1\n       8: aload_1\n       9: ldc           #4                  // String 111\n      11: invokevirtual #5                  // Method java/util/ArrayList.add:(Ljava/lang/Object;)Z\n      14: pop\n      15: aload_1\n      16: iconst_0\n      17: invokevirtual #6                  // Method java/util/ArrayList.get:(I)Ljava/lang/Object;\n      20: checkcast     #7                  // class java/lang/String\n      23: astore_2\n      24: return\n}\n\n```\n在`#7`处有一个`checkcast`指令，`checkcast`用于检查类型强制转换是否可以进行，也就是泛型在获取值的时候进行了强制类型转换。\n\n3. 再来看看下面这段代码  \n\n首先定义一个Java泛型类\n```java\npublic class GenericClass<T> {\n\n    private T value;\n\n    public T getValue() {\n        return value;\n    }\n\n    public void setValue(T value) {\n        this.value = value;\n    }\n}\n```\n再定义一个子类继承它\n```java\npublic class GenericClassTest extends GenericClass<Integer> {\n\n    @Override\n    public void setValue(Integer value) {\n        super.setValue(value);\n    }\n\n    @Override\n    public Integer getValue(){\n        return super.getValue();\n    }\n}\n```\n在`GenericClassTest`中将`GenericClass`的泛型定义为`Integer`类型，并重写了get和set方法，因为存在类型擦除，父类`GenericClass`的泛型被擦除了。  \n用`javap -c` 查看一下`GenericClass`编译后的字节码\n\n![2](2.png)\n\n可以看到类型擦除后泛型变为了`Object`。那么`GenericClass`也就变为了\n```java\npublic class GenericClass {\n\n    private Object value;\n\n    public Object getValue() {\n        return value;\n    }\n\n    public void setValue(Object value) {\n        this.value = value;\n    }\n}\n```\n这样，父类`GenericClass`中set和get方法操作的是Object对象，而子类`GenericClassTest` 操作的是Integer对象，为什么还可以重写？按照正常的继承关系中，这应该是重载。  \n按照重载的方式试一下\n\n![3](3.png)\n\n可以看到设置Object对象出现了红波浪线，不允许这样设置，看来确实是重写，而不是重载。为什么会时重写，这不是跟Java多态冲突么？继续往下研究。  \n现在用`javap -c`看一下子类`GenericClassTest`的字节码文件\n\n\n![4](4.png)\n\n在`GenericClassTest`中get和/set方法都有两个，一个是操作Object对象一个是操作Integer对象。  \n操作Integer对象的是`GenericClassTest`定义的，操作Object对象的是由编译器生成的。  \n再用`javap -v` 查看一下字节码更详细的信息。\n\n\n![5](5.png)\n\n编译器生成的两个操作Object对象的方法中多了两个`ACC_BRIDGE`、`ACC_SYNTHETIC`标志。  \n这就是虚拟机解决类型擦除和多态冲突问题的方法：使用`桥接方法`。  \n`桥接方法`方法是由编译器生成的，我们在代码中并不能直接使用，但是可以通过反射拿到桥接方法再使用。\n\n\n\n泛型一旦编译过后，类型就被擦除了，那到了运行时，怎么获取泛型信息？这就要使用JDK提供的Type类型接口了。\n### Type类型\n在没有泛型之前，所有的类型都通过Class类进行抽象，Class类的一个具体对象就代表了一个类型。  \n在JDK1.5增加了泛型之后，扩充了数据类型，将泛型也包含了。  \nJDK在原来的基础上增加了一个`Type`接口，它是所有类型的父接口，它的子类有\n- `Class`类： 原始/基本类型，包括平时我们所有的类、枚举、数组、注解，还有int、float等基本类型\n- `ParameterizedType`接口：参数化类型，比如List\\<String>\n- `TypeVariable`接口：类型变量，比如List\\<T>中的T就是参数化变量\n- `GenericArrayType`接口： 数组类型，比如List\\<String>[]、T[]\n- `WildcardType`接口：泛型表达式类型，比如List< ? extends Number>\n\n#### ParameterizedType \n参数化类型，即带有参数的类型，也就是带有\\<>的类型\n```java\npublic interface ParameterizedType extends Type {\n\t    Type[] getActualTypeArguments();\n\n\t    Type getRawType();\n\n     Type getOwnerType();\n}\n```\n- `getActualTypeArguments()`: 获取类型内部的参数化类型 比如Map<K,V>里面的K，V类型。\n- `getRawType()`: 类的原始类型，比如Map<K,V>中的Map类型。\n- `getOwnerType()`: 获取所有者类型（只有内部类才有所有者，比如Map.Entry他的所有者就是Map），若不是内部类，此处返回null。  \n\n实例：\n```java\npublic class GenericClass<T> {\n    private List<String> list;\n    private List<T> tList;\n\n    public static void main(String[] args) {\n        Class<GenericClass> genericClassClass = GenericClass.class;\n        Field[] declaredFields = genericClassClass.getDeclaredFields();\n        for (Field declaredField : declaredFields) {\n            Type genericType = declaredField.getGenericType();\n            if (genericType instanceof ParameterizedType) {\n                System.out.println(\"==========\" + genericType.getTypeName() + \"======ParameterizedType类型=====\");\n                ParameterizedType parameterizedType = (ParameterizedType) genericType;\n                System.out.println(\"getActualTypeArguments:\");\n                Type[] actualTypeArguments = (parameterizedType).getActualTypeArguments();\n                for (Type actualTypeArgument : actualTypeArguments) {\n                    System.out.println(\"    \" + actualTypeArgument);\n                }\n                Type rawType = (parameterizedType).getRawType();\n                System.out.println(\"getRawType:\");\n                System.out.println(\"    \" + rawType);\n\n            }\n        }\n    }\n}\n\n```\n输出\n```\n==========java.util.List<java.lang.String>======ParameterizedType类型=====\ngetActualTypeArguments:\n    java.lang.String\ngetRawType:\n    interface java.util.List\n==========java.util.List<T>======ParameterizedType类型=====\ngetActualTypeArguments:\n    T\ngetRawType:\n    interface java.util.List\n\n```\n\n#### TypeVariable\n类型变量，即泛型中的变量，例如：T、K、V等变量，可以表示任何类；\n> 注意: 与ParameterizedType的区别，TypeVariable代表着泛型中的变量，而ParameterizedType则代表整个泛型。比如List\\<T>中，T是TypeVariable类型，List\\<T>是ParameterizedType类型  \n\n```java\npublic interface TypeVariable<D extends GenericDeclaration> extends Type, AnnotatedElement {\n\t\n    Type[] getBounds();\n    \n    D getGenericDeclaration();\n    \n    String getName();\n    // JDK8新增的\n    AnnotatedType[] getAnnotatedBounds();\n}\n```\n- `getBounds()`：类型对应的上限，默认为Object  可以有多个。比如List< T extends Number & Serializable>中的Number和Serializable\n- `getGenericDeclaration()`： 获取声明该类型变量实体，比如GenericClass< T>中的GenericClass\n- `getName()`：获取类型变量在源码中定义的名称；  \n\n实例：\n\n```java\npublic class GenericClass<T extends Number> {\n    private T t;\n\n    public static void main(String[] args) {\n        Class<GenericClass> genericClassClass = GenericClass.class;\n        Field[] declaredFields = genericClassClass.getDeclaredFields();\n        for (Field declaredField : declaredFields) {\n            Type genericType = declaredField.getGenericType();\n            if (genericType instanceof TypeVariable) {\n                System.out.println(\"==========\" + genericType.getTypeName() + \"======TypeVariable类型=====\");\n                TypeVariable typeVariable = (TypeVariable) genericType;\n                Type[] bounds = typeVariable.getBounds();\n                System.out.println(\"getBounds：\");\n                for (Type bound : bounds) {\n                    System.out.println(\"    \" + bound);\n                }\n                System.out.println(\"getGenericDeclaration：\");\n                System.out.println(\"    \" + typeVariable.getGenericDeclaration());\n                System.out.println(\"getName：\");\n                System.out.println(\"    \" + typeVariable.getName());\n\n\n            }\n        }\n    }\n} \n```\n输出：\n```\n==========T======TypeVariable类型=====\ngetBounds：\n    class java.lang.Number\ngetGenericDeclaration：\n    class com.example.demo.test.GenericClass\ngetName：\n    T\n```\n\n#### GenericArrayType\n泛型数组类型，用来描述ParameterizedType、TypeVariable类型的数组；例如：List\\<T>[] 、T[]、List\\<String>[]等。\n> 注意： GenericArrayType是来描述与泛型相关的数组，与String[]、int[]、float[]这种类型不同。\n```java\npublic interface GenericArrayType extends Type {\n\n\tType getGenericComponentType();\n}\n```\n- `getGenericComponentType()`：返回泛型数组中元素的Type类型，比如List\\<String>[] 中的 List\\<String>  \n\n实例：\n```java\npublic class GenericClass<T extends Number> {\n\n    private List<String>[] lists;\n    private T[] ts;\n\n    public static void main(String[] args) {\n        Class<GenericClass> genericClassClass = GenericClass.class;\n        Field[] declaredFields = genericClassClass.getDeclaredFields();\n        for (Field declaredField : declaredFields) {\n            Type genericType = declaredField.getGenericType();\n\n            if (genericType instanceof GenericArrayType) {\n                GenericArrayType genericArrayType = (GenericArrayType) genericType;\n                System.out.println(\"==========\" + genericType.getTypeName() + \"======GenericArrayType类型=====\");\n                Type genericComponentType = genericArrayType.getGenericComponentType();\n                System.out.println(\"getGenericComponentType:\");\n                System.out.println(\"    \" + genericComponentType);\n            }\n        }\n    }\n}\n```\n输出：\n```\n==========java.util.List<java.lang.String>[]======GenericArrayType类型=====\ngetGenericComponentType:\n    java.util.List<java.lang.String>\n==========T[]======GenericArrayType类型=====\ngetGenericComponentType:\n    T\n```\n#### WildcardType\n泛型表达式（通配符表达式）。例如：？ extend Number、？ super Integer。\n> 注意： WildcardType虽然是Type的子接口，但不代表一种类型，，表示的仅仅是类似 ? extends T、? super K这样的通配符表达式。\n```java\npublic interface WildcardType extends Type {\n\t  \n\tType[] getUpperBounds();\n\t \n\tType[] getLowerBounds();\n}\n```\n- `getUpperBounds()` 获得泛型表达式上界（上限） 获取泛型变量的上边界（extends)\n- `getLowerBounds()` 获得泛型表达式下界（下限） 获取泛型变量的下边界（super）  \n\n实例：\n```java\npublic class GenericClass<T extends Number> {\n    private List<? extends Number> numbers;\n\n    private List<? super Integer> integers;\n\n    public static void main(String[] args) {\n        Class<GenericClass> genericClassClass = GenericClass.class;\n        Field[] declaredFields = genericClassClass.getDeclaredFields();\n        for (Field declaredField : declaredFields) {\n            Type genericType = declaredField.getGenericType();\n            if (genericType instanceof ParameterizedType) {\n                ParameterizedType parameterizedType = (ParameterizedType) genericType;\n\n                Type[] actualTypeArguments = (parameterizedType).getActualTypeArguments();\n                for (Type actualTypeArgument : actualTypeArguments) {\n                    if(actualTypeArgument instanceof WildcardType){\n                        System.out.println(\"==========\" + actualTypeArgument.getTypeName() + \"======WildcardType类型=====\");\n                        WildcardType wildcardType = (WildcardType) actualTypeArgument;\n                        System.out.println(\"getUpperBounds:\");\n                        Type[] upperBounds = wildcardType.getUpperBounds();\n                        for (Type upperBound : upperBounds) {\n                            System.out.println(\"    \"+ upperBound);\n                        }\n                        System.out.println(\"getLowerBounds:\");\n                        Type[] lowerBounds = wildcardType.getLowerBounds();\n                        for (Type lowerBound : lowerBounds) {\n                            System.out.println(\"    \"+ lowerBound);\n                        }\n\n                    }\n                }\n            }\n\n        }\n    }\n}\n```\n\n输出：\n```\n==========? extends java.lang.Number======WildcardType类型=====\ngetUpperBounds:\n    class java.lang.Number\ngetLowerBounds:\n==========? super java.lang.Integer======WildcardType类型=====\ngetUpperBounds:\n    class java.lang.Object\ngetLowerBounds:\n    class java.lang.Integer\n\n```","tags":["JAVA"],"categories":["JAVA"]},{"title":"Java函数式编程","url":"/2021/10/24/javalambda/","content":"### 简介\n\n#### 什么是函数式编程\n\n函数式编程是一种编程范式，即一切都是数学函数。在Java面向对象编程中，程序是一系列相互作用（方法）的对象，而在函数式编程中，程序会是一个无状态的函数组合序列。\n\n\n#### 函数是“第一等公民”\n\n“第一等公民”指的是函数和其他数据类型一样，处于平等的地位。可以赋值给变量、可以作为另一个函数的参数或者作为一个函数的返回值。比如\n\n```java\n// 将两数相加的逻辑赋值给变量sum\nvar sum = (a,b)->a+b;\n\n// 将函数作为另一个函数的参数\noperation(sum)\n```\n\n\n\n### Java函数试编程\n\n#### Lambda 表达式\n\n历史上研究函数式编程的理论是Lambda演算，所以我们经常把支持函数式编程的编码风格称为Lambda表达式。  \n\n在Java中Lambda 表达式的表达形式:\n\n```\n(参数)->方法体\n```\n\n1. 参数：可以有多个，如果只有一个可以省略括号\n2. ->：箭头符号。\n3. 方法体：方法体超过一句时，要用{}包裹，可以根据情况看是否需要`return`语句\n\n#### 函数式接口\n\nJava 8提供了函数式编程接口的概念，用作Lambda表达式的类型。 \n\n函数式接口：只定义了*单一抽象方法*的接口。  \n\n举个例子，看一下Java 8中Runnable接口 ： \n\n```java\n@FunctionalInterface\npublic interface Runnable {\n    public abstract void run();\n}\n\n```\n\n在类上多了一个`@FunctionalInterface`注解\n\nJava 8之前定义一个Runnable 对象\n\n```java\nRunnable r = new Runnable() {\n   public void run() {\n       System.out.println(\"Hello World!\");\n   }\n};\n```\n\nJava 8之后可以直接写成\n\n```java\nRunnable r =()-> System.out.println(\"Hello World!\");\n```\n\n`@FunctionalInterface`注解并不是必须的，只要符合单一抽象方法的接口都可以。  \n\n用一个加减乘除的例子来演示一下Java中函数式编程的使用。 \n\n首先定义一个函数式接口，\n\n```java\npublic interface Operate {\n    \n    int operate(int a, int b);\n    \n}\n\n```\n\n将不同的逻辑操作赋值给函数式接口\n\n```java\npublic class Main {\n\n    public static void main(String[] args) {\n        // 加\n        Operate add = (a, b) -> a + b;\n        // 减\n        Operate subtract = (a, b) -> a - b;\n        // 乘\n        Operate multiply = (a, b) -> a * b;\n        // 除\n        Operate divide = (a, b) -> a / b;\n        \n        System.out.println(operate(add, 2, 1));\n        System.out.println(operate(subtract, 2, 1));\n        System.out.println(operate(multiply, 2, 1));\n        System.out.println(operate(divide, 2, 1));\n    }\n\n    static int operate(Operate operate, int a, int b) {\n        return operate.operate(a, b);\n    }\n}\n```\n\n在上面的例子中，加减乘除的每个变量是一个个的函数，具体的函数逻辑在等号的右边。同时定义了一个operate的方法，第一个参数是Operate类型函数式接口，也就是接收的是一个函数，然后运行函数的逻辑，实际上是运行等号右边的逻辑。\n\n在Java 8中，`java.util.function`下定义了许多函数式接口。列一下几个核心的函数式接口\n\n| 接口              | 参数  | 返回类型 | 表述                             |\n| ----------------- | ----- | -------- | -------------------------------- |\n| Predicate<T>      | T     | boolean  | 用于判断操作函数                 |\n| Consumer<T>       | T     | void     | 没有返回结果的函数               |\n| Function<T, R>    | T     | R        | 入参是T，出参是R的函数           |\n| Supplier<T>       |       | T        | 生成一个对象T的函数              |\n| UnaryOperator<T>  | T     | T        | 入参、出参都是T的类型函数        |\n| BinaryOperator<T> | (T,T) | T        | 接收两个入参为T，出参也为T的函数 |\n\n还是那上面加减乘除的例子，可以用`BinaryOperator`函数来表示,表示有两个入参是Integer出参也是Integer。\n\n```java\n// 加\nBinaryOperator<Integer> add = (a, b) -> a + b;\n// 减\nBinaryOperator<Integer> subtract = (a, b) -> a - b;\n// 乘\nBinaryOperator<Integer> multiply = (a, b) -> a * b;\n// 除\nBinaryOperator<Integer> divide = (a, b) -> a / b;\n```\n\n\n\n#### 方法引用\n\n方法引用是用来直接访问类或者实例的已经存在的方法或者构造方法,方法引用的本质其实是简化Lambda 表达式。\n\n方法引用的使用是一对冒号`::`\n\n| 类型         | 方法引用          |        对应的Lambda表达式         |\n| ------------ | ----------------- | :-------------------------------: |\n| 构造方法引用 | 类名::new         |     (args) -> new 类名(args)      |\n| 静态方法引用 | 类名:: 静态方法名 | (args) -> 类名.staticMethod(args) |\n| 实例方法引用 | 类名::方法名      | (inst,args) -> inst.method(args)  |\n| 对象方法引用 | 对象::方法名      |    (args) -> 对象.method(args)    |\n\n定义一个类来说明方法引用的使用\n\n```java\npublic class Person {\n\n    private String name;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public static void say(Person person) {\n        System.out.println(person.getName());\n    }\n\n    public void equals(Person person) {\n        System.out.println(this.getName().equals(person.getName()));\n    }\n\n    public void eat(String food) {\n        System.out.println(\"eat \" + food);\n    }\n}\n```\n\n\n\n#### 构造方法引用\n\n```java\n Supplier<Person> supplier = Person::new;\n//Lambda表达式写法\n Supplier<Person> supplier = ()-> new Person();\n```\n\n`用`Supplier函数式接口是因为调用的构造函数是无参的，符合Supplier函数式接口的定义\n\n`注意：被调用的方法的参数列表和返回值类型需要与函数式接口中抽象方法的参数列表和返回值类型要一致。`\n\n#### 静态方法引用\n\n```java\nConsumer<Person> say = Person::say;\n//Lambda表达式写法\nConsumer<Person> say = person -> Person.say(person); \n```\n\n用Consumer函数式接口是因为say方法是一个包含一个参数，并且没有返回值的函数，符合Consumer函数式接口的定义\n\n注意：被调用的方法的参数列表和返回值类型需要与函数式接口中抽象方法的参数列表和返回值类型要一致。\n\n#### 实例方法引用\n\n```java\nBiConsumer<Person, Person> personPersonBiConsumer = Person::equals;\n//Lambda表达式写法\nBiConsumer<Person, Person> personPersonBiConsumer = (inst, args) -> inst.equals(args);\n```\n\n实例方法引用第一个参数是实例方法的调用者，第二个是实例方法的参数。\n\n`注意：被调用的方法的参数列表和返回值类型需要与函数式接口中抽象方法的参数列表和返回值类型要一致。`\n\n#### 对象方法引用\n\n```java\nPerson person = new Person();\nConsumer<String> eat = person::eat;\n// Lambda表达式写法\nConsumer<String> eat = food -> person.eat(food);\n```\n\n`注意：被调用的方法的参数列表和返回值类型需要与函数式接口中抽象方法的参数列表和返回值类型要一致。`\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"HashMap那些事儿","url":"/2021/09/30/hashmap/","content":"HashMap 在 Java 中是一个使用高频的数据结构，JDK1.8 以后 HashMap 进行了一次翻天覆地的改变。\n\n本文基于 JDK1.8 分析一下 HashMap\n\n### 存储结构转换\n\n在 JDK1.8 以前 HashMap 采用的是`数组+链表`的结构，JDK1.8 以后又引入了红黑树的结构，会在链接和红黑树之间转换，结合源码分析一下 HashMap 对`数组+链表`和`数组+红黑树`的转换  \n首先看一下数据的存储结构\n\n```java\n transient HashMap.Node<K, V>[] table;\n```\n\nHashMap 定义了一个 Node 的数组，Node 的定义\n\n```java\n   static class Node<K, V> implements Entry<K, V> {\n        final int hash;\n        final K key;\n        V value;\n        HashMap.Node<K, V> next;\n        // ....省略\n  }\n```\n\nNode 中包含了四个属性`hash`、`key`、`value`、`next`。\n\n- `key`、`value`是调用 HashMap 的`put()`方法传进来的。\n- `hash` 是判断 key 是否重复的关键\n- `next` 用于构建链表\n\n所以 HashMap 默认是一个`数组+链表`的形式\n\n![list](list.png)\n\n`链表`是否要转换成`红黑树`，是在调用`put()`方法添加数据时判断的，跟着源码分析`链表`转换成`红黑树`的过程\n\n`put()`方法调用的是`putVal()`方法，\n\n```java\n    final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {\n        // ...省略\n        while (true) {\n            if ((e = ((HashMap.Node) p).next) == null) {\n                ((HashMap.Node) p).next = this.newNode(hash, key, value,(HashMap.Node) null);\n                //转换成红黑树\n                if (binCount >= TREEIFY_THRESHOLD - 1) {\n                    this.treeifyBin(tab, hash);\n                }\n                break;\n            }\n            if ((((HashMap.Node) e).hash == hash) &&\n                    (((k = ((HashMap.Node) e).key) == key) ||\n                    ((key != null) && key.equals(k)))) {\n                break;\n            }\n            p = e;\n            ++binCount;\n        }\n        // ...省略\n    }\n```\n\n无关的部分省略了，while 循环中遍历链表中的数量，如果数量大于等于 8，调用`treeifyBin()`方法，\n在`treeifyBin()`中有一行\n\n```java\n  hd.treeify(tab);\n```\n\n`treeify()`方法会将`链表`转换为`红黑树`。同时会将链表中所有节点由`Node`结构转换为`TreeNode`结构。\n\n`TreeNode`继承自`java.util.LinkedHashMap.Entry`，`java.util.LinkedHashMap.Entry`又继承自`Node`\n\n那么`Node`就是`TreeNode`的父类，所以这样转换是不会有问题的。\n\n经过`treeifyBin()`后存储结构变为\n![tree](tree.png)\n\n### put 方法的具体逻辑\n\n`put`方法中可以划分为 4 个部分，看一下方法的执行流程图。\n![put](put.png)\n\n结合一下源码\n![put-source](put-source.png)\n\n结合流程图和源码，对 put 的过程做一个描述  \n①：判断 tab 是否为空，如果为空说明 table 还未初始化，先对数组进行初始化  \n②：先计算在数组中的位置，并判断该位置是否为空，如果为空，则直接赋值。然后跳转到⑥  \n③: 判断节点 key 是否存在，如果存在直接额赋值，不存在则执行 ④  \n④：判断是否是红黑树，如果是则添加到树中，否则进入到⑤\n⑤：为链表的情况，判断长度是否大于等于`TREEIFY_THRESHOLD - 1`，如果是，先将链表转花为红黑树，然后添加到树中。如果不是直接添加到列表中。  \n⑥：插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。\n\n### 扩容\n\n当 HashMap 键值对大于阀值时或者初始化时，会进行扩容。\n阀值是`threshold`的值，是由数组的长度和`loadFactor(默认值是0.75)`决定的，threshold = length \\* loadFactor\n\nHashMap 的扩容是在`resize()`方法里进行的，结合源码分析一下 HashMap 是怎么扩容的，因为 JDk1.8 引入了红黑数，所以代码比较长，就不贴全部的代码了，主要分析一下关键步骤。  \n先看一下初始化的几个变量\n\n```java\nint oldCap = (oldTab == null) ? 0 : oldTab.length; //现在容器的大小\nint oldThr = threshold; 现在的阀值\n int newCap  //计算过后，新的容器的大小\n     , newThr = 0; //计算后阀值的大小\n```\n\n`注意： 扩容不只是改变容器的大小，还要改变阀值的大小`\n\n#### 1. table 容器不为空的情况\n\n```java\n  if (oldCap > 0) {\n     if (oldCap >=  MAXIMUM_CAPACITY) {\n          this.threshold = Integer.MAX_VALUE;\n          return oldTab;\n     }\n\n     else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&\n                  oldCap >= DEFAULT_INITIAL_CAPACITY)\n                 newThr = oldThr << 1;\n  }\n```\n\n- 数量已经大于最大的容量，则将阀值设置为整数最大值，不再扩容\n- `newCap = oldCap << 1` 扩容后仍然小于最大容量 并且 oldCap 大于默认值 16，双倍扩容阀值 threshold\n\n#### 2. 旧的容量为 0，但 threshold 大于零\n\n```java\n   else if (oldThr > 0)\n      newCap = oldThr;\n```\n\n出现这种情况说明有参构造有 initialCapacity 传入，那么 threshold 已经被初始化成最小 2 的 n 次幂，所以直接将该值赋给新的容量\n\n#### 3. 旧的容量为 0，threshold 也等于 0\n\n```java\n else {\n      newCap = DEFAULT_INITIAL_CAPACITY;\n      newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n  }\n```\n\n这种情况说明是通过无参构造函数创建的，也就是`Map map = new HashMap()`这种格式，那么都被赋予默认的大小（默认 16）和默认的阈值（默认 16 \\* 0.75）\n\n#### 4、 计算新的阈值\n\n```java\n if (newThr == 0) {\n    float ft = (float)newCap * loadFactor;\n    newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?\n                      (int)ft : Integer.MAX_VALUE);\n}\n```\n\n这种情况说明是在有参构造时，默认的`loadFactor`被重新赋值，如果`loadFactor`大于 1，那么阈值会比容量大，有可能会超出最大容量，所以要重新计算。  \n还有一种情况在第一步中`newThr = oldThr << 1`，左移超出范围后会置0，也要重新计算。\n\n扩容也就这些了，剩下的代码是扩容后，元素重新排列的逻辑了。\n\n`注意：扩容的大小 （newCap = oldCap << 1） << 相当于乘2,所以HashMap的容量总是2的n次方`\n\n### 确定key在数组中的位置\n在调用`put()`方法添加新数据时，在`put()`方法内部，调用`hash()`操作key，得到一个hash值\n![hash](hash.png)\n\n在`putVal()`方法中，在第②步的时候确定key在数组中的位置\n\n![index](index.png)\n\n\n`hash()`方法的实现\n```java\n    static final int hash(Object key) {\n        int h;\n        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n    }\n```\n在key等于null的情况下，会直接放到0处，不为null时，获取key的`hashCode`后，将`hashCode`的高16位和低16位进行异或。  \n\n获取位置的整个过程有两个问题：\n1. `(n - 1) & hash` 是怎么获取到位置的？  \n    `n`是table数组的长度，而数据的长度又总是2的n次方，所以`(n - 1) & hash`正好是对n取模。  \n    `( (n - 1) & hash) ) == (hash % n)`, 这是一个非常巧妙的设计，用&比%具有更高的效率。\n    \n2. 将`hashCode`的高16位和低16位进行异或的作用是什么？  \n    `hashCode`是一个int类型的数据，占4个字节 32位，而在HashMap中默认的长度是`DEFAULT_INITIAL_CAPACITY = 1 << 4（即2的四次方16）`，要远小于int类型的范围，如果直接用`hashCode`进行运算，那么`hashCode`的高位部分对结果来说不会起太大作用，这样会增加hash碰撞的概率。所以用高16位和低16位进行异或来降低hash冲突的概率\n\n### 使用任意类作为key的情况\nHashMap判断key的位置是基于`hashCode`，如果要使用任意类作为key，必须要考虑是否要重写`hashCode`方法。默认的`hashCode`返回对象的是对象地址，直接使用使用可能会有问题。用伪代码举个例子\n```java\npublic class User{\n  private String name;\n  private int age;\n  \n  // ...省略get set方法\n}\n  \n  User user1 = new User();\n  user1.setName(\"张三\");\n  user1.setAge(\"20\");\n  \n  \n  User user2 = new User();\n  user2.setName(\"张三\");\n  user3.setAge(\"20\");\n\n  Map<User,Stirng> map = new HashMap<>();\n  map.put(user1,\"张三\");\n  map.put(user2,\"张三\");\n```\n这种情况下尽管user1和user2的属性都相同，但是user2并不会覆盖user1,因为user1和user2是两个对象，地址不相同，`hashCode`也不相同。  \n\n> 注意： 重写hashCode()方法时，要注意equals() 和 hashCode() 相关的规则\n#### 为什么String、Integer等包装类可以作为key\n1. String、Integer内部已重写了equals()、hashCode()等方法。\n2. 都是final类型，保证了不可更改性，不会存在获取hash值不同的情况\n\n### 线程安全问题\n在put第①步\n```java\n  if ((tab = table) == null || (n = tab.length) == 0)\n       n = (tab = resize()).length;\n```\n当第一个线程运行到这后已经拿到了数组数据和长度，如果这时让出CPU，而第二个线程进来后把数组数据改变了，那么当第一线程再次拿到CPU后，继续运行的话，会把第二个线程的数据覆盖掉，造成数据丢失。\n在put第⑥步\n```java\nif (++size > threshold)\n     resize();\n```\n`++size`并不是原子操作，当多个线程都执行这行代码时，会存在丢失数据的情况。\n\n来个例子验证一下：\n```java\npublic class HashMapTreadTest extends Thread{\n\n    private  static Map<Integer,Integer> map = new HashMap<>();\n    private static AtomicInteger mapSize = new AtomicInteger();\n\n    @Override\n    public void run() {\n        while (mapSize.get() < 10000){\n            map.put(mapSize.get(),map.get(mapSize));\n            mapSize.incrementAndGet();\n        }\n    }\n\n    public static void main(String[] args) {\n        HashThreadTest hashThreadTest = new HashThreadTest();\n        Thread[] threads=new Thread[5];\n        for (int i = 0; i < 5; i++) {\n            threads[i]=new Thread(hashThreadTest,\"线程\"+i);\n            threads[i].start();\n        }\n        //默认还有个守护线程\n        while (Thread.activeCount() > 2) {\n            Thread.yield();\n        }\n        System.out.println(\"map的数量 = \"+ hashThreadTest.map.size());\n    }\n}\n```\n上面代码功能是向map里添加10000条数据，开启5个线程同时操作，运行完后打印的数量并不是10000，说明数据丢失。","tags":["JAVA"],"categories":["JAVA"]},{"title":"TCP三次握手和四次挥手","url":"/2021/09/28/tcp34/","content":">定义：TCP（Transmission Control Protocol:传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议.\n\nTCP在发送数据前，会在通信双方之间建立一条连接。通过这条连接，客户端和服务端可以保存一份对方的信息，如ip地址、端口号等。通信双方的数据传输就是在这条连接上进行的。这条连接的建立和断开的过程就是所谓的`三次握手`和`四次挥手`\n\n### TCP报文头部数据\n\n在了解`三次握手`和`四次挥手`之前，先来了解一下TCP报文的头部数据结构\n![TCP头部](header.png)\n上图中有几个字段是在`三次握手`和`四次挥手`需要的\n\n1. Sequence number（seq）：序列号 32位\n2. Acknowledgment number（ack）: 确认序列号 32位\n3. SYN、ACK、FIN标志位\n   - SYN : 建立起一个新的连接\n   - ACK ： 确认号有效\n   - FIN ： 释放一个连接\n\n`注意： 不要将ack和ACK理解混了，ack是一串序列号，ACK是一个标志位。当ACK为1时，代表ack序列号有效`\n\n### 三次握手\n\n`三次握手`是TCP建立连接的过程。主要作用是判断通信双方有没有传输数据的能力。看一下整个握手的过程。\n![三次握手](tcp3.png)\n\n`三次握手`步骤：\n\n1. `第一次握手`：客户端主动向服务端发起一个建立连接的请求。请求数据中\n\n   - `SYN=1`表示客户端要与服务端建立一个新的连接\n   - 初始自己的序列号值`seq=x`  \n\n   此时客户端进入到`SYN-SENT`状态等待服务器的回复\n\n2. `第二次握手`：服务端收到客户端的请求后，发现`SYN=1`，知道这是要建立一个连接，于是向客户端发送一个回复消息\n\n   - 初始自己序列号值`seq=y`\n   - `ACK=1`表示确认收到了消息\n   - `SYN=1`表示同意了这次连接，并与客户端建立新连接\n   - `ack=x+1`客户端发过来的序列号+1  \n\n   此时服务器进入到`SYN-RCVD`状态\n\n3. `第三次握手`：客户端收到服务端的回复后，发现`SYN=1``ACK=1``ack=x+1`表示服务端已经收到第一次握手时客户端发送的请求，并同意建立连接，这时，客户端回复一个确认消息\n\n   - `ACK=1`表示确认收到了消息、\n   - `seq=x+1`表示客户端第一次握手x序列号的下一个序列号\n   - `ack=y+1`表示收到了服务端发动过来的`seq=y`的消息  \n\n   此时客户端进入到`ESTAB-LISHED`状态，在服务端收到消息后也进入到`ESTAB-LISHED`状态。\n\nOK，`三次握手`完毕，通信双方可以传输数据了\n\n### 四次挥手\n\n`四次挥手`是TCP断开的过程，主要的作用是确保数据已传输完毕，并断开连接，看一下四次挥手的过程\n![四次挥手](tcp4.png)\n\n`四次挥手`步骤\n\n\n1. `第一次挥手`：客户端主动向服务端发送发断开请求\n\n   - `FIN=1`表示释放连接\n   - `seq=u`客户端当前的序列号\n\n   此时客户端进入到`FIN-WAIT-1`状态\n\n2. `第二次挥手`：服务端收到客户端发来的请求后，发现`FIN=1`，知道了这是一个断开请求，然后给客户端发送一个确认请求\n\n   - `ACK=1`表示确认收到了客户端释放连接的请求\n   - `seq=u`服务器当前的序列号\n   - `ack=u+1`表示服务端收到客户端发来的`seq=u`的断开请求\n\n   此时服务区进入到`CLOSE-WAIT`状态，并且不会立即进行第三次挥手，因为这时数据可能还没有传输完成，需要再等待一段时间。  \n   客户端在接受到回复后进入到`FIN-WAIT-2`状态\n\n3. `第三次挥手`：当服务端发送完所有的数据后，主动向客户端发送断开请求\n\n   - `FIN=1`表示释放连接\n   - `ACK=1、seq=u、ack=u+1`和上一次一样  \n\n   此时服务端进入到`LAST-ACK`状态等待客户端回复\n\n4. `第四次挥手`：客户端收到服务端发来的关闭请求后，向服务端发出确认报文，并进入到`TIME-WAIT`状态。服务端接受到确认报文后，断开连接，而客户端要等2MSL(最长报文段寿命的2倍时长)后才断开连接，所以服务端结束的时间要比客户端早一些。\n\n\n\n### 常见问题\n\n#### 为什么是3次握手，2次不行么？\n\n如果是2次握手，假设在第二次握手的时候服务端发送给客户端的消息丢失了，那么这时服务端进入到`ESTAB-LISHED`状态，准备接收数据了。但是客户端却不知道服务端已经准备好了。那么客户端也不会给服务端发送数据。\n\n而3次握手多了向服务端最后确认阶段，这样就可以确保客户端已经知道服务端已经准备好了。\n\n#### 为什么建立连接的时候是3次，断开连接时是4次？\n\n主要的作用还是确保所有数据已经传输完，第一次挥手客户端主动向服务端发送断开请求表示客户端数据已经传输完毕，第三次挥手服务端主动向客户端发送断开请求表示服务端数据也传输完毕。\n\n#### 第四次挥手后为什么要等2MSL的时间才断开连接？\n\n主要是防止第四次挥手客户端的请求丢失，服务端没有接收到客户端最后的确认请求，那么服务端再发送一次第三次挥手的数据，再加上客户端回复确认消息的时间，所以要等待2MSL\n\n#### 建立连接以后，客户端出现故障怎么办？\n\nTCP有一个`保活机制`：\n在一个时间段内，如果连接没有任何的活动，`保活机制`会起作用，每隔一个时间间隔，会发送一个报文，如果连续几个报文都没有得到响应，就会认为TCP连接已经死亡，这时系统内核会将错误信息通知给上层应用\n\n#### 什么是SYN攻击？，如何避免？\n\n基于第一次握手时，服务器会进入`SYN_RCVD`状态。攻击者在短时间内伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务。\n\n\n这本身是TCP设计的原因，SYN攻击不能完全的避免，只能尽可能减少SYN的危害，常见预防方式：\n\n- 缩短超时（SYN Timeout）时间\n- 增加最大半连接数\n- 过滤网关防护\n- SYN cookies技术\n\n### 参考资料：\n\n- [1] [https://blog.csdn.net/ThinkWon/article/details/104903925#t11](https://blog.csdn.net/ThinkWon/article/details/104903925#t11)\n- [2] [https://www.cnblogs.com/xiaolincoding/p/12638546.html](https://www.cnblogs.com/xiaolincoding/p/12638546.html)\n- [3] [https://hit-alibaba.github.io/interview/basic/network/TCP.html](https://hit-alibaba.github.io/interview/basic/network/TCP.html)\n\n\n","tags":["计算机网络"],"categories":["计算机网络"]},{"title":"Mybatis中mapper生成代理的过程","url":"/2021/09/23/mybatis-mapper/","content":"### 目录\n1. mybatis中mapper代理的生成过程\n2. 与Spring集成时mapper代理的生成过程\n3. 与SpringBoot集成时mapper代理的生成过程\n\n### mybatis中mapper代理的生成过程\n#### 构建代理类工厂\n从入口点开始一步一步看，首先`SqlSessionFactoryBuilder`类中`build()`方法加载配置文件\n```java\n  public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) {\n    try {\n      XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);\n      return build(parser.parse());\n    } catch (Exception e) {\n      throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e);\n    } finally {\n      // ...省略\n    }\n  }\n```\n将配置文件读取为`XMLConfigBuilder`对象，并调用`parse()`方法来解析文件，进到`parse()`中\n```\n  public Configuration parse() {\n     // ...省略\n    parsed = true;\n    parseConfiguration(parser.evalNode(\"/configuration\"));\n    return configuration;\n  }\n```\n可以看到具体的解析过程是在`parseConfiguration`方法中进行的。\n```java\n  private void parseConfiguration(XNode root) {\n    try {\n       // ...省略\n      //解析mapper\n      mapperElement(root.evalNode(\"mappers\"));\n    } catch (Exception e) {\n      throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e);\n    }\n  }\n```\n这里重点看一下最后解析mapper的方法`mapperElement(root.evalNode(\"mappers\"))`，进到方法里，\n```java\n\n  private void mapperElement(XNode parent) throws Exception {\n    if (parent != null) {\n      for (XNode child : parent.getChildren()) {\n        if (\"package\".equals(child.getName())) {\n          //   package 形式加载 ,加载package下的所有class文件\n          String mapperPackage = child.getStringAttribute(\"name\");\n          configuration.addMappers(mapperPackage);\n        } else {\n          String resource = child.getStringAttribute(\"resource\");\n          String url = child.getStringAttribute(\"url\");\n          String mapperClass = child.getStringAttribute(\"class\");\n          if (resource != null && url == null && mapperClass == null) {\n            // 通过Mapper.xml 加载\n            ErrorContext.instance().resource(resource);\n            InputStream inputStream = Resources.getResourceAsStream(resource);\n            XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());\n            mapperParser.parse();\n          } else if (resource == null && url != null && mapperClass == null) {\n            // 通过Mapper.xml 加载\n            ErrorContext.instance().resource(url);\n            InputStream inputStream = Resources.getUrlAsStream(url);\n            XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments());\n            mapperParser.parse();\n          } else if (resource == null && url == null && mapperClass != null) {\n            // 通过单个class文件加载\n            Class<?> mapperInterface = Resources.classForName(mapperClass);\n            configuration.addMapper(mapperInterface);\n          } else {\n            throw new BuilderException(\"A mapper element may only specify a url, resource or class, but not more than one.\");\n          }\n        }\n      }\n    }\n  }\n```\n整个`mapperElement()`方法就是加载mapper的过程了，可以看到加载mapper\n有两种形式：通过class文件和通过xml文件。  \n构建mapper代理的过程也就是从这开始的，那就一步一步分析。  \n看一下通过XML文件加载的过程，mybatis将mapper相关的配置读取为一个`XMLMapperBuilder`对象，并通过`parse()`方法进行解析，进到这个方法中\n```java\n\n  public void parse() {\n    if (!configuration.isResourceLoaded(resource)) {\n      // 加载xml文件\n      configurationElement(parser.evalNode(\"/mapper\"));\n      configuration.addLoadedResource(resource);\n      // 加载mapper class文件\n      bindMapperForNamespace();\n    }\n   // ...省略\n  }\n```\n`parse()`方法做了主要做了两件事，加载xml文件和加载class文件。  \n看一下加载xml的过程\n```java\n  private void configurationElement(XNode context) {\n    try {\n      // 获取xml文件的namespace\n      String namespace = context.getStringAttribute(\"namespace\");\n      if (namespace == null || namespace.equals(\"\")) {\n        throw new BuilderException(\"Mapper's namespace cannot be empty\");\n      }\n      // 保存获取xml文件的namespace\n      builderAssistant.setCurrentNamespace(namespace);\n       // ...省略\n    } catch (Exception e) {\n      throw new BuilderException(\"Error parsing Mapper XML. The XML location is '\" + resource + \"'. Cause: \" + e, e);\n    }\n  }\n```\n本文是分析mapper代理的生成过程，所以加载xml的具体细节就不详细分析了，这里注意的是读取xml文件中`namespace`标签的值，并将值设置到`builderAssistant`对象中  \n现在回过头来看一下加载class文件的过程。进到`bindMapperForNamespace()`方法中去\n```java\n  private void bindMapperForNamespace() {\n    // 获取xml文件中设置的namespace值\n    String namespace = builderAssistant.getCurrentNamespace();\n    if (namespace != null) {\n      Class<?> boundType = null;\n      try {\n        // 加载类\n        boundType = Resources.classForName(namespace);\n      } catch (ClassNotFoundException e) {\n        //ignore, bound type is not required\n      }\n      if (boundType != null) {\n        if (!configuration.hasMapper(boundType)) {\n          // Spring may not know the real resource name so we set a flag\n          // to prevent loading again this resource from the mapper interface\n          // look at MapperAnnotationBuilder#loadXmlResource\n          configuration.addLoadedResource(\"namespace:\" + namespace);\n          // 添加到configuration中\n          configuration.addMapper(boundType);\n        }\n      }\n    }\n  }\n```\n`bindMapperForNamespace()`通过xml文件中设置的namespace值加载对应的mapper接口，最后通过`configuration.addMapper()`添加到`configuration`中。  \n\n还记不记得刚才提到的加载mapper\n有两种形式：通过class文件和通过xml文件。通过class文件的方式直接调用`configuration.addMapper()`将mapper接口加载到了`configuration` 中了。   \n\n`Configuration`是mybatis的全局配置类，所有的mybatis相关的信息都保存在`Configuration`中。  \n继续进到`Configuration`的`addMapper`方法中\n```java\n  public <T> void addMapper(Class<T> type) {\n    mapperRegistry.addMapper(type);\n  }\n```\n`Configuration`把对应的mapper接口添加到`mapperRegistry`中，再进到`mapperRegistry.addMapper()`方法中\n```java\n  public <T> void addMapper(Class<T> type) {\n    if (type.isInterface()) {\n        // ...省略\n      try {\n        knownMappers.put(type, new MapperProxyFactory<T>(type));\n         // ...省略\n      } finally {\n        if (!loadCompleted) {\n          knownMappers.remove(type);\n        }\n      }\n    }\n  }\n```\n该方法首先判断是否是接口，如果是接口则将mapper接口添加到`knownMappers`中。  \n看一下`knownMappers`的定义\n```java\n  private final Map<Class<?>, MapperProxyFactory<?>> knownMappers = new HashMap<Class<?>, MapperProxyFactory<?>>();\n```\n`knownMappers`是一个`HashMap`，它保存的是所有的mapper接口和对应的mapper代理工厂。\n\n到现在为止，mapper已经加载完了，但是并没有生成mapper的代理对象，只是生成了对应的代理工厂。\n#### 生成并使用代理对象\nmybatis并没有在加载mapper接口的时候生成代理对象，而是在调用的时候生成的。  \n首先从入口开始\n```java\nsqlSession.getMapper(XXX.class)\n```\n`sqlSession`默认是`DefaultSqlSession`。进到`DefaultSqlSession`的`getMapper()`方法中\n```java\n  @Override\n  public <T> T getMapper(Class<T> type) {\n    return configuration.<T>getMapper(type, this);\n  }\n```\n继续到`Configuration`的`getMapper`中  \n```java\n public <T> T getMapper(Class<T> type, SqlSession sqlSession) {\n    return mapperRegistry.getMapper(type, sqlSession);\n  }\n```\n继续到` mapperRegistry.getMapper()`中\n```java\n  public <T> T getMapper(Class<T> type, SqlSession sqlSession) {\n    final MapperProxyFactory<T> mapperProxyFactory = (MapperProxyFactory<T>) knownMappers.get(type);\n    // ...省略\n    }\n    try {\n      return mapperProxyFactory.newInstance(sqlSession);\n    } catch (Exception e) {\n      throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e);\n    }\n  }\n```\n从`knownMappers`中获取到对应mapper接口的代理工厂类`MapperProxyFactory`，然后通过`MapperProxyFactory`获取真正的代理对象。  \n进到`MapperProxyFactory`的`newInstance()`方法中\n```java\n  public T newInstance(SqlSession sqlSession) {\n    final MapperProxy<T> mapperProxy = new MapperProxy<T>(sqlSession, mapperInterface, methodCache);\n    return newInstance(mapperProxy);\n  }\n  \n   protected T newInstance(MapperProxy<T> mapperProxy) {\n    return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);\n  }\n```\n首先生成了`MapperProxy`类，再通过`Proxy`生成真正的代理类。  \n看一下`MapperProxy`类\n```java\npublic class MapperProxy<T> implements InvocationHandler, Serializable {\n  //  ...省略\n}\n```\n`MapperProxy`实现了`InvocationHandler`接口，mapper接口的具体处理逻辑也就是在这类中处理。\n\n到此为止，代理对象才真正的生成。\n\n### 与Spring集成时mapper代理的生成过程\nmybatis与Spring集成时需要用到`mybatis-spring`的jar。\n#### Spring注册mapper代理类\n既然是与Spring集成，那么就要配置一下，将mybatis交给Spring管理。\nspring的xml文件配置\n```xml\n    <bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\">\n        <property name=\"driverClassName\" value=\"driverClassName\"/>\n        <property name=\"url\" value=\"url\"/>\n        <property name=\"username\" value=\"username\"/>\n        <property name=\"password\" value=\"password\"/>\n    </bean>\n\n    <!--sqlSessionFactory-->\n    <bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <property name=\"dataSource\" ref=\"dataSource\"/>\n        <!--绑定mybatis配置文件-->\n        <property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/>\n        <!--注册Mapper.xm映射器-->\n        <property name=\"mapperLocations\" value=\"classpath:cn/ycl/mapper/*.xml\"/>\n    </bean>\n\n    <!--注册所有mapper-->\n    <bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\">\n        <!--basePackage 属性是映射器接口文件的包路径。-->\n        <!--你可以使用分号或逗号 作为分隔符设置多于一个的包路径-->\n        <property name=\"basePackage\" value=\"cn/ycl/mapper\"/>\n        <property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/>\n    </bean>\n```\n将mybatis交给Spring只需要配置3个bean就可以了   \n1、 数据库相关的`dataSource`  \n2、 mybatis的`sqlSessionFactory`  \n3、 将mapper委托给Spring的工具类`MapperScannerConfigurer`  \n生成mapper代理的过程主要在`MapperScannerConfigurer`里，看一下`MapperScannerConfigurer`的定义\n```java\npublic class MapperScannerConfigurer\n    implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware {\n    // ...省略\n}\n```\n关键点在`MapperScannerConfigurer` 实现了`BeanDefinitionRegistryPostProcessor`，`BeanDefinitionRegistryPostProcessor`是Spring留的扩展点，可以往Spring中注册自定义的bean。\n\n`MapperScannerConfigurer`中实现了`BeanDefinitionRegistryPostProcessor`的`postProcessBeanDefinitionRegistry()`方法，mapper的注册就是在该方法中注册的\n```java\n  public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) {\n    // ...省略\n    \n    // 实例化ClassPathMapperScanner，并对scanner相关属性进行配置\n    ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry);\n    scanner.setAddToConfig(this.addToConfig);\n    scanner.setAnnotationClass(this.annotationClass);\n    scanner.setMarkerInterface(this.markerInterface);\n    scanner.setSqlSessionFactory(this.sqlSessionFactory);\n    scanner.setSqlSessionTemplate(this.sqlSessionTemplate);\n    scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName);\n    scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName);\n    scanner.setResourceLoader(this.applicationContext);\n    scanner.setBeanNameGenerator(this.nameGenerator);\n    scanner.setMapperFactoryBeanClass(this.mapperFactoryBeanClass);\n    if (StringUtils.hasText(lazyInitialization)) {\n      scanner.setLazyInitialization(Boolean.valueOf(lazyInitialization));\n    }\n    if (StringUtils.hasText(defaultScope)) {\n      scanner.setDefaultScope(defaultScope);\n    }\n    // 注册扫描规则\n    scanner.registerFilters();\n    // 扫描并注册所有的mapper\n    scanner.scan(\n        StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));\n  }\n```\n`postProcessBeanDefinitionRegistry()`的主要逻辑是定义一个`ClassPathMapperScanner`对象，然后调用`registerFilters()`注册扫描规则,最后调用`scan()`方法。  \n\n在xml中定义`MapperScannerConfigurer`bean时可以设置一个`annotationClass`属性，值是一个注解类，调用`registerFilters()`时，`registerFilters()`会添加一个只扫描设置有`annotationClass`注解的类，这里没有设置，会扫描所有的接口。SpringBoot集成mybatis时会用到这个字段\n\n看一下`ClassPathMapperScanner`类的定义\n```java\npublic class ClassPathMapperScanner extends ClassPathBeanDefinitionScanner {\n    // ...省略\n}\n```\n`ClassPathMapperScanner`继承了`ClassPathBeanDefinitionScanner`，`ClassPathBeanDefinitionScanner`是Spring中定义的，是一个从指定包内扫描所有bean定义的Spring工具。 \n\n看一下`ClassPathMapperScanner`的`scan()`方法\n```java\n  public Set<BeanDefinitionHolder> doScan(String... basePackages) {\n    Set<BeanDefinitionHolder> beanDefinitions = super.doScan(basePackages);\n\n    if (beanDefinitions.isEmpty()) {\n        // ...省略\n    } else {\n      processBeanDefinitions(beanDefinitions);\n    }\n\n    return beanDefinitions;\n  }\n```\n通过`super.doScan(basePackages)`已经扫描到了所有的mapper，继续`processBeanDefinitions()`方法\n```java\n  private void processBeanDefinitions(Set<BeanDefinitionHolder> beanDefinitions) {\n    AbstractBeanDefinition definition;\n    BeanDefinitionRegistry registry = getRegistry();\n    // 遍历扫描到的所有bean\n    for (BeanDefinitionHolder holder : beanDefinitions) {\n      definition = (AbstractBeanDefinition) holder.getBeanDefinition();\n      boolean scopedProxy = false;\n      if (ScopedProxyFactoryBean.class.getName().equals(definition.getBeanClassName())) {\n        definition = (AbstractBeanDefinition) Optional\n            .ofNullable(((RootBeanDefinition) definition).getDecoratedDefinition())\n            .map(BeanDefinitionHolder::getBeanDefinition).orElseThrow(() -> new IllegalStateException(\n                \"The target bean definition of scoped proxy bean not found. Root bean definition[\" + holder + \"]\"));\n        scopedProxy = true;\n      }\n      String beanClassName = definition.getBeanClassName();\n      LOGGER.debug(() -> \"Creating MapperFactoryBean with name '\" + holder.getBeanName() + \"' and '\" + beanClassName\n          + \"' mapperInterface\");\n\n \n      // 增加一个构造方法，接口类型作为构造函数的入参\n      definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); \n\n      // 将bean的类型转换成mapperFactoryBean\n      definition.setBeanClass(this.mapperFactoryBeanClass);\n\n      // 增加addToConfig属性\n      definition.getPropertyValues().add(\"addToConfig\", this.addToConfig);\n\n  \n      definition.setAttribute(FACTORY_BEAN_OBJECT_TYPE, beanClassName);\n\n      boolean explicitFactoryUsed = false;\n      // 增加sqlSessionFactory属性\n      if (StringUtils.hasText(this.sqlSessionFactoryBeanName)) {\n        definition.getPropertyValues().add(\"sqlSessionFactory\",\n            new RuntimeBeanReference(this.sqlSessionFactoryBeanName));\n        explicitFactoryUsed = true;\n      } else if (this.sqlSessionFactory != null) {\n        definition.getPropertyValues().add(\"sqlSessionFactory\", this.sqlSessionFactory);\n        explicitFactoryUsed = true;\n      }\n\n      // 增加sqlSessionTemplate属性\n      if (StringUtils.hasText(this.sqlSessionTemplateBeanName)) {\n        if (explicitFactoryUsed) {\n          LOGGER.warn(\n              () -> \"Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.\");\n        }\n        definition.getPropertyValues().add(\"sqlSessionTemplate\",\n            new RuntimeBeanReference(this.sqlSessionTemplateBeanName));\n        explicitFactoryUsed = true;\n      } else if (this.sqlSessionTemplate != null) {\n        if (explicitFactoryUsed) {\n          LOGGER.warn(\n              () -> \"Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.\");\n        }\n        definition.getPropertyValues().add(\"sqlSessionTemplate\", this.sqlSessionTemplate);\n        explicitFactoryUsed = true;\n      }\n\n      if (!explicitFactoryUsed) {\n        LOGGER.debug(() -> \"Enabling autowire by type for MapperFactoryBean with name '\" + holder.getBeanName() + \"'.\");\n        definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n      }\n\n      definition.setLazyInit(lazyInitialization);\n\n      if (scopedProxy) {\n        continue;\n      }\n\n      if (ConfigurableBeanFactory.SCOPE_SINGLETON.equals(definition.getScope()) && defaultScope != null) {\n        definition.setScope(defaultScope);\n      }\n\n      if (!definition.isSingleton()) {\n        BeanDefinitionHolder proxyHolder = ScopedProxyUtils.createScopedProxy(holder, registry, true);\n        if (registry.containsBeanDefinition(proxyHolder.getBeanName())) {\n          registry.removeBeanDefinition(proxyHolder.getBeanName());\n        }\n        registry.registerBeanDefinition(proxyHolder.getBeanName(), proxyHolder.getBeanDefinition());\n      }\n\n    }\n  }\n\n```\n这个方法比较长，但是并不复杂，主要逻辑为将扫描的bean的类型修改成`MapperFactoryBean`类型，并增加一个将接口类型作为入参的构造函数，也就是说Spring获取mapper时都是通过FactoryBean生成的。最后通过调用`egistry.registerBeanDefinition()` 方法注册到Spring中。  \n\n看一下mybatis提供的`MapperFactoryBean`的定义\n```java\npublic class MapperFactoryBean<T> extends SqlSessionDaoSupport implements FactoryBean<T> {\n}\n```\n`MapperFactoryBean`实现了`FactoryBean`，`FactoryBean`是一个Spring提供的一个能生产对象的工厂Bean  \n\n`MapperFactoryBean`同时继承了`SqlSessionDaoSupport`，`SqlSessionDaoSupport`继承了`DaoSupport`，`DaoSupport`实现了`InitializingBean`。`InitializingBean`的作用是在Spring初始化bean对象时会首先调用`InitializingBean`的`afterPropertiesSet()`方法。  \n\n`DaoSupport`的`afterPropertiesSet()`中调用了`checkDaoConfig()`方法。\n```java\n    public final void afterPropertiesSet() throws IllegalArgumentException, BeanInitializationException {\n        this.checkDaoConfig();\n\n        try {\n            this.initDao();\n        } catch (Exception var2) {\n            throw new BeanInitializationException(\"Initialization of DAO failed\", var2);\n        }\n    }\n```\n具体`checkDaoConfig()`方法的实现逻辑在`MapperFactoryBean` 中\n```java\n protected void checkDaoConfig() {\n    super.checkDaoConfig();\n\n    notNull(this.mapperInterface, \"Property 'mapperInterface' is required\");\n\n    Configuration configuration = getSqlSession().getConfiguration();\n    if (this.addToConfig && !configuration.hasMapper(this.mapperInterface)) {\n      try {\n        configuration.addMapper(this.mapperInterface);\n      } catch (Exception e) {\n        // ..省略\n      } finally {\n        ErrorContext.instance().reset();\n      }\n    }\n  }\n```\nOK，到这又回到mybatis了。在前面中说了`configuration.addMapper()`方法只是生成了对应的代理工厂。  \n\n以上整个过程，即把mapper注册为Spring的bean，又将mapper设置到mybatis中的`configuration`中，所以，在使用时既可以使用Spring自动注入那一套，又可以使用mybatis中通过`sqlSession`来获取mapper的代理对象\n#### Spring生成代理对象\nSpring中所有的mapper对应的bean是mapper对应的`MapperFactoryBean`，那么在获取mapper bean时是通过`MapperFactoryBean`的`getObject()`方法生成的\n```java\n  public T getObject() throws Exception {\n    return getSqlSession().getMapper(this.mapperInterface);\n  }\n```\n`MapperFactoryBean`先获取到`sqlsession`，再通过`getMapper()`获取到的代理对象。到这里就回到了mybatis生成代理对象的过程了。\n\n\n### 与SpringBoot集成时mapper代理的生成过程\nmybatis与Spring集成时需要用到`mybatis-spring-boot-starter`的jar，`mybatis-spring-boot-starter`依赖`mybatis-spring-boot-autoconfigure`这个jar，而`mybatis-spring-boot-autoconfigure`这个jar又依赖`mybatis-spring`这个jar，所以最终其实还是mybatis集成Spring那一套  \n\n根据SpringBoot自动加载的原理直接看`mybatis-spring-boot-autoconfigure`jar下`META-INF/spring.factories`文件\n```\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\norg.mybatis.spring.boot.autoconfigure.MybatisLanguageDriverAutoConfiguration,\\\norg.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration\n```\nSpringBoot会自动加载`MybatisAutoConfiguration`这个类，直接看这个类，`MybatisAutoConfiguration`定义了mybtis所需的各个bean。\n```java\n\n    //生成SqlSessionFactory\n    @Bean\n    @ConditionalOnMissingBean\n    public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception {\n        // ...省略\n    }\n    \n    //生成SqlSessionTemplate\n    @Bean\n    @ConditionalOnMissingBean\n    public SqlSessionTemplate sqlSessionTemplate(SqlSessionFactory sqlSessionFactory) {\n     // ...省略\n    }\n    \n    //扫描mapper\n     @Configuration\n    @Import({MybatisAutoConfiguration.AutoConfiguredMapperScannerRegistrar.class})\n    @ConditionalOnMissingBean({MapperFactoryBean.class, MapperScannerConfigurer.class})\n    public static class MapperScannerRegistrarNotFoundConfiguration implements InitializingBean {\n        public MapperScannerRegistrarNotFoundConfiguration() {\n        }\n\n        public void afterPropertiesSet() {\n            MybatisAutoConfiguration.logger.debug(\"Not found configuration for registering mapper bean using @MapperScan, MapperFactoryBean and MapperScannerConfigurer.\");\n        }\n    }\n     //扫描mapper\n     public static class AutoConfiguredMapperScannerRegistrar implements BeanFactoryAware, ImportBeanDefinitionRegistrar {\n        private BeanFactory beanFactory;\n\n        public AutoConfiguredMapperScannerRegistrar() {\n        }\n\n        public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {\n            if (!AutoConfigurationPackages.has(this.beanFactory)) {\n                MybatisAutoConfiguration.logger.debug(\"Could not determine auto-configuration package, automatic mapper scanning disabled.\");\n            } else {\n                MybatisAutoConfiguration.logger.debug(\"Searching for mappers annotated with @Mapper\");\n                List<String> packages = AutoConfigurationPackages.get(this.beanFactory);\n                if (MybatisAutoConfiguration.logger.isDebugEnabled()) {\n                    packages.forEach((pkg) -> {\n                        MybatisAutoConfiguration.logger.debug(\"Using auto-configuration base package '{}'\", pkg);\n                    });\n                }\n                //生成MapperScannerConfigurer \n                BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(MapperScannerConfigurer.class);\n                builder.addPropertyValue(\"processPropertyPlaceHolders\", true);\n                // 注册扫描规则\n                builder.addPropertyValue(\"annotationClass\", Mapper.class);\n                builder.addPropertyValue(\"basePackage\", StringUtils.collectionToCommaDelimitedString(packages));\n                BeanWrapper beanWrapper = new BeanWrapperImpl(MapperScannerConfigurer.class);\n                Stream.of(beanWrapper.getPropertyDescriptors()).filter((x) -> {\n                    return x.getName().equals(\"lazyInitialization\");\n                }).findAny().ifPresent((x) -> {\n                    builder.addPropertyValue(\"lazyInitialization\", \"${mybatis.lazy-initialization:false}\");\n                });\n                registry.registerBeanDefinition(MapperScannerConfigurer.class.getName(), builder.getBeanDefinition());\n            }\n        }\n\n        public void setBeanFactory(BeanFactory beanFactory) {\n            this.beanFactory = beanFactory;\n        }\n    }\n    \n```\n","tags":["Mybatis"],"categories":["JAVA"]},{"title":"Java SPI机制","url":"/2021/07/10/spi/","content":"少侠你现在是否还这样连接数据库\n\n```java\ntry {\n    Class.forName(\"com.mysql.jdbc.Driver\");\n    Connection connection = DriverManager.getConnection(\"URL\",\"root\",\"password\");\n} catch (Exception e) {\n    e.printStackTrace();\n}\n```\n\n少侠你知道`Class.forName()`这句早已经没用了么？Java 官方已经把它优化掉了。想知道怎么优化的么？不要急，且看我慢慢道来。\n\n## SPI\n\nSPI 全名：Service Provider Interface，是 JDK 内置的一种服务发现机制，可以将服务接口与服务发现分离以达到解耦的效果。可以提升程序的可扩展性。比如 jdbc 只提供了接口，具体的实现由各个运营商解决、经常用的 log 日志类`LogFactory`，还有阿里的 dubbo 更是将 SPI 运用的淋漓尽致。\n\nSPI 使用说明：\n\n- 在 resources 目录下新建 META-INF/services 目录，并在目录下创建一个文件，文件名字为`接口`的全限定名，文件内容为`实现类`的全限定名。\n- 通过`java.util.ServiceLoder`类加载实现类。\n- SPI 的实现类必须携带一个不带参数的构造方法。\n\n来个示例\n\n首先定义一个接口\n\n```java\npublic interface Pay {\n    void pay();\n}\n```\n\n再来两个实现类\n\n```java\npublic class AliPay implements Pay {\n    @Override\n    public void pay() {\n        System.out.println(\"AliPay\");\n    }\n}\n```\n\n```java\npublic class WeChatPay implements Pay {\n    @Override\n    public void pay() {\n        System.out.println(\"WeChatPay\");\n    }\n}\n```\n\n在 resources 目录下新建 META-INF/services 目录，并在目录下创建一个文件，文件名为接口的权限定名`com.yao.spi.Pay`，文件内容为实现类的全限定名\n\n```java\ncom.yao.spi.AliPay\n```\n\n![](spi.png)\n\n通过`java.util.ServiceLoder`获取实现类。\n\n```java\npublic static void main(String[] args) {\n\n    ServiceLoader<Pay> spiDemoServiceLoader = ServiceLoader.load(Pay.class);\n\n    Iterator<Pay> payIterator = spiDemoServiceLoader.iterator();\n    while (payIterator.hasNext()){\n        Pay pay = payIterator.next();\n        pay.pay();\n    }\n}\n```\n\n看一下结果。\n\n```java\nAliPay\n```\n\n有没有注意到`ServiceLoder`获取到的是一个列表？这说明什么问题？对的，可以一次初始化多个实现类，只要在文件中声明就可以了。现在再把`WechatPay`给添加上\n\n```java\ncom.yao.spi.AliPay\ncom.yao.spi.WeChatPay\n```\n\n看一下运行结果\n\n```java\nAliPay\nWeChatPay\n```\n\n## 源码解析\n\nSPI 的功能比较简单，一个`ServiceLoader`类包含所有的功能。先来看一下有那些主要的属性和内部类的主要属性。\n\n```java\npublic final class ServiceLoader<S> implements Iterable<S> {\n    //配置文件的路径\n    private static final String PREFIX = \"META-INF/services/\";\n    //加载的类或接口\n    private final Class<S> service;\n    //类加载器\n    private final ClassLoader loader;\n    //已加载的服务类\n    private LinkedHashMap<String, S> providers = new LinkedHashMap();\n    //内部类，真正加载类的地方\n    private ServiceLoader<S>.LazyIterator lookupIterator;\n    //内部类\n    private class LazyIterator implements Iterator<S> {\n        //加载的类或接口\n        Class<S> service;\n        //类加载器\n        ClassLoader loader;\n        //保存配置文件中的信息\n        Enumeration<URL> configs;\n        //保存配置文件中所有的实现类的全限定名\n        Iterator<String> pending;\n        String nextName;\n        }\n}\n```\n\n当看到内部类`LazyIterator`这个`Lazy`时，会不会联想到 spring 加载 bean 时的懒加载。这里其实也是一样，当调用`load`方法时，并不会加载类，只初始化一些内部属性。真正加载实现类是在获取实现类时。\n![](source.png)\n\n沿着上面`main`方法第一次获取实现类的过程一步一步解析，第一次以后获取的过程有兴趣的少侠可以自己走一遍。\n\n### 注册实现类\n\n`spiDemoServiceLoader.iterator();`获取的迭代器是`ServiceLoader`重写的迭代器，迭代器中的方法都指向了内部类`LazyIterator`\n\n```java\n public Iterator<S> iterator() {\n        return new Iterator<S>() {\n            Iterator<Entry<String, S>> knownProviders;\n\n            {\n                this.knownProviders = ServiceLoader.this.providers.entrySet().iterator();\n            }\n\n            public boolean hasNext() {\n                return this.knownProviders.hasNext() ? true : ServiceLoader.this.lookupIterator.hasNext();\n            }\n\n            public S next() {\n                return this.knownProviders.hasNext() ? ((Entry)this.knownProviders.next()).getValue() : ServiceLoader.this.lookupIterator.next();\n            }\n\n            public void remove() {\n                throw new UnsupportedOperationException();\n            }\n        };\n    }\n```\n\n当调用`payIterator.hasNext()`时，调用的是重写迭代器中的\n\n```java\n  public boolean hasNext() {\n      return this.knownProviders.hasNext() ? true : ServiceLoader.this.lookupIterator.hasNext();\n  }\n```\n\n然后会调用内部类`LazyIterator`中的`hasNext()`方法\n\n```java\n public boolean hasNext() {\n      if (ServiceLoader.this.acc == null) {\n          return this.hasNextService();\n      } else {\n          //省略\n      }\n  }\n```\n\n接着调用调用内部类`LazyIterator`中的`hasNextService()`方法\n\n```java\n private boolean hasNextService() {\n      if (this.nextName != null) {\n          return true;\n      } else {\n          if (this.configs == null) {\n              try \n                  ////文件路径\n                  String var1 = \"META-INF/services/\" + this.service.getName();\n                  //读取配置文件，并将配置文件内容保存到configs\n                  if (this.loader == null) {\n                      this.configs = ClassLoader.getSystemResources(var1);\n                  } else {\n                      this.configs = this.loader.getResources(var1);\n                  }\n              } catch (IOException var2) {\n                    //省略\n              }\n          }\n\n          while(this.pending == null || !this.pending.hasNext()) {\n            if (!this.configs.hasMoreElements()) {\n                  return false;\n                }\n              //将文件中的实现类权限定名保存到pending中\n              this.pending = ServiceLoader.this.parse(this.service, (URL)this.configs.nextElement());\n              }\n\n          this.nextName = (String)this.pending.next();\n          return true;\n          }\n        }\n```\n\n第一次到这里时，会将配置文件的信息保存到到内部类中的'configs'属性中，并解析文件将配置的所有实现类保存到内部类中的`pending`中，但是这里还是没有未初始化类。\n\n### 获取实现类\n\n当调用`payIterator.next();`时，调用的是重写的\n\n```java\npublic S next() {\n    return this.knownProviders.hasNext() ? ((Entry)this.knownProviders.next()).getValue() : ServiceLoader.this.lookupIterator.next();\n}\n```\n\n并最终调用到内部类`LazyIterator`中的`next()`方法\n\n```java\npublic S next() {\n    if (ServiceLoader.this.acc == null) {\n         return this.nextService();\n    } else {\n        PrivilegedAction var1 = new PrivilegedAction<S>() {\n            public S run() {\n                return LazyIterator.this.nextService();\n            }\n        };\n        return AccessController.doPrivileged(var1, ServiceLoader.this.acc);\n    }\n}\n```\n\n然后调用内部类`LazyIterator`中的`nextService()`方法\n\n```java\nprivate S nextService() {\n    if (!this.hasNextService()) {\n        throw new NoSuchElementException();\n    } else {\n        String var1 = this.nextName;\n        this.nextName = null;\n        Class var2 = null;\n\n        try {\n\t         //初始化实现类\n            var2 = Class.forName(var1, false, this.loader);\n        } catch (ClassNotFoundException var5) {\n         \n        }\n\n        //忽略掉后面的代码\n    }\n}\n```\n\n看到`Class.forName()`，到此才是初始化实现类。\n\n## JDBC 中的运用\n回到最初的话题，既然`Class.forName()`没有用了，那JDBC在那优化的呢？首先要知道`Class.forName()`的作用：强制JVM将com.mysql.jdbc.Driver这个类加载入内存，以便`DriverManager`类使用，现在既然用不到了，那肯定是在别的地方加载了。那用什么方式加载的？当然是SPI了，要不然前面一大堆东西不是白说了么，哈哈哈哈！看看mysql的jar里\n![MySQL](jdbc.png)\n是不是很熟悉，这不就是SPI规范么。\n\nOK，来看看加载的过程。\n既然只需要这一句就可以了\n```java\nConnection connection = DriverManager.getConnection(\"URL\",\"root\",\"password\");\n```\n### 加载\n那就从`DriverManager`类开始，类加载当然要从静态代码块开始了，看一下`DriverManager`的静态代码块。\n```java\n    static {\n        loadInitialDrivers();\n        println(\"JDBC DriverManager initialized\");\n        SET_LOG_PERMISSION = new SQLPermission(\"setLog\");\n        DEREGISTER_DRIVER_PERMISSION = new SQLPermission(\"deregisterDriver\");\n    }\n```\n进`loadInitialDrivers()`方法\n![](jdbc2.png)\n熟不熟悉？是不是SPI机制？`DriverManager`在初始化类时，会先利用SPI机制加载数据库的驱动。那又是怎么注册到`DriverManager`的呢？继续看！\n### 加载\n在上面SPI机制中说了，当调用`next()`方法时会初始化实现类，也就是会初始化`Driver`类，那就再看`Driver`类。\n```java\npublic class Driver extends NonRegisteringDriver implements java.sql.Driver {\n    static {\n        try {\n            java.sql.DriverManager.registerDriver(new Driver());\n        } catch (SQLException E) {\n            throw new RuntimeException(\"Can't register driver!\");\n        }\n    }\n    public Driver() throws SQLException {\n        // Required for Class.forName().newInstance()\n    }\n}\n```\n静态代码块中`DriverManager.registerDriver(new Driver());`就是将`Driver`注册到`DriverManager`。  \n总结一下加载过程：\n1. DriverManager在静态代码块中利用SPI机制获取到数据库驱动，并初始化Driver\n2. Driver初始化时首先运行静态代码块将Driver注册到DriverManager\n\n\n\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"Mysql优化工具explain","url":"/2021/06/26/explain/","content":" \nexplain的使用很简单，只要在select语句的前面加上`explain`的关键字就好了，来看个例子\n\n先创建两个表，注意两个表的索引\n```sql\nCREATE TABLE `user` (\n  `id` varchar(32) NOT NULL,\n  `name` varchar(32) DEFAULT NULL,\n  `role` varchar(32) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\nINSERT INTO `user` VALUES ('1', '1', '1');\nINSERT INTO `user` VALUES ('10', '10', '5');\nINSERT INTO `user` VALUES ('2', '2', '2');\nINSERT INTO `user` VALUES ('3', '3', '3');\nINSERT INTO `user` VALUES ('4', '4', '4');\nINSERT INTO `user` VALUES ('5', '5', '5');\nINSERT INTO `user` VALUES ('6', '6', '1');\nINSERT INTO `user` VALUES ('7', '7', '2');\nINSERT INTO `user` VALUES ('8', '8', '3');\nINSERT INTO `user` VALUES ('9', '9', '4');\n\nCREATE TABLE `role` (\n  `id` varchar(32) NOT NULL,\n  `name` varchar(32) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `name` (`name`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\nINSERT INTO `role` VALUES ('1', '1');\nINSERT INTO `role` VALUES ('6', '1');\nINSERT INTO `role` VALUES ('2', '2');\nINSERT INTO `role` VALUES ('3', '3');\nINSERT INTO `role` VALUES ('4', '4');\nINSERT INTO `role` VALUES ('5', '5');\n```\n\n试一下`explain`\n\n```sql\n EXPLAIN SELECT * FROM `user` WHERE id = '1'\n```\n来看输出结果,表格太长了，就不以表格的形式显示结果了\n```\n             id: 1\n   select_type : SIMPLE\n          table: user\n           type: const\n  possible_keys: PRIMARY\n            key: PRIMARY\n        ken_len: 98\n            ref: const\n           rows: 1\n          Extra: NULL\n```\n\n来看看各个字段的含义：\n+ id: select查询的序号。\n+ select_type: 查询的类型\n+ table：查询涉及的表\n+ partitions: 匹配的分区\n+ type：表的连接类型\n+ possible_keys：可能应用到的索引\n+ key：实际被使用的索引列\n+ ken_len： 索引中使用的字节数\n+ ref： 关联的字段\n+ rows: 此查询一共扫描了多少行\n+ filtered: 表示此查询条件所过滤的数据的百分比\n+ extra：执行情况的额外的说明\n\n有两个字段（partitions，filtered）没有在查询的结果中出现，一般也不需要关注这两个字段，同时所有的字段并不是全部是重要的，这里来详细了解下各个字段。\n\n## id\nid的值说明了sql执行的先后顺序，可能出现三种情况：\n### id相同\nid相同时，执行的顺序是自上到下依次运行\n### id不同\n比如使用子查询的情况下，会出现id的值递增的情况。id的值越大执行的优先级越高。\n### id不同和相同的同时存在\n可以把相同的理解为一组，相同一组的执行顺序自上到下依次运行，不同组的id的值越大，执行的优先级越高。\n## select_type\n  select_type的值主要有以下几种：\n### SIMPLE\n简单的`select`,不使用UNION或子查询  \n\n例子\n```sql\nEXPLAIN SELECT * FROM `user` WHERE id = '1'\n```\n### PRIMARY\n最外层查询的`select`查询  \n\n例子\n```sql\nEXPLAIN SELECT * FROM `user`\nWHERE role = (\n  SELECT id FROM role\n  WHERE `name` = '1'\n  )\n```\n其中`user`表的类型是`PRIMARY`\n![](primary.png)\n\n\n### UNION\n`UNION`查询中的第二个语句或后面的语句  \n\n例如\n```sql\nEXPLAIN SELECT * FROM `user` WHERE id = '1'\n         UNION\n         SELECT * FROM `user` WHERE id = '2'\n```\n![](union.png)\n\n### DEPENDENT UNION\nUNION查询中的第二个或后面的查询语句, 取决于外面的查询， 即子查询依赖于外层查询的结果.\n### UNION RESULT  \nUNION查询的结果  \n\n例如\n```sql\nEXPLAIN SELECT * FROM `user` WHERE id = '1'\n         UNION\n         SELECT * FROM `user` WHERE id = '2'\n```\n![](result.png)\n\n### SUBQUERY\n子查询中的第一个`select`  \n\n例如\n```sql\nEXPLAIN SELECT * FROM `user`\nWHERE role = (\n  SELECT id FROM role\n  WHERE `name` = '1'\n  )\n```\n![](subquery.png)\n\n### DEPENDENT SUBQUERY\n子查询中的第一个`select`,取决于外面的查询。\n\n\n## table\n`table`表示该次查询涉及到的表名或表的别名。\n\n\n## type\n`type`是一个非常重要的一个字段。根据`type`字段可以判断查询是否性能高效。\n\n常用的类型有：\n### system\n表示结果集仅有一行，这是`const`类型的一个特例，一般是在`myisam`或`memory`存储引擎中，在`innodb`存储引擎中为`const`\n### const\n表示通过主键或者唯一索引查找数据时只匹配了一行数据，`const`说明查询速度非常快。  \n\n例子\n```sql\nEXPLAIN SELECT * FROM `user` WHERE id = '1'\n```\n### eq_ref\n多出现在联接查询，表示索引是主键或唯一非 NULL 索引时，对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =, 查询效率较高,这是最好的联接类型。  \n\n例子\n```sql\nEXPLAIN SELECT * FROM `user`,role\n         WHERE `user`.id = role.`id`\n```\n说明：\n`user.id`是唯一索引, 每条`user.id`可以联接`role`中的一条数据。\n### ref\n通常出现在多表的联接查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询.  \n\n例子：\n```sql\nEXPLAIN SELECT * FROM `user`,role\n         WHERE `user`.`name` = role.name\n```\n说明：`role.name`是索引，但并不是唯一索引和主键索引\n### range\n表示使用索引范围查询,这个类型通常出现在 =, <>, >, >=, <, <=, IS NULL, <=>, BETWEEN, IN() 操作中。\n\n例子\n```sql\nEXPLAIN SELECT * FROM `user`\n        WHERE id IN ('1','2','3')\n```\n### index\n表示全索引扫描，扫描所有的索引  \n\n例子\n```sql\nEXPLAIN SELECT id,`name` FROM `role` \n```\n### ALL\n表示全表扫描，这是最坏的结果。\n\n最好的结果到最差的结果：system > const > eq_ref > ref > range > index > ALL，一般来说，得保证查询至少达到range级别，最好能达到ref。\n## possible_keys\n可能用到的索引。注意：只是可能。即使有些索引在这个字段中出现。也不一定会被真正用到。\n\n\n## key\n实际被用到的索引列。注意和`possible_keys`做区分\n\n\n## ken_len\n表示索引中使用的字节数，key_len显示的值为索引字段的最大可能长度，并非实际使用长度。这个当然越短越好。\n\n\n## ref\n表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值\n\n\n## rows\n`rows`这个也是非常重要的一个字段,估算要扫描的行数，原则上越少越好。注意：这个值并不是完全准确的值，只是估算。\n\n\n## Extra\n`Extra`提供了多个值，这只说几个比较常见的，有兴趣的少侠可以自行百度，谷歌。\n### Using temporary\n查询时需要用额外的临时表来存储结果集，比较常见在`group by`,`order by`中。\n### Using filesort\n当包含`order by`操作，而且无法利用索引完成的排序操作称为“文件排序”，建议优化。\n### Using join buffer\n在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。\n### Using index\n\"覆盖索引\",表示查询的数据在索引中就可以找到，说明性能不错。\n    \n## 注意\n1. `explain`只能解释`select`\n2. `explain`不计算各种Cache\n3.  部分信息只是估算。","tags":["MySql"],"categories":["MySql"]},{"title":"Java动态代理","url":"/2021/05/15/java-proxy/","content":"JDK动态代理使用的非常广泛，Spring AOP中、MyBatis的mapper中都用到了JDK动态代理。\n\n## JDK动态代理的使用\n1、创建代理类接口及代理类。  \n2、创建一个实现了InvocationHandler接口的类，实现该接口中的invoke方法。  \n3、通过Proxy的newProxyInstance(ClassLoaderloader, Class[] interfaces, InvocationHandler h)方法创建一个代理对象。  \n来个例子：  \n创建一个Hello的接口\n```java\npublic interface Hello {\n\n    void sayHello();\n}\n```\n创建一个实现了Hello接口的实现类。\n```java\npublic class HelloImpl implements Hello {\n\n    public void sayHello() {\n        System.out.println(\"hello\");\n    }\n}\n```\n创建一个实现了InvocationHandler接口的类。\n```java\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\n\npublic class HelloInvocationHandler implements InvocationHandler {\n\n    private Object hello;\n\n    public HelloInvocationHandler(Object hello) {\n        this.hello = hello;\n    }\n\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        System.out.println(\"start\");\n        Object invoke = method.invoke(hello, args);\n        System.out.println(\"end\");\n        return invoke;\n    }\n}\n```\n通过Proxy创建一个代理对象\n```java\nHello hello = new HelloImpl();\nHelloInvocationHandler helloInvocationHandler = new HelloInvocationHandler(hello);\nClassLoader classLoader = hello.getClass().getClassLoader();\nClass<?>[] interfaces = hello.getClass().getInterfaces();\nHello helloProxy = (Hello)Proxy.newProxyInstance(classLoader, interfaces, helloInvocationHandler);\nhelloProxy.sayHello();\n```\n看一看输出结果\n```\nstart\nhello\nend\n```\n\n\n## 源码\n看一下Proxy的newProxyInstance方法\n```java\npublic static Object newProxyInstance(ClassLoader loader,\n                                          Class<?>[] interfaces,\n                                          InvocationHandler h)\n        throws IllegalArgumentException\n    {\n\n\n\t//省略\n\n        /*\n         * 生成代理类    \n         */\n        Class<?> cl = getProxyClass0(loader, intfs);\n\n        /*\n         * Invoke its constructor with the designated invocation handler.\n         */\n        try {\n\t    //省略\n            \n\t    //获取代理类的构造函数\n            final Constructor<?> cons = cl.getConstructor(constructorParams);\n            final InvocationHandler ih = h;\n            if (!Modifier.isPublic(cl.getModifiers())) {\n                AccessController.doPrivileged(new PrivilegedAction<Void>() {\n                    public Void run() {\n                        cons.setAccessible(true);\n                        return null;\n                    }\n                });\n            }\n            // 通过构造函数，将InvocationHandler设置到代理对象中，并创建代理对象\n            return cons.newInstance(new Object[]{h});\n        } catch (IllegalAccessException|InstantiationException e) {\n            throw new InternalError(e.toString(), e);\n        } catch (InvocationTargetException e) {\n            Throwable t = e.getCause();\n            if (t instanceof RuntimeException) {\n                throw (RuntimeException) t;\n            } else {\n                throw new InternalError(t.toString(), t);\n            }\n        } catch (NoSuchMethodException e) {\n            throw new InternalError(e.toString(), e);\n        }\n    }\n\n```\n这段代码的主要功能功能是生成代理类,通过代理类的构造函数创建了一个代理对象，代理类是怎么生成的，继续看`getProxyClass0`方法\n```java\n private static Class<?> getProxyClass0(ClassLoader loader,\n                                           Class<?>... interfaces) {\n        if (interfaces.length > 65535) {\n            throw new IllegalArgumentException(\"interface limit exceeded\");\n        }\n\n        return proxyClassCache.get(loader, interfaces);\n    }\n\n```\n`getProxyClass0`首先判断了接口的数量，然后通过`proxyClassCache`获取到了代理类，`proxyClassCache`是什么东西？看一下`proxyClassCache`的定义\n```java\nprivate static final WeakCache<ClassLoader, Class<?>[], Class<?>>\n        proxyClassCache = new WeakCache<>(new KeyFactory(), new ProxyClassFactory());\n```\n通过定义可以发现，`proxyClassCache`其实是一个缓存类，生成的类是放在缓存里的。接着看一个这个类的构造函数\n```java\n public WeakCache(BiFunction<K, P, ?> subKeyFactory,\n                     BiFunction<K, P, V> valueFactory) {\n        this.subKeyFactory = Objects.requireNonNull(subKeyFactory);\n        this.valueFactory = Objects.requireNonNull(valueFactory);\n    }\n```\n可以看到`subKeyFactory`其实是`KeyFactory`，`valueFactory`其实是`ProxyClassFactory`\n\n好了，现在回到`getProxyClass0`的方法中，上面分析了`proxyClassCache`了，那继续看它的`get`方法\n```java\npublic V get(K key, P parameter) { // key 是ClassLoader parameter是interfaces\n    //省略\n\n    //根据ClassLoader获取cachekey\n    Object cacheKey = CacheKey.valueOf(key, refQueue);\n\n    ConcurrentMap<Object, Supplier<V>> valuesMap = map.get(cacheKey);\n    if (valuesMap == null) {\n        ConcurrentMap<Object, Supplier<V>> oldValuesMap\n            = map.putIfAbsent(cacheKey,\n                              valuesMap = new ConcurrentHashMap<>());\n        if (oldValuesMap != null) {\n            valuesMap = oldValuesMap;\n        }\n    }\n\n    // 根据key 和 interfaces生成subkey\n    Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter));\n    Supplier<V> supplier = valuesMap.get(subKey);\n    Factory factory = null;\n\n    while (true) {\n        if (supplier != null) {\n            V value = supplier.get();\n            if (value != null) {\n                return value;\n            }\n        }\n\n        if (factory == null) {\n            factory = new Factory(key, parameter, subKey, valuesMap);\n        }\n\n        if (supplier == null) {\n            supplier = valuesMap.putIfAbsent(subKey, factory);\n            if (supplier == null) {\n                supplier = factory;\n            }\n        } else {\n            if (valuesMap.replace(subKey, supplier, factory)) {\n                supplier = factory;\n            } else {\n                supplier = valuesMap.get(subKey);\n            }\n        }\n    }\n}\n```\n这段代码看着比较绕，我们知道这个方法的作用主要是生成代理类的，那`retrun value`返回的肯定是代理类，那么不妨反着推一下：  \n`value` 是`supplier.get()`获取的;  \n`supplier`其实是`Factory`;  \n`Factory`是由`key`、`paramter`、`subkey`、`valuesMap`生成的，`key`和`paramter`是方法入参`classloader`和`interfaces`;  \n`subkey` 是由`subKeyFactory`跟据`key`和`paramter`得到的，也就是根据`classloader`和`interfaces`得到的;  \n`vlauesMap`是由`map`根据`cacheKey`获取的，而`cacheKey`是由`key`得到的，也就是根据`classloader`得到的。  \n最后，根据反推的结果再来看一边代码就好理解了，这个方法其实就是根据`map`获取`supplier`，只是这个map的结构比较复杂，它是一个两层的map结构：第一层的key是根据`classloader`生成的一个`cacheKey`对象，第二层的key是`classloader`和`interfaces`生成的一个`subkey`对象。  \n\n接下来接着走到`supplier.get()`这，看看它是怎么生成代理对象的。`supplier`其实是`Factory`，那就直接看`Factory`的get方法\n```java\n @Override\n public synchronized V get() { // serialize access\n      Supplier<V> supplier = valuesMap.get(subKey);\n      if (supplier != this) {\n          return null;\n      }\n\n      V value = null;\n      try {\n          //获取代理类\n          value = Objects.requireNonNull(valueFactory.apply(key, parameter));\n      } finally {\n          if (value == null) { // remove us on failure\n              valuesMap.remove(subKey, this);\n          }\n      }\n      assert value != null;\n\n      CacheValue<V> cacheValue = new CacheValue<>(value);\n\n      reverseMap.put(cacheValue, Boolean.TRUE);\n\n      if (!valuesMap.replace(subKey, this, cacheValue)) {\n          throw new AssertionError(\"Should not reach here\");\n      }\n\n      return value;\n  }\n}\n```\n整个方法的关键点其实在`valueFactory.apply(key,paramter)`这，在前面分析中已经只知道了`valueFactory`其实是`ProxyClassFactory`，直接看`apply`方法\n```java\n@Override\npublic Class<?> apply(ClassLoader loader, Class<?>[] interfaces) {\n\n     //接口验证 省略\n\n\n    String proxyPkg = null;     // package to define proxy class in\n    int accessFlags = Modifier.PUBLIC | Modifier.FINAL;\n\n    //验证接口 省略\n\n    if (proxyPkg == null) {\n        // if no non-public proxy interfaces, use com.sun.proxy package\n        proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\";\n    }\n\n    //拼装生成的类名\n    long num = nextUniqueNumber.getAndIncrement();\n    String proxyName = proxyPkg + proxyClassNamePrefix + num;\n    \n   //获取类的字节数组\n    byte[] proxyClassFile = ProxyGenerator.generateProxyClass(\n            proxyName, interfaces, accessFlags);\n    try {\n        return defineClass0(loader, proxyName,\n                            proxyClassFile, 0, proxyClassFile.length);\n    } catch (ClassFormatError e) {\n            throw new IllegalArgumentException(e.toString());\n        }\n    }\n}\n```\n最后代理类是通过`ProxyGenerator`生成的，具体的生成细节不再分析了，这里涉及到了很多java类字节码的知识，在`ProxyGenerator`中也体现了很多字节码的东西，有兴趣的可以研究、谷歌。\n\n既然能够得到字节数组，那么就可以把它保存成class类，反编译看一下生成的代理类代码。\n```java\n //代理类类名\n String className = \"HelloProxy\";\n int accessFlags = Modifier.PUBLIC | Modifier.FINAL;\n //获取代理类字节数组 \n byte[] data = ProxyGenerator.generateProxyClass(className, new Class[]{Hello.class},accessFlags);\n FileOutputStream out;\n out = null;\n try {\n     //将代理类保存到文件\n     out = new FileOutputStream(className + \".class\");\n     System.out.println((new File(\"HelloProxy\")).getAbsolutePath());\n     out.write(data);\n } catch (FileNotFoundException e) {\n     e.printStackTrace();\n } catch (IOException e) {\n     e.printStackTrace();\n } finally {\n     if (null != out) {\n         try {\n             out.close();\n         } catch (IOException e) {\n             e.printStackTrace();\n         }\n     }\n }\n\n```\n反编译生成的代理类：\n```java\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\nimport java.lang.reflect.UndeclaredThrowableException;\n\npublic final class HelloProxy extends Proxy implements Hello {\n    private static Method m1;\n    private static Method m3;\n    private static Method m2;\n    private static Method m0;\n\n    public Hello(InvocationHandler var1) throws  {\n        super(var1);\n    }\n\n    public final boolean equals(Object var1) throws  {\n        try {\n            return (Boolean)super.h.invoke(this, m1, new Object[]{var1});\n        } catch (RuntimeException | Error var3) {\n            throw var3;\n        } catch (Throwable var4) {\n            throw new UndeclaredThrowableException(var4);\n        }\n    }\n\n    public final void sayHello() throws  {\n        try {\n            super.h.invoke(this, m3, (Object[])null);\n        } catch (RuntimeException | Error var2) {\n            throw var2;\n        } catch (Throwable var3) {\n            throw new UndeclaredThrowableException(var3);\n        }\n    }\n\n    public final String toString() throws  {\n        try {\n            return (String)super.h.invoke(this, m2, (Object[])null);\n        } catch (RuntimeException | Error var2) {\n            throw var2;\n        } catch (Throwable var3) {\n            throw new UndeclaredThrowableException(var3);\n        }\n    }\n\n    public final int hashCode() throws  {\n        try {\n            return (Integer)super.h.invoke(this, m0, (Object[])null);\n        } catch (RuntimeException | Error var2) {\n            throw var2;\n        } catch (Throwable var3) {\n            throw new UndeclaredThrowableException(var3);\n        }\n    }\n\n    static {\n        try {\n            m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\"));\n            m3 = Class.forName(\"Bolg.Hello\").getMethod(\"sayHello\");\n            m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\");\n            m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\");\n        } catch (NoSuchMethodException var2) {\n            throw new NoSuchMethodError(var2.getMessage());\n        } catch (ClassNotFoundException var3) {\n            throw new NoClassDefFoundError(var3.getMessage());\n        }\n    }\n}\n\n```\n代理类用的是反射的方式获取所有被代理对象的方法，在调用方法时其实调用的是从构造函数中传入的`InvocationHandler`的`invoke`方法，并传入被代理对象的方法。\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"Java内省","url":"/2021/04/15/introspector/","content":"内省(Introspector) 是Java 语言对 JavaBean 类属性、事件的一种缺省处理方法。说简单一点就是操作JavaBean的一套API。  \n\n什么是JavaBean？  \njavaBean只是一种规范，大家都按照约定好的一套规则写java类，既然是规范就有一定的要求：  \n+ 类是public的，然后有个无参的构造函数\n+ 属性是private的，通过设置setXXX()和getXXX()来访问\n+ 能支持事件，例如 addXXXXListener(XXXEvent e), 事件可以是 Click 事件，Keyboard 事件等等\n+ 提供应该 反射机制，这样可以查看java bean的各种信息\n+ 可以序列化，可以保存在硬盘上\n例如：\n```java\npublic class User {\n    private String name;\n\n    private String address;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public String getAddress() {\n        return address;\n    }\n\n    public void setAddress(String address) {\n        this.address = address;\n    }\n}\n\n```\n\n## JDK内省类库\n### PropertyDescriptor类:\n  PropertyDescriptor可以获取某一个具体的属性。主要的方法有： \n  +  getPropertyType()，获得属性的Class对象;\n  +  getReadMethod()，获得用于读取属性值的方法，例如getXXX()方法；\n  +  getWriteMethod()，获得用于写入属性值的方法，例如setXXX()方法;\n  +  hashCode()，获取对象的哈希值;\n  +  setReadMethod(Method readMethod)，设置用于读取属性值的方法;\n  +  setWriteMethod(Method writeMethod)，设置用于写入属性值的方法。\n 示例代码： \n```java\npublic class JavaBeanUtils {\n    public static void main(String[] args) throws IntrospectionException {\n        User user = new User();\n\n        PropertyDescriptor propertyDescriptor = new PropertyDescriptor(\"name\",user.getClass());\n        System.out.println(propertyDescriptor.getPropertyType());\n        Method  method = propertyDescriptor.getReadMethod();\n        System.out.println(method.getName());\n        method = propertyDescriptor.getWriteMethod();\n        System.out.println(method.getName());\n\n    }\n}\n\n```\n输入结果：  \n```\nclass java.lang.String\ngetName\nsetName\n```\n### Introspector类:\n  Introspector可以按照JavaBean的规范将一个类封装成BeanInfo对象。通过调用`getPropertyDescriptors()`方法会返回一个包含所有属性的`PropertyDescriptor`对象数组，通过`PropertyDescriptor`可以操作类的属性。  \n  具体代码如下：\n  ```java\n  public class JavaBeanUtils {\n    public static void main(String[] args) throws IntrospectionException {\n        BeanInfo beanInfo = Introspector.getBeanInfo(User.class);\n        PropertyDescriptor[] pd = beanInfo.getPropertyDescriptors();\n\n        //迭代每一个描述器\n        for (PropertyDescriptor propertyDescriptor : pd) {\n\n            System.out.println(\"属性名 :\"+propertyDescriptor.getName());\n            System.out.println(\"setter :\"+propertyDescriptor.getWriteMethod());\n            System.out.println(\"getter :\"+propertyDescriptor.getReadMethod());\n        }\n    }\n}\n  ```\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"ReentrantLock源码分析","url":"/2021/04/13/rl/","content":"ReentrantLock是一个可重入且独占式的锁，该锁支持获取锁时的公平和非公平选择。\n\n### 公平锁\n公平锁遵循FIFO的原则，所有的线程都会顺序执行\n#### 获取锁\n```java\n\n       //加锁\n    final void lock() {\n        acquire(1);\n    }\n\n   //调用AbstractQueuedSynchronizer\n    public final void acquire(int arg) {\n        if (!tryAcquire(arg) &&\n            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n            selfInterrupt();\n    }\n```\n是否是获得锁，还是进入队列等待的逻辑在`tryAcquire` 函数里。\n```java\n    protected final boolean tryAcquire(int acquires) {\n        //获取当前线程\n        final Thread current = Thread.currentThread();\n            \n        // 获取state值，state代表前线程获取锁的可重入次数\n        int c = getState();\n        /** 如果c为0，判断阻塞队列中是否还有线程，\n        *   如果不存在，设置state的值，并设置当前线程为独占锁的拥有者 \n        *   如果队列中还存在节点，则将该线程加入到队列中。\n        **/\n        if (c == 0) {\n            //判断队列中是否还存在线程\n            if (!hasQueuedPredecessors() &&\n            //设置state值\n                compareAndSetState(0, acquires)) {\n                // 设置当前线程为独占锁的拥有者 \n                setExclusiveOwnerThread(current);\n                //返回ture代表获取锁成功\n                return true;\n            }\n        }\n        /**\n        * 如果c不为0，判断独占锁的拥有者是否是当前线程，\n        * 如果是，则修改state值 \n        **/\n        else if (current == getExclusiveOwnerThread()) {\n            int nextc = c + acquires;\n            if (nextc < 0)\n                throw new Error(\"Maximum lock count exceeded\");\n            setState(nextc);\n            return true;\n        }\n        /**返回 false 代表获取锁失败，\n        * 则AbstractQueuedSynchronizer类的acquire函数继续往下进行，将该线程加入到队列中。\n        **/\n        return false;\n    }\n\n\n    public final boolean hasQueuedPredecessors() {\n        Node t = tail; \n        Node h = head;\n        Node s;\n        return h != t &&\n            ((s = h.next) == null || s.thread != Thread.currentThread());\n    }\n\n```\n#### 释放锁\n```java\n    public void unlock() {\n        sync.release(1);\n    }\n\n   //调用AbstractQueuedSynchronizer\n    public final boolean release(int arg) {\n        if (tryRelease(arg)) {\n            Node h = head;\n            if (h != null && h.waitStatus != 0)\n                unparkSuccessor(h);\n            return true;\n        }\n        return false;\n    }\n```\n具体的释放逻辑在`release`中，free代表该锁是否已完全释放锁，如果为true，AbstractQueuedSynchronizer继续执行`release`，唤醒队列中的下一个节点；\nfalse则该线程继续持有锁。\n```java\n    protected final boolean tryRelease(int releases) {\n        int c = getState() - releases;\n        if (Thread.currentThread() != getExclusiveOwnerThread())\n            throw new IllegalMonitorStateException();\n        boolean free = false;\n        //如果当前可重入次数为0 则清空锁持有线程\n        if (c == 0) {\n            free = true;\n            setExclusiveOwnerThread(null);\n        }\n         setState(c);\n\n        return free;\n    }\n```\n### 非公平锁\n非公平锁不会关注阻塞队列中是否还有线程，而是直接尝试获取锁，获取不到时在将线程加入到队列中。\n#### 获取锁\n```java\n    final void lock() {\n        //修改state的值，修改成功则设值设置当前线程为独占锁的拥有者\n        if (compareAndSetState(0, 1))\n            setExclusiveOwnerThread(Thread.currentThread());\n        else\n            acquire(1);\n    }\n     //调用AbstractQueuedSynchronizer\n    public final void acquire(int arg) {\n        if (!tryAcquire(arg) &&\n            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n            selfInterrupt();\n    }\n```\n非公平锁与公平锁的差别在于当c为0时，不去查询队列的状态，而是直接尝试修改state的值\n```java\n    protected final boolean tryAcquire(int acquires) {\n         return nonfairTryAcquire(acquires);\n    }\n\n    final boolean nonfairTryAcquire(int acquires) {\n        final Thread current = Thread.currentThread();\n        int c = getState();\n        if (c == 0) {\n            if (compareAndSetState(0, acquires)) {\n                setExclusiveOwnerThread(current);\n                return true;\n            }\n        }\n        else if (current == getExclusiveOwnerThread()) {\n            int nextc = c + acquires;\n            if (nextc < 0) // overflow\n                 throw new Error(\"Maximum lock count exceeded\");\n            setState(nextc);\n            return true;\n        }\n        return false;\n    }   \n```\n非公平锁和共平锁的释放锁逻辑相同。","tags":["JAVA"],"categories":["JAVA"]},{"title":"AbstractQueuedSynchronizer源码分析-独占式","url":"/2021/03/03/aqs2/","content":"\n### 独占式获得锁\n独占式下的顶层函数为`acquire()`,首先调用`tryAcquire()`函数获得锁，如果获取不到锁，则将线程加入到队列中。\n```java\npublic final void acquire(int arg) {\n    if (!tryAcquire(arg) && //尝试获得锁\n       //将线程加入到对列中，循环获取资源，并在一定次数后阻塞\n        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n        //在阻塞过程中线程可能被中断，忽略中断，在获取到锁后再进行中断。\n        selfInterrupt();\n}\n```\n`addWaiter()`将线程加入到阻塞队列中。\n```java\nprivate Node addWaiter(Node mode) {\n\n   //将建一个队列节点，并设置该节点为独占模式\n    Node node = new Node(Thread.currentThread(), mode);\n    // 尝试快速插入到队列中，失败则调用enq函数\n    Node pred = tail;\n    if (pred != null) {\n        node.prev = pred;\n        if (compareAndSetTail(pred, node)) {\n            pred.next = node;\n            return node;\n        }\n    }\n    enq(node);\n    return node;\n}\n```\n将node节点放入到对尾中。\n```java\nprivate Node enq(final Node node) {\n    for (;;) {\n        Node t = tail;\n        //如果队列为空，则设置对尾节点为空，并将队首指向对尾\n        if (t == null) { \n            if (compareAndSetHead(new Node()))\n                tail = head;\n        } else {\n           //将该节点的前趋节点设置为当前对列尾节点\n            node.prev = t;\n            //将对尾节点设置为尾节点\n            if (compareAndSetTail(t, node)) {\n               //将原尾节点的后继指向该节点\n                t.next = node;\n                return t;\n            }\n        }\n    }\n}\n```\n\n`acquireQueued()`通过自旋的方式获取同步状态，在需要阻塞线程的时候阻塞线程。\n```java\nfinal boolean acquireQueued(final Node node, int arg) {\n      boolean failed = true;\n      try {\n          boolean interrupted = false;\n          for (;;) {\n             //获取当前节点的前趋节点\n              final Node p = node.predecessor();\n              //判断前趋节点是否是头节点，如果是，再次掉用tryAcquire尝试获取锁\n              if (p == head && tryAcquire(arg)) {\n                  //如果获取到锁，则将当前节点设置成头节点\n                  setHead(node);\n                  //在设置头节点时，node的前趋节点已经设置成null，所以这里只将p的next设置成null，p节点将不在队列中\n                  p.next = null; // help GC\n                  failed = false;\n                  return interrupted;\n              }\n              //判断是否应该被阻塞，如果应该被阻塞则阻塞该节点\n              if (shouldParkAfterFailedAcquire(p, node) &&\n                  parkAndCheckInterrupt())\n                  interrupted = true;\n          }\n      } finally {\n          if (failed)\n              cancelAcquire(node);\n      }\n  }\n ```\n判断是否应该挂起该线程\n```java\nprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {\n    int ws = pred.waitStatus;\n    if (ws == Node.SIGNAL)\n       //如果当前节点的前趋节点的状态为SIGNAL则阻塞当前节点\n        return true;\n    if (ws > 0) {\n        do {\n           //如果当前节点的前趋节点状态>0(CANCELLED),那就一直往前找\n            node.prev = pred = pred.prev;\n        } while (pred.waitStatus > 0);\n        pred.next = node;\n    } else {\n        //如果前趋节点为正常状态，则修改前趋节点的状态为SIGNAL，用于线程结束时，唤起下一个节点\n        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\n    }\n    return false;\n}\n```\n挂起线程\n```java\nprivate final boolean parkAndCheckInterrupt() {\n    //阻塞当前线程\n    LockSupport.park(this);\n    //当前线程可被中断，返回该线程的中断状态，在该线程获取到锁后，再进行中断\n    return Thread.interrupted();\n}\n```\n### 独占式释放锁\n```java\npublic final boolean release(int arg) {\n//尝试获释放锁\n    if (tryRelease(arg)) {\n        Node h = head;\n        if (h != null && h.waitStatus != 0)\n            unparkSuccessor(h);\n        return true;\n    }\n    return false;\n}\n```\n```java\nprivate void unparkSuccessor(Node node) {\n      int ws = node.waitStatus;\n      //修改头节点的状态\n      if (ws < 0)\n          compareAndSetWaitStatus(node, ws, 0);\n\n      //获取头节点的下一个节点\n      Node s = node.next;\n      \n      //判断s线程是否是null，或线程状态是否是>0(比如CANCELLED状态 代表取消），如果为true，则遍历队列，找到应该被唤醒的线程。\n      if (s == null || s.waitStatus > 0) {\n          s = null;\n          for (Node t = tail; t != null && t != node; t = t.prev)\n              if (t.waitStatus <= 0)\n                  s = t;\n      }\n      if (s != null)\n         //唤醒线程\n          LockSupport.unpark(s.thread);\n  }\n  ```","tags":["JAVA"],"categories":["JAVA"]},{"title":"AbstractQueuedSynchronizer源码分析-共享式","url":"/2021/02/13/aqs1/","content":"\n### 共享式获得锁\n共享式获取锁的顶层函数为`acquireShared()`,该函数首先调用`tryAcquireShared()`尝试互锁，如果获取不到锁，则将该线程加入到队列中。\n```java\npublic final void acquireShared(int arg) {\n          //尝试获取锁\n          //小于0，代表获取锁失败\n          // 具体的逻辑由子类实现\n        if (tryAcquireShared(arg) < 0)\n            doAcquireShared(arg);\n    }\n```\n`doAcquireShared()`函数将该线程加入到队列中，然后通过有限次的循环获取锁，并判断是否该阻塞\n```java\n    private void doAcquireShared(int arg) {\n        //将该线程加入到队列中\n        final Node node = addWaiter(Node.SHARED);\n        boolean failed = true;\n        try {\n            boolean interrupted = false;\n            for (;;) {\n                //获取该线程节点的前趋节点。\n                final Node p = node.predecessor();\n                /**\n                * 如果p为头节点，再次尝试获取锁\n                * p可能是独占式节点（EXCLUSIVE），也可能是共享式节点（SHARED）.\n                * 独占式节点则不能再获取锁\n                * 共享式节点可以获取锁，但当资源用尽时也不能获取到锁\n                * 能不能获取到锁，要看具体tryAcquireShared的实现\n                **/\n                if (p == head) {\n                    int r = tryAcquireShared(arg);\n                    if (r >= 0) {\n\n                        //设置头节点和唤醒下一个共享线程\n                        setHeadAndPropagate(node, r);\n                        p.next = null; // help GC\n                        if (interrupted)\n                            //如果阻塞过程中，有过中断，先不处理，再获取到资源后，再处理中断。\n                            selfInterrupt();\n                        failed = false;\n                        return;\n                    }\n                }\n                // 判断是否应该阻塞，如果要阻塞则将线程阻塞，并判断是否有过中断\n                if (shouldParkAfterFailedAcquire(p, node) &&\n                    parkAndCheckInterrupt())\n                    interrupted = true;\n            }\n        } finally {\n            if (failed)\n                cancelAcquire(node);\n        }\n    }\n```\n```java\n    private void setHeadAndPropagate(Node node, int propagate) {\n        //获取头节点\n        Node h = head; \n        //将当前节点设置成头节点\n        setHead(node);\n        \n        if (propagate > 0 || h == null || h.waitStatus < 0 ||\n            (h = head) == null || h.waitStatus < 0) {\n            Node s = node.next;\n            //如果s是共享节点，则唤醒共享节点\n            if (s == null || s.isShared())\n                doReleaseShared();\n        }\n    }\n\n```\n\n```java\n   private void doReleaseShared() {\n       /*\n     * 下面的循环在 head 节点存在后继节点的情况下，做了两件事情：\n     * 1. 如果 head 节点等待状态为 SIGNAL，则将 head 节点状态设为 0，并唤醒后继节点\n     * 2. 如果 head 节点等待状态为 0，则将 head 节点状态设为 PROPAGATE，保证唤醒能够正\n     *    常传播下去。关于 PROPAGATE 状态的细节分析，后面会讲到。\n     */\n        for (;;) {\n            Node h = head;\n            if (h != null && h != tail) {\n                int ws = h.waitStatus;\n                if (ws == Node.SIGNAL) {\n                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                        continue;            // loop to recheck cases\n                    unparkSuccessor(h);\n                }\n                else if (ws == 0 &&\n                         !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n                    continue;                // loop on failed CAS\n            }\n            if (h == head)                   // loop if head changed\n                break;\n        }\n    }\n```\n### 共享式释放锁\n```java\n public final boolean releaseShared(int arg) {\n        if (tryReleaseShared(arg)) {\n            doReleaseShared();\n            return true;\n        }\n        return false;\n    }\n```","tags":["JAVA"],"categories":["JAVA"]}]