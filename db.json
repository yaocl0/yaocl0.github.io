[{"title":"Proof-of-History：Solana 区块链的创新时间证明机制","url":"/2025/01/22/35poh/","content":"Proof-of-History (PoH) 是 Solana 区块链提出的一种创新的共识机制，它并不是传统意义上的共识算法，而是一种利用加密哈希链来确定全局时间和交易顺序的技术。PoH 不仅仅通过哈希函数确保数据的完整性，还提供了一个无需节点间同步的可靠时间证明机制，从而提高区块链的效率和吞吐量。\n\n本文将深入探讨 PoH 的核心概念、实现细节以及它如何与其他共识机制（如 Proof-of-Stake）结合使用，最终为 Solana 区块链提供高效、安全的交易处理能力。\n\n## 一、核心概念：哈希链与时间证明\n\n### 1. **加密哈希函数**\n\nPoH 的核心概念是通过一个连续的哈希链来生成时间证明。每个新区块的哈希值都依赖于前一个区块的哈希值，这样形成一个不可篡改的时间顺序链。PoH 使用加密哈希函数，尤其是 **SHA-256**，它是用于计算数据完整性的重要工具。给定一个输入 `X`，SHA-256 会输出唯一的哈希值 `Y`，任何对 `X` 的改动都会导致输出 `Y` 完全不同。\n\n这种特性是 PoH 的关键，它确保了区块数据的顺序和完整性。\n\n在 Solana 的 PoH 序列中，通过将每个区块的哈希值作为下一个区块哈希函数输入的一部分，形成一个链条，这样，任何变动都会改变区块的哈希值，确保数据的不可篡改性。\n\n### 2. **时间戳的生成**\n\nPoH 通过链式哈希实现了时间证明。每个区块的哈希值不仅代表了区块的内容，还携带了时间信息，确保了区块之间的时间顺序。区块链网络中的节点无需依赖传统的时间同步协议，它们只需通过验证哈希链中的时间顺序来确认每个事件的发生顺序。\n\n具体地，Solana 的实现是通过构造一个连续的哈希流（即 PoH 链）来实现“时间戳”功能。区块的顺序即为 PoH 链中的哈希流的顺序。因此，节点可以通过查看 PoH 链中的哈希值，快速确定一个区块的生成时间，而无需依赖外部时间源。\n\n### 3. **POH序列与SHA-256**\n\nSolana 的 PoH 序列使用 SHA-256 哈希算法来确保交易的顺序和完整性。举个例子，如果将交易打包成一个区块并生成相应的 SHA-256 哈希值，则区块内的交易顺序就被确定了。任何对交易的更改都会导致该区块的哈希值发生变化，而该哈希值又会成为下一个区块的输入，形成链条式的时间证明。\n\n这个过程的核心就是 **Proof of History**：上一个区块的哈希值作为下一个区块哈希函数的一部分，通过哈希链不断地“证明”历史交易的顺序。\n\n![POH序列，图源：Solana白皮书](6.png)\n\n\n![POH序列示意图，图源：Solana白皮书](1.png)\n\n\n## 二、PoH 的具体实现：哈希链的生成与验证\n\n### 1. **区块生成过程**\n\nPoH 的区块生成过程由 Solana 网络中的领导者节点（Leader）负责。该节点从交易池中收集交易并将其排序，生成 PoH 链，最终创建新区块并广播给其他节点。\n\n1. **初始化哈希链**：系统从一个初始的哈希值开始，这个哈希值可能是一个随机数或特定的时间戳。\n   \n2. **生成新区块**：领导者节点通过将前一个区块的哈希值与当前区块的数据（如交易信息）结合，使用 SHA-256 计算出新区块的哈希值。\n   \n3. **广播新区块**：生成的新区块会广播给网络中的其他节点，其他节点通过验证新区块的哈希值与前一个区块的哈希值的一致性来确保区块的有效性。\n\n4. **验证哈希链**：每个节点验证新区块时，都会检查当前区块的哈希值是否依赖于上一个区块的哈希值，从而确保哈希链的顺序性和一致性。\n\n![交易Flow架构图，图源：Solana白皮书](2.png)\n\n\n### 2. **PoH 时间验证机制**\n\nPoH 的时间验证与传统的时间同步协议（如 NTP）不同。通常，在区块链中，时间同步是通过各个节点交换时间戳来实现的。但是，PoH 的实现方式则是让每个新区块的哈希值与前一个区块的哈希值绑定，从而自动构建一个可信的时间线。\n\n具体地，假设某个区块的时间戳为 T，该时间戳并不是由节点直接提供的，而是通过哈希链中的序列来确定。也就是说，区块的生成顺序（而非实际时间）决定了其时间戳。PoH 保证了即使网络中的节点时间不同，区块的时间顺序依然是可信的。\n\n## 三、PoH 与 Proof-of-Stake (PoS) 的结合\n\nPoH 并不是一个独立的共识机制，而是与其他共识机制（如 Proof-of-Stake）结合使用。在 Solana 中，PoH 与 PoS 结合，提供了一个高效的共识机制，能够确保区块的顺序性和时间验证。\n\n### 1. **PoH 与 PoS 的结合**\n\n在 Solana 网络中，PoS 负责选择验证者节点，这些节点通过锁定代币来获得生成新区块的机会，而 PoH 负责为区块生成提供时间戳。\n\n- **PoS**：确定了哪些节点有资格生成新区块。\n- **PoH**：为区块生成提供了时间验证，确保了区块的顺序性。\n\n通过这种结合，Solana 可以高效且安全地生成和验证区块，避免了传统共识机制的性能瓶颈。\n\n### 2. **领导者节点的选举与时间线**\n\nSolana 网络采用 Leader Rotation 机制周期性地轮换领导者节点，每个周期由 PoS 确定新的领导者节点，领导者节点负责通过 PoH 生成新区块并广播给其他节点。PoH 的连续性保证了时间的顺序性，领导者节点在每个时隙（slot）内生成并广播区块，不依赖其他节点的时间同步。\n\n## 四、Leader节点与时间限制\n\n为了避免单点故障，Solana 引入了时间限制机制。在 Solana 中，时间单位以 epoch 进行划分，每个 epoch 包含 432,000 个时隙（slot），每个时隙持续 400 毫秒。在每个时隙内，PoS 会分配一个新的领导者节点，该节点必须在 400 毫秒内完成区块的生成并广播，否则会跳过该时隙并重新选举新的领导者节点。\n\n\n![Leader选举机制，图源：Helius](3.jpg)\n\n通过这种机制，Solana 网络能够在每个时隙内保证新区块的生成，同时通过 PoH 保证了交易的历史顺序。\n\n## 五、Tower BFT 共识机制\n\n虽然 PoH 提供了高效的时间证明，但单靠 PoH 还不足以保证区块链的最终一致性和安全性。因此，Solana 使用了 **Tower BFT 共识机制** 来对区块进行最终的验证和达成共识。\n\nTower BFT（拜占庭容错共识协议）是 Solana 网络的核心共识机制之一，它基于传统的 BFT 共识算法，并且与 Proof-of-History（PoH）紧密结合，提供了一种高效、去中心化的方式来确保区块链网络的安全性和一致性。\n\n### 1. **Tower BFT 的基本原理**\n\nTower BFT 协议是 BFT 共识算法的一种具体实现，核心理念是通过验证者节点的投票来达成共识。与传统的共识机制不同，Tower BFT 通过 PoH 提供的历史时间证明和哈希链来进行投票，避免了传统机制中的冗余数据和投票冲突。\n\n在 Tower BFT 中，验证者的投票不仅仅是对区块的选择，它还作为交易的历史证明。每个区块的哈希值以及它与前一个区块的关联信息在整个网络中得到一致确认，确保了区块的顺序性和不可篡改性。\n\n![Tower BFT协议，图源：Helius](4.jpg)\n\n### 2. **投票机制与区块确认**\n\n在 Tower BFT 协议中，验证者节点会对新区块进行投票。具体而言，如果超过2/3的验证者对一个区块投出了“同意”（approve）票，那么该区块就会被确认并最终加入到区块链中。这种投票机制的优势在于，它通过简单的哈希序列投票来确认区块的有效性，而不需要额外的资源来传递区块本身。这样做不仅节省了内存，还避免了传统共识机制中由于区块广播和冗余数据传输而产生的网络拥堵。\n\n![投票图示](5.jpg)\n\n这种设计减少了区块传播时的冗余，避免了传统方法中每个验证者接收到的区块需要向周围的节点再次广播的问题，减少了网络带宽的压力，提高了整个系统的效率。\n\n### 3. **PoH与Tower BFT的协作**\n\nTower BFT 与 Proof-of-History（PoH）技术密切结合，PoH 提供了一个可靠的、不可篡改的时间证明，验证者可以根据 PoH 链中的历史证明来投票。每个区块的哈希不仅代表着区块的内容，还承载了与历史区块的关联信息，保证了交易顺序的不可篡改性。\n\nPoH 确保了区块链的时间顺序，而 Tower BFT 确保了区块的最终一致性和网络中的验证者对区块的共识。两者的结合极大提升了区块链的性能和安全性。\n\n## 六、总结\n\nProof-of-History (PoH) 是一种利用加密哈希链提供时间证明的技术，它通过确保区块的顺序性和不可篡改性来提高区块链网络的效率。PoH 通过与 Proof-of-Stake (PoS) 相结合，帮助 Solana 网络在高吞吐量的情况下，保持区块生成和验证的安全性。\n\n\nTower BFT 进一步提高了网络的共识效率，通过投票机制与 PoH 紧密结合，减少了冗余通信并提高了容错性。PoH 和 Tower BFT 的结合使 Solana 成为一个高效、低延迟且具有高吞吐量的区块链网络，在高频交易和大规模应用场景中具有广泛的应用潜力。随着区块链技术的不断发展，PoH 和 Tower BFT 技术有望推动更多区块链应用的普及与创新。","tags":["区块链","Solana"],"categories":["区块链"]},{"title":"LangChain：构建智能语言模型应用的开源框架","url":"/2025/01/20/34langchain/","content":"## 什么是 LangChain\n\nLangChain 是一个强大的开源框架，旨在帮助开发者快速构建和管理基于大语言模型（LLMs）的应用程序。随着自然语言处理技术的飞速发展，LLMs 在文本生成、对话系统、内容推荐等领域展现出巨大的潜力。然而，要充分利用这些强大的模型并整合到复杂的应用中，开发者需要处理许多复杂的任务，如上下文管理、调用外部工具和数据整合。LangChain 通过提供一套模块化、可扩展的工具，简化了这些过程。\n\nLangChain 的核心目标是使开发者能够构建 \"智能\" 应用，这些应用可以理解上下文、动态调整和集成外部资源。\n\n---\n\n## LangChain 的主要应用场景\n\n### 1. **对话式 AI**\n\n通过记忆功能和高级提示优化，可以构建更智能、更自然的聊天机器人。\n\n### 2. **信息抽取与总结**\n\nLangChain 可以处理长文档，提取关键信息并生成简洁摘要。\n\n### 3. **搜索增强**\n\n结合搜索工具，构建支持实时信息检索的问答系统。\n\n### 4. **多步骤工作流自动化**\n\n通过链和代理，可以创建复杂的自动化工作流，例如客户支持、教育内容生成等。\n\n### 5. **多模态应用**\n\n结合图像、视频等其他数据源，构建更丰富的交互体验。\n\n---\n\n## LangChain 的核心组件\n\nLangChain 的设计是模块化的，以下是其主要组件：\n\n### 1. **模型（Models）**\n\n这是应用的核心，用于生成或理解自然语言。LangChain 支持多种语言模型，包括但不限于 OpenAI、Hugging Face，以及其他开源和商业模型。开发者可以选择最适合的模型来满足特定需求。\n\n### 2. **提示（Prompts）**\n\n提示（Prompts）是与语言模型交互的关键。LangChain 允许开发者设计、优化和动态构建提示，以确保更好的输出效果。它还支持模板化提示和参数化的动态生成。\n\n### 3. **链（Chains）**\n\n链是 LangChain 的核心概念，用于将多个模型或功能模块组合成复杂的工作流。例如，一个典型的链可能包括：\n\n- 先从用户输入中提取关键信息。\n- 然后用提取的信息生成新的文本。\n- 最后返回结构化的响应。\n\n### 4. **记忆（Memory）**\n\nLangChain 支持应用记忆功能，用于存储上下文信息。这在构建对话系统时尤为重要，因为它允许模型记住对话历史，从而提供更连贯的交互体验。\n\n### 5. **工具和代理（Tools and Agents）**\n\nLangChain 支持与外部工具和 API 集成。例如，可以通过工具调用数据库、执行计算，甚至访问实时信息。此外，代理（Agents）允许模型根据上下文动态选择合适的工具。\n\n---\n\n## 安装 LangChain\n\n在开始使用 LangChain 之前，需要先安装相关依赖。\n\n### 1. **安装 LangChain**\n\n使用`pip`安装 LangChain：\n\n```bash\npip install langchain\n```\n\n### 2. **安装支持的 LLM 依赖**\n\n例如，安装 OpenAI API 的依赖：\n\n```bash\npip install openai\n```\n\n### 3. **其他依赖**\n\n根据具体需求安装其他库，例如：\n\n```bash\npip install sqlalchemy  # 数据库支持\npip install faiss       # 向量搜索\n```\n\n---\n\n## 使用\n\n### **1. Prompt Templates（提示模板）示例**\n\n**用途**：定义一个可复用的提示模板，用于生成动态输入。\n\n```python\nfrom langchain.prompts import PromptTemplate\n\n# 定义一个提示模板\ntemplate = \"\"\"\n你是一位经验丰富的翻译官。\n请将以下英文翻译成中文：\n\"{text}\"\n\"\"\"\n\n# 创建 PromptTemplate 实例\nprompt = PromptTemplate(\n    input_variables=[\"text\"],\n    template=template,\n)\n\n# 使用模板生成提示\nresult = prompt.format(text=\"This is an example sentence.\")\nprint(result)\n```\n\n### **2. Chains（链）示例**\n\n**用途**：将多个逻辑步骤连接在一起，形成一个完整的任务流程。\n\n```python\nfrom langchain.chains import LLMChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import OpenAI\n\n# 定义提示模板\nprompt = PromptTemplate(\n    input_variables=[\"topic\"],\n    template=\"请为以下主题写一段简短的文章：{topic}\",\n)\n\n# 创建一个 LLM（大语言模型）\nllm = OpenAI(model_name=\"text-davinci-003\", api_key=\"your_openai_api_key\")\n\n# 创建一个 LLMChain\nchain = LLMChain(llm=llm, prompt=prompt)\n\n# 执行链操作\nresponse = chain.run(\"人工智能的未来\")\nprint(response)\n```\n\n### **3. Agents（智能体）示例**\n\n**用途**：智能体根据工具动态决定解决问题的策略。\n\n```python\nfrom langchain.agents import load_tools, initialize_agent\nfrom langchain.llms import OpenAI\n\n# 创建一个 LLM\nllm = OpenAI(model_name=\"text-davinci-003\", api_key=\"your_openai_api_key\")\n\n# 加载工具\ntools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n\n# 初始化智能体\nagent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n\n# 智能体执行任务\nresponse = agent.run(\"谁赢得了2018年世界杯冠军？17乘以23等于多少？\")\nprint(response)\n```\n\n### **4. Memory（记忆）示例**\n\n**用途**：为会话保存上下文，使模型能在多轮对话中理解用户意图。\n\n```python\nfrom langchain.chains import ConversationChain\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.llms import OpenAI\n\n# 创建记忆模块\nmemory = ConversationBufferMemory()\n\n# 创建 ConversationChain，绑定记忆模块\nllm = OpenAI(model_name=\"text-davinci-003\", api_key=\"your_openai_api_key\")\nconversation = ConversationChain(llm=llm, memory=memory, verbose=True)\n\n# 进行多轮对话\nresponse1 = conversation.predict(input=\"你好，你是谁？\")\nresponse2 = conversation.predict(input=\"你还记得我们之前聊过什么吗？\")\n\nprint(\"Response 1:\", response1)\nprint(\"Response 2:\", response2)\n```\n\n---\n\n## 案例\n\n### 案例 1：创建一个简单的问答系统\n\n```python\nfrom langchain import OpenAI, PromptTemplate\nfrom langchain.chains import LLMChain\n\n# 1. 初始化LLM\nllm = OpenAI(model_name=\"text-davinci-003\", api_key=\"your_openai_api_key\")\n\n# 2. 定义Prompt模板\nprompt = PromptTemplate(\n    input_variables=[\"question\"],\n    template=\"以下是一个问题：{question}。请提供详细回答。\"\n)\n\n# 3. 构建LLM链\nqa_chain = LLMChain(llm=llm, prompt=prompt)\n\n# 4. 输入问题并获取答案\nquestion = \"什么是LangChain？\"\nanswer = qa_chain.run(question=question)\nprint(\"回答：\", answer)\n```\n\n### 案例 2：多轮对话示例\n\n```python\n from langchain.memory import ConversationBufferMemory\n\nllm = OpenAI(model_name=\"text-davinci-003\", api_key=\"your_openai_api_key\")\n\n memory = ConversationBufferMemory()\n qa_chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n\n question1 = \"LangChain有哪些核心组件？\"\n print(qa_chain.run(question=question1))\n\n question2 = \"可以详细说说记忆模块吗？\"\n print(qa_chain.run(question=question2))\n```\n\n### 案例 3： 结合外部数据源\n\n```python\n from langchain.chains import SQLDatabaseChain\n from langchain.sql_database import SQLDatabase\n\n db = SQLDatabase.from_uri(\"sqlite:///example.db\")\n\n llm = OpenAI(model_name=\"text-davinci-003\", api_key=\"your_openai_api_key\")\n db_chain = SQLDatabaseChain(llm=llm, database=db)\n\n query = \"SELECT * FROM users WHERE age > 30;\"\n print(db_chain.run(query))\n```\n\n### 案例 4：知识库问答\n\n结合外部文档数据，实现基于知识库的问答系统：\n\n```python\nfrom langchain.document_loaders import TextLoader\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import OpenAI\n\n# 加载文档\nloader = TextLoader(\"knowledge_base.txt\")\ndocuments = loader.load()\n\n# 创建向量存储\nvector_store = FAISS.from_documents(documents)\n\n# 创建问答链\nllm = OpenAI(model=\"text-davinci-003\", temperature=0.7, api_key=\"your_openai_api_key\")\nqa_chain = RetrievalQA(llm=llm, retriever=vector_store.as_retriever())\n\n# 提问\nresponse = qa_chain.run(\"这篇文档的主要内容是什么？\")\nprint(response)\n```\n","tags":["LLM"],"categories":["LLM"]},{"title":"区块链预言机：智能合约与现实世界的桥梁","url":"/2025/01/14/33Oracles/","content":"18 年 11 月 6 日，中国人民银行发布的《区块链能做什么？不能做什么？》报告中，是这样对预言机定义的：\n\n> 区块链外信息写入区块链内的机制，一般被称为预言机 (oracle mechanism)。\n\n随着区块链技术的快速发展，区块链不仅在金融、供应链、物联网等领域取得了广泛应用，而且它的智能合约功能也逐渐成为去中心化应用（DApp）的核心。然而，区块链的智能合约有一个固有的限制——它只能在链内的数据上进行操作，无法与链外的世界进行交互。为了克服这一局限，区块链预言机（Oracle）应运而生，成为区块链和现实世界之间至关重要的桥梁。本文将深入探讨区块链预言机的工作原理、类型、应用场景以及面临的挑战，并展望其未来的发展趋势。\n\n## 一、什么是区块链预言机？\n\n区块链预言机（Oracle）是一种将外部世界数据引入区块链的机制，它能够为智能合约提供必要的链外数据，使得智能合约能够在真实世界的基础上执行。这些数据可能包括天气信息、市场价格、体育比赛结果、地理位置数据等，任何与区块链内部状态无关的外部数据，都可以通过预言机传递给区块链智能合约。\n\n智能合约本质上是一个自动化执行合同的程序，但其运行只能依赖于区块链内部的数据。当智能合约需要外部信息来执行某些操作时，预言机的作用就显得尤为重要。例如，在一个去中心化保险平台中，智能合约可能需要根据天气预报来决定是否启动赔付程序。在这种情况下，预言机可以提供天气数据，并将其传递给智能合约，触发合同的执行。\n\n## 二、区块链预言机的工作原理\n\n区块链预言机的工作原理主要包括以下几个步骤：\n\n1. **外部事件触发**：预言机首先需要获取外部事件的数据。这些事件可能是金融市场的变化、传感器数据的读取、天气预报的变化等。\n\n2. **数据源获取**：预言机通过多个数据源（如 API 接口、传感器、网站抓取等）获取外部数据。这些数据源可以是金融数据提供商、天气预报平台、物联网设备等。\n\n3. **数据验证与处理**：获取到外部数据后，预言机会对数据进行验证，以确保数据的准确性、完整性和可信度。验证方法通常包括使用多个数据源进行比对，或者通过加密技术保证数据的可靠性。\n\n4. **数据传递到区块链**：经过验证的数据被传递到区块链上的智能合约，智能合约根据这些数据执行相应的操作。\n\n5. **合约执行**：智能合约根据外部数据的变化，自动执行合约条款。智能合约的执行是完全自动化和去中心化的，这意味着不需要任何中介参与。\n\n#### 例子说明\n\n假设有一个去中心化金融应用（DeFi），该应用允许用户借贷加密货币。该应用中的智能合约可能需要借助一个预言机获取外部市场的价格数据，以确定借贷利率或是否执行清算操作。预言机会实时监测市场数据，当价格波动达到某个阈值时，自动将数据传递给智能合约，智能合约则会基于预定规则执行相应的操作。\n\n## 三、区块链预言机的类型\n\n根据预言机获取数据的方式和使用的验证机制，区块链预言机可以分为以下几种类型：\n\n### 1. **软件预言机（Software Oracles）**\n\n软件预言机通过访问外部的在线数据源（如 API、数据库）来获取信息。它们将这些信息传递给区块链，通常用于获取价格数据、天气数据等。\n\n- **例子**：获取股票价格、货币汇率、天气预报等。\n\n### 2. **硬件预言机（Hardware Oracles）**\n\n硬件预言机通过物理设备获取外部世界的数据。它们通常与传感器或物联网设备连接，实时收集数据并传递给区块链。例如，硬件预言机可以用于获取温度、湿度、地震活动等数据。\n\n- **例子**：利用 IoT 传感器获取温度、湿度等环境数据。\n\n### 3. **输入预言机（Input Oracles）**\n\n输入预言机主要是指通过人为输入的方式将数据传递到区块链。这类预言机通常依赖于人工操作来触发数据传递。\n\n- **例子**：某些竞猜类应用中，用户的输入可以作为智能合约执行的依据。\n\n### 4. **输出预言机（Output Oracles）**\n\n输出预言机将区块链上的数据传递到外部系统。这类预言机主要用于将区块链上执行的结果反馈到现实世界，影响外部系统的状态。\n\n- **例子**：智能合约执行后，将结果传递给一个传统的数据库或支付系统，触发后续操作。\n\n### 5. **去中心化预言机（Decentralized Oracles）**\n\n去中心化预言机通过多个数据源来提供信息，避免了单一数据源可能带来的可信度问题。多个节点会对数据的正确性进行验证，并最终汇总结果。去中心化预言机被认为更加安全和可靠，因为它减少了单点故障和数据操控的风险。\n\n- **例子**：Chainlink 就是一个知名的去中心化预言机网络，它利用多个独立的节点来提供可靠的数据源。\n\n## 四、区块链预言机的应用场景\n\n区块链预言机为多个行业带来了创新和变革，以下是一些典型的应用场景：\n\n### 1. **去中心化金融（DeFi）**\n\n在 DeFi 应用中，预言机的作用至关重要。DeFi 平台需要从外部获取数据，如市场价格、借贷利率等。例如，去中心化交易所（DEX）依赖预言机提供实时的资产价格，以确保交易的公平性和透明度。在借贷平台中，预言机帮助计算利率和资产的抵押价值。\n\n### 2. **智能合约与保险**\n\n在去中心化保险平台中，预言机用来提供有关外部事件的数据，如天气、自然灾害、事故等。智能合约会根据这些数据自动判断是否触发保险赔付。如果天气预报显示某个地区将发生暴雨，预言机将触发保险合约，开始赔付过程。\n\n### 3. **供应链管理**\n\n在供应链管理中，预言机可用于追踪和验证物品的运输、储存和交付情况。例如，传感器可以提供实时的温度和湿度数据，确保易腐物品的运输过程符合要求。预言机将这些数据传递给智能合约，以确保供应链的透明度和高效性。\n\n### 4. **物联网（IoT）**\n\n在物联网应用中，预言机为设备之间提供数据交互的能力。例如，智能家居设备可以通过传感器获取温度、湿度、空气质量等数据，预言机将这些信息传递给区块链上的智能合约，从而自动调节设备的工作状态。\n\n## 五、目前的区块链预言机项目与解决方案\n\n随着区块链技术的发展，越来越多的预言机项目应运而生，各自采用不同的技术架构、数据源和验证机制，以满足不同领域的需求。以下是一些主流的区块链预言机项目和解决方案，它们在去中心化金融（DeFi）、保险、供应链等行业中发挥着重要作用。\n\n### 1. **Chainlink**\n\n简介： Chainlink 是目前最知名且应用最广泛的区块链预言机平台之一。它通过去中心化的节点网络，为智能合约提供可靠的外部数据，确保数据的准确性和防篡改性。\n\n特点：\n\n- 去中心化：Chainlink 使用多个数据提供者和节点来确保数据的多样性与可靠性，避免了单点故障的问题。\n- 强大的生态系统：Chainlink 支持数百个去中心化应用（dApps），包括 DeFi 项目、保险、预测市场等。\n- 安全性：通过加密和多重签名机制，确保链外数据传输的完整性和安全性。\n- Oracle 聚合：通过聚合多个数据源，Chainlink 提供的数据具有更高的准确性和可信度。\n\n官方链接：[https://chain.link/](https://chain.link/)\n\n### 2. **Band Protocol**\n\n简介：  Band Protocol 是一个去中心化的预言机平台，旨在为区块链提供高效、安全的外部数据。它支持多链操作，并通过去中心化的验证机制确保数据的准确性。\n\n特点：\n\n- 跨链兼容性：Band Protocol 支持多种区块链平台，能够为跨链应用提供预言机服务。\n- 高效性：与 Chainlink 相比，Band Protocol 提供了更低延迟的数据验证，并在成本上具有优势。\n- 去中心化的数据验证：通过多个节点和数据源验证数据，确保结果的准确性。\n\n官方链接：[https://bandprotocol.com/](https://bandprotocol.com/)\n\n### 3. **Tellor**\n\n简介：  Tellor 是一个去中心化的预言机平台，通过矿工网络提供链外数据。Tellor 的矿工通过工作量证明（PoW）机制验证和提供数据，这种机制增加了数据的可信度和防篡改性。\n\n特点：\n\n- 去中心化的数据源：Tellor 的数据提供者（矿工）通过挖矿的方式提供数据，确保数据来源的去中心化。\n- 数据验证和奖励机制：矿工提交的数据经过其他矿工的验证，确保数据的正确性。成功提交有效数据的矿工会获得奖励。\n- 开放性：任何人都可以参与 Tellor 网络，成为数据提供者或验证者。\n\n官方链接：[https://tellor.io/](https://tellor.io/)\n\n## 五、区块链预言机面临的挑战\n\n尽管区块链预言机在多个领域展现出巨大的潜力，但它仍然面临许多挑战：\n\n### 1. **数据的准确性与可靠性**\n\n预言机依赖外部数据源，而外部数据的质量直接影响智能合约的执行。如果预言机提供的数据不准确或受到篡改，可能会导致合约执行的错误，从而带来不必要的风险。\n\n### 2. **去中心化与信任问题**\n\n许多区块链应用强调去中心化，但预言机往往是中心化的数据源，这可能引发信任问题。中心化的预言机容易受到单点故障或攻击的影响，因此，去中心化的预言机成为了新的研究方向。\n\n### 3. **延迟问题**\n\n数据传递的延迟可能影响智能合约的执行，尤其是在需要快速响应的场景中。例如，高频交易应用中，延迟可能导致重大的经济损失。\n\n### 4. **数据隐私问题**\n\n许多区块链应用涉及敏感数据，如金融交易、个人健康信息等。如何确保预言机在提供数据时不泄露用户隐私，是未来需要解决的重要问题。\n\n## 六、区块链预言机的未来展望\n\n随着区块链技术和预言机的不断发展，未来的预言机将变得更加高效、安全和去中心化。以下是未来发展的一些趋势：\n\n1. **去中心化预言机的普及**：随着去中心化预言机技术的成熟，更多区块链应用将采用这种方式来保证数据的可靠性和透明性。\n\n2. **隐私保护技术的引入**：为了保护用户隐私，未来的预言机可能会采用零知识证明、同态加密等技术，确保数据传输过程中的安全性和隐私性。\n\n3. **跨链数据互操作性**：随着区块链技术的发展，跨链互操作性将成为未来的趋势。预言机可以实现不同区块链之间的数据交换，促进不同平台之间的协同工作。\n\n## 七、结语\n\n区块链预言机作为区块链技术的关键组件，解决了区块链与现实世界数据对接的难题，推动了智能合约和去中心化应用的发展。随着技术的不断创新，预言机将更加完善，助力区块链生态系统实现更广泛的应用。然而，如何解决数据可信性、安全性和隐私保护等问题，仍是区块链预言机发展的关键挑战。随着这些问题的逐步解决，区块链预言机的前景无疑是光明的，它将为区块链的广泛应用打开新的大门。\n","tags":["区块链"],"categories":["区块链"]},{"title":"使用 HSDIS 和 JITWatch 探索 Java 汇编指令","url":"/2025/01/11/33JavaAssembly/","content":"Java 虚拟机（JVM）作为一种现代化的虚拟机，具备即时编译（Just-In-Time, JIT）功能，可以将热点代码编译为高效的本地机器码以提高性能。在实际开发和性能调优中，我们可能需要分析 JVM 将 Java 字节码编译成的汇编指令。本篇博客将详细介绍如何使用 HSDIS 和 JitWatch 工具来查看和分析这些生成的汇编代码。\n\n---\n\n### 一、HSDIS 简介\n\nHSDIS（HotSpot Disassembler）是 HotSpot JVM 的反汇编插件，可以将 JIT 编译器生成的机器码转换成人类可读的汇编指令。HSDIS 是 JDK 的非官方组件，因此需要手动下载或编译。\n\n### 二、JITWatch 简介\n\nJITWatch 是一个用于分析 JVM JIT 编译过程的可视化工具。它可以解析 JVM 日志文件（通常是通过 `-XX:+UnlockDiagnosticVMOptions -XX:+LogCompilation` 生成的），并展示 JIT 编译的详细信息，包括内联决策和汇编代码。\n\n### 三、环境准备\n\n以下步骤基于 Linux 环境，但可以适配其他操作系统。\n\n1. **安装 JDK**\n\n   确保你的系统安装了支持 HSDIS 和 JIT 日志的 JDK（推荐使用 OpenJDK 或 Oracle JDK 8/11，`本文使用的是Oracle JDK 8`）。\n\n2. **下载或编译 HSDIS**\n\n- 检查你的 JDK 是使用哪种架构（`x86_64` 或 `aarch64`）。\n\n- 安装 HSDIS：\n\n  - 方式一： 从[https://github.com/liuzhengyang/hsdis](https://github.com/liuzhengyang/hsdis)下载编译 `本文使用该方式`。\n\n  - 方式二：\n    从 [GraalVM 的 GitHub 仓库：https://github.com/graalvm/labs-openjdk-11](https://github.com/graalvm/labs-openjdk-11) 下载预编译的 HSDIS 动态库，或者自己编译：\n\n    ```bash\n       git clone https://github.com/openjdk/jdk.git\n       cd jdk/src/utils/hsdis\n       make ARCH=<x86_64 或 aarch64>\n    ```\n\n  - 方式三： 从[https://chriswhocodes.com/hsdis/](https://chriswhocodes.com/hsdis/)下载已经编译好的\n\n* 将生成的 `hsdis-<arch>.so` 放到 JDK 的 `$JAVA_HOME/jre/bin/server` 目录下。\n\n3. **安装 JITWatch**\n\n- 从 [JitWatch GitHub 仓库：https://github.com/AdoptOpenJDK/jitwatch](https://github.com/AdoptOpenJDK/jitwatch) 下载最新版本。\n- 解压后运行 `launchUI.sh`（Linux/macOS）或 `launchUI.bat`（Windows）。\n- 确保你已安装 Java 8 或更高版本。\n\n### 生成汇编代码\n\n#### 1. 编写测试代码\n\n首先，创建一个简单的 Java 类用于测试：\n\n```java\npublic class Test {\n    public static void main(String[] args) {\n        for (int i = 0; i < 10_000_000; i++) {\n            compute(i);\n        }\n    }\n\n    private static int compute(int x) {\n        return (x * 2 + 1) / 3;\n    }\n}\n```\n\n#### 2. 使用 HSDIS 查看汇编\n\n运行上述代码时，启动 JVM 时添加 HSDIS 配置参数：\n\n```bash\n   -XX:+UnlockDiagnosticVMOptions\n   -XX:+PrintAssembly\n   -Xcomp\n   -XX:+LogCompilation\n   -XX:LogFile=/home/yao/hotspot.log\n```\n\n其中：\n\n- `-XX:+PrintAssembly`：启用汇编代码打印。\n- `-XX:+LogCompilation`：生成 JIT 日志文件。\n- `-XX:LogFile`：指定 JIT 日志文件的位置。\n\n![](1.png)\n\n运行后，终端将输出大量信息，其中包含 `compute` 方法的汇编代码。你可以通过分析这些汇编指令了解 JVM 如何优化你的代码。\n\n![](2.png)\n\n#### 3. 使用 JitWatch 分析\n\n1. 配置源码目录和编译字节码目录\n\n![](3.png) \n2.打开生成的 hotspot.log 文件。并启动分析\n\n![](4.png)\n\n![](5.png)\n\n---\n\n### 常见问题\n\n1. **未加载 HSDIS 动态库**\n\n   - 检查 HSDIS 文件名是否正确，并确认其路径与 JVM 的 `lib` 目录匹配。\n   - 使用 `java -version` 确认使用的是预期的 JVM。\n\n2. **汇编输出乱码**\n\n   - 确保 JVM 使用的指令集架构与 HSDIS 编译版本一致（如 x86_64）。\n   - 检查终端编码是否支持正确显示特殊字符。\n\n3. **JitWatch 无法加载日志**\n\n   - 确保日志文件完整无误。\n   - 使用 `grep` 检查日志是否包含方法编译记录。\n\n---\n\n### 总结\n\n通过 HSDIS 和 JitWatch，我们可以深入了解 JVM 的 JIT 编译过程以及生成的汇编代码。对于性能调优或研究 JVM 工作原理，这些工具提供了强大的支持。希望本文能够帮助你快速上手这些工具，进一步探索 Java 性能优化的奥秘！\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"Solana：重塑区块链生态的高速革命","url":"/2025/01/05/32Solana/","content":"\nSolana 是一个高性能的区块链平台，以其卓越的可扩展性和极快的交易速度吸引了全球开发者和加密爱好者的关注。作为一个相对较新的区块链项目，Solana 不仅在技术创新上突破重围，还在实际应用上展现出强大的潜力。本文将详细探讨 Solana 的背景、技术特点、与其他区块链的比较以及它在去中心化金融（DeFi）和非同质化代币（NFT）等领域的应用。\n\n\n## 一、Solana 背景简介\n\nSolana 是由 Anatoly Yakovenko 于 2020 年推出的一个区块链平台。Yakovenko 是前 Qualcomm 的工程师，他设计 Solana 的初衷是为了克服以太坊等现有区块链平台在扩展性和交易速度上的局限。Solana 提供了一个非常快速、低成本且高可扩展的区块链环境，旨在支持大规模的去中心化应用（DApps）和智能合约。\n\n与以太坊、比特币等传统区块链相比，Solana 的最大特点就是其极高的吞吐量。Solana 采用了一系列创新的技术，使其能够处理数万笔交易，而不会出现拥堵的现象。这一特点使得 Solana 成为加密行业中的新兴领导者，特别是在去中心化金融（DeFi）和非同质化代币（NFT）等热门领域中，Solana 的应用前景广阔。\n\n## 二、Solana 的核心技术特点\n\n### 1. Proof of History (PoH)\n\nSolana 的创新之一是其独特的“历史证明”（Proof of History，PoH）共识机制。传统的区块链共识机制，如比特币的 Proof of Work（PoW）或以太坊的 Proof of Stake（PoS），都需要通过节点间的竞争或选举来验证交易和区块。这种方式虽然能够保证网络的去中心化，但在处理速度和吞吐量上存在一定的瓶颈。\n\nSolana 通过 PoH 技术，解决了这一问题。PoH 并不依赖传统的竞争方式来验证交易，而是使用一种加密算法，通过时间戳记录交易顺序，使得区块链上的每笔交易都能够按时间顺序链式存储。这不仅大大提高了交易的效率，还降低了网络的验证成本。\n\n### 2. Proof of Stake (PoS)\n\n虽然 PoH 是 Solana 的核心技术之一，但它并不是唯一的共识机制。Solana 还采用了 Proof of Stake（PoS）共识机制。PoS 机制要求节点质押一定数量的代币来参与区块验证，这使得攻击者需要持有大量的代币才能控制网络，从而增强了网络的安全性。\n\n与传统的 PoW 共识机制相比，PoS 不需要大量的计算资源和能源消耗，因此它在能源效率上要优越得多。此外，Solana 的 PoS 机制还通过优化了区块验证过程，提高了网络的吞吐量。\n\n### 3. **并行处理与分片（Sharding）**\n\nSolana 采用了并行处理的技术，通过优化其区块链架构，实现了高效的并行交易处理。与传统的区块链需要依赖单线程处理交易不同，Solana 通过支持多线程并行执行，极大提高了其交易吞吐量。\n\nSolana 还计划通过分片（Sharding）技术进一步提升网络的可扩展性。分片技术将区块链网络划分为多个独立的子链（Shards），每个子链能够独立处理一部分交易，从而实现交易负载的均匀分布。通过这种方式，Solana 可以在不牺牲去中心化的情况下，实现更多交易的并行处理，从而提高整体网络的性能。\n\n### 4. **Turbine 协议**\n\nSolana 的 Turbine 协议是其核心网络协议之一，它负责高效地传播区块信息。Turbine 使用一种类似比特币的“传播树”结构，将每个新区块的传播过程拆分成多个小的片段，并通过多层级的分发机制快速传播。这不仅减少了区块传播时的延迟，还优化了网络带宽的使用，使得 Solana 能够更快地处理大量交易。\n\nTurbine 协议的设计使得即使在高负载的情况下，Solana 也能保持其低延迟和高吞吐量，确保交易能够迅速被验证并添加到区块链中。\n\n### 5. Gulf Stream 网络优化\n\nGulf Stream 是 Solana 网络中的一种优化协议，旨在减少交易确认的延迟。它允许节点在交易尚未被完全确认时，就能开始处理这些交易，并在未来的区块中完成确认。通过这种方式，Solana 大大缩短了交易的确认时间，并提高了整体网络的响应速度。\n\n此外，Gulf Stream 协议还减少了网络中的交易等待时间和网络拥堵的情况，从而帮助 Solana 更加高效地处理交易。\n\n### 6. SeaLevel 多线程执行\n\nSolana 的 SeaLevel 是其用于执行智能合约和交易的一种并行执行环境。与传统的区块链环境不同，Solana 能够在多个线程中并行执行智能合约。这种并行处理能力使得 Solana 能够同时处理多个交易和智能合约，而无需像其他区块链那样依赖于单个线程的顺序执行。\n\n这种技术创新大大提高了 Solana 的交易吞吐量，使其能够在处理大规模 DApp 和复杂交易时，仍然保持高效的性能。\n\n## 三、Solana 的独特优势\n\n### 1. 高吞吐量与低延迟\n\nSolana 的另一个显著特点是其极高的交易吞吐量和低延迟。Solana 的设计目标是每秒处理超过 65,000 笔交易（TPS），并且能够在毫秒级别内确认交易。这比目前市场上大多数区块链平台（如比特币的 7 TPS 和以太坊的 30 TPS）要高出几个数量级。\n\n为了实现这一目标，Solana 采用了多个创新技术，包括分片（Sharding）、优化的交易验证算法、以及高效的内存池（Mempool）设计。这些技术使得 Solana 能够在不牺牲去中心化的前提下，提供大规模的交易处理能力。\n\n### 2. 可扩展性\n\nSolana 的可扩展性不仅体现在交易吞吐量上，还体现在其能够支持复杂的去中心化应用和智能合约。Solana 使用的编程语言 Rust 和 C 语言使得开发者能够更高效地编写智能合约，而其高效的虚拟机（Solana VM）则确保了这些合约能够快速执行。\n\n与以太坊相比，Solana 能够更好地处理高频交易和复杂应用，这使得它成为了去中心化金融、去中心化交易所（DEX）和其他应用的理想平台。\n\n### 3. 低交易费用\n\nSolana 提供极低的交易费用，这是它相较于其他区块链平台的另一个重要优势。每笔交易的费用通常低于 0.01 美元，这使得 Solana 成为适合小额支付、微支付和高频交易的理想选择。\n\n这种低费用的优势在 DeFi 和 NFT 市场中尤为显著，Solana 能够让用户以几乎为零的成本进行交易和交互，这为平台的增长和用户的参与提供了巨大的推动力。\n\n## 四、Solana 与其他区块链的比较\n\n### 1. Solana 与以太坊\n\n以太坊作为智能合约和去中心化应用的先驱，一直是区块链领域的重要平台。然而，随着使用者和应用的增长，以太坊在交易吞吐量和手续费方面出现了瓶颈，特别是在 DeFi 和 NFT 的高峰时期，网络拥堵严重，导致交易确认时间延长，手续费飙升。\n\n与以太坊相比，Solana 的优势在于其更高的吞吐量、更低的交易费用以及更快的交易确认速度。Solana 能够支持更大规模的去中心化应用，同时保持网络的低成本和高效能，这使得它成为开发者和用户的热门选择。\n\n### 2. Solana 与比特币\n\n比特币是最早的区块链平台，主要用于数字货币交易和储值。然而，比特币的区块链相对较慢，交易吞吐量也有限，通常只有 7 笔交易每秒（TPS）。虽然比特币的安全性和去中心化程度无与伦比，但它并不适合大规模的去中心化应用和高频交易。\n\n相比之下，Solana 在吞吐量、交易速度和低延迟方面拥有明显的优势。虽然比特币在区块链领域的地位难以撼动，但 Solana 在技术层面为更复杂的应用提供了更强大的支持。\n\n## 五、Solana 的应用场景\n\n### 1. 去中心化金融（DeFi）\n\nSolana 已成为去中心化金融（DeFi）领域的领先平台之一。DeFi 通过去中心化的协议为用户提供金融服务，Solana 以其低延迟和高吞吐量，为 DeFi 提供了理想的基础设施。Solana 上的去中心化交易所（DEX）、借贷平台和稳定币协议，已经吸引了大量的用户和资金。\n\n例如，Solana 上的 Serum 是一个去中心化交易所，它通过 Solana 高速区块链的特性，提供快速且低成本的交易体验。相比于以太坊上常见的高交易费用，Serum 让用户能够以更低的成本进行资产交换。\n\n### 2. 非同质化代币（NFT）\n\nSolana 还在非同质化代币（NFT）领域取得了显著的进展。Solana 的高吞吐量和低交易费用使得它成为了 NFT 项目的理想平台。Solana 上的 NFT 市场，如 Solanart 和 Magic Eden，已经吸引了大量的艺术家和收藏家。\n\n与以太坊上的高交易费用不同，Solana 的低费用使得 NFT 创作者能够更频繁地进行交易，同时也降低了用户进入门槛。这种优势使得 Solana 在 NFT 领域成为了一个热门选择。\n\n### 3. 物联网（IoT）与其他领域\n\n除了 DeFi 和 NFT，Solana 还在物联网（IoT）、游戏、供应链管理等多个领域展现出潜力。由于 Solana 强大的扩展性和低交易费用，它能够为这些领域提供高效、去中心化的解决方案。\n## 三、Solana 面临的主要问题\n\n尽管 Solana 拥有强大的技术优势，但它在快速发展的过程中也面临着一些挑战和问题：\n\n### 1. 网络稳定性与宕机问题  \nSolana 曾多次遭遇网络停运或宕机的情况，尤其是在网络流量激增时，导致交易拥堵或中断。这些问题对用户的信任和平台的稳定性产生了较大的影响。尽管 Solana 开发团队采取了一些修复措施，但频繁的网络宕机依然影响了平台的可靠性。\n\n### 2. 去中心化和节点集中化问题  \nSolana 的去中心化程度较低，节点集中度较高。尽管 Solana 采用了 PoS 共识机制，推动多个节点参与验证，但相较于比特币和以太坊，Solana 网络中少数大型资金和矿池主导了大部分验证工作。这可能影响网络的安全性和公平性，降低其去中心化的能力。\n\n### 3. 生态系统的成熟度与开发者支持  \nSolana 的生态系统仍在扩展阶段，尽管其在 DeFi 和 NFT 等领域取得了一定成就，但与以太坊等老牌区块链相比，Solana 的应用数量和开发者支持还存在差距。Solana 需要更多的开发者参与和更完善的工具和文档，以促进生态系统的成熟。\n\n### 4. 跨链兼容性与安全性问题  \nSolana 在与其他区块链的互操作性方面存在挑战。尽管通过协议如 Wormhole 实现了与以太坊等网络的跨链转移，但跨链操作的安全性和效率仍然是问题。同时，由于 Solana 网络的复杂性，网络安全和智能合约的漏洞也可能导致资金损失。如何在保证性能的同时增强跨链兼容性和网络安全，是 Solana 需要解决的关键问题。\n\n## 七、总结\n\nSolana 凭借其创新的技术架构和高性能特点，已经在区块链领域占据了一席之地。通过引入独特的 Proof of History（PoH）共识机制、高吞吐量、低延迟以及并行处理等技术，Solana 成为解决区块链扩展性问题的一个重要创新平台。尤其在 DeFi、NFT 和 Web3 等应用场景中，Solana 展现了强大的潜力，吸引了大量开发者和用户的关注。\n\n然而，Solana 在快速发展的过程中，也面临着一些不可忽视的问题。网络稳定性、去中心化程度、生态系统的成熟度以及跨链兼容性等挑战，仍然是平台面临的主要瓶颈。尽管如此，Solana 的技术优势和高速发展使其成为区块链领域的重要竞争者，未来通过持续优化和解决这些问题，Solana 有望在区块链的竞争中稳固自己的位置，推动更多创新应用的落地和发展。\n\n总之，Solana 是一款在技术上具有重大突破的区块链平台，虽然存在一些挑战，但其独特的设计理念和性能优势使得它在行业中占据了重要的地位。随着生态的不断成熟和技术的不断优化，Solana 有望继续引领区块链行业走向更高效、去中心化的未来。","tags":["区块链","Solana"],"categories":["区块链"]},{"title":"InnoDB 存储引擎是如何管理和存储数据","url":"/2023/08/06/31innodb/","content":"\n## 如何连接 Mysql ？\n\n在 Java 中，通常使用 JDBC（Java Database Connectivity）来连接数据库。JDBC 定义了一套用于访问数据库的 API，它提供了一种标准的接口，使得我们可以通过 Java 代码与各种数据库进行交互。\n\n常见的 Java Web 系统是部署在 Tomcat 中的，那么 Tomcat 本身肯定是有多个线程来并发处理接收到的多个请求的，Mysql 是怎么处理的呢？\n\n在 Mysql 中，引入了连接池，连接池会维护一组可重用的数据库连接，应用程序需要访问数据库时可以从连接池中获取一个可用连接，执行完毕后将连接归还给连接池。这样可以减少连接的频繁创建和销毁，提升性能。\n\n如下所示：\n\n![](1.png)\n\n## Mysql 如何处理连接请求的？\n\n当 Mysql 接收到一个网络连接请求后，它是如何去处理该请求的，如何执行 SQL 的，总体的步骤可以分为一下几步：\n\n1. 开启一个端口监听的线程，用于网络连接以及读取请求。\n\n2. Mysql 内部提供了一个 SQL 接口（SQL Interface）的组件，用来专门执行 SQL 语句的接口\n\n3. 通过`查询优化器`选择最优的查询路径来执行\n\n4. 调用执行器，根据执行计划调用存储引擎的接口\n\n5. 调用存储引擎接口，真正执行 SQL 语句\n\n6. 存储引擎管理和存储数据\n\n比如：InnoDB、MyISAM、Memory，我们可以自己选择使用哪种存储引擎来负责具体的 SQL 语句执行。\n现在 MySQL 一般都是默认使用 InnoDB 存储引擎\n\n![](2.png)\n\n接着来分析 InnoDB 存储引擎是如何管理和存储我们的数据。\n\n## InnoDB 的重要内存结构：缓冲池\n\nInnoDB 存储引擎中有一个非常重要的组件：缓冲池（Buffer Pool）。 Buffer Pool 会将磁盘上的数据页缓存到内存中。\n\n![](3.png)\n\nBuffer Pool 使用 LRU（Least Recently Used，最近最少使用）算法来管理内存中的数据页。当查询需要访问数据时，InnoDB 首先检查缓冲池中是否存在相应的数据页。如果存在，它会直接从内存中获取数据，而不是从磁盘中读取，这大大提高了查询性能。如果数据页不在缓冲池中，InnoDB 会将其读取到缓冲池，并将其保留在内存中供后续查询使用。\n\n比如 SQL 语句：`update user set name='xxx' where id=1`，Mysql 会先从 Buffer Pool 中查询存不存在，存在直接操作缓存中的数据，如果不在的话，先从磁盘里加载到缓冲池里来。\n\n默认配置下 Buffer Pool 只有 128MB ，可以通过配置`innodb_buffer_pool_size`调整 Buffer Pool 大小。 通过适当配置缓冲池的大小，可以使常用的数据页始终在内存中，提高查询效率。\n\n## undo 日志文件：让更新的数据可以回滚\n\nUndo 日志文件用于记录数据库中正在进行的事务操作，用于回滚数据。当有更新、删除或插入操作发生时，InnoDB 引擎会将相关信息记录到 Undo 日志文件中。\n\n当需要回滚事务时，InnoDB 引擎使用 Undo 日志来还原到事务开始之前的数据状态。它通过逆向操作来撤销对数据的修改，并将数据还原为先前的状态。\n\n![](4.png)\n\n当要更新一条数据时，首先会从磁盘文件中加载数据到缓冲池，然后然后对这条数据加锁，接着把更新前的旧值写入 undo 日志文件。这时才开始更新这条记录更新的时候，先更新缓冲池中的记录，此时这条数据变成了脏数据。\n\n![](5.png)\n\n## redo 日志文件：保证数据的一致性和持久性\n\n如果修改操作已经写入缓存中，但是没有同步到磁盘进行持久化，此时，Mysql 的机器宕机了那么缓存中的数据也会丢失，那么本次更新的数据也就丢失了。\n\n为了保障 Mysql 数据的一致性和持久性，InnoDB 引擎引入了 redo 日志文件。\n\n> Redo Log 日志是一种物理日志，主要用于记录在事务提交前对数据库进行的修改操作。当数据库崩溃或发生故障时，通过 Redo Log 可以恢复到最后一次提交的状态，保证数据的持久性。\n\nRedo Log 的作用主要体现在以下两个方面：\n\n数据恢复：当数据库发生故障时，通过 Redo Log 可以将未提交的修改操作重新应用到数据库中，从而恢复到最后一次提交的状态。\n\n提高性能：通过将修改操作记录到 Redo Log 中，可以将磁盘 IO 操作转化为顺序写操作，大幅提高了数据库的写入性能。\n\n因此，当更新操作执行后，Mysql 会把对内存所做的修改写入到一个 Redo Log Buffer 里去，这也是内存里的一个缓冲区，是用来存放 redo 日志的。如下图所示：\n\n![](6.png)\n\n可以配置`innodb_log_buffer_size`来指定 Redo Log 的缓冲区大小，默认为 8MB。较大的值可以减少频繁的刷新操作，提高性能，但同时也会占用更多的内存。\n\n\nredo 日志写入磁盘有三种策略，可以通过 innodb_flush_log_at_trx_commit 来配置的：\n\n① 参数值为 0，redo log 不进磁盘\n\n表示不刷写 Redo Log 到磁盘，即异步写入策略。事务提交时，Redo Log 的修改操作只会写入到操作系统的页缓存中，并不会马上刷写到磁盘。这样可以提供最好的写入性能，但在数据库崩溃或发生故障时，可能会造成一定程度的数据丢失。\n\n② 参数值为 1，redo log 进磁盘【默认值】\n\n表示同步刷写 Redo Log 到磁盘。事务提交时，Redo Log 的修改操作会立即写入磁盘并等待 IO 操作完成。确保数据持久性的同时，也会对性能产生一定的影响。这是最常用的设置，适合大多数应用场景。\n\n![](7.png)\n\n③ 参数值为 2，redo log 进 os cache 缓存\n\n表示每次事务提交时将 Redo Log 的修改操作写入磁盘，但不会等待 IO 操作完成。事务提交时，Redo Log 会先写入到操作系统的页缓存，然后由后台线程异步地将数据刷写到磁盘。这种设置可以提供较好的性能和一定程度的数据保护，但仍然存在一定的风险。\n\n![](8.png)\n\n选择适当的 innodb_flush_log_at_trx_commit 值取决于对数据的持久性和性能的需求。如果对数据的持久性要求非常高，可以将其设置为 1。如果对性能要求较高且可以接受一定程度的数据丢失，可以将其设置为 0。如果在保证一定程度的数据保护的同时追求更好的性能，可以选择设置为 2。\n\n## binlog 到底是什么东西？\n\nbinlog 不是 InnoDB 存储引擎特有的日志文件，是属于 mysql server 自己的日志文件。用于记录对 MySQL 数据库执行的更改操作，包括语句的发生时间、执行时长，主要用于数据库恢复和主从复制。\n\nredo log 和 binlog 都是记录修改的日志，但是两者是有差别的。redo log 是一种偏向物理性质的重做日志，它里面记录的类似`对哪个数据页中的什么记录，做了个什么修改`，而 binlog 叫做归档日志，它里面记录的是偏向于逻辑性的日志，类似于`对 xxx 表中的 id=1 的一行数据做了更新操作，更新以后的值是什么`，\n\n因此在提交事务的时候，同时也会写入 binlog：\n\n![](9.png)\n\n### binlog 日志的刷盘策略分析\n\n对于 binlog 日志，有两种刷盘策略，可以通过 `sync_binlog` 设置：\n\n① 参数值为 0，【默认值】\n\n把 binlog 写入磁盘的时候，不是直接进入磁盘文件，而是进入 os cache 内存缓存。\n所以跟之前分析的一样，如果此时机器宕机，那么在 os cache 里的 binlog 日志是会丢失的：\n\n![](10.png)\n\n② 参数值为 1\n\n强制在提交事务的时候，把 binlog 直接写入到磁盘文件里去，那么这样提交事务之后，哪怕机器宕机，磁盘上的 binlog 是不会丢失的。\n\n当把 binlog 写入磁盘文件之后，接着就会完成最终的事务提交，此时会把本次更新对应的 binlog 文件名称和本次更新的 binlog 日志在文件里的位置，都写入到 redo log 日志文件里去，同时在 redo log 日志文件里写入一个 commit 标记。\n\n在完成这个事情之后，才算最终完成了事务的提交，我们看下图的示意：\n\n![](11.png)\n\n## 后台 IO 线程随机将内存更新后的脏数据刷回磁盘\n\nMySQL 有一个后台的 IO 线程，会在之后某个时间里，随机的把内存 buffer pool 中的修改后的脏数据给刷回到磁盘上的数据文件里去，我们看下图：\n\n![](12.png)\n\n在 IO 线程把脏数据刷回磁盘之前，哪怕 mysql 宕机崩溃也没关系，因为重启之后，会根据 redo 日志恢复之前提交事务做过的修改到内存里去，然后等适当时机，IO 线程自然还是会把这个修改后的数据刷到磁盘上的数据文件里去的。\n\n## 总结\n\nInnoDB 存储引擎主要就是包含了一些 Buffer Pool、redo log buffer 等内存里的缓存数据，同时还包含了一些 undo 日志文件，redo 日志文件等东西，同时 mysql server 自己还有 binlog 日志文件。\n\n在执行更新的时候，每条 SQL 语句，都会对应修改 buffer pool 里的缓存数据、写 undo 日志、写 redo log buffer 几个步骤；当提交事务的时候，一定会把 redo log 刷入磁盘，binlog 刷入磁盘，完成 redo log 中的事务 commit 标记；最后后台的 IO 线程会随机的把 buffer pool 里的脏数据刷入磁盘里去。\n\n\n####  参考\nhttps://developer.aliyun.com/article/1286718\n","tags":["MySql","InnoDB"],"categories":["MySql"]},{"title":"搞明白什么是零拷贝，就是这么简单","url":"/2023/07/26/28zerocopy/","content":"我们总会在各种地方看到零拷贝，那零拷贝到底是个什么东西。接下来，让我们来理一理啊。拷贝说的是计算机里的 I/O 操作，也就是数据的读写操作。计算机可是一个复杂的家伙，包括软件和硬件两大部分，软件主要指操作系统、驱动程序和应用程序。硬件那就多了，CPU、内存、硬盘等等一大堆东西。这么复杂的设备要进行读写操作，其中繁琐和复杂程度可想而知。\n\n## 传统I/O的读写过程\n\n如果要了解零拷贝，那就必须要知道一般情况下，计算机是如何读写数据的，我把这种情况称为传统 I/O。数据读写的发起者是计算机中的应用程序，比如我们常用的浏览器、办公软件、音视频软件等。而数据的来源呢，一般是硬盘、外部存储设备或者是网络套接字（也就是网络上的数据通过网口+网卡的处理）。过程本来是很复杂的，所以大学课程里要通过《操作系统》、《计算机组成原理》来专门讲计算机的软硬件。\n\n### 简化版读操作流程\n\n那么细的没办法讲来，所以，我们把这个读写过程简化一下，忽略大多数细节，只讲流程。\n\n\n![](1.png)\n\n\n上图是应用程序进行一次读操作的过程。\n\n1.  应用程序先发起读操作，准备读取数据了；\n2.  内核将数据从硬盘或外部存储读取到内核缓冲区；\n3.  内核将数据从内核缓冲区拷贝到用户缓冲区；\n4.  应用程序读取用户缓冲区的数据进行处理加工；\n\n### 详细的读写操作流程\n\n下面是一个更详细的 I/O 读写过程。这个图可好用极了，我会借助这个图来厘清 I/O 操作的一些基础但非常重要的概念。\n\n\n![](2.png)\n\n\n先看一下这个图，上面红粉色部分是读操作，下面蓝色部分是写操作。如果一下子看着有点儿迷糊的话，没关系，看看下面几个概念就清楚了。\n\n#### 应用程序\n\n就是安装在操作系统上的各种应用。\n\n#### 系统内核\n\n系统内核是一些列计算机的核心资源的集合，不仅包括CPU、总线这些硬件设备，也包括进程管理、文件管理、内存管理、设备驱动、系统调用等一些列功能。\n\n#### 外部存储\n\n外部存储就是指硬盘、U盘等外部存储介质。\n\n#### 内核态\n\n- 内核态是操作系统内核运行的模式，当操作系统内核执行特权指令时，处于内核态。\n- 在内核态下，操作系统内核拥有最高权限，可以访问计算机的所有硬件资源和敏感数据，执行特权指令，控制系统的整体运行。\n- 内核态提供了操作系统管理和控制计算机硬件的能力，它负责处理系统调用、中断、硬件异常等核心任务。\n\n#### 用户态\n\n这里的用户可以理解为应用程序，这个用户是对于计算机的内核而言的，对于内核来说，系统上的各种应用程序会发出指令来调用内核的资源，这时候，应用程序就是内核的用户。\n\n- 用户态是应用程序运行的模式，当应用程序执行普通的指令时，处于用户态。\n- 在用户态下，应用程序只能访问自己的内存空间和受限的硬件资源，无法直接访问操作系统的敏感数据或控制计算机的硬件设备。\n- 用户态提供了一种安全的运行环境，确保应用程序之间相互隔离，防止恶意程序对系统造成影响。\n\n#### 模式切换\n\n计算机为了安全性考虑，区分了内核态和用户态，应用程序不能直接调用内核资源，必须要切换到内核态之后，让内核来调用，内核调用完资源，再返回给应用程序，这个时候，系统在切换会用户态，应用程序在用户态下才能处理数据。上述过程其实一次读和一次写都分别发生了两次模式切换。\n\n\n![](3.png)\n\n\n#### 内核缓冲区\n\n内核缓冲区指内存中专门用来给内核直接使用的内存空间。可以把它理解为应用程序和外部存储进行数据交互的一个中间介质。应用程序想要读外部数据，要从这里读。应用程序想要写入外部存储，要通过内核缓冲区。\n\n#### 用户缓冲区\n\n用户缓冲区可以理解为应用程序可以直接读写的内存空间。因为应用程序没法直接到内核读写数据， 所以应用程序想要处理数据，必须先通过用户缓冲区。\n\n#### 磁盘缓冲区\n\n磁盘缓冲区是计算机内存中用于暂存从磁盘读取的数据或将数据写入磁盘之前的临时存储区域。它是一种优化磁盘 I/O 操作的机制，通过利用内存的快速访问速度，减少对慢速磁盘的频繁访问，提高数据读取和写入的性能和效率。\n\n#### PageCache\n\n- PageCache 是 Linux 内核对文件系统进行缓存的一种机制。它使用空闲内存来缓存从文件系统读取的数据块，加速文件的读取和写入操作。\n- 当应用程序或进程读取文件时，数据会首先从文件系统读取到 PageCache 中。如果之后再次读取相同的数据，就可以直接从 PageCache 中获取，避免了再次访问文件系统。\n- 同样，当应用程序或进程将数据写入文件时，数据会先暂存到 PageCache 中，然后由 Linux 内核异步地将数据写入磁盘，从而提高写入操作的效率。\n\n#### 再说数据读写操作流程\n\n上面弄明白了这几个概念后，再回过头看一下那个流程图，是不是就清楚多了。\n\n##### 读操作\n\n1.  首先应用程序向内核发起读请求，这时候进行一次模式切换了，从用户态切换到内核态；\n2.  内核向外部存储或网络套接字发起读操作；\n3.  将数据写入磁盘缓冲区；\n4.  系统内核将数据从磁盘缓冲区拷贝到内核缓冲区，顺便再将一份（或者一部分）拷贝到 PageCache；\n5.  内核将数据拷贝到用户缓冲区，供应用程序处理。此时又进行一次模态切换，从内核态切换回用户态；\n\n##### 写操作\n\n1.  应用程序向内核发起写请求，这时候进行一次模式切换了，从用户态切换到内核态；\n2.  内核将要写入的数据从用户缓冲区拷贝到 PageCache，同时将数据拷贝到内核缓冲区；\n3.  然后内核将数据写入到磁盘缓冲区，从而写入磁盘，或者直接写入网络套接字。\n\n## 瓶颈在哪里\n\n但是传统I/O有它的瓶颈，这才是零拷贝技术出现的缘由。瓶颈是啥呢，当然是性能问题，太慢了。尤其是在高并发场景下，I/O性能经常会卡脖子。那是什么地方耗时了呢？\n\n### 数据拷贝\n\n在传统 I/O 中，数据的传输通常涉及多次数据拷贝。数据需要从应用程序的用户缓冲区复制到内核缓冲区，然后再从内核缓冲区复制到设备或网络缓冲区。这些数据拷贝过程导致了多次内存访问和数据复制，消耗了大量的 CPU 时间和内存带宽。\n\n### 用户态和内核态的切换\n\n由于数据要经过内核缓冲区，导致数据在用户态和内核态之间来回切换，切换过程中会有上下文的切换，如此一来，大大增加了处理数据的复杂性和时间开销。每一次操作耗费的时间虽然很小，但是当并发量高了以后，积少成多，也是不小的开销。所以要提高性能、减少开销就要从以上两个问题下手了。这时候，零拷贝技术就出来解决问题了。\n\n## 什么是零拷贝\n\n问题出来数据拷贝和模态切换上。但既然是 I/O 操作，不可能没有数据拷贝的，只能减少拷贝的次数，还有就是尽量将数据存储在离应用程序（用户缓冲区）更近的地方。而区分用户态和内核态有其他更重要的原因，不可能单纯为了 I/O 效率就改变这种设计吧。那也只能尽量减少切换的次数。零拷贝的理想状态就是操作数据不用拷贝，但是显示情况下并不一定真的就是一次复制操作都没有，而是尽量减少拷贝操作的次数。要实现零拷贝，应该从下面这三个方面入手：\n\n1.  尽量减少数据在各个存储区域的复制操作，例如从磁盘缓冲区到内核缓冲区等；\n2.  尽量减少用户态和内核态的切换次数及上下文切换；\n3.  使用一些优化手段，例如对需要操作的数据先缓存起来，内核中的 PageCache 就是这个作用；\n\n## 实现零拷贝方案\n\n### 直接内存访问（DMA）\n\nDMA 是一种硬件特性，允许外设（如网络适配器、磁盘控制器等）直接访问系统内存，而无需通过 CPU 的介入。在数据传输时，DMA 可以直接将数据从内存传输到外设，或者从外设传输数据到内存，避免了数据在用户态和内核态之间的多次拷贝。\n\n\n![](4.png)\n\n\n如上图所示，内核将数据读取的大部分数据读取操作都交个了 DMA 控制器，而空出来的资源就可以去处理其他的任务了。\n\n### sendfile\n\n一些操作系统（例如 Linux）提供了特殊的系统调用，如 sendfile，在网络传输文件时实现零拷贝。通过 sendfile，应用程序可以直接将文件数据从文件系统传输到网络套接字或者目标文件，而无需经过用户缓冲区和内核缓冲区。如果不用sendfile，如果将A文件写入B文件。\n\n1.  需要先将A文件的数据拷贝到内核缓冲区，再从内核缓冲区拷贝到用户缓冲区；\n2.  然后内核再将用户缓冲区的数据拷贝到内核缓冲区，之后才能写入到B文件；\n\n而用了sendfile，用户缓冲区和内核缓冲区的拷贝都不用了，节省了一大部分的开销。\n\n### 共享内存\n\n使用共享内存技术，应用程序和内核可以共享同一块内存区域，避免在用户态和内核态之间进行数据拷贝。应用程序可以直接将数据写入共享内存，然后内核可以直接从共享内存中读取数据进行传输，或者反之。\n\n\n![](5.png)\n\n\n通过共享一块儿内存区域，实现数据的共享。就像程序中的引用对象一样，实际上就是一个指针、一个地址。\n\n### 内存映射文件（Memory-mapped Files）\n\n内存映射文件直接将磁盘文件映射到应用程序的地址空间，使得应用程序可以直接在内存中读取和写入文件数据，这样一来，对映射内容的修改就是直接的反应到实际的文件中。当文件数据需要传输时，内核可以直接从内存映射区域读取数据进行传输，避免了数据在用户态和内核态之间的额外拷贝。虽然看上去感觉和共享内存没什么差别，但是两者的实现方式完全不同，一个是共享地址，一个是映射文件内容。\n\n## Java 实现零拷贝的方式\n\nJava 标准的 IO 库是没有零拷贝方式的实现的，标准IO就相当于上面所说的传统模式。只是在 Java 推出的 NIO 中，才包含了一套新的 I/O 类，如 `ByteBuffer` 和 `Channel`，它们可以在一定程度上实现零拷贝。`ByteBuffer`：可以直接操作字节数据，避免了数据在用户态和内核态之间的复制。`Channel`：支持直接将数据从文件通道或网络通道传输到另一个通道，实现文件和网络的零拷贝传输。借助这两种对象，结合 NIO 中的API，我们就能在 Java 中实现零拷贝了。首先我们先用传统 IO 写一个方法，用来和后面的 NIO 作对比，这个程序的目的很简单，就是将一个100M左右的PDF文件从一个目录拷贝到另一个目录。\n\n```java\npublic static void ioCopy() {  \n  try {  \n    File sourceFile = new File(SOURCE_FILE_PATH);  \n    File targetFile = new File(TARGET_FILE_PATH);  \n    try (FileInputStream fis = new FileInputStream(sourceFile);  \n         FileOutputStream fos = new FileOutputStream(targetFile)) {  \n      byte[] buffer = new byte[1024];  \n      int bytesRead;  \n      while ((bytesRead = fis.read(buffer)) != -1) {  \n        fos.write(buffer, 0, bytesRead);  \n      }  \n    }  \n    System.out.println(\"传输 \" + formatFileSize(sourceFile.length()) + \" 字节到目标文件\");  \n  } catch (IOException e) {  \n    e.printStackTrace();  \n  }  \n}  \n```\n\n下面是这个拷贝程序的执行结果，109.92M，耗时1.29秒。\n\n> “传输 109.92 M 字节到目标文件 耗时: 1.290 秒”\n\n### FileChannel.transferTo\\(\\) 和 transferFrom\\(\\)\n\nFileChannel 是一个用于文件读写、映射和操作的通道，同时它在并发环境下是线程安全的，基于 FileInputStream、FileOutputStream 或者 RandomAccessFile 的 getChannel\\(\\) 方法可以创建并打开一个文件通道。FileChannel 定义了 transferFrom\\(\\) 和 transferTo\\(\\) 两个抽象方法，它通过在通道和通道之间建立连接实现数据传输的。这两个方法首选用 sendfile 方式，只要当前操作系统支持，就用 sendfile，例如Linux或MacOS。如果系统不支持，例如windows，则采用内存映射文件的方式实现。\n\n#### transferTo\\(\\)\n\n下面是一个 transferTo 的例子，仍然是拷贝那个100M左右的 PDF，我的系统是 MacOS。\n\n```java\npublic static void nioTransferTo() {  \n  try {  \n    File sourceFile = new File(SOURCE_FILE_PATH);  \n    File targetFile = new File(TARGET_FILE_PATH);  \n    try (FileChannel sourceChannel = new RandomAccessFile(sourceFile, \"r\").getChannel();  \n         FileChannel targetChannel = new RandomAccessFile(targetFile, \"rw\").getChannel()) {  \n      long transferredBytes = sourceChannel.transferTo(0, sourceChannel.size(), targetChannel);  \n  \n      System.out.println(\"传输 \" + formatFileSize(transferredBytes) + \" 字节到目标文件\");  \n    }  \n  } catch (IOException e) {  \n    e.printStackTrace();  \n  }  \n}  \n```\n\n只耗时0.536秒，快了一倍。\n\n> “传输 109.92 M 字节到目标文件 耗时: 0.536 秒”\n\n#### transferFrom\\(\\)\n\n下面是一个 transferFrom 的例子，仍然是拷贝那个100M左右的 PDF，我的系统是 MacOS。\n\n```java\npublic static void nioTransferFrom() {  \n  try {  \n    File sourceFile = new File(SOURCE_FILE_PATH);  \n    File targetFile = new File(TARGET_FILE_PATH);  \n  \n    try (FileChannel sourceChannel = new RandomAccessFile(sourceFile, \"r\").getChannel();  \n         FileChannel targetChannel = new RandomAccessFile(targetFile, \"rw\").getChannel()) {  \n      long transferredBytes = targetChannel.transferFrom(sourceChannel, 0, sourceChannel.size());  \n      System.out.println(\"传输 \" + formatFileSize(transferredBytes) + \" 字节到目标文件\");  \n    }  \n  } catch (IOException e) {  \n    e.printStackTrace();  \n  }  \n}  \n```\n\n执行时间：\n\n> “传输 109.92 M 字节到目标文件 耗时: 0.603 秒”\n\n### Memory-Mapped Files\n\nJava 的 NIO 也支持内存映射文件（Memory-mapped Files），通过 `FileChannel.map()` 实现。下面是一个 `FileChannel.map()`的例子，仍然是拷贝那个100M左右的 PDF，我的系统是 MacOS。\n\n```java\npublic static void nioMap(){  \n        try {  \n            File sourceFile = new File(SOURCE_FILE_PATH);  \n            File targetFile = new File(TARGET_FILE_PATH);  \n  \n            try (FileChannel sourceChannel = new RandomAccessFile(sourceFile, \"r\").getChannel();  \n                 FileChannel targetChannel = new RandomAccessFile(targetFile, \"rw\").getChannel()) {  \n                long fileSize = sourceChannel.size();  \n                MappedByteBuffer buffer = sourceChannel.map(FileChannel.MapMode.READ_ONLY, 0, fileSize);  \n                targetChannel.write(buffer);  \n                System.out.println(\"传输 \" + formatFileSize(fileSize) + \" 字节到目标文件\");  \n            }  \n        } catch (IOException e) {  \n            e.printStackTrace();  \n        }  \n    }  \n```\n\n执行时间：\n\n> “传输 109.92 M 字节到目标文件 耗时: 0.663 秒”\n\n原文： [https://mp.weixin.qq.com/s/ULVCvSLIGvj3VtY5prtxGw](https://mp.weixin.qq.com/s/ULVCvSLIGvj3VtY5prtxGw)","tags":["JAVA","计算机"],"categories":["JAVA"]},{"title":"跨越性能瓶颈：Layer2技术为区块链解决可扩展性问题","url":"/2023/06/06/30layer2/","content":"区块链有个著名的”不可能三角”问题，即一条区块链的发展很难兼顾安全、去中心化和可拓展性。\n\n![](1.png)\n\n以太坊举例，虽然在去中心化和安全方面做的已经足够好，但随着用户越来越多，其交易速度变慢、交易手续费高、用户体验恶化是一直以来有待解决的问题。尤其是在 17 年出现了一款非常火爆的 Dapp 应用叫加密猫，造成以太坊主网大规模的拥堵。造成拥堵的原因是以太坊当时的 TPS 只有 15，这意味着以太坊每秒只能处理 15 笔交易，如此低的 TPS 严重限制了区块链应用的大规模落地。\n\n想提升公链的可扩展性，有两种方式：\n\n1、链上扩容：\n\n扩展主网本身（Layer 1）称为链上扩容方案。主要通过提高区块链本身的交易容量来实现扩容。比如早期对比特币进行区块大小调整，隔离见证的引入，以太坊 2.0 的转 POS 和分片机制。但是 Layer 1 的扩容要么进展缓慢，要么对性能的提升没有质的变化。\n\n2、链下扩容：\n\n链下扩容是在底层区块链 Layer 1 上构建一个扩展层 Layer 2，通过将一部分交易或计算迁移到区块链外的第二层网络来提高可扩展性和效率。  Layer1 来保证安全和去中心化，绝对可靠、可信；它能做到全球共识，并作为“加密法院”，通过智能合约设计的规则进行仲裁，以经济激励的形式将信任传递到 Layer2 上，而 Layer2 追求极致的性能，它只能做到局部共识，但是能够满足各类商业场景的需求。\n\n![](2.png)\n\n## 常见的区块链 Layer 2 技术方案\n\n### 状态通道（State Channels）\n\n状态通道是一种基于区块链的链下交易方案，通过在链上锁定资金，交易双方在链下构建一个通道，实现链下的快速交易。其原理是将交易数据限制在链下的通道内，并只在必要时将最终结果提交到主链上。状态通道可以极大地提高交易吞吐量，并降低交易成本。\n\n其实可以把状态通道理解成一个执行特殊操作的智能合约，一个专门建立双向通道，在一定条件下进行`状态保持`的智能合约。可以将状态通道中的执行过程作为`原子操作`，在执行完成这个原子操作后，将最终结果上链。\n\n![](3.png)\n\n比如建立价值为 100 美元的支付通道，首先进行资金锁定，一旦锁定完成，交易者双方可互相发送状态更新来实现转账，无需与主链进行交互，只要双方的余额都还为正值即可。一旦有一方想要停止使用支付通道，可以执行 “退出” 操作，将最后的状态更新提交至主链，结算下来的余额会退给发起支付通道的两方。主链可以通过核实签名和最后结余来验证状态更新的有效性，从而防止交易双方使用无效状态来退出支付通道,保证退出机制的安全性。\n\n状态通道存在一些缺点：\n\n1. “退出” 模式存在一个问题，即主链无法验证支付通道是否提交了全部交易，也就是说，在提交了状态更新之后是否不再出现新的状态更新。\n2. 状态通道的第二个缺点就是低资金利用率。由于资金流动性无法扩容，当众多资金锁在一个状态通道里，只能用状态通道转发的话，这个效率是非常低下。\n\n应用代表：\n\n- 比特币中的闪电网络\n- 以太坊中的的 Raiden Network。\n\n### 侧链（Sidechains）\n\n侧链是一种独立于主链的区块链网络，通过与主链进行资产锁定和解锁的方式实现与主链的互操作性。它们通过“双向锚定” （Two-Way Pegging）来建立关联，实现主链与侧链之间价值的双向转移。侧链的思路可以简单的理解为在主链锁定资产，在侧链派生相应资产；当资产在侧链完成应用后要转回主链时，从侧链销毁资产，并在主链解锁。侧链可以承载大量的交易，并在需要时将交易结果提交到主链上。\n\n![](4.png)\n\n优点：\n\n- 不受主链 TPS 限制\n- 侧链合约运行的手续费大大降低，对小金额玩家以及新玩家较友好\n\n缺点：\n\n- 中心化威胁：通过第三方公证人或中继者进行验证，牺牲了部分去中心化特性\n\n项目代表：\n\n- Injective Protocol（注射协议）：首个 Layer 2 的衍生品 dex\n- Rootstock（RSK）（砧木）：第一条比特币侧链\n\n### 等离子体（Plasma）\n\nPlasma 曾是 Vitalik 认为大有可为的一个解决方案，由 Vitalik Buterin 和 Joseph Poon 在 2017 年共同提出。可以将 Plasma 视为以太坊的原生侧链，使用智能合约和 Merkle 树的组合来创建无限的子链分支。这些子链是以太坊主链的较小副本，具有自己的共识机制。\n\nPlasma 是一种设计模式，它允许链外消息驱动链上资产的转移。它通过将交易吞吐量转移到 Plasma 链来实现对根链的扩展。\n\nPlasma 在一个树形结构上组装区块链。最底层的是根区块链，根区块链之上是第一级子链——Plasma 链。在第一级链上，可进一步分支出二级和三级 Plasma 链。上一级 Plasma 链称为下一级链的`父链`。\n\n区块的承诺流向下，出口能被提交给任何父链，最终在根链上被执行。理解为子链的交易、状态等运算可以向下层层递交，最终在根链上落定和执行。\n\n![](5.png)\n\n优点：\n\n- 相对安全：即使链下环境崩塌，也能从主链上提取交易结果\n- 操作快、交易费用低：因为与主链的交互较少\n\n缺点：\n\n- 不具备主链的数据可用性：给 Layer 1 返回的仅有交易结果的证明、没有详细的交易信息，主链无法还原交易\n- 退出期长：用户需要从主链上提取资金，需要等待挑战期过去。\n- 拓展困难：技术框架限定了子链的数据结构\n\n项目代表：\n\n- Loom Network：第一个 Plasma 产品实现\n- Polygon\n\n### 聚合链（Rollups）\n\nRollups 是一种将大量交易聚合到单个链上进行处理的技术方案，其本质是将原本分布在区块中的大量交易数据，`打包成一笔集合的交易`，发布到链上。Roll Up 实际上是一条侧链，因此它会生成区块，并且将这些区块的快照发送到主链上。不过，Roll Up 上的运营者是无需信任的。也就是说，Roll Up 假定运营者可以在任何时候做出停止出块、生成无效块、隐瞒数据等恶意行为。\n\n主流的 Rollup 技术可以分为两类：ZkRollup 和 Optimistic Rollup。\n\n***ZkRollup***：基于[零知识证明](https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==&mid=2247484540&idx=1&sn=af2d2f3711b712952b8e4bb8278ff41f&chksm=fcafc1fecbd848e8673bd61edd693ad60f2bbd6334915e825d95551987b5df872cc4437edadb#rd)的 Layer2 扩容方案，采用有效性验证方法(VP)，默认所有交易都是不诚实的，只有通过有效性验证才会被接受。ZkRollup 在链下进行复杂的计算和证明的生成，链上进行证明的校验并存储部分数据保证数据可用性。\n\n优点：\n\n- 安全性：牺牲了等待时间来换取较好的安全性\n- 上链效率高：将多笔交易打包操作，节约时间和 gas fee\n\n缺点：\n\n- 验证效率低：较长的等待期，任何交易在等待期不会被确认，也无法从主链提取资金\n- 交易压缩率相对较低\n\n项目代表：\n\n- 路印\n- ZKSync：旨在为以太坊带来 Visa 级别、每秒数千笔交易的吞吐量\n\n***Optimistic Rollup***：采用的是欺诈性证明（Fraud Proof），它趋于相信操作者提交的数据都是真实的（乐观假设，大家都是好人）。但保险起见，需要操作者质押一定资产作为保证金，且在上链前留出两周的挑战期，任何人都可以在此期间挑战其真实性并发布欺诈证明，一旦挑战成功，质押金将会被没收，挑战者会获得奖励，且回滚交易细节。因此，从概率角度防止作恶行为。\n\n优点：\n\n- 高度的去中心化\n- 隐私性好：零知识证明不会透露任何交易细节\n- 上链效率高：一次性提交多笔操作的结果，节约时间和 gas fee\n- 验证效率高：无需等待期，快速完成资产取出动作\n- 安全性极高：zk 技术保证了提交给主链的数据真实有效，同时主链可随时还原侧链发生的交易细节（即拥有主链的数据可用性），因此拥有以太坊级别的安全性\n\n缺点：\n\n- 技术开发难度大\n- 难兼容不同智能合约\n- 需要大量运算\n\n项目代表：\n\n- Fuel：Optimistic Rollup（乐观汇总）概念提出者所在团队研发\n- Synthetix：DeFi 巨头的 Layer2 扩容选择\n\n## 结尾\n\n经过数年发展，Layer 2 扩容诞生了很多方案，在以太坊发展早期，以太坊创始人 V 神都曾认为侧链、Plasma 技术是解决区块链扩容问题的最佳方案。但时间和实践都证明，在 DeFi 大爆发的背景下，侧链、状态通道、Plasma 等 Layer 2 扩容方案都无法满足市场的要求，发展到现在，Rollup 成为了目前最有希望的方案。\n\n","tags":["区块链","layer2"],"categories":["区块链"]},{"title":"MVCC如何应对MySQL并发问题","url":"/2023/05/28/29mvcc/","content":"数据库使用事务来保持数据最终一致性，但是在并发下执行事务，会引起脏读、不可重复读、幻读等问题。为了解决这些问题，设计了四种隔离级别：\n\n- 读未提交(Read uncommitted)\n- 读已提交(Read committed)\n- 可重复读(Repeatable read)\n- 串行化(Serializable)\n\n![](1.png)\n\n不同的隔离级别，解决了不一样的并发问题，那么不同的隔离级别是怎么解决并发问题的呢？ 一个比较简单粗暴的方法是加锁，但是加锁必然会带来性能的降低。因此，数据库又引入了 MVCC（多版本并发控制）和锁配合使用，在读取数据不用加锁的情况下，实现读取数据的同时可以修改数据，修改数据时同时可以读取数据。\n\n## 什么是 MVCC\n\n> MVCC，全称 Multi-Version Concurrency Control，即多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。\n\n### 数据库并发场景：\n\n- 读-读：不存在任何问题，不需要并发控制。\n- 读-写：有线程安全问题，可能会造成事务隔离性问题，可能会有脏读，幻读，不可重复读。\n- 写-写：有线程安全问题，可能会存在更新丢失问题。\n\nMVCC 通过维护一个数据的多个版本，用来解决`读-写`冲突的无锁并发控制，可以解决以下问题：\n\n- 在并发读写数据时，可以做到在读操作时不用阻塞写操作，写操作不用阻塞读操作，提高数据库并发读写的性能。\n\n- 可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决`写-写`引起的更新丢失问题。\n\nMVCC 只在读已提交(Read Committed )和可重复读(Repeatable Read) 两个隔离级别下起作用，因为读未提交(Read UnCommitted) 隔离级别下，读写都不加锁，串行化（Serializable） 隔离级别下，读写都加锁，也就不需要 MVCC 了。\n\nMVCC 没有正式的标准，在不同的 DBMS 中 MVCC 的实现方式可能是不同的。本文讲解 InnoDB 中 MVCC 的实现机制（MySQL 其它的存储引擎并不支持它）。\n\n## 实现原理\n\n### 隐式字段\n\n在 InnoDB 存储引擎，针对每行记录都有固定的隐藏列：\n\n- DB_ROW_ID\n\n6-byte，隐含的自增 ID（隐藏主键），如果表中没有主键和非 NULL 唯一键时，则会生成一个单调递增的行 ID 作为聚簇索引。\n\n- DB_TRX_ID\n\n6-byte，操作这个数据的事务 ID，事务开启之前，从数据库获得一个自增长的事务 ID，用其判断事务的执行顺序。\n\n- DB_ROLL_PTR\n\n7-byte，回滚指针，也就是指向这个记录的 Undo Log 信息。\n\n![](2.png)\n\n> 其实还有一个删除的 flag 字段，用来判断该行记录是否已经被删除。\n\n### Undo Log 版本链\n\nInnoDB 把那些为了回滚而记录的东西称之为 Undo Log。在事务开始之前，会先将记录存放到 Undo Log 文件里备份起来，当事务回滚时或者数据库崩溃时用于回滚事务。\n\nUndo Log 日志分为两种：\n\n- insert undo log：\n\n事务在插入新记录产生的 Undo Log，当事务提交之后可以直接删除。\n\n- update undo log：\n\n事务在进行 update 或者 delete 的时候产生的 Undo Log。不仅在事务回滚时需要，在快照读的时候还是需要的，所以不能直接删除，只有当系统没有比这个 log 更早的 Read View 了的时候才能删除。ps：所以长事务会产生很多老的视图导致 undo log 无法删除 大量占用存储空间。\n\nMVCC 实际上是使用的`update undo log`。\n\n每次更新记录时，旧值都会放入`Undo Log`中，形成该记录的旧版本，随着更新次数的增加，所有版本通过回滚指针（DB_ROLL_PTR）链接成一条链，我们称之为版本链。版本链的头节点是当前记录的最新值。\n\n![](3.png)\n\n### 当前读和快照读\n\n- 当前读\n\n读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。像下面这些语句：\n\n```sql\nSELECT  LOCK IN SHARE MODE;  # 共享锁\nSELECT  FOR UPDATE; # 排他锁\nINSERT   # 排他锁\nDELETE  # 排他锁\nUPDATE   # 排他锁\n```\n\n- 快照读\n\n读取的是记录数据的可见版本，不加锁，不加锁的普通 `select` 语句都是快照读，即不加锁的非阻塞读。快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读。\n\n快照读的执行方式是生成 ReadView，直接利用 MVCC 机制来进行读取，并不会对记录进行加锁。\n\n### Read View\n\nRead View 就是事务进行`快照读`操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的 ID(当每个事务开启时，都会被分配一个 ID, 这个 ID 是递增的，所以最新的事务，ID 值越大).\n\nRead View 相当于某个时刻表记录的一个快照，在这个快照中我们能获取到与当前记录相关的事务中，哪些事务是已提交的稳定事务，哪些是正在活跃的事务，哪些是生成快照之后才开启的事务。\n\nRead View 中有四个属性(基于 Mysql 5.7)\n\n- creator_trx_id\n\n创建当前 Read View 的事务 ID\n\n- m_ids\n\n当前系统中所有的活跃事务的 id，活跃事务指的是当前系统中开启了事务，但还没有提交的事务;\n\n- m_low_limit_id\n\n表示在生成 Read View 时，当前系统中活跃的读写事务中最小的事务 id，即 m_ids 中的最小值。\n\n- m_up_limit_id\n\n当前系统中事务的 id 值最大的那个事务 id 值再加 1，也就是系统中下一个要生成的事务 id。\n\n`Read View 会根据这 4 个属性，结合 undo log 版本链，来实现 MVCC 机制，决定一个事务能读取到那个版本的数据。`\n\n## 实现过程--可见性比较算法\n\n当一个事务读取某条数据时，Read View 是如何判断版本链中的哪个版本是可用的呢？ 通过数据中的隐藏字段`DB_TRX_ID`进行可见性规则判断，如下：\n\n![](4.png)\n\n① 当 `DB_TRX_ID < m_low_limit_id`：\n\n表示 DB_TRX_ID 对应这条数据是在当前事务【creator_trx_id】开启之前，其他的事务就已经将该条数据修改了并提交了事务，所以当前事务（开启 Read View 的事务）能读取到。\n\n② 当 `DB_TRX_ID >= m_up_limit_id`：\n\n表示在当前事务【creator_trx_id】开启以后，有新的事务开启，并且新的事务修改了这行数据的值并提交了事务，因为这是【creator_trx_id】后面的事务修改提交的数据，所以当前事务是不能读取到的。\n\n③ 当 `m_low_limit_id =< DB_TRX_ID < m_up_limit_id`：\n\n1、如果 DB_TRX_ID 在 m_ids 数组中\n\n- `DB_TRX_ID 等于 creator_trx_id`\n\n  表明数据是自己生成的，因此是可见的\n\n- `DB_TRX_ID 不等于 creator_trx_id`\n\n  DB_TRX_ID 事务修改了数据的值，并提交了事务，所以当前事务【creator_trx_id】不能读取到。\n\n2、如果 DB_TRX_ID 不在 m_ids 数组中\n\n表示的是在当前事务【creator_trx_id】开启之前，其他事务【DB_TRX_ID】将数据修改后就已经提交了事务，所以当前事务能读取到。\n\n## 案例说明\n\n我们先准备一条数据\n\n![](5.png)\n\n现在有两个事务同时执行， 事务 A 的`DB_TRX_ID=2`，事务 B 的`DB_TRX_ID=3`。\n\n```sql\n#事务A：\nselect name from table where id = 1;\n#事务B：\nupdate table set name = 'Go' where id = 1;\n```\n\n事物开始后分别生成 ReadView\n\n事务 A 的 ReadView :\n\n> m_ids=[2,3]，  \n> m_low_limit_id=2，  \n> m_up_limit_id=4，  \n> creator_trx_id=2。\n\n事务 B 的 ReadView ：\n\n> m_ids=[2,3]，  \n> m_low_limit_id=2，  \n> m_up_limit_id=4，  \n> creator_trx_id=3。\n\n1、当事务 A 去查询时，发现数据的`DB_TRX_ID=1`，小于`m_low_limit_id`，说明这条数据是事物 A 开启之前就已经写入，并提交了事物，所以事物 A 可以读取到。\n\n2、 事务 B 去更新数据，修改后写入 Undo Log 日志，此时还`没有提交事务B`。示意图如下：\n![](6.png)\n\n3、此时事务 A 再去查询数据，发现数据`DB_TRX_ID=3`，并且在 m_ids 里，但是不等与`creator_trx_id`，说明这个版本的数据是和自己同一时刻启动的事务修改的，因此这个版本的数据，事务 A 读取不到。\n\n此时需要沿着 undo log 的版本链向前找，接着会找到该行数据的上一个版本`DB_TRX_ID=1`，由于 DB_TRX_ID=1 小于 m_low_limit_id 的值，因此事务 A 能读取到该版本的值，\n\n4、此时事务 B 提交事务，系统中活跃的事务只有事物 A，事物 A 第三次读取，读取到内容就有两种可能性：\n\n- 读已提交（RC）隔离级别：读取到是事物 B 提交的数据。\n- 可重复读（RR）隔离级别：读取到是原始数据。\n\n### 读已提交（RC）MVCC 实现\n\n在读已提交(Read committed)的隔离级别下实现 MVCC，同一个事务里面，每一次查询都会产生一个`新的 Read View 副本`，这样可能造成同一个事务里前后读取数据可能不一致的问题（不可重复读并发问题）。\n\n在事务 A 第一次读的时候生成的 Read View：\n\n> `m_ids=[2,3]`，  \n> m_low_limit_id=2，  \n> m_up_limit_id=4，  \n> creator_trx_id=2。\n\n此时数据没有修改，`DB_TRX_ID=1`,小于 m_low_limit_id，事务 A 可以读取到数据。\n\n当事务 B 提交后，事务 A 再去读时，又生成新的 Read View：\n\n> `m_ids=[2]`，  \n> m_low_limit_id=2，  \n> m_up_limit_id=4，  \n> creator_trx_id=2。\n\n此时数据已经被修改，`DB_TRX_ID=3`，满足`m_low_limit_id =< DB_TRX_ID < m_up_limit_id`，DB_TRX_ID 不在 m_ids 数组中的情况，所以事务 A 可以读取到。\n\n### 可重复读（RR）MVCC 实现\n\n在可重复读(Repeatable read)的隔离级别下实现 MVCC，同一个事务里面，多次查询，都`只会产生一个共用Read View`，从而保证每次查询的数据都是一样的。\n\n### 参考\n\n- https://www.modb.pro/db/397162\n- https://heapdump.cn/article/4465449\n- https://github.com/lifei6671/interview-go/blob/master/mysql/mysql-mvcc.md\n- https://www.6hu.cc/archives/86666.html\n","tags":["MySql"],"categories":["MySql"]},{"title":"以太坊概述","url":"/2023/04/27/27Ethereum/","content":"# 以太坊基础知识\n\n\n## 什么是以太坊\n\n以太坊（Ethereum）是一个去中心化的开源的有智能合约功能的公共区块链平台。 以太坊的概念首次在 2013 至 2014 年间由程序员维塔利克·布特林（Vitalik Buterin）受比特币启发后提出，大意为“下一代加密货币与去中心化应用平台”，在 2014 年通过 ICO 众筹得以开始发展。以太坊亦被称为“第二代的区块链平台”，仅次于比特币。目前为止，以太坊是被使用最多的区块链平台。\n\n![](1.png)\n\n以太币（ETH 或 Ξ）是以太坊的原生加密货币，目前是市值第二高的加密货币，仅次于比特币。\n\n## 以太坊特点\n\n1.  以太坊是 “世界计算机”，这代表它是一个开源的、全球分布的计算基础设施。\n2.  执行称为智能合约（smart contract）的程序。\n3.  使用区块链来同步和存储系统状态以及使用名为以太币（ether）的加密货币，以计量和约束执行资源成本。\n4.  本质是一个基于交易的状态机 (transaction-based state machine)。\n5.  以太坊平台使开发人员能够构建具有内置经济功能的强大去中心化应用程序（DApp）；在持续自我正常运行的同时，它还减少或消除了审查，第三方界面和交易对手风险。\n\n## 以太坊的组成部分\n\n![](2.png)\n\n### P2P 网络\n\n以太坊在以太坊主网络上运行，该网络可在 TCP 端口 30303 上寻址，并运行一个名为 ÐΞVp2p 的协议。\n\n### 交易（Transaction）\n\n以太坊交易是网络消息，其中包括发送者（sender），接收者（receiver），值（value） 和数据的有效载荷（payload）。\n\n### 以太坊虚拟机（EVM）\n\n以太坊状态转换由以太坊虚拟机（EVM）处理，这是一个执行字节码（机器语言指令）的 基于堆栈的虚拟机。\n\n### 数据库（Blockchain）\n\n以太坊的区块链作为数据库（通常是 Google 的 LevelDB）本地存储在每个节点上，包含 序列化后的交易和系统状态。\n\n### 客户端\n\n以太坊有几种可互操作的客户端软件实现，其中最突出的是 Go-Ethereum（Geth）和 Parity。\n\n## 以太坊中的重要概念\n\n### 账户（Account）\n\n账户包含地址，余额和随机数，以及可选的存储和代码的对象。\n\n*   普通账户（EOA），存储和代码均为空。\n*   合约账户（Contract），包含存储和代码。\n\n### 地址（Address）\n\n一般来说，代表一个 EOA 或合约，它可以在区块链上接收或发送交易， 更具体地说，它是 ECDSA 公钥的 keccak 散列的最右边的 160 位\n\n### 交易（Transaction）\n\n*   可以发送以太币和信息。\n*   向合约发送的交易可以调用合约代码，并以信息数据为函数参数。\n*   向空用户发送信息，可以自动生成以信息为代码块的合约账户。\n\n### gas\n\n以太坊用于执行智能合约的虚拟燃料， 以太坊虚拟机使用核算机制来衡量 gas 的消耗量并限制计算资源的消耗\n\n## 以太坊的货币\n\n以太坊的货币单位称为以太（ether），也可以表示为 ETH 或符号 Ξ\n\n*   以太币的发行规则：\n\n    1 、挖矿前（Pre-mine，Genesis）\n\n    2014 年 7 月 / 8 月间，为众筹大约发行了 7200 万以太币。这些币有的时候被称之为 “矿前”。众筹阶段之后，以太币每年的产量基本稳定，被限制不超过 7200 万的 25%。\n\n    2、挖矿产出（Mining）\n\n    *   区块奖励（block reward）\n    *   叔块奖励（uncle reward）\n    *   叔块引用奖励（uncle referencing reward）\n\n*   以太币产量未来的变化\n\n    以太坊出块机制从工作量证明（PoW）转换为股权证明（PoS）后，以太币的发行会有什么变化尚未有定论。股权证明机制将使用一个称为 Casper 的协议。在 Casper 协议下，以太币的发行率将大大低于工作量证明下幽灵（GHOST）协议下的发行率。\n\n## 以太坊的挖矿产出\n\n### 区块奖励（Block rewards）\n\n每产生一个新区块就会有一笔固定的奖励给矿工，初始是 5 个以太币，现在是 3 个。\n\n### 叔块奖励（Uncle rewards）\n\n有些区块被挖得稍晚一些，因此不能作为主区块链的组成部分。比特币称这类区块为 “孤块”，并且完全舍弃它们。但是，以太币称它们为 “叔块”（uncles），并且在之后的区块中，可以引用它们。如果叔块在之后的区块链中作为叔块被引用，每个叔块会为挖矿者产出区块奖励的 7/8。这被称之为叔块奖励。\n\n### 叔块引用奖励（Uncle referencing rewards）\n\n矿工每引用一个叔块，可以得到区块奖励的 1/32 作为奖励（最多引用两个叔块）。\n\n## 以太坊区块收入\n\n### 普通区块收入\n\n*   固定奖励（挖矿奖励），每个普通区块都有。\n*   区块内包含的所有程序的 gas 花费的总和。\n*   如果普通区块引用了叔块，每引用一个叔块可以得到固定奖励的 1/32\n\n### 叔块收入\n\n叔块收入只有一项，就是叔块奖励，计算公式为： 叔块奖励 = (叔块高度 + 8 – 引用叔块的区块高度) \\* 普通区块奖励 / 8。\n\n## 以太坊和图灵完备\n\n1936 年，英国数学家艾伦 · 图灵（Alan Turing）创建了一个计算机的数学模型，它由一个控制器、一个读写头和一根无限长的工作带组成。纸带起着存储的作用，被分成一个个的小方格（可以看成磁带）；读写头能够读取纸带上的信息，以及将运算结果写进纸带；控制器则负责根据程序对搜集到的信息进行处理。在每个时刻，机器头都要从当前纸带上读入一个方格信息，然后结合自己的内部状态查找程序表，根据程序输出信息到纸带方格上，并转换自己的内部状态，然后进行移动纸带。这样的机器称为图灵机。\n\n![](3.png)\n如果一个系统可以模拟任何图灵机，它就被定义为 “图灵完备”（Turing Complete）的。 这种系统称为通用图灵机（UTM）\n\n以太坊能够在称为以太坊虚拟机的状态机中执行存储程序，同时向内存读取和写入数据， 使其成为图灵完备系统，因此成为通用图灵机。考虑到有限存储器的限制，以太坊可以计 算任何可由任何图灵机计算的算法。简单来说，以太坊中支持循环语句，理论上可以运行 “无限循环” 的程序\n\n## 去中心化应用\n\n*   基于以太坊可以创建智能合约 (Smart Contract) 来构建去中心化应用 (Decentralized Application，简称为 DApp）\n*   以太坊的构想是成为 DApps 编程开发的平台\n*   DApp 至少由以下组成：\n    *   区块链上的智能合约\n    *   Web 前端用户界面\n\n## 以太坊应用\n\n*   基于以太坊创建新的加密货币（CryptoCurrency，这种能力是 2017 年各种 ICO 泛滥的技术动因）。\n*   基于以太坊创建域名注册系统、博彩系统。\n*   基于以太坊开发去中心化的游戏，比如 2017 年底红极一时的以太猫（CryptoKitties，最高单只猫售价高达 80W 美元)。\n\n## 代币（Token）\n\n*   代币（token）也称作通证，本意为 “令牌”，代表有所有权的资产、货币、权限等在区块链上的抽象。\n*   可替代性通证（fungible token）：指的是基于区块链技术发行的，互相可以替代的，可以接近无限拆分的 token。\n*   非同质通证（non-fungible token）： 指的是基于区块链技术发行的，唯一的，不可替代的，大多数情况下不可拆分的 token，如加密猫（CryptoKitties）。\n\n## 名词解释\n\n*   IP： Ethereum Improvement Proposals，以太坊改进建议。\n*   ERC：Ethereum Request for Comments 的缩写，以太坊征求意见。一些 EIP 被标记为 ERC，表示试图定义以太坊使用的特定标准的提议。\n*   EOA：External Owned Account，外部账户。由以太坊网络的人类用户创建的账户。\n*   Ethash：以太坊 1.0 的工作量证明算法。\n*   HD 钱包：使用分层确定性（HD protocol）密钥创建和转账协议（BIP32）的钱包。\n*   Keccak256：以太坊中使用的密码哈希函数。Keccak256 被标准化为 SHA-3。\n*   Nonce：在密码学中，术语 nonce 用于指代只能使用一次的值。以太坊使用两种类型的随机数，账户随机数和 POW 随机数。\n\n# 以太坊客户端\n\n\n## 什么是以太坊客户端\n\n以太坊客户端是一个软件应用程序，它实现以太坊规范并通过 p2p 网络与其他以太坊客户端进行通信。如果不同的以太坊客户端符合参考规范和标准化通信协议，则可以进行相互操作。\n\n以太坊是一个开源项目，由 “[以太坊黄皮书](https://ethereum.github.io/yellowpaper/paper.pdf \"以太坊黄皮书\")” 正式规范定义。除了各种以太坊改进提案之外，此正式规范还定义了以太坊客户端的标准行为，因为有了明确的正式规范，以太网客户端有了许多独立开发的软件实现，它们之间又可以彼此交互。\n\n![](4.png)\n\n## 基于以太坊规范的网络\n\n存在各种基于以太坊规范的网络，这些网络基本符合 “以太坊黄皮书” 中定义的形式规范，但它们之间可能相互也可能不相互操作。\n\n这些基于以太坊的网络中有：以太坊，以太坊经典，Ella，Expanse，Ubiq，Musicoin 等等。\n\n虽然大多数在协议级别兼容，但这些网络通常具有特殊要求，以太坊客户端软件的维护人员、需要进行微小更改、以支持每个网络的功能或属性。\n\n## 以太坊的多种客户端\n\n- go-ethereum (Go)：\n  官方推荐，开发使用最多， Geth 是由以太坊基金会积极开发的 Go 语言实现，因此被认为是以太坊客户端的 “官方” 实现。通常，每个基于以太坊的区块链都有自己的 Geth 实现\n- parity (Rust)： 最轻便客户端，在历次以太坊网络攻击中表现卓越。\n- cpp-ethereum (C++)\n- pyethapp (python)\n- ethereumjs (javascript)\n- EthereumJ / Harmony (Java)\n\n## JSON-RPC\n\n以太坊客户端提供了 API 和一组远程调用（RPC）命令，这些命令被编码为 JSON。这被称为 JSON-RPC API。本质上，JSON-RPC API 就是一个接口，允许编写的程序使用以太坊客户端作为网关，访问以太坊网络和链上数据。\n\n通常，RPC 接口作为一个 HTTP 服务，端口设定为 8545。出于安全原因，默认情况下，它仅限于接受来自 localhost 的连接。\n\n要访问 JSON-RPC API，可以使用编程语言编写的专用库，例如 JavaScript 的 web3.js，或者也可以手动构建 HTTP 请求并发送 / 接收 JSON 编码的请求。\n\n## 以太坊全节点\n\n全节点是整个主链的一个副本，存储并维护链上的所有数据，可以随时验证新区块的合法性，运行全节点将耗费巨大的成本，包括硬件资源和带宽。\n\n区块链的健康和扩展弹性，取决于具有许多独立操作和地理上分散的全节点。每个全节点都可以帮助其他新节点获取区块数据，并提供所有交易和合约的独立验证。\n\n以太坊开发不需要在实时网络（主网）上运行的全节点。可以使用测试网络的节点来代替，也可以用本地私链，或者使用服务商提供的基于云的以太坊客户端，这些几乎都可以执行所有操作。\n\n## 远程客户端和轻节点\n\n远程客户端：\n不存储区块链的本地副本或验证块和交易。这些客户端一般只提供钱包的功能，可以创建和广播交易。远程客户端可用于连接到现有网络，MetaMask 就是一个这样的客户端。\n\n轻节点：\n不保存链上的区块历史数据，只保存区块链当前的状态。轻节点可以对块和交易进行验证。\n\n### 全节点的优缺点\n\n- 优点\n    - 为以太坊网络的灵活性和抗审查性提供有力支持。\n    - 权威地验证所有交易。\n    - 可以直接与公共区块链上的任何合约交互。\n    - 可以离线查询区块链状态（帐户，合约等）。\n    - 可以直接把自己的合约部署到公共区块链中。\n- 缺点\n    - 需要巨大的硬件和带宽资源，而且会不断增长。\n    - 第一次下载往往需要几天才能完全同步。\n    - 必须及时维护、升级并保持在线状态以同步区块。。\n\n### 公共测试网络节点的优缺点\n\n- 优点\n    - 一个 testnet 节点需要同步和存储更少的数据，大约 10GB，具体取决于不同的网络\n    - 一个 testnet 节点一般可以在几个小时内完全同步\n    - 部署合约或进行交易只需要发送测试以太，可以从 “水龙头” 免费获得\n    - 测试网络是公共区块链，有许多其他用户和合约运行（区别于私链）\n- 缺点\n    - 测试网络上使用测试以太，它没有价值。因此，无法测试交易对手的安全性，因为没有任何利害关系\n    - 测试网络上的测试无法涵盖所有的真实主网特性。例如，交易费用虽然是发送交易所必需的，但由于 gas 免费，因此 testnet 上往往不会考虑。而且一般来说，测试网络不会像主网那样经常拥堵\n\n### 本地私链的优缺点\n\n- 优点\n    - 磁盘上几乎没有数据，也不同步别的数据，是一个完全 “干净” 的环境\n    - 无需获取测试以太，你可以任意分配以太，也可以随时自己挖矿获得\n    - 没有其他用户，也没有其他合约，没有任何外部干扰\n- 缺点\n    - 没有其他用户意味与公链的行为不同。发送的交易并不存在空间或交易顺序的竞争\n    - 除自己之外没有矿工意味着挖矿更容易预测，因此无法测试公链上发生的某些情况\n    - 没有其他合约，意味着你必须部署要测试的所有内容\n\n## 用 Geth 搭建以太坊私链\n\n一种是直接用源码安装，直接克隆 git 仓库，获取源代码的副本。\n\n```shell\ngit clone https://github.com/ethereum/go-ethereum.git\n```\n\n另一种是到官网直接下载对应系统的安装程序。\n\n查看`geth version`，确保在真正运行之前安装正常。\n\n### 启动节点同步\n\n安装好了 Geth，可以尝试运行一下它。执行下面的命令，geth 就会开始同步区块，并存储在当前目录下。这里的`--syncmode fast`参数表示会以 “快速” 模式同步区块。在这种模式下，只会下载每个区块头和区块体，但不会执行验证所有的交易，直到所有区块同步完毕再去获取一个系统当前的状态。这样就节省了很多交易验证的时间。\n\n```shell\n geth –datadir . --syncmode fast\n```\n\n如果想同步测试网络的区块，可以用下面的命令：\n\n```shell\n geth --testnet --datadir . --syncmode fast\n```\n\n`--testnet`这个参数会告诉 geth 启动并连接到最新的测试网络，测试网络的区块和交易数量会明显少于主网，所以会更快一点。但即使是用快速模式同步测试网络，也会需要几个小时的时间。\n\n### 搭建自己的私链\n\n因为公共网络的区块数量太多，同步耗时太长，为了方便快速了解 Geth，可以试着用它来搭一个只属于自己的私链。\n\n首先，需要创建网络的 “创世”（genesis）状态，这写在一个小小的 JSON 文件里（例如，将其命名为 genesis.json）：\n\n```json\n{\n    \"config\": {\n        \"chainId\": 15\n    },\n    \"difficulty\": \"2000\",\n    \"gasLimit\": \"2100000\",\n    \"alloc\": {\n        \"7df9a875a174b3bc565e6424a0050ebc1b2d1d82\": { \"balance\": \"300000\" },\n        \"f41c74c9ae680c1aa78f42e5647a62f353b7bdde\": { \"balance\": \"400000\" }\n    }\n}\n```\n\n要创建一条以它作为创世块的区块链，可以使用下面的命令：\n\n```shell\ngeth --datadir path/to/custom/data/folder init genesis.json\n```\n\n在当前目录下运行 geth，就会启动这条私链，注意要将 networked 设置为与创世块配置里的 chainId 一致。\n\n```shell\ngeth --datadir path/to/custom/data/folder --networkid 15\n```\n\n现在，节点正常启动，恭喜！已经成功启动了一条自己的私链。\n\n### Geth 控制台命令\n\nGeth Console 是一个交互式的 JavaScript 执行环境，里面内置了一些用来操作以太坊的 JavaScript 对象，可以直接调用这些对象来获取区块链上的相关信息。这些对象主要包括：\n\n- eth：主要包含对区块链进行访问和交互相关的方法；\n- net：主要包含查看 p2p 网络状态的方法；\n- admin：主要包含与管理节点相关的方法；\n- miner：主要包含挖矿相关的一些方法；\n- personal：包含账户管理的方法；\n- txpool：包含查看交易内存池的方法；\n- web3：包含以上所有对象，还包含一些通用方法\n  常用命令有：\n\n- personal.newAccount()：创建账户；\n- personal.unlockAccount()：解锁账户；\n- eth.accounts：列出系统中的账户；\n- eth.getBalance()：查看账户余额，返回值的单位是 Wei；\n- eth.blockNumber：列出当前区块高度；\n- eth.getTransaction()：获取交易信息；\n- eth.getBlock()：获取区块信息；\n- miner.start()：开始挖矿；\n- miner.stop()：停止挖矿；\n- web3.fromWei()：Wei 换算成以太币；\n- web3.toWei()：以太币换算成 Wei；\n- txpool.status：交易池中的状态；\n\n# 以太坊交易\n\n\n## 以太币单位\n\n![](5.png)\n\n*   以太坊的货币单位称为以太，也称为 ETH 或符号 Ξ 。\n*   ether 被细分为更小的单位，直到可能的最小单位，称为 wei；1 ether = 10^18 wei 。\n*   以太的值总是在以太坊内部表示为以 wei 表示的无符号整数值。\n*   以太的各种单位都有一个使用国际单位制（SI）的科学名称，和一个口语名称。\n\n## 以太坊账户\n\n### 私钥、公钥和地址\n\n*   私钥（Private Key）：以太坊私钥是一个 256 位的随机数，用于发送以太的交易中创建签名来证明自己对资金的所有权\n\n*   公钥（Public Key）：公钥是由私钥通过椭圆曲线加密 secp256k1 算法单向生成的 512 位 （64 字节）数\n\n*   地址（Address）：地址是由公钥的 Keccak-256 单向哈希，取最后 20 个字节（160 位） 派生出来的标识符\n\n### 以太坊账户类型\n\n以太坊账户分为外部账户 (Externally owned account, EOA)和 合约账户 (Contract accounts)。\n![](6.png)\n\n#### EOA\n\n外部账户：普通用户用私钥控制的账户\n\n*   有对应的以太币余额\n*   可发送交易（转币或触发合约代码）\n*   由用户私钥控制\n*   没有关联代码\n\n#### 合约账户\n\n一种拥有合约代码的账户，它不属于任何人，也没有私钥与之对应。\n\n*   有对应的以太币余额\n*   有关联代码\n*   由代码控制\n*   可通过交易或来自其它合约的调用消息来触发代码执行\n*   执行代码时可以操作自己的存储空间，也可以调用其它合约\n\n## 以太坊钱包\n\n以太坊钱包是我们进入以太坊系统的门户。它包含了私钥，可以代表我们创建和广播交易，常见得钱包有：\n\n*   MetaMask：一个浏览器扩展钱包，可在浏览器中运行。下面例子中使用的是 MetaMask。\n\n*   Jaxx：一款多平台、多币种的钱包，可在各种操作系统上运行，包括 Android，iOS，Windows，Mac 和 Linux。\n\n*   MyEtherWallet（MEW）：一个基于 web 的钱包，可以在任何浏览器中运行。\n\n*   Emerald Wallet：旨在与 ETC 配合使用，但与其他基于以太坊的区块链兼容。\n\n## 交易\n\n以太坊中的交易是一个签名的数据包，由 EOA 发送到另一个账户，由以太坊网络传输，并被序列化后记录在以太坊区块链上，并且以太坊是一个全局单例状态机，交易是唯一可以触发状态更改或导致合约在 EVM 中执行的事物。\n\n数据包里包含：\n\n*   nonce：由发起人 EOA 发出的序列号，用于防止交易消息重播\n*   gas price：交易发起人愿意支付的 gas 单价（wei）\n*   start gas：交易发起人愿意支付的最大 gas 量\n*   to：目的以太坊地址\n*   value：要发送到目的地的以太数量\n*   data：可变长度二进制数据负载（payload）\n*   v,r,s：发起人 EOA 的 ECDSA 签名的三个组成部分\n\n交易消息的结构使用递归长度前缀（RLP）编码方案进行序列化，该方案专为在以太坊中准确和字节完美的数据序列化而创建。\n\n### nonce\n\n对于 EOA 账户，nonce 等于从这个账户地址发送的交易数。 对于合约账户，nonce 等于这个这个账户中创建的合约数。\n\nnonce 值还用于防止错误计算账户余额。nonce 强制来自任何地址的交易按顺序处理，没有间隔，无论节点接收它们的顺序如何。使用 nonce 确保所有节点计算相同的余额和正确的序列交易，等同于用于防止比特币 “双重支付”（“重放攻击”）的机制。\n\n### gas\n\n当交易或消息触发 EVM 运行时，每个指令都会在网络的每个节点上执行。对于每个执行的操作，都存在固定的成本，这个成本用一定量的 gas 表示。发起交易时，需要从执行代码的矿工那里用以太币购买 gas。\n\ngas 与消耗的系统资源对应，这是具有自然成本的。因此在设计上 gas 和 ether 有意地解耦，消耗的 gas 数量代表了对资源的占用，而对应的交易费用则还跟 gas 对以太的单价有关。这两者是由自由市场调节的：gas 的价格实际上是由矿工决定的，他们可以拒绝处理 gas 价格低于最低限额的交易。我们不需要专门购买 gas ，只需将以太币添加到帐户即可，客户端在发送交易时会自动用以太币购买 gas。而以太币本身的价格通常由于市场力量而波动。\n\n### gas 的计算\n\n在发起交易时发起人会先设置一个`gas limit`，代表消耗 gas 得上限，相当于押金。 实际支付的 gas 数量是执行过程中消耗的 gas （gasUsed），`gas limit` 中剩余的部分会返回给发送人。最终支付的 gas 费用是 gasUsed 对应的以太币费用，单价由设定的 gasPrice 而定。\n\n最终支付费用 `totalCost = gasPrice * gasUsed` totalCost 会作为交易手续费（Tx fee）支付给矿工\n\n### 交易的接收者：to\n\n`to`字段是一个 20 字节的以太坊地址，可以是 EOA 也可以是合约地址。\n\n在以太坊中，任何 20 字节的值都被认为是有效的，以太坊没有做验证。如果 20 字节值没有对应的地址或者是不存在的合约，交易也是有效的，但是以太坊会销毁发送的以太，使其永远无法访问。\n\n### 交易的 value 和 data\n\n`value` 和 `data`是交易主要的“有效负载”，它们可以有 4 中组合。\n\n*   仅有 value： 表示一笔以太的付款。\n*   仅有 data： 一般表示合约调用。\n*   同时有 value 和 data： 进行合约调用，同时忘合约中发送以太。\n*   既没有 value 也没有 data： 只是在浪费 gas，但它是有效的。\n\n## 特殊交易：创建（部署）合约\n\n有一种特殊的交易，具有数据负载且没有 value，那就是一个创建新合约的交易。这个交易的`to`地址是一个特殊的地址，即零地址： 0x0。该地址既不代表 EOA 也不代表合约。它永远不会花费以太或发起交易，它仅用作目的地，具有特殊含义 “创建合约”。\n\n虽然零地址仅用于合同注册，但它有时会收到来自各种地址的付款。 这种情况要么是偶然误操作，导致失去以太；要么是故意销毁以太。\n\n# 以太坊虚拟机 (EVM)\n\n## 以太坊虚拟机 (EVM) 简介\n\n以太坊虚拟机（ EVM ）是`智能合约`的运行环境， 作为区块验证协议的一部分，参与网络的每个节点都会运行 EVM。他们会检查正在验证的块中列出的交易，并运行由 EVM 中的交易触发的代码。\n\nEVM 不仅是沙盒封装的，而且是完全隔离的，也就是说在 EVM 中运行的代码是无法访问网络、文件系统和其他进程的， 甚至智能合约之间的访问也是受限的。\n\n合约以字节码的格式（EVM bytecode）存在于区块链上， 合约通常以高级语言（solidity）编写，通过 EVM 编译器编译为字节码，最终通过客户端上载部署到区块链网络中。\n\n## EVM的工作原理\n\n### 代码编译和部署\n\n在以太坊上开发智能合约时，开发者使用Solidity等高级编程语言编写合约代码，并通过编译器将其转换为EVM能够理解和执行的字节码。\n\n编译得到的字节码会被写入以太坊区块链，并分配一个唯一的合约地址。合约地址用于唯一标识合约在区块链上的存储位置。\n\n### 交易执行\n\n当一个合约交易被广播到以太坊网络时，EVM的节点会接收到该交易，并进行验证。验证通过后，EVM开始执行交易中的智能合约代码。\n\n### EVM执行环境\n\nEVM提供了一个独立的执行环境，每个交易都在自己的环境中执行。EVM的执行环境由以下几个组成部分：\n\n![](7.png)\n\n*   栈（Stack）\n\n    EVM 使用栈来存储和处理数据。栈是一种后进先出（LIFO）结构，用于执行指令时的操作数栈和返回值栈。\n\n    存放部分局部值类型变量，几乎免费使用的内存，但有数量限制。\n\n*   内存（Memory）\n\n    EVM 提供了一块可扩展的内存区域，用于临时存储和操作数据。智能合约可以通过读写内存来进行复杂的计算和数据处理。\n\n    每一次消息调用，合约会临时获取一块干净的内存空间，生命周期仅为整个方法执行期间，函数调用后回收，因为仅保存临时变量，故读写 gas 开销较小。\n\n*   存储（Storage）\n    EVM 提供了持久化的存储空间，用于永久保存合约的状态和数据。这是一个将 256 位字映射到 256 位字的 key-value 存储区，可以理解为合约的数据库，每个合约都有自己的存储空间。\n\n    由于会永久保存合约状态变量，所以读写的 gas 开销也最大。\n\n*   指令集（Instruction Set）\n\n    EVM 定义了一套指令集，用于执行智能合约的操作和功能。指令集包括基本的算术运算、逻辑运算、存储读写操作等，也可以做到有条件和无条件跳转。所有的指令都是针对 \"256 位的字（word）“这个基本的数据类型来进行操作。\n\n### 执行过程\n\nEVM的执行过程可以简单概括为以下几个步骤：\n\n解析交易：EVM首先解析交易数据，提取出合约地址、调用参数等信息。\n\n创建执行环境：EVM为该交易创建一个独立的执行环境，包括栈、存储和内存空间。\n\n执行合约代码：EVM按照合约代码的指令顺序逐条执行，通过操作码来执行各种操作，如计算、存储、跳转等。\n\n栈操作：EVM使用栈来保存和处理数据。在执行过程中，可以将数据压入栈顶、从栈顶弹出数据，进行栈上计算操作。\n\n存储操作：EVM提供了持久化的存储空间Storage，可以读取和写入合约的状态和数据。通过存储操作码，可以将数据存储到存储空间或从存储空间中读取数据。\n\n内存操作：EVM的临时内存空间可用于临时存储数据。通过内存操作码，可以将数据加载到内存中或从内存中读取数据。\n\n跳转操作：EVM支持跳转操作，可以根据条件或无条件地改变代码执行的流程，实现条件判断、循环等控制结构。\n\n异常处理：在执行过程中，如果遇到错误或异常情况，EVM会停止执行并回滚状态，确保合约的执行不会导致不一致的状态。\n\n结束执行：当合约代码执行完毕或遇到返回指令时，EVM将结束执行，并将执行结果返回给调用者。\n\n# 编写智能合约\n\n\n## MetaMask 钱包\n\n以太坊钱包是我们进入以太坊系统的门户。它包含了私钥，可以代表我们创建和广播交易。本文我们使用 MetaMask 钱包。 MetaMask 钱包可以在谷歌浏览器插件中安装。\n\n### 添加测试地址\n\n在以太坊主网上进行交易和执行智能合约需要支付 gas 费用，这些费用在开发和测试阶段可能会累积成相当大的开销。 因此，在开发和测试阶段一般都是使用太坊测试网络。这些测试网络通常提供免费的测试以太币。\n\n这里有一些以太坊测试地址：<https://talk.comunion.org/d/650-comunion-rpc-erc-20>\n\n本文选择 Avalanch 测试链：\n\n    Avalanch Avalanch - Avalanch Testent\n    网络名称：Avalanche Fuji Testnet\n    新增 RPC URL：https://api.avax-test.network/ext/bc/C/rpc\n    Chain ID：43113\n    货币符号：AVAX\n    区块链浏览器 URL：https://cchain.explorer.avax-test.network\n    水龙头地址：https://faucet.avax.network/\n\n### 领取测试币\n\n进入测试网络的水龙头地址`https://faucet.avax.network/`中，连接 MetaMask\n\n![](8.png)\n\n连接到 MetaMask 后，地址栏中会显示钱包的地址，点击`Request 2 AVAX`，等待交易完成，钱包地址中会有 2 AVAX 代币。\n![](9.png)\n\n### MateMask 中添加测试网络。\n\n点击下面的`将子网添加到钱包`，并将钱包切换到测试网络。\n![](10.png)\n\n完成后，可以在钱包查看测试网中的账户信息\n![](11.png)\n\n## 在 Remix 上构建简单的水龙头合约\n\nRemix 是一个在线用于构建和部署以太坊智能合约的开发工具和平台。它提供了一个用户友好的界面和功能强大的集成开发环境（IDE），帮助开发者更轻松地编写、测试和部署智能合约。\n\nRemix 集成了 Solidity 编译器，可以将 Solidity 合约代码编译成 EVM（以太坊虚拟机）字节码。开发者可以使用 Remix 提供的编译器生成合约的字节码和 ABI（应用二进制接口），以便在以太坊上部署和调用合约。\n\nRemix 的地址：<https://remix.ethereum.org>\n\n![](12.png)\n\n### 编写水龙头合约\n\n水龙头是一件相对简单的事情：它会向任何要求的地址发出以太。\n\n在`contracts`目录下，新建一个`Faucet.sol`文件\n\n![](13.png)\n\n```java\n// Version of Solidity compiler this program was written for\npragma solidity ^0.4.19;\n// Our first contract is a faucet!\ncontract Faucet {\n    // Give out ether to anyone who asks\n    function withdraw(uint withdraw_amount) public {\n        // Limit withdrawal amount\n        require(withdraw_amount <= 100000000000000000);\n        // Send the amount to the address that requested it\n        msg.sender.transfer(withdraw_amount);\n    }\n    // Accept any incoming amount\n    function () public payable {}\n}\n\n```\n\n`contract Faucet {` ： 该行声明了一个合约对象，类似于其他面向对象语言中的类声明\n\n`function withdraw(uint withdraw_amount) public {`： 该函数名为 withdraw，它接受一个名为 withdraw\\_amount 的无符号整数（uint）参数。它被声明为公共函数，这意味着它可以被其他合约调用\n\n`require(withdraw_amount <= 100000000000000000);`： 该行设定提款限额。\n\n使用内置的 Solidity 函数 require 来测试一个前提条件，即 withdraw\\_amount 小于或等于 100000000000000000 wei，这是 ether 的 基本单位，相当于 0.1 ether。\n\n如果使用大于该数量的 withdraw\\_amount 调用 withdraw 函数，则此处的 require 函数将导致合约执行停止并因异常而失败\n\n`msg.sender.transfer(withdraw_amount);`： 该行是实际提现。\n\n*   msg 对象：所有合约都可以访问的输入之一，它表示触发此合约执行的交易\n*   sender 属性：交易的发件人地址\n*   transfer 函数：是一个内置函数，它将以太从合约传递到调用它的地址。向后读，这意味着将以太转移到触发此合约执行的 msg 的发送者\n*   transfer 函数将金额作为其唯一参数。我们将 withdraw\\_amount 值作为参数传递给上面几行声明的 withdraw 函数\n\n`function () public payable {}`： 此函数是所谓的 “回退” 或默认函数，如果触发合约的交易未命名合约中的任何已声明函数或任何函数或未包含数据，则调用此函数\n\n### 编译水龙头合约\n\n现在我们有了第一个示例合约，需要使用 Solidity 编译器将 Solidity 代码转换为 EVM 字节码，以便它可以由 EVM 执行。\n\n在编译页面，首先要选择与代码中`pragma solidity ^0.4.19`相同的 solidity 版本。然后点击`Compile Faucet.sol`编译程序。\n\n![](14.png)\n\n### 在区块链上创建合约\n\n我们写了合约并把它编译成字节码。现在，我们需要在以太坊区块链上 “注册” 合约。我们将使用测试网来测试我们的合约。\n\n在区块链上注册合约涉及创建一个特殊交易，其目的地是一个 “零地址”，也就是地址为：`0x0000000000000000000000000000000000000000`。零地址是一个特殊地址，告诉以太坊区块链我们想要注册合约。不过我们不需要手动输入这么多个 0，Remix IDE 将为我们处理所有这些，并将交易发送到 MetaMask，由钱包账户确认提交。\n\n将运行环境关联到 MetaMask 上的测试链，然后点击 `Deploy`部署合约\n![](15.png)\n\n部署完成后会生成一个合约地址。同时包含了一些合约的其他信息，像合约地址的余额：`balance`，调用方法名`withdraw`等。\n![](16.png)\n\n## 与合约交互\n\n以太坊合约是控制资金的程序，它在称为 EVM 的虚拟机内运行。它们由特殊交易创建，该交易提交其字节码以记录在区块链上。一旦他们在区块链上创建，他们就有了一个以太坊地址，就像钱包一样。只要有人将某个交易发送到合约地址，就会导致合约在 EVM 中运行，并将该合约作为其输入。\n\n发送到合约地址的交易可能包含 ether 或数据或两者。如果它们含有 ether，则将其 “存入” 合约余额。如果它们包含数据，则数据可以在合约中指定命名函数并调用它，将参数传递给函数\n\n### 资助合约\n\n目前，合约在其历史记录中只有一个交易：合约创建交易。\n\n合约也还没有以太（零余额）。那是因为我们没有在创建交易中向合约发送任何以太。\n\n我们可以给合约发一些以太，打开 MetaMask，给合约的地址发送以太，就像发送给其他任何以太坊地址一样。\n\n![](17.png)\n\n当交易完成后，再看合约的余额。\n\n![](18.png)\n\n### 调用合约\n\n接下来，让我们从水龙头中提取一些资金。要提现，我们必须构造一个调用 `withdraw` 函数的交易，并将 withdraw\\_amount 参数传递给它。为了使事情变得简单，Remix 将为我们构建该交易，并由MetaMask发送交易。\n\n我们输入要体现的金额，然后点击`withdraw`，表示调用withdraw方法。\n![](19.png)\n\n该交易导致合约在 EVM 内部运行，当 EVM 运行水龙头合约的提现功能时，首先它调用 require 函数并验证我们的金额小于或等于允许的最大提现 0.1 以太；然后它调用 transfer 函数向我们发送以太，运行转账功能会产生一个内部交易，从合约的余额中withdraw\\_amount的以太币存入我们的钱包地址；\n\n当交易完成后，可以看到合约中的余额减少了。并且钱包中会多一条交易记录\n\n![](20.png)\n\n![](21.png)\n\n我们可以点击`在区块浏览器上查看`，查看这条交易的详细信息。\n\n![](22.png)迟到\n","tags":["web3","以太坊"],"categories":["以太坊"]},{"title":"从CPU聊到Java内存模型","url":"/2023/03/30/jmm/","content":"当谈到`并发编程`时，Java 内存模型（Java Memory Model，简称 JMM）是一个关键概念。它定义了线程如何与主内存交互以及如何在自己的工作内存中存储数据。理解和遵守 Java 内存模型对于编写正确且高效的多线程程序至关重要。\n\n`注意：`Java 内存模型并不是 JVM 内存模型。JVM 内存模型指的是 JVM 内存是如何划分的，比如我们平常所说的堆、栈、方法区等。而 Java 内存模型定义了 Java 语言如何与内存进行交互，具体地说是 Java 语言运行时的变量，如何与我们的硬件内存进行交互。\n\n## 从 CPU 说起\n\n### 缓存一致性\n\n在计算机中 CPU 负责计算，内存负责存储，每次运算 CPU 需要从内存中获取数据。但是 CUP 的运算速度远远大于内存的速度，这样会出现每次计算时 CPU 等待内存的情况。\n\n为了弥补 CPU 和内存之间存在的速度差异，因此引入了 CPU 高速缓存，CPU 高速缓存介于 CPU 和内存之间。每次运算先从内存读取到 CPU 高速缓存中，CPU 再从 CPU 高速缓存中读取。\n\n下面是我现在的使用的电脑，有三级缓存。\n![](1.png)\n\n随着技术的发展，出现了多核 CPU，进一步提升了 CPU 的计算能力，但同时也引入了新的问题：缓存一致性。在多 CPU 下，每个 CPU 共享内存，同时每个 CPU 又有自己的高速缓存，如果多个 CPU 同时处理一块主内存区域的数据时，那该如何保证数据的正确。比如下面这段代码\n\n```java\ni = i + 1;\n```\n\n假设 i 初始值为 0，按照正常的逻辑 ，2 个 CPU 运算完成后 i 的值会是 2，但是因为高速缓存的存在，会有下面的运算过程。\n\n- CPU1 读取 i 的初始值放到 CPU1 高速缓存中，\n- CPU2 读取 i 的初始值放到 CPU2 高速缓存中，\n- CPU1 进行运算，得出结果 1，运算结束，写回内存，此时内存 i 的值为 1。\n- CPU2 进行运算，得出结果 1，运算结束，写回内存，此时内存 i 的值为 1。\n\n那么，如何保证数据的一致性呢？答案是：缓存一致性协议。在多 CPU 系统中，一种用来保持多个高速缓存之间，以及高速缓存与主存储器之间数据一致的机制。\n\n![](2.png)\n\n在不同的 CPU 中，会使用不同的缓存一致性协议。例如 奔腾系列的 CPU 中使用的是 MESI 协议， AMD 系列 CPU 中使用的是 MOSEI 协议，Intel 的 core i7 使用 MESIF 协议。\n\n### 处理器优化和指令重排序\n\n为了使 CPU 内部运算单元被充分利用，CPU 会对输入的代码进行乱序执行（Out-Of-Order Execution）优化，CPU 会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，`但不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致`。\n\n![](3.png)\n\n如果是在单核处理器上运行，这是没有问题的。但是在多核处理器下，如果存在一个核的计算任务依赖另一个核的计算任务的中间结果，而且对相关数据读写没做任何防护措施，那么其顺序性并不能靠代码的先后顺序来保证。\n\n![](4.png)\n\n除了 CPU 会对代码进行优化处理，很多现代编程语言的编译器也会做类似的优化，比如像 Java 的即时编译器(JIT)会做`指令重排序`。\n\n处理器优化其实也是重排序的一种类型，重排序可以分为三种类型：\n\n- 编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。\n- 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。\n- 内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。\n\n![](5.png)\n\n## 并发编程的问题\n\n并发编程的三个特点：`可见性`、`有序性`、`原子性`。如果从更深层次看这三个问题，其实就是上面讲的`缓存一致性`、`处理器优化`、`指令重排序`造成的。\n\n缓存一致性问题其实就是可见性问题，处理器优化可能会造成原子性问题，指令重排序会造成有序性问题。\n\n了解过 JVM 得都清楚，JVM 运行时内存区域是分片的，分为栈、堆等，其实这些都是 JVM 定义的逻辑概念。在传统的硬件内存架构中是没有栈和堆这种概念。从下图中可以看出栈和堆既存在于高速缓存中又存在于主内存中。\n\n![](6.png)\n\nJava 一直秉持着「Write Once, Run Anywhere」，即一次编译哪里都可以运行的理念。为了达到这个目地必须要解决上面这些问题，Java 定义出了一套内存模型， 规范内存的读写操作。\n\n## Java 内存模型\n\nJava 内存模型用于屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台都能达到一致的内存访问效果。\n\nJava 内存模型定义了程序中各个变量的访问规则，即在 Java 虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。这里说的变量包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与方法参数。因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。\n\n### 主内存和工作内存\n\nJava 内存模型规定所有的变量都存储在主内存（Main Memory）中。每条线程还有自己的工作内存（Working Memory），工作内存中保留了该线程使用到的变量的主内存的副本。\n\n工作内存是 JMM 的一个抽象概念，并不真实存在，它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。\n\n线程对变量的操作必须是在工作内存中，不能直接操作主内存。不同的线程间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。\n\n![](7.png)\n\n### 内存间的交互\n\n关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存，以及如何从工作内存同步回主内存的细节，Java 内存模型定义了 8 种操作来完成。Java 虚拟机实现的时候必须保证下面提及的每一种操作都是原子的、不可再分的。\n\n- `lock`（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。\n- `unlock`（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。\n- `read`（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的 load 动作使用。\n- `load`（载入）：作用于工作内存的变量，它把 read 操作从主内存中得到的变量值放入工作内存的变量副本中。\n- `use`（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。\n- `assign`（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。\n- `store`（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存中，以便随后的 write 操作使用。\n- `write`（写入）：作用于主内存的变量，它把 store 操作从工作内存中得到的变量的值放入主内存的变量中。\n\nJMM 还规定了上述 8 种基本操作，需要满足以下规则：\n\n有关变量拷贝过程的规则:\n\n- read 和 load 必须成对出现；store 和 write 必须成对出现。即不允许一个变量从主内存读取了但工作内存不接受，或从工作内存发起回写了但主内存不接受的情况出现。\n- 不允许一个线程丢弃它的最近 assign 的操作，即变量在工作内存中改变了之后必须把变化同步到主内存中。\n- 不允许一个线程无原因的（没有发生过任何 assign 操作）把数据从工作内存同步回主内存中。\n- 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load 或 assign ）的变量。换句话说，就是对一个变量实施 use 和 store 操作之前，必须先执行过了 load 或 assign 操作。\n\n有关加锁的规则:\n\n- 一个变量在同一个时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一条线程重复执行多次，多次执行 lock 后，只有执行相同次数的 unlock 操作，变量才会被解锁。所以 lock 和 unlock 必须成对出现。\n- 如果对一个变量执行 lock 操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行 load 或 assign 操作初始化变量的值。\n- 如果一个变量事先没有被 lock 操作锁定，则不允许对它执行 unlock 操作，也不允许去 unlock 一个被其他线程锁定的变量。\n- 对一个变量执行 unlock 操作之前，必须先把此变量同步到主内存中（执行 store 和 write 操作）\n\n![](8.png)\n\n一个变量从主内存拷贝到工作内存，再从工作内存同步回主内存的流程为：\n\n```\n|主内存| -> read -> load -> |工作内存| -> use -> |Java线程| -> assign -> |工作内存| -> store -> write -> |主内存|\n```\n\n### 可见性和有序性问题\n\n在上图中，Java 中每个线程只能操作自己得工作内存，这样就有可能产生可见性问题。\n\n对于在主内存中的变量 A，不同线程中的工作内存中有着不同得副本 A1,A2,A3。不同线程的`read`和`load`、`store`和`write`不一定是连续的，中间可以插入其他命令，Java 只能保证 read 和 load、store 和 write 的执行`对于一个线程而言是连续的，但是并不保证不同线程的 read 和 load、store 和 write 的执行是连续的`。\n\n比如下图中：\n\n![](9.png)\n\n两个线程 A、B，其中 A 写入共享变量，B 读取变量。 假设 A 先写。B 再读取，按照正常得逻辑应该是`storeA -> writeA -> readB -> loadB`。但是 Java 并不能保证不同线程的执行是连续的，可能得会有这样的顺序`storeA -> readB -> writeA -> load`，在 A 还没写完时，B 已经读取了共享变量得旧值。\n\n通过上述的分析可以发现，`可见性问题的本身，也是由于不同线程之间的执行顺序得不到保证导致的`，因此可以将它的解决和有序性合并，即对 Java 一些指令的操作顺序进行限制，这样既保证了有序性，又解决了可见性。\n\n### Happens-Before 原则\n\nHappens-Before 规则保证：`前面的操作的结果对后面的操作一定是可见的`。\n\nHappens-Before 规则本质上是一种顺序约束规范，用来约束编译器的优化行为。就是说，为了执行效率，我们允许编译器的优化行为，但是为了保证程序运行的正确性，我们要求编译器优化后需要满足 Happens-Before 规则。\n\n根据类别，可以将 Happens-Before 规则分为了以下 4 类：\n\n操作的顺序：\n\n- 程序顺序规则： 如果代码中操作 A 在操作 B 之前，那么同一个线程中 A 操作一定在 B 操作前执行，即在本线程内观察，所有操作都是有序的。\n- 传递性： 在同一个线程中，如果 A 先于 B ，B 先于 C 那么 A 必然先于 C。\n\n锁和 volatile：\n\n- 监视器锁规则： 监视器锁的解锁操作必须在同一个监视器锁的加锁操作前执行。\n- volatile 变量规则： 对 volatile 变量的写操作必须在对该变量的读操作前执行，保证时刻读取到这个变量的最新值。\n\n线程和中断：\n\n- 线程启动规则： Thread#start() 方法一定先于该线程中执行的操作。\n- 线程结束规则： 线程的所有操作先于线程的终结。\n- 中断规则： 假设有线程 A，其他线程 interrupt A 的操作先于检测 A 线程是否中断的操作，即对一个线程的 interrupt() 操作和 interrupted() 等检测中断的操作同时发生，那么 interrupt() 先执行。\n\n对象生命周期相关：\n\n- 终结器规则： 对象的构造函数执行先于 finalize() 方法。\n\n根据 Happens-Before 原则，要确保上图中得问题能够正常运行，只要在共享变量上加个`volatile`即可。\n\n### 内存屏障\n\nJava 底层是怎么实现这些规则来保证有序性和可见性？ 通过内存屏障（memory barrier）。\n\n内存屏障是一种 CPU 指令，用来禁止处理器指令发生重排序。常见有 4 种屏障：\n\n- LoadLoad 屏障 - 对于这样的语句`Load1; LoadLoad; Load2`，在 Load2 及后续读取操作要读取的数据被访问前，保证 Load1 要读取的数据被读取完毕。\n- StoreStore 屏障 - 对于这样的语句 `Store1; StoreStore; Store2`，在 Store2 及后续写入操作执行前，保证 Store1 的写入操作对其它处理器可见。\n- LoadStore 屏障 - 对于这样的语句 `Load1; LoadStore; Store2`，在 Store2 及后续写入操作被执行前，保证 Load1 要读取的数据被读取完毕。\n- StoreLoad 屏障 - 对于这样的语句 `Store1; StoreLoad; Load2`，在 Load2 及后续所有读取操作执行前，保证 Store1 的写入对所有处理器可见。它的开销是四种屏障中最大的（冲刷写缓冲器，清空无效化队列）。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。\n\n比如下面这段代码：\n\n```java\npublic class VolatileTest {\n    private volatile static boolean flag = false;\n\n    public static void main(String[] args) {\n        long i = 0L;\n        flag = true;\n        while (!flag) {\n            i++;\n        }\n        System.out.println(\"count = \" + i);\n        flag = true;\n    }\n```\n\n编译成 CPU 汇编指令后，被`volatile`修饰得flag变量在进行写操作时会有一个`lock`指令\n\n![](10.png)\n\n在 Intel CPU 中`lock`指令功能如下：\n\n- 被修饰的汇编指令成为“原子的”\n- 与被修饰的汇编指令一起提供`内存屏障`效果\n\n### Java 语言级别的处理\n\n上面说的这些都是 Java 底层的处理逻辑，我们真正在使用 Java 时，并不需要关心底层的编译器优化、缓存一致性等问题，Java 已经提供了关键字来处理并发安全问题。。所以，`Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用`。\n\nJava 语言级别中来解决要解决原子性、有序性和一致性的问题的方法。\n\n#### 原子性\n\n使用`synchronized`来保证方法和代码块内的操作是原子性的。\n\n#### 可见性\n\n`volatile`关键字其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在`每次是用之前都从主内存刷新`。因此，可以使用 volatile 来保证多线程操作时变量的可见性。\n\n另外，synchronized 和 final 两个关键字也可以实现可见性。只不过实现方式不同。\n\n#### 有序性\n\n`volatile` 关键字会禁止指令重排。`synchronized` 关键字保证同一时刻只允许一条线程操作。\n\n### 参考\n\n- https://dunwu.github.io/javacore/pages/d4e06f\n- https://bbs.huaweicloud.com/blogs/338476\n- https://github.com/TangBean/Java-Concurrency-in-Practice/blob/master/Ch0-Java并发编程基础/00-Java内存模型.md\n\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"SkyWalking，分布式链路追踪","url":"/2023/02/25/26SkyWalking/","content":"随着业务的发展，软件架构也越来越复杂，为了适应海量用户高并发请求，系统中的组件也逐渐的变为分布式，单体服务变为微服务、缓存变为分布式缓存、组件通信变为分布式消息。\n\n系统进行交互时，一个请求往往需要调用多个服务，当需要排查问题时，搞清楚服务之间的调用关系，服务与服务的调用顺序就变得重要起来。\n\n![](1.png)\n\n\n## 什么是分布式链路追踪\n\n分布式链路追踪就是将一次分布式请求还原成调用链路，将一次分布式请求的调用情况集中展示，比如各个服务节点上的耗时、请求具体到达哪台机器上、每个服务节点的请求状态等等。\n\n\n![](2.png)\n\n\n链路追踪最早可以追溯到谷歌的 Dapper 系统，但是 Dapper 链路追踪系统并没有开源，不过谷歌发表了一篇论文：《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》，讲述了分布式链路追踪的理论和 Dapper 的设计思想，特别是微服务架构中链路追踪的概念、数据表示、埋点、传递、收集、存储与展示等技术细节。\n\nDapper 中有几个关键的技术点来表示链路的信息：Trace、Span、Annotations。\n\n### Trace\n\nTrace 表示一次请求经过所有服务的路径。用一个全局唯一的 traceid 来标识。\n\n### Span\n\nSpan 用来表示父子关系，同一层级 parent id 相同，span id 不同，span id 从小到大表示请求的顺序。\n\n### Annotations\n\nAnnotations 用于用户自定义事件，用来辅助定位问题。\n通常包含四个注解信息：\n\ncs：Client Start，表示客户端发起请求；\n\nsr：ServerReceived，表示服务端收到请求；\n\nss：Server Send，表示服务端完成处理，并将结果发送给客户端；\n\ncr：ClientReceived，表示客户端获取到服务端返回信息；\n\n![](3.png)\n\n### 采样和存储\n\n为了减少性能消耗，避免存储资源的浪费，dapper 并不会上报所有的 span 数据，而是使用采样的方式。举个例子，每秒有 1000 个请求访问系统，如果设置采样率为 1/1000，那么只会上报一个请求到存储端。\n\n链路中的 span 数据经过收集和上报后会集中存储在一个地方，Dapper 使用了 BigTable 数据仓库，常用的存储还有 ElasticSearch, HBase, In-memory DB 等。\n\n目前业界的链路追踪系统，如 Twitter 的 Zipkin，Uber 的 Jaeger，阿里的鹰眼，美团的 Mtrace 以及本文介绍的 SkyWalking，大多数都是受谷歌 Dapper 的启发。\n\n## SkyWalking\n\nSkyWalking 是一个优秀的国产开源 APM（Application Performance Management） 组件，是一个对分布式应用程序集群的业务运行情况进行追踪、告警和分析的系统。2015 年由个人吴晟开源 ， 2017 年加入 Apache 孵化器。\n\nSkyWalking 支持 SpringBoot、SpringCloud、dubbo 集成，代码无侵入，通信方式采用 GRPC，性能较好，实现方式是 探针，支持告警，支持 JVM 监控，支持全局调用统计等等，功能较完善。\n\nSkyWalking 的核心是数据分析和度量结果的存储平台，通过 HTTP 或 gRPC 方式向 SkyWalking Collecter 提交分析和度量数据。\n\n### SkyWalking 架构\n\n![](4.png)\n\nSkyWalking Collecter 对数据进行分析和聚合，存储到 Elasticsearch、H2、MySQL、TiDB 等其一即可，最后可以通过 SkyWalking UI 的可视化界面对最终的结果进行查看。\n\nSkywalking 支持从多个来源和多种格式收集数据：多种语言的 Skywalking Agent 、Zipkin v1/v2 、Istio 勘测、Envoy 度量等数据格式。\n\n在上面的架构图中我们需要关注的只有 SkyWalking Collecter、SkyWalking UI 和 存储设备，SkyWalking Collecter、SkyWalking UI 官方下载安装包内已包含，最终我们只需考虑存储设备即可。\n\n### 安装\n\n本文以 SkyWalking9.4.0 演示，SkyWalking 下载地址：http://skywalking.apache.org/downloads/\n\n![](5.png)\n\n以 Linux 为例。启动脚本在 bin/startup.sh。会启动两个服务:\n\n1、 skywalking-oap-server 服务\n\nskywalking-oap-server 服务启动后会暴露 11800 和 12800 两个端口，分别为收集监控数据的端口 11800 和接受前端请求的端口 12800，可以在 config/applicaiton.yml 修改端口，数据库存储等。默认使用 H2 数据库存储。\n\n![](6.png)\n\n2、 skywalking-web-ui 服务\n\nSkyWalking UI 界面的数据是通过请求 SkyWalking OAP 服务来获得。\n\nskywalking-web-ui 服务会占用 8080 端口， 可以在 webapp/applicaiton.yml 修改端口。\n\n![](7.png)\n\n启动成功之后，访问 Skywalking UI 界面：http://127.0.0.1:8080/\n\n### 项目集成\n\n监控 Java 项目，需要下载 Java 所需的探针 Skywalking Agent。\n\n![](8.png)\n\n在 IDEA 中使用 SkyWalking， 配置 java 启动参数\n\n![](9.png)\n\n```java\n// 探针的位置\n-javaagent:/kywalking-agent所在目录/skywalking-agent/skywalking-agent.jar\n//服务名称\n-Dskywalking.agent.service_name=system\n//skywalking collector的地址\n-Dskywalking.collector.backend_service=192.168.68.28:11800\n```\n\n配置完，启动 Java 项目。\n\n![](10.png)\n\n### 展示效果\n\n链路拓扑\n\n![](11.png)\n\n每个请求的调用链路\n\n![](12.png)\n\n\n概览全局页\n\n![](13.png)\n\n","tags":["分布式链路追踪"],"categories":["分布式链路追踪"]},{"title":"什么是DAPP","url":"/2023/01/13/25dapp/","content":"## DAPP（分布式应用），区块链新物种，去中心化 App\n\n简单来说，DAPP 和普通的 App 原理一样，除了他们是完全去中心化的，由类似以太坊网络本身自己的节点来运作的 DAPP，不依赖于任何中心化的服务器，DAPP 是去中心化的，可以完全自动地运行。\n\n### 1、DAPP（分布式应用）是什么\n\nDAPP 是 Decentralized Application 的缩写，中文叫分布式应用/去中心化应用，通常来说，不同的 DAPP 会采用不同的底层区块链开发平台和共识机制，或者自行发布代币（也可以使用基于相同区块链平台的通用代币）。\n\n![](1.png)\n\n符合以下 3 个条件的应用可以认为是一个 DAPP（分布式应用）：\n\n运行在分布式网络上；\n\n参与者信息被安全存储，隐私得到很好的保护；\n\n通过网络节点去中心化操作。\n\n![](2.png)\n\n### 2、DAPP 的四个特征\n\nDAPP 不同的底层区块链开发平台就好比手机的 IOS 系统和 Android 系统，是各 DAPP 的底层生态环境，DAPP 就是底层区块链平台生态上衍生的各种分布式应用，也是区块链世界中的基础服务提供方，DAPP 于区块链，就好比 APP 之于 IOS 和 Android。\n\n![](3.png)\n\n一个真正的 DAPP 应用，需要同时满足一下几个条件：\n\n应用必须完全开源、自治，且没有一个实体控制着该应用超 51%Token。该应用必须能够根据用户的反馈及技术要求进行升级，且应用升级必须由大部分用户达成共识之后方可进行；\n\n应用的数据必须加密后存储在公开的区块链上；\n\n应用必须拥有 Token 机制（可用基于相同底层区块链平台的通用代币或自行发行新币），矿工或应用维护节点需要得到代币奖励；\n\n应用代币的产生必须依据标准的加密算法，有价值的节点可以根据该算法获取应用的代币奖励。\n\n### 3、DAPP 应该制定类似宪法章程的智能合约\n\n区块链的早期应用是货币交易、金融交易，随后是智能资产，包括房产、汽车等实物资产和知识产权、司法认证、公共档案等虚拟资产。\n\n未来随着智能合约的发展，智能合约构建的组织如同现实商业社会一样的运行，这样形成的去中心化组织网络会变得极其复杂和自治，会出现各种形态：\n\nDapp（去中心化应用）  \nDAO（去中心化自治组织）  \nDAC（去中心化自治公司）  \nDAS（去中心化自治社会）  \n在没有人类干预的前提下，通过预先设定的业务规则自动运行。\n\n一个简单的智能合约例子：2 个人打赌一场球赛，筹码会暂时保存到网络，球赛结束后，网络中预先设定的智能合约会校验在线结果，然后把钱打到赢家账户。\n\n![](4.png)\n\n## DAPP 优势\n\nDAPP 用户体验由于区块链特有的数据确权、价值传递功能，可以消除很多影响用户体验、提升开发难度的因素：\n\n（1）用户实名认证流程变更\n\nDAPP 场景下，如果公链内支持数据共享，那么开发者只需要完成数据匹配，就可以从其他生态内的开发者处共享到用户实名资料，同时只需要支付 Token 即可；同时对用户而言，这也算是 POD（Proof of Data）挖矿模式，同样有收益，算是合作共赢；比如公信宝“布洛克城”。\n\n（2）交易安全性提升\n\n随着交易大爆炸的出现，交易效率的需求日渐提升；原来基于金融中介（例如银行、VISA 等）的交易处理方式效率低，信用生产成本高，为了降低这种风险，现在需要投入大量的风控成本进行审核但收效甚微。而基于 UTXO（Unspent Transaction Output）的区块链技术可以简单解决这个问题，而不需要对现有业务流程做任何变动升级，比如央行“数字票据交易平台”。\n\n（3）行业生产关系的变更\n\n区块链的数据确权、价值网络的两个属性可以变更现在的互联网生产关系，促使行业类应用出现，用户不用再为选择焦虑症发愁，典型的例子就是互联网视频；版权成本高昂导致腾讯、爱奇艺、搜狐只能付出极高的成本打击盗版、而用户追剧则需要在不同的平台购买 VIP 账号，如果基于区块链技术，剧集可以被版权方确权，用户不管通过任何渠道观看剧集，其支付的费用都可以 Token 化，然后由区块链基于价值网络分配给版权方、渠道方。在此生态内，盗版的问题被解决（比如 B 站 UGC 上传等），版权争夺成本下降，开发者专注于用户体验的提升，获取用户的方式也从版权壁垒变成社群运营，体验比拼，真正的互联网运营时代将会到来。例如当年的“火花电视”将各个平台的电视剧做到一站式观看，但是私自添加广告，影响版权方利益，最后被禁就是例子。\n\n（4）项目运维成本降低\n\n项目的运维成本往往高于开发成本，我们评估资源阈值的依据是预计最大流量，如果评估太低，则容易宕机，太高则浪费严重，例如：大多数产品应该都面临过运营活动带来的高并发问题，一次营销爆服务器的现象屡见不鲜，而添置服务器所带来的成本浪费则令人头疼，目前几个开发中的底层链（例如 EOS、Elastos）的资源分配模型基于用户持有 Token 的数量，这就意味着我们可以在某个活动开始前临时性购买 Token（资源），并在日常运维中将其释放（卖出），极大减少了运维成本。\n\n（5）技术开发成本降低\n\n目前项目开发通常会评估四个版本：iOS、Android、小程序、Web，理论上 DAPP 类似小程序，设计思想是无需安装，用完即走，所有的计算都在线上完成，本地禁止创建进程，系统自动创建或查找本地、周边、链内的其他微服务。\n\n## DAPP 的劣势\n\n（1）产品设计思路的颠覆\n\n目前互联网产品设计思路是“小步快跑、高速迭代”，这个方式在纯 DAPP 应用中应该会出现较大问题。简单来说，现有的 APP 都基于自有服务器，重大问题迭代强行刷新版本即可，但 DAPP 基于分布式的区块链网络，一旦提交上线出现核心 bug 很难迭代。\n\n拿 The DAO 来举个例子，The DAO 的核心漏洞如果是中心化处理，只需要下线更改 Bug 即可，但是以太坊却只能以硬分叉解决，这就是 DAPP 与现有 APP 设计思想的不同，在 MVP1.0 的调研阶段，一定要确认核心机制不出意外。\n\n（2）公链处理效率低\n\n目前成功落地的底层链都存在效率低、资源占用不合理问题，比特币的 5TPS、以太坊的 25TPS 跟 VISA 的 1300TPS 几乎没有可对比性。所以，目前公链并不适合商业化应用开发，如果借用其中几个技术（不涉及实时交易）倒是没有问题，比如积分交易、版权分享等。\n\n（3）研发风险大\n\n现在尚未出现普适性质的公链，就好像 PC 时代的 Windows、Mac OS；智能机时代的 iOS、Android。所以，基于某条公链的开发就要承担如果该公链被淘汰后血本无归的风险，好比当年的塞班开发者，或许跨链技术可以解决，但谁知道呢？综上所述，从互联网生态意义上来说，区块链技术是其底层结构的重要部分，未来所有的应用都需要考虑与其结合，也可能会有更多的全新应用模式出现。\n\n## 底线\n\n网上看到一句话说：DAPP 是技术进化的下一个合乎逻辑的步骤。我觉得有道理，区块链带来的人们的共识和数据的公开不可篡改，在这个基础上不依赖于人来执行的智能合约成为了可能，于是一切 App 的底层规则也就变了。\n\n","tags":["web3"],"categories":["web3"]},{"title":"分布式事务框架Seata","url":"/2022/12/19/24seata/","content":"分布式事务基础\n\n[<<分布式事务基础理论>>](https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==\\&mid=2247484102\\&idx=1\\&sn=58aca57cc3c96f64af6c68e9944918d7\\&chksm=fcafc744cbd84e52da07629c679a9915ee9cb7ba5698aee5934429b19a95ce2a402c07dca756\\&token=1611733318\\&lang=zh_CN#rd)\n\n[<<分布式事务解决方案>>](https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==\\&mid=2247484148\\&idx=1\\&sn=2e5395cf06ce1fcf5fd52b1c4381ea49\\&chksm=fcafc776cbd84e600b244ba4040f1cdd8b4845bb3a1ec144497a41e4b65652468c621f9be8dd\\&token=1611733318\\&lang=zh_CN#rd)\n\nSeata 一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。\n\n## Seata 全局框架\n\nSeata 的设计思路是将一个分布式事务理解成一个全局事务下面挂了多个分支事务，而一个分支事务是一个满足 ACID 的本地事务，因此我们可以操作分布式事务像操作本地事务一样。\n\n在 Seata 内部定义了三个模块来处理全局事务和分支事务：\n\n*   Transaction Coordinator（TC) - 事务协调者: 维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。\n*   Transaction Manager (TM)-  事务管理器： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。\n*   Resource Manager (RM)  - 资源管理器： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。\n\nSeata 提供的 AT、TCC、SAGA 和 XA 事务模式，都是基于这三个模块进行的。Seata 整体的执行步骤为：\n\n1.  TM 向 TC 申请开启一个全局事务，TC 创建全局事务并返回一个唯一的 XID，XID 会在全局事务的上下文中传播。\n2.  RM 向 TC 注册分支事务，该分支事务归属于拥有相同 XID 的全局事务。\n3.  TM 向 TC 发起全局的提交或回滚。\n4.  TC 调度 XID 下的所有分支事务提交或回滚。\n\n![](1.png)\n\n### AT 模式\n\n在[《分布式事务解决方案》](https://mp.weixin.qq.com/s?__biz=MzU2NjMwMTkzMw==\\&mid=2247484148\\&idx=1\\&sn=2e5395cf06ce1fcf5fd52b1c4381ea49\\&chksm=fcafc776cbd84e600b244ba4040f1cdd8b4845bb3a1ec144497a41e4b65652468c621f9be8dd\\&token=1611733318\\&lang=zh_CN#rd)中介绍了常见的几种方案，总的来说主要分为两类：对业务无入侵和有入侵的方案。无入侵方案主要有基于数据库 XA 协议，虽然 XA 协议与业务代码解耦，但是它必须要求数据库对 XA 协议的支持，且 XA 协议会造成事务资源长时间得不到释放，锁定周期长，性能很差。有入侵的方案都需要通过在应用层做手脚，比如很出名的 TCC 方案，基于 TCC 也有很多成熟的框架，如 ByteTCC、tcc-transaction 等。\n\n针对以上事务解决方案的痛点，Seata 提出了 AT 模式，`也是Seata默认的事务模式`。\n\nAT 模式的实现原理是在数据源做了一层代理(DataSourceProxy)，在代理层中 Seata 加入了一些额外的逻辑，包括解析 SQL，把业务数据在更新前后的数据镜像组织成回滚日志，并将 undo log 日志插入 undo\\_log 表中，保证每条更新数据的业务 sql 都有对应的回滚日志存在。\n\nAT 模式的执行过程\n\n*   一阶段：\n\nSeata 拦截“业务 SQL”，首先解析 SQL 语义，找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将其保存成`before image`，然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将其保存成`after image`，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。最后生成的`before image`和`after image`会保存到 undo log 表中\n\n![](2.png)\n\n*   二阶段：\n\n如果是提交，因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。\n\n![](3.png)\n\n如果是回滚，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用`before image`还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。\n\n![](4.png)\n\nAT 模式的一阶段、二阶段提交和回滚均由 Seata 框架自动生成，用户只需编写业务 SQL，便能轻松使用分布式事务，AT 模式是一种对业务无任何侵入的分布式事务解决方案。\n\n## 环境搭建\n\nSeata 分 TC、TM 和 RM 三个角色，TC（Server 端）为单独服务端部署，TM 和 RM（Client 端）由业务系统集成。\n\n### 服务端部署\n\n1.  下载启动包：<https://github.com/seata/seata/releases>\n2.  建表，主要的表有三个：\n\n*   全局事务：global\\_table\n*   分支事务：branch\\_table\n*   全局锁：lock\\_table\n\n    在 MySQL 中，创建一个名为 seata 的数据库实例。创建相关表的脚本在 `seata-->script-->server-->db`目录下\n\n1.  设置配置中心和注册中心\n\n*   搭建 nacos，具体的搭建过程自行查资料\n\n*   配置中心： `seata-->conf-->application.yml` 修改 seata.config.type=\"nacos\",在 `seata-->conf-->application.example.yml` 中 seata.config.nacos 下有相关的 nacos 配置，将其复制到 application.yml 下，并将 nacos 相关的数据配置完整。\n\n    设置配置中心可以参考官网：<https://seata.io/zh-cn/docs/user/configuration/nacos.html>\n\n*   注册中心： `seata-->conf-->application.yml` 修改 seata.registry.type=\"nacos\",在 `seata-->conf-->application.example.yml` 中 seata.registry.nacos 下有相关的 nacos 配置，将其复制到 application.yml 下，并将 nacos 相关的数据配置完整。\n\n1.  修改存储模式 store.mode\\\n    Server 端存储模式（store.mode）现有 file、db、redis 三种，file 模式无需改动，直接启动即可，下面专门讲下 db，因为 db 模式为高可用模式，全局事务会话信息通过 db 共享。\n    `seata-->conf-->application.yml`，修改 store.mode=\"db\"\n\n2.  修改数据库连接\\\n    `seata-->conf-->application.example.yml` 中附带额外配置，将其 db 相关配置复制至 application.yml，修改 store.db 相关属性。\n\n3.  启动\n\n```shell\nseata-server.sh -h 127.0.0.1 -p 8091 -m db\n```\n\n### 业务系统集成\n\n1.  添加依赖，Seata 提供了不同的依赖包。可以根据项目自行选择，建议单选。\n\n*   依赖 seata-all\n*   依赖 seata-spring-boot-starter，支持 yml、properties 配置(.conf 可删除)，内部已依赖 seata-all\n*   依赖 spring-cloud-alibaba-seata，内部集成了 seata，并实现了 xid 传递\n\n1.  在涉及到的服务的数据库中创建`undo_log`表\n\n```sql\nCREATE TABLE `undo_log` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT,\n  `branch_id` bigint(20) NOT NULL,\n  `xid` varchar(100) NOT NULL,\n  `context` varchar(128) NOT NULL,\n  `rollback_info` longblob NOT NULL,\n  `log_status` int(11) NOT NULL,\n  `log_created` datetime NOT NULL,\n  `log_modified` datetime NOT NULL,\n  `ext` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;\n```\n\n1.  初始化 GlobalTransactionScanner，如果引入`seata-spring-boot-starter`、`spring-cloud-starter-alibaba-seata`等 jar 会自动初始化，否则需要手动初始化。\n\n```java\n@Bean\npublic GlobalTransactionScanner globalTransactionScanner() {\n    String applicationName = this.applicationContext.getEnvironment().getProperty(\"spring.application.name\");\n    String txServiceGroup = this.seataProperties.getTxServiceGroup();\n    if (StringUtils.isEmpty(txServiceGroup)) {\n        txServiceGroup = applicationName + \"-fescar-service-group\";\n        this.seataProperties.setTxServiceGroup(txServiceGroup);\n    }\n\n    return new GlobalTransactionScanner(applicationName, txServiceGroup);\n}\n```\n\n1.  实现 xid 跨服务传递，如果是 Spring Cloud 项目，并引用了`spring-cloud-starter-alibaba-seata`jar，则已经自动实现了，否则需要参考源码 integration 文件夹下的各种 rpc 实现 module\n\n#### 业务使用\n\n1、以一个 Spring Cloud 项目为例，项目中有两个服务：订单服务和 库存服务。业务场景为创建订单的同时减库存。\n\n在两个服务中添加依赖\n\n```xml\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-seata</artifactId>\n</dependency>\n<dependency>\n    <groupId>com.alibaba.nacos</groupId>\n    <artifactId>nacos-client</artifactId>\n</dependency>\n```\n\n2、在每个业务服务下的数据库里添加`undo_log`表。\n\n3、在每个业务服务下的配置文件中添加 seata 配置\n\n```yml\nseata:\n  tx-service-group: default_tx_group\n  registry:\n    type: nacos\n    nacos:\n      application: seata-server # seata server 的服务名seata-server ，如果没有修改可以不配\n      server-addr:  127.0.0.1:8848 # seata server 所在的nacos服务地址\n      group : DEFAULT_GROUP  # seata server 所在的组，默认就是SEATA_GROUP，没有改也可以不配\n      namespace: 0d876b7d-4cfd-4860-bf81-8e5266c9375c # 自己seata注册中心namespace\n      username: nacos\n      password: nacos\n  config:\n    type: nacos\n    nacos:\n      server-addr: 127.0.0.1:8848 # seata server 所在的nacos服务地址\n      username: nacos\n      password: nacos\n      group: DEFAULT_GROUP\n      namespace: 0d876b7d-4cfd-4860-bf81-8e5266c9375c # 自己seata注册中心namespace\n  application-id: seata-demo #\n  enabled: true\n```\n\n`注意`：\n\n1.  这里的 group 要与 server 端配置的保持一致\n2.  tx-service-group 为事务群组，要部署同一套分布式事务的微服务要求事务群组要一致。可以在 nacos 的配置中查询 ：service.vgroupMapping.xxx。\n\n![](5.png)\n\n1.  库存服务 `StockController`\n\n```java\n@PostMapping(value = \"/reduct\")\npublic void reduct(String productId) {\n    //去库存\n    stockService.reduct(order.getProductId());\n    // 异常\n    int a=1/0;\n    return order;\n}\n```\n\n在减库存的方法中模拟了一个业务异常`int a=1/0`，表示服务调用发生异常。\n\n1.  订单服务中创建调用库存服务的 Feign\n\n```java\n@FeignClient(value = \"stock-service\")\npublic interface StockApi {\n    @PostMapping(value = \"/reduct\")\n   void reduct(String productId);\n}\n\n```\n\n订单服务`OrderService`，在需要开启全局事务的方法上添加`@GlobalTransactional`注解\n\n```java\nAutowired\nprivate StockApi stockApi;\n\n@GlobalTransactional\npublic Order create(Order order) {\n    // 插入\n    orderMapper.insert(order);\n    // 减库存\n    stockApi.reduct(order.getProductId());\n    return order;\n}\n```\n\n当调用订单服务时，库存服务发生异常，可以判断发生异常后两个数据库中的数据是否回滚。\n\n参考： <https://seata.io/zh-cn/blog/seata-at-tcc-saga.html>\n","tags":["分布式事务"],"categories":["分布式事务"]},{"title":"分布式事务基础","url":"/2022/11/23/23distributedTransaction/","content":"事务是数据库执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。\n事务有四个特性，习惯上被称为 ACID 特性：\n\n- Atomicity(原子性)\n- Consistency(一致性)\n- Isolation(隔离性)\n- Durability(持久性)\n\n## 本地事物\n\n在系统发展初期，单体应用对应一个数据库，整个服务操作只涉及一个数据库资源，通过数据库自带的事务很容易实现 ACID，这类基于单个服务单一数据库资源访问的事务，被称为本地事务(Local Transaction)。\n\n![](1.png)\n\n## 分布式事务\n\n随着互联网的发展，微服务架构大规模的普及，软件系统由原来的单体应用转变为分布式应用。分布式系统一般由多个独立的子系统组成，多个子系统通过网络通信互相协作配合完成各个功能。\n\n分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。比如在一个电商系统中，一条订单的生成涉及库存、订单、支付等不同的服务，不同的服务之间要么全成功、要么全失败，保证事务的 ACID 特性。\n\n![](2.png)\n\n本质上来说，分布式事务就是为了保证不同数据库的数据一致性。\n\n在分布式系统中数据一致性又可以划分出多个一致性模型\n\n- 强一致性：任何一次读都能读到某个数据的最近一次写的数据。系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致。简言之，在任意时刻，所有节点中的数据是一样的。\n\n- 弱一致性：数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。\n\n- 最终一致性：不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。简单说，就是在一段时间后，节点间的数据会最终达到一致状态。\n\n在解决分布式事物的数据一致性问题上，产生了多个相关的理论。\n\n## CAP 理论\n\nCAP 定理又被称作布鲁尔定理，是加州大学的计算机科学家布鲁尔在 2000 年提出的一个猜想。2002 年，麻省理工学院的赛斯·吉尔伯特和南希·林奇发表了布鲁尔猜想的证明，使之成为分布式计算领域公认的一个定理。\n\n- C : Consistency 一致性 , 所有实例节点同一时间看到是相同的数据\n- A : Availability 可用性 , 不管是否成功，确保每一个请求都能接收到响应\n- P : Partition tolerance 分区容错性 , 系统任意分区后，在网络故障时，仍能操作\n\nCAP 理论是指在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性、可用性、分区容错性者中的两个，另外一个必须被牺牲。\n\n在真实的分布式环境下，如果我们选择了 CA（一致性 + 可用性） 而放弃了 P（分区容错性），那么当发生分区现象时，为了保证 C（一致性），系统需要禁止写入，当有写入请求时，系统返回 error（例如，当前系统不允许写入），这又和 A(可用性) 冲突了，因为 A（可用性）要求返回 no error 和 no timeout。因此虽然在 CAP 理论定义是三个要素中只能取两个，但放到分布式环境下来，必须选择 P（分区容错）要素，因为网络本身无法做到 100% 可靠，有可能出故障，所以分区是一个必然的现象。\n也就说在真是环境下我们只能选择 CP（一致性 + 分区容错性） 或者 AP （可用性 + 分区容错性）架构，在一致性和可用性做折中选择。\n\n虽然 CAP 理论告诉我们分布式系统只能选择 AP 或者 CP，但实际上并不是说整个系统只能选择 AP 或者 CP，在 CAP 理论落地实践时，我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP 还是 AP），而不是直接限定整个系统所有数据都是同一策略。\n\n## BASE 理论--CAP 理论的延伸\n\n由于在分布式系统中 C、A、P 三者都无法抛弃，但 CAP 定理限制三者无法同时满足，这种情况，我们会选择尽量靠近 CAP 定理，即尽量让 C、A、P 都满足，在此所趋下，出现了 BASE 定理。\n\nBASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent （最终一致性）三个短语的缩写。核心思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。\n\n- BA：Basically Available 基本可用，分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。  \n  电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。\n- S：Soft State 软状态，允许系统存在中间状态，而该中间状态不会影响系统整体可用性。  \n  分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication 的异步复制也是一种体现。\n- E: Eventual Consistency 最终一致性， 系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。\n\nBASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。\n\nBASE和ACID的区别与联系\n\n- ACID是传统数据库常用的设计理念, 追求强一致性模型。\n- BASE支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性\n\nACID和BASE代表了两种截然相反的设计哲学。  \n总的来说，BASE 理论面向大型高可用可扩展的分布式系统，与ACID这种强一致性模型不同，常常是牺牲强一致性来获得可用性，并允许数据在一段时间是不一致的。虽然两者处于（一致性-可用性）分布图的两级，但两者并不是孤立的，对于分布式系统来说，往往依据业务的不同和使用的系统组件不同，而需要灵活的调整一致性要求，也因此，常常会组合使用ACID和BASE。\n\n## 柔性事务\n\n不同于 ACID 的刚性事务，在分布式场景下基于 BASE 理论，就出现了柔性事务的概念。柔性事务下，在不影响系统整体可用性的情况下(Basically Available 基本可用)，允许系统存在数据不一致的中间状态(Soft State 软状态)，在经过数据同步的延时之后，最终数据能够达到一致。并不是完全放弃了 ACID，而是通过放宽一致性要求，借助本地事务来实现最终分布式事务一致性的同时也保证系统的吞吐。\n\n## XA --强一致性\n\n由 Tuxedo 提出的 XA 是一个分布式事务协议，规定了事务管理器和资源管理器接口。XA 协议可以分为两部分，即事务管理器和本地资源管理器。\n\n- 事务管理器作为`协调者`，负责各个本地资源的提交和回滚。\n- 资源管理器就是分布式事务的`参与者`.其中资源管理通常是数据库。\n\n基于 XA 协议的，发展出了二阶段提交协议（The two-phase commit protocol，2PC）和三阶段提交协议（Three-phase commit protocol，3PC）。\n\n### 2PC\n\n二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。\n\n将事务的提交过程分为两个阶段来进行处理：准备阶段和提交阶段。\n\n0x1 准备阶段\n\n1.  协调者向所有参与者发送 CanCommit 操作请求，并等待参与者的响应。\n2.  参与者接收到请求后，会执行请求中的事务操作，将 undo 和 redo 信息记入事务日志中，但是这时并不提交事务。\n    ![](3.png)\n    若不成功，则发送“No”消息，表示终止操作。当所有的参与者都返回了操作结果（Yes 或 No 消息）后，系统进入了提交阶段。  \n    ![](4.png)\n\n0x2 提交阶段\n\n协调者会根据所有参与者返回的信息向参与者发送 DoCommit 或 DoAbort 指令\n\n1. 若协调者收到的都是“Yes”消息，则向参与者发送“DoCommit”消息，参与者会提交事务并释放资源，然后向协调者返回“Ack”消息。\n   ![](5.png)\n\n2. 如果协调者收到的消息中包含“No”消息，则向所有参与者发送“DoAbort”消息，此时发送“Yes”的参与者会根据之前执行操作时的回滚日志对操作进行回滚，然后所有参与者会向协调者发送“Ack”消息；\n   ![](6.png)\n\n3) 协调者接收到所有参与者的“Ack”消息，就意味着整个事务结束了。\n\n2PC 实现起来比较简单，但是实际项目中使用比较少，主要因为以下问题：\n\n性能问题：所有参与节点都是事务阻塞型的，占用系统资源，容易导致性能瓶颈。\n\n可靠性问题：如果协调者出现故障，参与者将一直处于锁定状态。\n\n数据一致性问题：在提交阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。\n\n### 3PC\n\n基于 2PC 基础上，3PC 对 2PC 进行了改进，引入了超时机制。同时将准备阶段拆分为 2 个阶段，多了一个 PreCommit 阶段。\n\n3PC 可以划分为 CanCommit 阶段、PreCommit 阶段、DoCommit 阶段。\n\n0x1 CanCommit 阶段\n\n1. 协调者向所有参与者发送 \"CanCommit\" 请求，询问是否可以提交事务，并等待所有参与者答复。\n2. 参与者收到 \"CanCommit\" 请求之后，回复 \"Yes\"，表示可以顺利执行事务；否则回复 \"No\"。\n\n![](7.png)\n\n0x2 PreCommit 阶段\n\n协调者根据参与者的回复情况，来决定是否可以进行 PreCommit 操作或中断事务。\n\n如果参与者返回的回复情况全部是 Yes\n\n1. 协调者向所有参与者发送 \"PreCommit\" 请求，参与者进入到预提交阶段。\n2. 参与者收到 \"PreCommit\" 请求后，执行事务操作，并将 undo 和 redo 信息记入事务日志中，但这时并不提交事务。\n3. 参与者向协调者反馈执行成功 \"Yes\" 或失败响应 \"No\"。\n\n![](8.png)\n\n如果参与者返回的回复情况中包含 No，说明有一个事务执行失败。\n\n1. 协调者向所有参与者发送 “Abort”请求\n2. 参与者收到“Abort”消息之后，或超时后仍未收到协调者的消息，执行事务的中断操作。\n\n0x3 DoCommit 阶段\n\n协调者根据参与者的回复情况，来决定是否可以进行 DoCommit 操作 或 中断事务。\n\n如果参与者返回的回复情况全部是 YES\n\n1. 协调者向所有参与者发送 \"DoCommit\" 消息。\n2. 参与者接收到 \"DoCommit\" 消息之后，正式提交事务。完成事务提交之后，释放所有锁住的资源。\n3. 参与者提交完事务之后，向协调者发送 \"Ack\" 响应\n4. 协调者接收到所有参与者的 \"Ack\" 响应之后，完成事务。\n\n![](9.png)\n\n如果参与者返回的回复情况中包含 No，说明有一个事务执行失败。\n\n1. 协调者向所有参与者发送 \"Abort\" 请求。\n2. 参与者接收到 \"Abort\" 消息之后，利用其在 \"PreCommit\" 阶段记录的 undo 信息执行事务的回滚操作，并释放所有锁住的资源。\n3. 参与者完成事务回滚之后，向协调者发送 \"Ack\" 消息。\n4. 协调者接收到参与者反馈的 \"Ack\" 消息之后，执行事务的中断，并结束事务。\n\n相比二阶段提交，三阶段降低了阻塞范围，在等待超时后协调者或参与者会中断事务，避免了协调者单点问题。DoCommit 阶段中协调者出现问题时，参与者会继续提交事务。\n\n但是数据不一致问题依然存在，当在参与者收到 preCommit 请求后等待 DoCommit 指令时，此时如果协调者请求中断事务，而协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。\n\n## TCC --最终一致性\n\nTCC（Try-Confirm-Cancel）的概念，最早是由 Pat Helland 于 2007 年发表的一篇名为《Life beyond Distributed Transactions:an Apostate’s Opinion》的论文提出。\n\nTCC 是服务化的二阶段编程模型， 针对每个操作，都要实现对应的确认和补偿操作，也就是业务逻辑的每个服务都需要实现 Try、Confirm、Cancel 三个操作，第一阶段由业务代码编排来调用 Try 接口进行资源预留，当所有参与者的 Try 接口都成功了，事务协调者提交事务，并调用参与者的 Confirm 接口真正提交业务操作，否则调用每个参与者的 Cancel 接口回滚事务，并且由于 Confirm 或者 Cancel 有可能会重试，因此对应的部分需要支持幂等。\n\n- Try 阶段：尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性）\n- Confirm 阶段： 确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作满足幂等性\n- Cancel 阶段： 取消执行，释放 Try 阶段预留的业务资源 Cancel 操作满足幂等性 Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致。\n\n![](10.png)\n\nTCC 事务机制相比于上面介绍的 XA，解决了其几个缺点：\n\n1. 解决了协调者单点，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。\n2. 同步阻塞：引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。\n3. 数据一致性，有了补偿机制之后，由业务活动管理器控制一致性\n\n但是TCC中Try、Confirm、Cancel 的操作需要业务来实现，耦合度过高。\n\n## 本地消息表 --最终一致性\n\n本地消息表这个方案最初是 ebay 架构师 Dan Pritchett 在 2008 年发表给 ACM 的文章。核心思路是将分布式事务拆分成本地事务进行处理。 本地事物表方案可以将事务分为事务主动方和事物被动方。\n\n- 事务主动方: 分布式事务最先开始处理的事务方\n- 事务被动方: 在事务主动方之后处理的业务内的其他事务\n\n事务的主动方需要`额外新建事务消息表`，用于记录分布式事务的消息的发生、处理状态。整个业务流程：\n\n1. 事务主动方在本地事务中处理业务更新操作和写消息表操作。\n2. 事务主动方通过消息中间件，通知事务被动方处理事务。\n3. 事务被动方通过消息中间件，通知事务主动方事务已处理的消息\n\n![](11.png)\n\n本地消息表实现的条件：\n\n- 消费者与生成者的接口都要支持幂等\n- 生产者需要额外的创建消息表\n- 需要提供补偿逻辑，如果消费者业务失败，需要生产者支持回滚操作\n\n容错机制：\n\n- 步骤 1 失败时，事务直接回滚\n- 步骤 2、3 写 mq 与消费 mq 失败会进行重试\n- 步骤 3 业务失败事务被动方向事务主动方发起事务回滚操作\n\n## MQ 事务 --最终一致性\n\n有些 MQ 的实现支持事务，比如 RocketMQ ，基于 MQ 的分布式事务方案其实是对本地消息表的封装。以 RocketMQ 为例介绍 MQ 的分布式事务方案。\n\n1. 发送方向 MQ 服务端(MQ Server)发送 half 消息。这个 half 消息与普通消息的区别在于，在事物提交之前，这个消息对订阅方来说是不可见的，订阅方不会消费这个消息。\n2. MQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功。\n3. 发送方开始执行本地事务逻辑。\n4. 如果事务提交成功，将会发送确认消息（commit 或是 rollback）至 MQ Server。\n5. MQ Server 收到 commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 rollback 状态则删除half消息，订阅方将不会接受该消息。\n\n![](12.png)\n\n异常情况 1：如果发送方发送 commit 或 rollback 消息失败，未到达消息集群\n\n- MQ Server 会发起消息回查\n- 发送方收到回查消息后，会检查本地事务的执行结果\n- 根据本地事务的执行结果重新发送 commit 或 rollback 消息\n- MQ Server 根据接收到的消息（commit 或 rollback）判断消息是否可消费或直接删除\n\n异常情况 2：接收方消费失败或消费超时\n\n- 一直重试消费，直到事务订阅方消费消息成功，整个过程可能会导致重复消费问题，所以业务逻辑需要保证幂等性\n\n异常情况 3：消息已消费，但接收方业务处理失败\n\n- 通过 MQ Server 通知发送方进行补偿或事务回滚\n\n## Saga 事务 --最终一致性\n\nSaga 事务源于 1987 年普林斯顿大学的 Hecto 和 Kenneth 发表的如何处理 long lived transaction（长活事务）论文，Saga 事务核心思想是将长事务拆分为多个本地短事务，由 Saga 事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。\n\nSaga 事务基本协议如下：\n\n每个 Saga 事务由一系列幂等的有序子事务(sub-transaction) Ti 组成。  \n每个 Ti 都有对应的幂等补偿动作 Ci，补偿动作用于撤销 Ti 造成的结果。\n\nSaga 的执行顺序有两种：\n\n- T1, T2, T3, ..., Tn\n- T1, T2, ..., Tj, Cj,..., C2, C1，其中 0 < j < n\n\nSaga 定义了两种恢复策略：\n\n- 向前恢复(forward recovery)\n  适用于必须要成功的场景，发生失败进行重试，执行顺序是类似于这样的：T1, T2, ..., Tj(失败), Tj(重试),..., Tn，其中 j 是发生错误的子事务(sub-transaction)。该情况下不需要 Ci。\n\n![](13.png)\n\n- 向后恢复(backward recovery)\n  如果任一子事务失败，补偿所有已完成的事务。即上面提到的第二种执行顺序，其中 j 是发生错误的 sub-transaction，这种做法的效果是撤销掉之前所有成功的 sub-transation，使得整个 Saga 的执行结果撤销。\n\n![](14.png)\n\nSaga 事务常见的有两种不同的实现方式：\n\n1. 命令协调(Order Orchestrator)：中央协调器负责集中处理事件的决策和业务逻辑排序\n\n![](15.png)\n\n2. 事件编排 (Event Choreography)：没有中央协调器（没有单点风险）时，每个服务产生并观察其他服务的事件，并决定是否应采取行动。\n   在事件编排方法中，第一个服务执行一个事务，然后发布一个事件。该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布（或不发布）新的事件。\n   当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何 Saga 参与者听到都意味着事务结束。\n\n\n![](16.png)\n\n\n","tags":["分布式事务"],"categories":["分布式事务"]},{"title":"智能合约","url":"/2022/10/10/22smartContract/","content":"\n接触区块链的，经常会听到智能合约这个词，那什么是智能合约？今天就来了解了解。\n\n## 比特币引领区块链，以太坊复活智能合约\n\n1994 年，计算机科学家和密码学家 Nick Szabo 首次提出“智能合约”概念，它早于区块链概念的诞生，几乎与互联网同龄。\n\n![](1.png)\n\nSzabo 描述了什么是“以数字形式指定的一系列承诺，包括各方履行这些承诺的协议”。虽然有它的好处，但智能合约的想法一直未取得进展——一个重要原因是因为缺乏能够支持可编程合约的数字系统和技术。\n\n直到 2008 年，第一个加密货币比特币出现，同时引入了现代区块链技术。区块链最初是以比特币的底层技术出现的，但是智能合约在 2008 年依然无法融入比特币区块链网络。五年后，以太坊创始人 Vitalik Buterin 发布了白皮书《以太坊：下一代智能合约和去中心化应用平台》， 作为首个支持“图灵完备”智能合约的区块链网络，以太坊掀开了以智能合约为代表的区块链 2.0 时代的序章。从此，涌现出了各种不同形式的智能合约，其中以太坊智能合约使用最广。\n\n![](2.png)\n\n## 智能合约是什么\n\n> 智能合约是一种特殊协议，旨在提供、验证及执行合约。\n\n智能合约的英文是 `Smart Contract`，这里的智能 Smart 不等同于人工智能的 Artificial Intelligence。Smart 的意思是聪明的、灵活的，还远远未达到 Intelligence 的级别。中文的翻译有点误导的意思。\n\n智能合约本质上是一个数字协议，数字协议在我们日常生活很常见，比如信用卡自动还款服务就是一个数字协议，在某一个时间（还款日），条件满足（储蓄卡余额比信用卡还款金额要多）的情况下，计算机系统会自动完成这笔交易。自动售货机也是一个数字协议，当选择商品，付钱后，如果付的钱足以支付该商品，那么售货机会弹出想要的商品，如果钱不够则运行另一套逻辑。\n\n所以，智能合约就是一段计算机程序，程序中预先设定好了合约双方的职责和要执行的条件，一旦满足条约中的条款，程序会自动执行。只是与传统数字协议不同的是，智能合约是运行在区块链上的。\n\n站在程序员的角度去理解智能合约，可以类比为一个类实例化对象，唯一的区别是这个对象永远存在区块链网络中（除非程序进行自毁）。\n\n## 智能合约是怎么运行的\n\n智能合约一定要在区块链上么？ 并不是，就像上面说的信用卡自动还款、自动售货机的例子。但是运行在传统的计算机方式中存在合约被恶意篡改之类风险，还有一个重要的信任问题。在信用卡自动还款的例子中，因为是银行的服务，有银行背书，许多人相信银行。如果把这个服务放在淘宝、京东这类网店上，还会有人相信么？ 即使从技术角度来说实现这种服务也并不难。\n\n所以相对于传统的方式，区块链去中心化、不可篡改、过程透明可追踪、去信任等优点，天然适合于智能合约。智能合约也是区块链被称之为“去中心化的”重要原因，它允许我们在不需要第三方的情况下，执行可追溯、不可逆转和安全的交易。\n\n基于区块链的智能合约构建及执行主要分为如下几步：\n\n`构建 → 存储 → 执行`\n\n1. 多方共同制定合约内容，将编写好的智能合约代码上传到区块链上，全网的验证节点都会收到编写好的合约。\n2. 智能合约会定期检查是否存在相关事件和触发条件，满足条件的事件将会推送到待验证的队列中。比如每月10号信用卡还款日，这个事件就是智能合约的触发条件。\n3. 区块链上的验证节点先对该事件进行签名验证，以确保其有效，等大多数验证节点对该事件达成共识后，智能合约将成功执行，并通知用户。\n4. 合约成功执行后将移出区块，未执行的合约则继续等待下一轮处理，直至成功执行。\n\n智能合约的代码是具体如何运行的，不同区块链运行的方式不同，像以太坊是运行在以太坊的 EVM 中，超级账本 Fabric 是运行在 dcoker 中。\n\n基于区块链乌托邦式的智能合约虽然能够解决当前传统计算机合约下的许多问题，但是现阶区块链段智能合约仍然有一些缺点。\n\n- 区块链不可篡改的特性，智能合约一旦上链就不容易修改，这使得修改代码变得困难。\n- 区块链公开透明的特性，使得所有的私人信息都进入了公共领域。对于想要完全隐私的企业和个人来说，缺乏保密性是使用智能合约的一大缺点。\n- 区块链上的智能合约只是将信任问题进行了转移并没有得到解决，比如房产交易合约，房屋归属权上链的首要条件是现实生活中房产交付确认同样是必须的输入信息。也就是，区块链无法解决外部虚假信息的录入。\n\n互联网从诞生到成熟这条路走了有三十年，对于仅活跃几年的区块链智能合约，未来的路依旧会很漫长。\n\n![](https://img.soogif.com/zr4XXRlsRpSDwFA4N1wNkrWM923md01V.gif?scope=mdnice)\n","tags":["web3"],"categories":["web3"]},{"title":"编译器对代码做了哪些工作","url":"/2022/09/15/21compile/","content":"> 知乎上有一种说法是「编译器、图形学、操作系统是程序员的三大浪漫」。\n\n计算机很笨，它只认识 0 和 1,也只会运行最简单的机器指令，而我们平时写的代码大多都属于高级语言。高级语言编写的指令要想在计算机上执行，需要将高级语言转换成计算机识别的机器语言。编译器就是将高级语言转换成机器语言的一款软件。\n\n一个完整的编译器将源码编译成目标机器指令主要包含以下几个步骤。\n\n![](1.png)\n\n\n## 词法分析\n\n词法分析从左到右扫描源程序的字符，识别出每个单词，并组成`词素`（源代码中的一个字符串，比如一个变量名，一个运算符，都会被识别为一个词素。）。对于每个词素，词法分析会把它解析成一个词法单元。这个词法单元被称为 Token。Token 的形式一般为\n\n```\n〈token-name, attribute-value〉\n```\n\n- token-name: 单词的类别\n\n程序中的单词大体可以分成五类：\n\n![](2.png)\n\n- attribute-value： 指向符号表中关于这个词法单元的条目。符号表条目的信息会被语义分析和代码生成步骤使用\n\n什么是符号表？\n\n编译器的重要功能之一是记录源程序中使用的变量的名字，并收集和每个名字的各种属性有关的信息。这些属性可以提供一个名字的存储分配、类型、作用域等信息。对于过程名字，这些信息还包括：它的参数数量和类型、每个参数的传递方法及返回类型。\n\n符号表数据结构为每个变量名字创建了一个记录条目。记录的字段就是名字的各个属性。这个数据结构应该允许编译器迅速查找到每个名字的记录，并向记录中快速存放和获取记录中的数据。\n\n比如，对于赋值语句`position = initial + 2 * 60`\n\n`position`是一个词素，被映射成词法单元`<id, 1>`，其中 id 是表示标识符（identifier）的抽象符号，而 1 指向符号表中 position 对应的条目。\n\n赋值符号`=`是一个词素，被映射成词法单元`<=>`，因为这个词法单元不需要属性值，所以省略了第二个分量。\n\n整条语句被词法分析后的结果可以表示为   \n`<id, 1> <=> <id, 2> <+> <2> <*> <60>`\n\n\n\n## 语法分析\n\n语法分析对词法分析中扫描的 Token 进行分析，并产生语法树，这棵树被称为 AST 抽象语法树。整个分析过程采用的是上下文无关语法（Context-free Grammar）。\n\n简单来说，语法分析生成的树是以表达式为节点的树。\n\n比如，对于赋值语句`position = initial + 2 * 60`，经过语法分析后生成的数\n\n\n![](3.png)\n\n\n## 语义分析\n\n语义分析利用前面生成的语法树和符号表来检查源程序是否符合语言定义。同时收集类型信息，以便在代码生成过程中使用。\n\n语义分析的一个重要作用就是类型检查，编译器检查每一个运算符是否具有合法的运算分量。另外对于某些语言允许自动类型转换，编译器需要根据自动类型转换规则，对数据类型进行转换。\n\n语义分析结束以后，整个语法树的表达式都被标识了类型，如果有些类型需要做隐式转换的，在分析完后会在语法书树上插入相应的转换节点。\n\n比如`position = initial + 2 * 60` 经过语义分析后\n\n![](4.png)\n\n语义分析同时还会对更新符号表里的符号类型。\n\n## 中间语言生成\n\n在经过语义分析后。大多数的编译器不会直接生成目标代码，一般会生成一个抽象于平台的中间语言(Intermediate Representation，简称 IR )，该中间语言与机器无关。\n\n先生成中间代码一方面可以增加编译器的模块化、可移植性和可扩展性。中间代码既独立于任何高级语言，也独立于任何目标机器架构，这样可以开发出适应广泛高级语言的编译器。\n\n![](5.png)\n\n另一方面，也可以做一些与机器无关的优化操作。\n\n中间语言有很多种，在不同的编译器中可能也会有不同的表达形式。常用的方式有三地址码、P-代码等。\n\n拿三地址码来举例，基本的三地址码是这样的`x = y op z`，表示将变量y和z操作后赋值给x，op既可以是算术运算也可以是其他的操作。 `position = initial + 2 * 60` 被三地址成三地址码\n```\nt1 = 2 * 60\nt2 = initial + t1\nposition  = t2\n```\n\n## 中间代码优化\n\n中间代码优化的主要是做一些于底层机器无关的优化，比如消除死代码，函数内联优化，for 循环展开等优化。这一步输入的是中间代码IR,输出的也是中间代码IR。\n\n`position = initial + 2 * 60` 被翻译成中间语言后，`t1 = 2 * 60` 是可以在生成目标代码之前计算出来的，`t2 = initial + t1` 中的t1也是可以直接被替换成值的。 经过优化后的中间代码\n```\nt2 = initial + 120\nposition  = t2\n```\n\n## 目标代码生成\n\n目标代码生成的工作是将中间代码转换成目标机器代码，这个过程十分依赖目标机器，因为不同的机器有着不同的字长、寄存器、数据类型等等，需要生成不同的机器代码。\n\n现在编译器有着异常复杂的机构，因为现代高级语言本身非常的复杂，像C++编译器，至今也没有一个编译器能够完整的支持C++标准所规定的所有语言特性。 那么作为一个高级语言的使用者，为什么要学习编译原理呢？这里引用《三体》中的一段话结束。\n\n> 成吉思汗的骑兵，攻击速度与二十世纪的装甲部队相当;北宋的床弩，射程达一千五百米，与二十世纪的狙击步枪差不多;但这些仍不过是古代的骑兵与弓弩而已，不可能与现代力量抗衡。`基础理论决定一切`，未来史学派清楚地看到了这一点。而你们，却被回光返照的低级技术蒙住了眼睛。\n","tags":["编译原理"],"categories":["编译原理"]},{"title":"Java8中的Stream流","url":"/2022/08/20/20stream/","content":"## 定义\n什么是Stream流，Java doc中是这样写的\n\n> A sequence of elements supporting sequential and parallel aggregate operations\n\n翻译一下就是一个支持顺序和并行聚合操作的元素序列。  \n可以把它理解成一个迭代器，但是只能遍历一次，就像是流水一样，要处理的元素在流中传输，并且可以在流中设置多个处理节点，元素在经过每个节点后会被节点的逻辑所处理。比如可以进行过滤、排序、转换等操作。\n\nStream流的使用可以分为三个步骤：\n- 数据源，创建流\n- 中间操作，可以有多个，生成一个新的流\n- 终端操作，只能有一个，放在最后，代表流中止。\n\nStream流有几个特点：  \n1、Stream流一般不会改变数据源，只会生成一个新的数据流。  \n2、Stream流不会存储数据，只会根据设置的操作节点处理数据。  \n3、Stream流是延迟执行的，只有在调用终端操作后才会进行流转。\n\n看一下Stream的结构\n![stream](1.png)\n\n\n\n## 使用\n\n### 数据源生成流\n- 如果是集合的话，可以直接使用`stream()`创建流。\n- 如果是数组的话，可以使用`Arrays.stream()`或`Stream.of()`来创建流。\n```java\n// 集合生成流\nList<String> strList = new ArrayList<>();\nStream<String> stream = strList.stream();\n\n//数据生成流\nString[] strs = new String[]{\"1\",\"2\",\"3\"};\nStream<String> stream1 = Arrays.stream(strs);\nStream<String> stream2 = Stream.of(strs);\n```\n### 中间操作\n在上边Stream定义中，返回是`Stream`类型的大多数都是中间操作，入参大多数都是函数式编程，不熟悉的可以看看这篇<Java函数式编程>。常用的中间操作有\n- 过滤操作 `filter()`\n```java\nArrays.stream(strs).filter(s -> s.equals(\"1\"));\n```\n- 排序操作 `sorted()`\n```java\nArrays.stream(strs).sorted();\n```\n- 去重操作 `distinct()`\n```java\nArrays.stream(strs).distinct();\n```\n- 映射操作，将流中元素转换成新的元素\n    - `mapToInt()`转换成Integer类型\n    - `mapToLong()`转换成Long类型\n    - `mapToDouble()`转换成Double类型\n    - `map()` 自定义转换类型，这是一个使用频率非常高的方法。\n```java\n//将字符串转换成Integer\nArrays.stream(strs).mapToInt(s -> Integer.valueOf(s));\n//将字符串转换成Long\nArrays.stream(strs).mapToLong(s -> Long.valueOf(s));\n//将字符串转换成Doublde\nArrays.stream(strs).mapToDouble(s -> Double.valueOf(s));\n//自定义转换的类型\nArrays.stream(strs).map(s -> new BigDecimal(s));\n```\n中间操作是可以有多个的，我们可以根据业务功能组合多个中间操作，比如求数组中字符串包含s的字符串长度排序\n```java\nArrays.stream(strs).filter(e->e.contains(\"s\")).map(String::length).sorted();\n```\n\n### 终端操作\n终端操作，表示结束流操作，是在流的最后，常用的有\n- 统计 `count()`\n```java\nlong count = Arrays.stream(strs).count();\n// count=3\n```\n- 获取最小值 `min()`\n```java\n// 将字符串转换成Interger类型再比较大小\n OptionalInt min = Arrays.stream(strs).mapToInt(Integer::valueOf).min();\n System.out.println(min.getAsInt());\n // 1\n```\n- 获取最大值 `max()`\n```java\n OptionalInt max = Arrays.stream(strs).mapToInt(Integer::valueOf).max();\n System.out.println(max.getAsInt());\n // 3\n```\n- 匹配\n    - `anyMatch()`，只要有一个匹配就返回`true`\n    - `allMatch()`，只有全部匹配才返回`true`\n    - `noneMatch()`，只要有一个匹配就返回 `false`\n```java\nboolean all = Arrays.stream(strs).allMatch(s -> s.equals(\"2\"));\nboolean any = Arrays.stream(strs).anyMatch(s -> s.equals(\"2\"));\nboolean none = Arrays.stream(strs).noneMatch(s -> s.equals(\"2\"));\n// all = false\n// any = true\n// none = false\n```\n- 组合 `reduce()`将Stream 中的元素组合起来，有两种用法\n    - `Optional reduce(BinaryOperator accumulator)` 没有起始值只有运算规则\n    - `T reduce(T identity, BinaryOperator accumulator)`，有运算起始值和运算规则、返回的是和起始值一样的类型\n\n```java\nInteger[] integers = new Integer[]{1,2,3};\nOptional<Integer> reduce1 = Arrays.stream(integers).reduce((i1, i2) -> i1 + i2);\nInteger reduce2 = Arrays.stream(integers).reduce(100, (i1, i2) -> i1 + i2);\n// reduce1.get() = 6\n// reduce2 = 106\n```\n- 转换 `collect()`，转换作用是将流再转换成集合或数组，这也是一个使用频率非常高的方法。  \n  `collect()`一般配合`Collectors`使用，`Collectors` 是一个收集器的工具类，内置了一系列收集器实现，比如`toList()` 转换成list集合，`toMap()`转换成Map,`toSet()`转换成Set集合,`joining()` 将元素收集到一个可以用分隔符指定的字符串中。\n```java\nString[] strs = new String[]{\"11111\", \"222\", \"3\"};\n//统计每个字符串的长度\nList<Integer> lengths = Arrays.stream(strs).map(String::length).collect(Collectors.toList());\nString s = Arrays.stream(strs).collect(Collectors.joining(\",\"));\n// lengths=[5,3,1]\n// s = 11111,222,3\n```\n合理的组合Steam操作，可以很大的提升生产力\n\n## 原理\n![](2.png)\nStream的实现类中，将Stream划分成了`Head`、`StatelessOp`和`StatefulOp`，`Head`控制数据流入，中间操作分为了`StatelessOp`和`StatefulOp`。\n\nStatelessOp代表无状态操作：每个数据的处理是独立的，不会影响或依赖之前的数据。像`filter()`、`map()`等。\n\nStatefulOp代表有状态操作：：处理时会记录状态，比如后面元素的处理会依赖前面记录的状态，或者拿到所有元素才能继续下去等这样有状态的操作，像`sorted()`。\n\n现在已下面代码为例，分析一下Stream的原理\n```java\n list.stream()\n     .filter(e -> e.length() > 1)\n     .sorted()\n     .filter(e -> e.equals(\"333\"))\n     .collect(Collectors.toList());\n```\n### 数据源生成流\n首先，进入到`list.stream()`里\n```java\n//Collection#stream\n\n default Stream<E> stream() {\n    return StreamSupport.stream(spliterator(), false);\n }\n\ndefault Spliterator<E> spliterator() {\n    return Spliterators.spliterator(this, 0);\n }\n\n```\n```java\n//StreamSupport#stream\npublic static <T> Stream<T> stream(Spliterator<T> spliterator, boolean parallel) {\n    Objects.requireNonNull(spliterator);\n    return new ReferencePipeline.Head<>(spliterator,\n                                        StreamOpFlag.fromCharacteristics(spliterator),\n                                        parallel);\n}\n```\n将原数据封装成`Spliterator`，同时生成一个`Head`，将`Spliterator`放到`Head`中。\n\n![](3.png)\n\n### 中间操作\n接着分析中间操作`.filter(e -> e.length() > 1)`的代码\n\n```java\n//ReferencePipeline#filter\npublic final Stream<P_OUT> filter(Predicate<? super P_OUT> predicate) {\n    Objects.requireNonNull(predicate);\n    return new StatelessOp<P_OUT, P_OUT>(this, StreamShape.REFERENCE,\n                                  StreamOpFlag.NOT_SIZED) {\n        @Override\n        Sink<P_OUT> opWrapSink(int flags, Sink<P_OUT> sink) {\n            return new Sink.ChainedReference<P_OUT, P_OUT>(sink) {\n                @Override\n                public void begin(long size) {\n                    downstream.begin(-1);\n                }\n\n                @Override\n                public void accept(P_OUT u) {\n                    if (predicate.test(u))\n                        downstream.accept(u);\n                }\n            };\n        }\n    };\n}\n```\n返回的是一个无状态操作`StatelessOp`，查看`StatelessOp`的构造函数\n\n```java\n// AbstractPipeline#AbstractPipeline\n  AbstractPipeline(AbstractPipeline<?, E_IN, ?> previousStage, int opFlags) {\n      if (previousStage.linkedOrConsumed)\n          throw new IllegalStateException(MSG_STREAM_LINKED);\n      previousStage.linkedOrConsumed = true;\n      previousStage.nextStage = this;\n\n      this.previousStage = previousStage;\n      this.sourceOrOpFlags = opFlags & StreamOpFlag.OP_MASK;\n      this.combinedFlags = StreamOpFlag.combineOpFlags(opFlags, previousStage.combinedFlags);\n      this.sourceStage = previousStage.sourceStage;\n      if (opIsStateful())\n          sourceStage.sourceAnyStateful = true;\n      this.depth = previousStage.depth + 1;\n  }\n```\n构造函数中有`previousStage.nextStage = this;`和`this.previousStage = previousStage;`，相当于将当前的`StatelessOp`操作拼接到`Head`后面，构成了一条双向链表。\n\n![](4.png)\n\n再看后面的`.sorted().filter(e -> e.equals(\"333\")).limit(10)`，也会将操作添加到了双向链表后面。`.sorted()`在链表后面添加的是`StatefulOp`有状态操作。\n\n![](5.png)\n\n### 终端操作\n最后走到终端操作`.collect(Collectors.toList())`。进入到`collect()` 中\n```java\n//ReferencePipeline#collect\npublic final <R, A> R collect(Collector<? super P_OUT, A, R> collector) {\n    A container;\n    if (isParallel()\n            && (collector.characteristics().contains(Collector.Characteristics.CONCURRENT))\n            && (!isOrdered() || collector.characteristics().contains(Collector.Characteristics.UNORDERED))) {\n        container = collector.supplier().get();\n        BiConsumer<A, ? super P_OUT> accumulator = collector.accumulator();\n        forEach(u -> accumulator.accept(container, u));\n    }\n    else {\n        container = evaluate(ReduceOps.makeRef(collector));\n    }\n    return collector.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)\n            ? (R) container\n            : collector.finisher().apply(container);\n}\n```\n\n并发操作先不看，直接看`container = evaluate(ReduceOps.makeRef(collector));`，`ReduceOps.makeRef()`返回是`TerminalOp`，代表的是终端操作。\n\n![](6.png)\n\n\n进`evaluate()`中\n```java\n//AbstractPipeline#evaluate\nfinal <R> R evaluate(TerminalOp<E_OUT, R> terminalOp) {\n  assert getOutputShape() == terminalOp.inputShape();\n    if (linkedOrConsumed)\n        throw new IllegalStateException(MSG_STREAM_LINKED);\n    linkedOrConsumed = true;\n\n    return isParallel()\n            ? terminalOp.evaluateParallel(this, sourceSpliterator(terminalOp.getOpFlags()))\n            : terminalOp.evaluateSequential(this, sourceSpliterator(terminalOp.getOpFlags()));\n    }\n```\n\n先不管并行，进串行入`evaluateSequential()`中\n```java\n//ReduceOps#evaluateSequential\npublic <P_IN> R evaluateSequential(PipelineHelper<T> helper,\n                                    Spliterator<P_IN> spliterator) {\n    return helper.wrapAndCopyInto(makeSink(), spliterator).get();\n}\n```\n`makeSink()`将返回一个`Sink`实例，并作为参数和 spliterator 一起传入最后一个节点(terminalOp)的 wrapAndCopyInto() 方法\n```java\n//AbstractPipeline#wrapAndCopyInto\nfinal <P_IN, S extends Sink<E_OUT>> S wrapAndCopyInto(S sink, Spliterator<P_IN> spliterator) {\n    copyInto(wrapSink(Objects.requireNonNull(sink)), spliterator);\n    return sink;\n}\n\nfinal <P_IN> Sink<P_IN> wrapSink(Sink<E_OUT> sink) {\n     Objects.requireNonNull(sink);\n\n    for ( @SuppressWarnings(\"rawtypes\") AbstractPipeline p=AbstractPipeline.this; p.depth > 0; p=p.previousStage) {\n        sink = p.opWrapSink(p.previousStage.combinedFlags, sink);\n    }\n    return (Sink<P_IN>) sink;\n}\n```\n`wrapSink()`将最后一个节点创建的 Sink 传入，并且看到里面有个 for 循环。这个 for 循环是从最后一个节点开始，到第二个节点结束。每一次循环都是将上一节点的 combinedFlags 和当前的 Sink 包起来生成一个新的 Sink 。这和前面拼接各个操作很类似，只不过拼接的是 Sink 的实现类的实例，方向相反。\n\n![](7.png)\n\n\n到现在整个流水已经拼接完成。真正的数据处理在`copyInto()`中。\n```java\n//AbstractPipeline#copyInto\nfinal <P_IN> void copyInto(Sink<P_IN> wrappedSink, Spliterator<P_IN> spliterator) {\n    Objects.requireNonNull(wrappedSink);\n\n    if (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) {\n        wrappedSink.begin(spliterator.getExactSizeIfKnown());\n        spliterator.forEachRemaining(wrappedSink);\n        wrappedSink.end();\n    }\n    else {\n        copyIntoWithCancel(wrappedSink, spliterator);\n    }\n}\n```\n`Sink`中有三个方法：\n- `begin`：节点开始准备\n- `accept`: 节点处理数据\n- `end`： 节点处理结束\n\n`Sink`与操作是相关的，不同的`Sink`有不同的职责，无状态操作的 Sink 接收到通知或者数据，处理完了会马上通知自己的下游。有状态操作的 Sink 则像有一个缓冲区一样，它会等要处理的数据处理完了才开始通知下游，并将自己处理的结果传递给下游。\n\n比如`filter`这种无状态的操作，处理完数据会直接交给下游，而像`sorted`这种无有状态的操作在`begin`阶段会先创建一个容器，`accept`会将流转过来的数据保存起来，最后在执行 `end`方法时才正在开始排序。排序之后再将数据，采用同样的方式依次传递给下游节点。  \n![](8.png)\n\nwrapAndCopyInto() 返回了 TerminalOps 创建的 Sink，这时候它里面已经包含了最终处理的结果。调用它的 get() 方法就获得了最终的结果。\n\n\n`Steam`还可以支持并行流，把`list.stream()`换成`list.parallelStream()`即可使用并行操作。\n\n并行过程中，构建操作链的双向链表是不变的，区别实在构建完后的操作\n```java\n//AbstractPipeline#evaluate\nfinal <R> R evaluate(TerminalOp<E_OUT, R> terminalOp) {\n  assert getOutputShape() == terminalOp.inputShape();\n    if (linkedOrConsumed)\n        throw new IllegalStateException(MSG_STREAM_LINKED);\n    linkedOrConsumed = true;\n\n    return isParallel()\n            ? terminalOp.evaluateParallel(this, sourceSpliterator(terminalOp.getOpFlags()))\n            : terminalOp.evaluateSequential(this, sourceSpliterator(terminalOp.getOpFlags()));\n    }\n```\n这次进入到 `evaluateParallel()`中\n\n```java\n//ReduceOps#evaluateSequential\npublic <P_IN> R evaluateParallel(PipelineHelper<T> helper,\n                                         Spliterator<P_IN> spliterator) {\n    return new ReduceTask<>(this, helper, spliterator).invoke().get();\n}\n```\n`ReduceTask`继承自`ForkJoinTask`，`Steam`的并行底层用的是ForkJoin框架。\n\n\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"区块链的灵魂-共识机制","url":"/2022/07/15/19consensus/","content":"区块链是去中心化、分布式的，每个人都可以自由的参与进来，共同处理区块链中的数据。所谓绝对的自由必然带来绝对的混乱，作为一个巨大的分布式计算网络，必然有一个绕不开的问题--拜占庭将军问题\n\n### 拜占庭将军问题\n拜占庭将军问题（Byzantine failures），是由计算机科学史上的传奇人物莱斯利·兰伯特（Leslie Lamport）提出的。\n\n拜占庭帝国派出10个将军去攻击敌人，这支敌人可以同时抵御5支拜占庭军队的同时袭击。而这10个拜占庭将军在分开的状态下包围了敌人，并且只能依靠通信兵骑马相互通信来协商进攻意向及进攻时间。但是这些将军们不能确定他们的通信兵中是否有叛徒，叛徒可能擅自改变进攻意向及进攻时间。在这种情况下怎样才能保证同时有多于5支军队攻击，来赢得胜利？\n\n![](1.png)\n\n放到区块链中，拜占庭将军问题主要针对点对点通信中的分布式系统一致性问题。可以简单的概括为为 `在整个网络中的任意节点都无法信任与之通信的对方时，如何能创造出共识基础来进行安全信息的交互而无需担心数据被篡改。`\n\n区块链四大核心技术之一的共识机制就是为了解决这个问题。\n\n### 什么是共识机制？\n共识，对特定事务具有相同的认识或态度。 共识在我们的生活中无处不在，说一个场景  \n中午你和同事一起吃午饭，你们在讨论怎么吃，然后你出来提议一起点外卖。其他人对你的提议进行投票，如果没有异议那么这就达成了共识。\n\n![](2.png)\n\n区块链是一个点对点的分布式数据库结构的网络账本。这个账本与传统账本不同，不是由会计或少数几个人来记账，而是人人都可以参与记账。在没有中心机构的情况下，怎么确保别人的数据是正确的？\n\n这就需要一套规则来规定`怎样记账才是有效的`，而这一套规则就是共识机制。\n\n这一套规则主要有两点功能：\n\n- 如何记账\n- 怎样达成共识\n\n按照这套规则来决定区块链中谁取得区块链中的记账权，也就决定着由谁来产生新的区块。\n\n共识机制的作用非常大，直接关系到记账权和相关收益的分配。如果把区块链比作一个社会，那共识机制就是这个社会的法律。不夸张地说，共识机制就是区块链的灵魂。\n\n区块链发展到现在，已经有了多种共识机制，这里主要介绍三种被提及最多的共识机制。\n\n![](3.jpg)\n\n## POW 工作量证明\nPOW(Proof of Work)，工作量证明，闻名于比特币，经常提到的`挖矿`一词也是起源于POW。\n\n![](4.png)\n\nPOW的设计思想是计算一道数学难题，这道题计算过程是复杂的，但是验证过程是简单的。这种特性称之为计算不对称特性。\n\n比如在比特币中选定为以SHA256算法计算一个目标哈希，使得这个哈希值符合前N位全是0。 举个例子,给出一个字符串\"Blockchain\"，要求计算一个数字，与给出的字符串拼接起来，进行SHA256后，得到的结果前4位是0，这个数字称作nonce。比如字符串\"Blockchain1234\"，nonce就是1234。由于结果只能暴力搜索，而且搜索空间非常巨大，作弊几乎不可能。\n\n只要计算出目标值nonce就会获得记账权，距离上一次打包到现在未确认的交易，就可以一次性将未确认的交易打包并广播了。其他节点在接收到消息后，可以对nonce进行验证。\n\n简单来说POW就是谁的计算能力越强，计算的越快，获得记账权的概率就越高。每个节点都在同时解题，一旦有一个节点解出来，其余节点解题的过程也就白费了，只能解下一个节点。所以这种证明方式需要消耗大量能源(电力及计算硬件损耗)。\n\n并且理论上，在POW共识机制保护下，如果一个节点的计算力超过区块链全网的51%，即可对区块链网络进行有效攻击。因此许多基于比特币代码产生的、市值较小的山寨币很容易遭受攻击。这个51%攻击法在「矽谷」这个美剧第四季上曾经上演过这个情节。\n\n## POS 权益证明\nPOS(Proof of Stake), 权益证明，最早出现在点点币的创始人Sunny King的白皮书中，它出现的目地就是为了解决POW挖矿出现大量资源浪费的问题。\n\n在POS中个有`币龄`的概念，它指的是持币数量乘以持币天数。  \n相较与POW中人人都可以参与，人人都可以计算，POW更像是一种选举机制。节点需要抵押一定的代币，区块链网络会根据抵押代币的币龄，随机选取一个节点，由该节点进行打包区块。 抵押代币的多少，影响着被选中的概率。\n\n![](5.png)\n\n\n这种方式不需要每个节点都进行大量的运算，节省了能源。但它同样也有一些缺点。比如，PoS机制中初始的代币分发比较模糊，如果初始代币分发不下去，就很难形成之后的权益证明。并且POS也存在51%的问题，理论上谁能掌握51%的代币，谁就能掌控整个网络，所以，它的去中心化程度要弱一些。\n\n\n## DPOS 代理权益证明\nDPOS(Delegated Proof of Stake),代理权益证明。最初由Bitshares、Steemit以及 EOS 的创办人Dan Larimer提出，他在区块链项目Bitshares中实现了 DPoS 共识机制。DPOS与POS类似也是一种选举机制，它有点像民主大会。\n\n其过程是每一个持币人进行投票，选举出一定数量的代表，并由这些代表来打包区块和验证。这些代表节点的权利是相等的。比如，EOS将产生21个主节点，以及100个备用节点。如果有些代表节点不称职，就随时有可能被投票出局。\n\n![](6.png)\n\nDPOS就像董事会投票，持币者投出一定数量的节点 （董事）。代表按照既定时间表，轮流产生区块，如果代表没能很好的行使权力（比如产生区块），他们会被除名，网络会选出新的代表节点来取代他们。\n\nDPOS通过选举少数节点来出块记账，确实从网络传输和确认时间上看，大幅提升了性能。但是只有少数的节点出块记账的理念，牺牲了部分去中心化。因为DPOS机制的设计并不能保证一定有足额的真实的区块生产者，因为一个人或一个实体，可能控制着多个节点。如果节点的持有人相互串通，将进一步形成巨头垄断，这和区块链思想更是南辕北辙。这也是为什么V神怒怼DPOS的原因。\n\n\n\n","tags":["web3"],"categories":["web3"]},{"title":"认识区块链和web3.0","url":"/2022/06/19/18web3/","content":"\n2017-2018年期间，伴随着比特币的又一轮牛市，第一次认识和了解了区块链。\\\n2019年，高层大佬们集体学习区块链，也跟着重新关注起了区块链。也是因为区块链，去年第一次接触到了Web3.0，给我的第一印象是这东西太过超前了，如果真的能落地，那真的又是一场技术革命了，从那以后陆陆续续的关注着。\\\n今年下半年换了份工作，发现公司做区块链的大牛也在关注Web3.0，也跟着学习长进了不少。\\\n这篇文章主要介绍一些区块链和Web3.0的基本知识，可以对区块链和Web3.0有个大概的了解。\n\n## 区块链\n\n![](web31.png)\n\n2008年，全球金融危机，全世界掀起了反思传统金融制度的思潮，一个叫中本聪的人在P2P foundation网站上发布了比特币白皮书[《比特币：一种点对点的电子现金系统》](https://bitcoin.org/bitcoin.pdf)。\n\n![](web32.png)\n\n在书里提出了一种无须可信第三方的电子支付系统——比特币，通过整合非对称加密技术、工作量证明机制（Proof of Work，简称PoW）、点对点技术（Peer-to-Peer，简称P2P）等来保障个人对资产的所有权和匿名性，彻底颠覆了对于货币需要依赖中心化机构发行的传统认知。\n\n区块链和比特币由此诞生，那区块链到底是什么呢？。\\\n可以把区块链理解成一个数据库，这个数据库有几个重要的特点：\n\n*   去中心化\n*   不可篡改\n*   透明性\n\n区块链是怎么做到这些的呢？先看一下区块链的大致结构。\n\n![](web33.png)\n\n区块链可以大致理解为： 由一笔一笔的交易组成一个区块，一个一个的区块组成的一条链。这里的交易不单单指的双方买卖，双方发生的任何业务都可以称为交易。\n\n整个区块链是由所有参与节点共同维护的，每个节点都可以保存区块链的全部数据。\n\n在区块链系统里，每当发生一个交易，交易都是双方是直接进行的。交易的双方会把交易信息广播到整个交易系统里，系统中的一些节点会将这些交易打包成区块，并广播到整个区块链系统中，这些节点就可以称为矿工，而打包的过程就是挖矿。系统中的节点会对矿工打包的区块进行验证，验证通过则放到区块链中。\n\n在每个区块的头部包含了上一个区块的哈希值，这个哈希值是由上个区块中的内容生成的，如果某个节点想要修改某个区块中的内容，那么该区块的哈希值也会改变，该区块以后所有的区块也都需要改变。这就相当与以一己之力对抗系统中的所有人，当系统中的节点多的时候，这种操作可以说是几乎不可能的。\n\n区块链从诞生到现在，整个发展过程可以简单的划分为3个阶段：\n\n### 1、 区块链1.0 以比特币为代表的数字货币阶段\n\n![](web34.png)\n\n比特币的出现，催生出了区块链，但是比特币区块链，所有规则是事先写好的，没有人可以在比特币区块链上修改任何规则，你只能用它，而不能在它的基础上再去发展。也就是说这一时期的区块链，只是为了服务与特定的业务，并不能作为一个通用的平台。以太坊对于区块链技术而言，是一次飞跃性的突破，它让区块链商业应用变得可能。\n\n### 2、 区块链2.0 以太坊为代表的智能合约阶段\n\n![](web35.png)\n\n2015年，一个新的公链出现，叫做以太坊。并将智能合约带到了区块链中。以太坊可以被看作是一台`全球计算机`，它允许所有人在以太坊区块链的基础上做其他的应用开发。\n\n### 3、 区块链3.0 开始超出金融行业，为各行各业提供解决方案，为新的互联网理念web3.0提供支持。\n\n![](web36.png)\n\n## Web3.0\n\n![](web37.png)\n\n说起Web3.0,先要从Web1.0和Web2.0说起。\n\n### 1、Web1.0 静态互联网\n\nWeb1.0时期，也称为静态互联网时期，是互联网发展的第一个阶段，这一阶段互联网上的内容是由平台提供，用户只能`读取信息`而不能写入信息。最典型的互联网产品是门户网站、搜索引擎等工具。代表性的有搜狐、新浪和网易三大门户网站。\n\n### 2、Web2.0 平台互联网\n\nWeb2.0时期，也就是我们现在所处的时期，被称为平台互联网时期。Web2.0的概念在2004年始于出版社经营者O'Reilly和Media Live International之间的一场头脑风暴论坛。当时对Web2.0的讨论也像今天我们讨论Web3.0一样激烈。\n\nWeb2.0相比于Web1.0更加注重用户的交互，用户既可以是网站内容的浏览者也可以是内容的创造者，由以前的只能`读`向`写`和`共同建设`发展。用户也参与到互联网的发展。开始慢慢全面移动化，同时平台经济崛起，比如百度、阿里、腾讯、字节。\n\n但是随着Web2.0的发展，平台互联网的弊端也越来越让人难以接受，所谓天下苦平台互联网时代久矣。当下的平台互联网：用户创造、平台所有、平台控制、平台分配、平台垄断、隐私泄漏等问题，形成了平台吞噬一切的现象。\n\n2019年，《纽约时报》发布了一篇名为《减少互联网是唯一的答案》（The Only Answer Is Less Internet）的文章，对Web2.0时代的平台垄断、数据隐私、假新闻等问题进行了严厉批评。随着各国监管机构逐渐加强对互联网行业的监管，赢家通吃不再是互联网的铁律，合规化运营与寻找新增量成了行业发展的迫切需求，这也为Web3.0的到来埋下了伏笔。\n\n### 3、Web3.0 价值互联网\n\n那里有压迫，那里就有反抗。在经历了一系列Web2.0弊端后，区块链时代的Web3.0出现了。\n\n其实Web3.0一直是一个动态变化的过程，在区块链技术没有诞生之前，Web3.0通常意味这是一个更加智能的互联网，能够理解语义进行判断。在区块链诞生之后，Web3.0一般指建立在区块链技术之上的去中心化、去信任、无须许可的下一代互联网。\n\nWeb3.0有一下主要几个特点：\n\n*   去中心化、去信任，不依赖第三方机构运作，避免平台吞噬一切\n\n*   可拥有，用户可以掌握自己在互联网上的数据和数字资产\n\n*   无须许可，代码开源、抗审查、可自由接入\n\n*   全球化，资产在全球自由流动\\\n    ......\n\nWeb3.0的核心理念为数据的所有权归用户所有，每个人都可以控制自己的身份、数据和资产。\n\n比如，我写了一篇文章，我授权给了某个平台，平台展示我的文章，并在文章下产生了一些评论。如果有一天我觉着这个平台不靠谱，我可以取消授权，同时将文章和评论授权给别的平台。实现真正的我的数据归我所有。\n\n从2008年中本聪发布比特币白皮书，到2021年NFT和元宇宙的爆发，Web3.0已经从一小撮极客圈子，逐渐发展成为了一个庞大的科技产业，并且在多个方面带来了技术和应用\n\n*   去中心化金融(Defi)\n\n    无须中心化的金融机构，即可实现传统金融中的贷款、保险、理财、股票等服务。比如Maker、Compound用于借贷的平台\n*   非同质化代币(NFT)\n\n    NFT有可验证、唯一、不可分割和可追溯的特性，可以用来标记特定资产，在数字货币中是重要的工具。比如著名球星库里花18万美元买一个NFT数字头像、游戏方面的GameFi、国内阿里，腾讯等推出的数字藏品等。\n*   分布式自治组织(Dao)\n\n    没有公司章程、没有层级制度、没有董事会，完全依靠民主治理、由参与者共同投票决定。比如Aragon、Moloch等Dao操作系统\n*   元宇宙\n\n可能大家还是觉着Web3.0现在还只是概念居多，但是在资本市场上Web3.0早已成为投资人眼里的香饽饽。\n\n*   全球最大的风险投资公司之一的红杉资本一口气投资了20多家Web3.0公司。\n\n在政府层面上，也是同样在你追我敢\n\n*   美国出台支持性政策，要保证Web3.0革命发生在美国。\n\n*   今年中国证监会科技监管局局长在《中国金融》杂志上撰文指出，“如今互联网正处在Web2.0向Web3.0演进的重要时点，加强Web3.0前瞻研究和战略预判，对我国未来互联网基础设施建设无疑具有重要意义。”\n\n*   10月31号，香港财政司正式发布《有关香港虚拟资产发展的政策宣言》，迎接Web3.0。\n\n处在风口的Web3.0到底是资本炒作的工具，还是一场真正的技术革命？\n\n屠龙少年会不会终成恶龙？\n\n让我们拭目以待。\n\n","tags":["web3"],"categories":["web3"]},{"title":"Java类加载器","url":"/2022/05/27/classload/","content":"### 类加载器\n我们写的每一个Java文件，首先通过编译器编译成class文件，然后经过类加载器加载到jdk运行时内存中生成一个class类，才会被程序使用。而类加载器就是加载字节码(.class)文件的类--`java.lang.ClassLoader`。\n### 类加载器的分类\nJava默认设置了三个类加载器。\n- BootstrapClassloader\n- ExtClassloader\n- AppClassloader  \n\nBootstrapClassloader 叫做启用类加载器，用于加载JRE核心类库，使用C++实现。加载路径%JAVA_HOME%/lib下的所有类库。  \n\nExtClassloader 扩展类加载器，加载%JAVA_HOME%/lib/ext中的所有类库。  \n\nAppClassloader 应用类加载器也叫系统类加载器System Classloader，加载%CLASSPATH%路径下的所有类库。\n\nJava 也提供了扩展，可以让我们自己实现类加载的功能。类加载器在Java中是`java.lang.ClassLoader`这个类，如果要自定义类加载器，只要实现这个类，重写加载方法就好了。\n\n在Java中，由不同的类加载器加载的两个相同的类在Java虚拟机里是两个不同的类，那么Java是怎么确保一个类不会被多个类加载器重复加载，并且保证核心API不会被篡改的呢？  \n\n这就需要Java的双亲委派机制。\n\n### 双亲委派机制\n\n![](classload.png)\n\n1、当一个类加载器接到加载类的请求后，首先会交给父类去加载，如果所有父类都无法加载，自己加载，并将被加载的类缓存起来。。\n\n2、每加载一个类，所有的类加载器都会判断是否可以加载，最终会委托到启动类加载器来首先加载。所有的类的加载都尽可能由顶层的类加载器加载，这样就保证了加载的类的唯一性。  \n\n3、启动类加载器、扩展类加载器、应用程序类加载器，都有自己加载的类的范围，因此并不是所有的类父类都可以加载。\n\nJava 类加载器中还有一个全盘委托机制，当指定一个`ClassLoader`加载一个类时，该类所依赖或者引用的类也会由这个类加载器来加载，除非显示的用别的类加载器加载\n\n比如：程序入口默认用的是`AppClassloader`，那么以后创建出来的类也是用`AppClassloader`来加载，除非自己显示的用别的类加载器去加载。(classX引用了classY，那么ClassX的类加载器就会去加载classY(前提是classY尚未被加载))\n\n### 线程上下文加载器\n因为双亲委派机制的存在，每个类加载器都有自己的加载范围。但是在JDK中提供了很多服务提供者接口（Service Provider Interface，SPI），他们允许第三方来实现接口，比如常见的JDBC、JNDI、JAXP等。  \n\n 这些接口是由Java核心库提供的，并由启用类加载器(BootstrapClassloader)加载，而实现确是在Java应用所依赖的第三方Jar包里的，默认是由应用类加载器(AppClassloader)加载。 \n \nJava引入了线程上下文加载器的概念来打破双亲委派机制。 通过线程`Thread`类的`getContextClassLoader()`和 `setContextClassLoader(ClassLoader cl)`来设置线程上下文加载器。如果没有通过`setContextClassLoader(ClassLoader cl)`进行设置的话，线程将继承其父线程的上下文类加载器。\n\n线程上下文加载器并不是一个真实存在的类，而是一个概念。它是Thread类里的一个成员变量。\n```java\npublic class Thread implements Runnable {\n\n   private ClassLoader contextClassLoader;\n\n   public void setContextClassLoader(ClassLoader cl) {\n       SecurityManager sm = System.getSecurityManager();\n       if (sm != null) {\n           sm.checkPermission(new RuntimePermission(\"setContextClassLoader\"));\n       }\n       contextClassLoader = cl;\n   }\n\n\n\n   public ClassLoader getContextClassLoader() {\n       if (contextClassLoader == null)\n           return null;\n       SecurityManager sm = System.getSecurityManager();\n       if (sm != null) {\n           ClassLoader.checkClassLoaderPermission(contextClassLoader,\n                                                  Reflection.getCallerClass());\n       }\n       return contextClassLoader;\n   }\n}\n```\n \n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"Java工具 Jstack 的使用","url":"/2022/04/27/jstack/","content":"\n> jstack - Prints Java thread stack traces for a Java process, core file, or remote debug server.\n\n\nJstack主要的作用是生成当前进程中所有线程的信息，也就是当前时刻JVM的线程快照，通过线程的信息我们可以定位到程序中出现长时间停顿、CPU占用率过高等问题。\n\n线程快照中的信息是当前java虚拟机内每一条线程正在执行的方法的堆栈集合，有了堆栈信息我们就可以分析出我们的程序问题出现在哪，比如线程间死锁、外部资源请求时间过长、死循环等。\n\n\n\n使用：\n\n```\njstack [ options ] pid\n\njstack [ options ] executable core\n\njstack [ options ] [ server-id@ ] remote-hostname-or-IP\n\n\nOPTIONS\n       -F\n              Force a stack dump when jstack [-l] pid does not respond.\n\n       -l\n              Long listing. Prints additional information about locks such as a list of owned java.util.concurrent ownable synchronizers. See the\n              AbstractOwnableSynchronizer class description at\n              http://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/AbstractOwnableSynchronizer.html\n\n       -m\n              Prints a mixed mode stack trace that has both Java and native C/C++ frames.\n```\n\n- -F  当正常的请求不被响应时，强制输出堆栈信息。\n- -l  额外打印锁的信息，当发生死锁时可以查看锁的信息\n- -m 如果调用本地方法栈的信息，可以打印C/C++的堆栈\n\n\n\n以一个发生死锁的例子来看一下使用Jstack查看到的信息\n\n```java\npublic class Jstack {\n\n    private static Object obj1 = new Object();\n    private static Object obj2 = new Object();\n\n    public static void main(String[] args) {\n\n        new Thread(() -> {\n            synchronized (obj1) {\n                try {\n                    Thread.sleep(2000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                synchronized (obj2) {\n                }\n            }\n        }).start();\n        new Thread(() -> {\n            synchronized (obj2) {\n                try {\n                    Thread.sleep(2000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                synchronized (obj1) {\n                }\n            }\n        }).start();\n    }\n}\n```\n\n上面代码中，第一个线程拿到obj1的锁，等待obj2的锁，第二个线程拿到obj2的锁，等待obj1的锁，这样就会发生死锁。\n\n\n\n先通过`jps`命令获取到先拿到当前的进程pid，然后通过jstack获取线程的信息。可以看到有两个线程都处于阻塞状态。\n\n```\n\"Thread-1\" #12 prio=5 os_prio=0 tid=0x00007fdff871c800 nid=0x3cc2 waiting for monitor entry [0x00007fdfce0fc000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat com.example.demo.jstack.Jstack.lambda$main$1(Jstack.java:36)\n\t- waiting to lock <0x000000076e925a90> (a java.lang.Object)\n\t- locked <0x000000076e925aa0> (a java.lang.Object)\n\tat com.example.demo.jstack.Jstack$$Lambda$2/2052001577.run(Unknown Source)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\"Thread-0\" #11 prio=5 os_prio=0 tid=0x00007fdff871a800 nid=0x3cc1 waiting for monitor entry [0x00007fdfce1fc000]\n   java.lang.Thread.State: BLOCKED (on object monitor)\n\tat com.example.demo.jstack.Jstack.lambda$main$0(Jstack.java:25)\n\t- waiting to lock <0x000000076e925aa0> (a java.lang.Object)\n\t- locked <0x000000076e925a90> (a java.lang.Object)\n\tat com.example.demo.jstack.Jstack$$Lambda$1/1174361318.run(Unknown Source)\n\tat java.lang.Thread.run(Thread.java:748)\n```\n\n第一行显示线程名、线程优先级、线程id、线程状态描述等信息\n\n第二行显示的是当前线程的状态\n\n​      Java中线程的状态分为NEW、RUNNABLE、BLOCKED、WATING、TIMED_WATING、TERMINATED，但是在快照中NEW状态是不会出现的。\n\n再下面的就是当前线程的调用栈的信息。调用栈中包含了锁的信息。\n\n​     `locked    `   表示使用synchronized申请对象锁成功,监视器的拥有者\n\n​     `waiting to lock `  表示使用synchronized申请对象锁未成功,进入等待区。\n\n​\t `waiting on`    表示用synchronized申请对象锁成功后,调用了wait方法,进入对象的等待区等待。\n\n​    `parking to wait for`  park是基本的线程阻塞原语,不通过监视器在对象上阻塞。随concurrent包会出现的新的机制,与synchronized体系不同。\n\n\n\n在最后也显示出了代码中出现死锁的信息\n\n```\nFound one Java-level deadlock:\n=============================\n\"Thread-1\":\n  waiting to lock monitor 0x00007fdfac006638 (object 0x000000076e925a90, a java.lang.Object),\n  which is held by \"Thread-0\"\n\"Thread-0\":\n  waiting to lock monitor 0x00007fdfac003da8 (object 0x000000076e925aa0, a java.lang.Object),\n  which is held by \"Thread-1\"\n\nJava stack information for the threads listed above:\n===================================================\n\"Thread-1\":\n\tat com.example.demo.jstack.Jstack.lambda$main$1(Jstack.java:36)\n\t- waiting to lock <0x000000076e925a90> (a java.lang.Object)\n\t- locked <0x000000076e925aa0> (a java.lang.Object)\n\tat com.example.demo.jstack.Jstack$$Lambda$2/2052001577.run(Unknown Source)\n\tat java.lang.Thread.run(Thread.java:748)\n\"Thread-0\":\n\tat com.example.demo.jstack.Jstack.lambda$main$0(Jstack.java:25)\n\t- waiting to lock <0x000000076e925aa0> (a java.lang.Object)\n\t- locked <0x000000076e925a90> (a java.lang.Object)\n\tat com.example.demo.jstack.Jstack$$Lambda$1/1174361318.run(Unknown Source)\n\tat java.lang.Thread.run(Thread.java:748)\n\nFound 1 deadlock.\n```\n\n\n\n好了，熟悉了Jstack，我们用一段死循环的代码，通过Jstack来定位到使CPU占用100%的代码行\n\n```java\npublic class JstackDemo {\n    public static Executor executor = Executors.newFixedThreadPool(3);\n    private static Object lock = new Object();\n\n    public static void main(String[] args) {\n        Task task1 = new Task();\n        Task task2 = new Task();\n        executor.execute(task1);\n        executor.execute(task2);\n    }\n\n    public static class Task implements Runnable {\n\n        @Override\n        public void run() {\n            synchronized (lock) {\n                run0();\n            }\n        }\n\n        private void run0() {\n            int i = 0;\n            while (true) {\n                i++;\n            }\n        }\n    }\n}\n\n```\n\n\n\n1、首先通过`top`查看到使CPU占用到100%的进程id\n\n  ![](top.png)\n\n2、使用`top -Hp 进程id` 查看占用CPU最多的线程id\n\n![](top-Hp.png)\n\n3、将线程id转换为16进制\n\n 17997 -> 464d\n\n4、使用Jstack查看Java所在的进程，并找到相应的线程\n\n![](run0.png)\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"ThreadLocal 内存泄露问题","url":"/2022/04/06/threadlocal/","content":"\n\n> 内存泄漏（Memory Leak）是指程序中已动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。  ——百度百科\n\n\n上述的意思用在java中就是存在已经没有任何引用的对象，但是GC又不能把对象所在的内存回收掉，所以就造成了内存泄漏。\n\nThreadLocal主要解决的是对象不能被多个线程同时访问的问题。根据ThreadLocal的源码看看它是怎么实现的。\n\nThreadLocal设置数据的`set()`方法\n\n```java\n  public void set(T value) {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null)\n            map.set(this, value);\n        else\n            createMap(t, value);\n    }\n\n    ThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }\n\n    void createMap(Thread t, T firstValue) {\n        t.threadLocals = new ThreadLocalMap(this, firstValue);\n    }\n```\n\n\n\n可以看到在使用ThreadLocal设置数据时，其实设置到的是当前线程的threadLocals字段里，去Thread里看一看threadLocals变量\n\n```java\n  ThreadLocal.ThreadLocalMap threadLocals = null;\n```\n\nthreadLocals的类型是ThreadLocal里的内部类ThreadLocalMap，ThreadLocalMap的中用来存储数据的又是一个内部类是`Entry`\n\n```java\n static class Entry extends WeakReference<ThreadLocal<?>> {\n        Object value;\n\n        Entry(ThreadLocal<?> k, Object v) {\n             super(k);\n             value = v;\n         }\n   }\n```\n\n`Entry`的key是当前ThreadLocal，value值是我们要设置的数据。\n\n`WeakReference`表示的是弱引用，当JVM进行GC时，一旦发现了只具有弱引用的对象，不管当前内存空间是否足够，都会回收它的内存。\n\n因为`WeakReference<ThreadLocal<?>>`，所以在`Entry`中`ThreadLocal`是弱引用，一旦发生GC，`ThreadLocal`会被GC回收掉，但是`value`是强引用，它不会被回收掉。用一张图来表示一下\n\n![ThreadLocal](ThreadLocal.png)\n\n\n\n图中实线表示的是强引用，虚线表示的是弱引用。\n\n当JVM发生GC后，虚线会断开应用，也就是key会变为null，value是强引用不会为null，整个Entry也不为null，它依然在ThreadLocalMap中，并占据着内存，\n\n我们获取数据时，使用ThreadLocal的`get()`方法，ThreadLocal并不为null，所以我们无法通过一个key为null去访问到该entry的value。这就造成了内存泄漏。\n\n\n\n既然用弱引用会造成内存泄漏，直接用强引用可以么？\n\n答案是不行。如果是强引用的话，看看下面代码\n\n```java\n ThreadLocal threadLocal = new ThreadLocal();\n threadLocal.set(new Object());\n threadLocal = null;\n```\n\n我们在设置完数据后，直接将threadLocal设为null，这时栈中`ThreadLocal Ref` 到堆中`ThreadLocal`断开了，但是`key`到`ThreadLocal`的引用依然存在，GC依旧没法回收，同样会造成内存泄漏。\n\n\n\n那弱引用比强引用好在哪？\n\n当key为弱引用时，同样是上面代码，当threadLocal设为null时，栈中`ThreadLocal Ref` 到堆中`ThreadLoacl`断开了，`key`到`ThreadLoacl`也因为GC断开了，这时`ThreadLocal`就可以被回收了。\n\n同时,ThreadLocal也可以根据`key.get() == null` 来判断key是否已经被回收，因此ThreadLocal可以自己清理这些过期的节点来避免内存泄漏。\n\n\n\n其实，ThreadLocal做了很大的工作清除过期的key来避免发生内存泄漏\n\n1. 在调用`set（）`方法时，会进行清理\n\n   ```java\n    private void set(ThreadLocal<?> key, Object value) {\n   \n        Entry[] tab = table;\n        int len = tab.length;\n        int i = key.threadLocalHashCode & (len-1);\n   \n        for (Entry e = tab[i];\n             e != null;\n             e = tab[i = nextIndex(i, len)]) {\n             ThreadLocal<?> k = e.get();\n   \n             if (k == key) {\n                 e.value = value;\n                 return;\n              }\n   \t\t\t// 当key为null时，替换掉\n              if (k == null) {\n                  replaceStaleEntry(key, value, i);\n                  return;\n              }\n        }\n   \n        tab[i] = new Entry(key, value);\n        int sz = ++size;\n        // 清理一些槽位，清理过期key\n        if (!cleanSomeSlots(i, sz) && sz >= threshold)\n            rehash();\n    }\n   \n   ```\n\n   1、 当key为null时，说明该位置被GC回收了，会将当前位置覆盖掉。\n\n   2、 在`set()`方法最后调用了`cleanSomeSlots()`中还会有清理的操作。看一看`cleanSomeSlots()`\n\n   ```java\n    private boolean cleanSomeSlots(int i, int n) {\n        boolean removed = false;\n        Entry[] tab = table;\n        int len = tab.length;\n        do {\n            i = nextIndex(i, len);\n            Entry e = tab[i];\n            if (e != null && e.get() == null) {\n                n = len;\n                removed = true;\n                // 真正的清理工作\n                i = expungeStaleEntry(i);\n             }\n         } while ( (n >>>= 1) != 0);\n         return removed;\n    }\n   \n   ```\n\n   `cleanSomeSlots()`中当判断`e != null && e.get() == null`为true时，说明已经被GC回收了，会调用`expungeStaleEntry()`进行清理工作，具体的逻辑就不再看了。\n\n   \n\n2. 在调用`get()`方法时，如果没有命中，会向后查找，也会进行清理操作\n\n   ```java\n    \n   private Entry getEntry(ThreadLocal<?> key) {\n        int i = key.threadLocalHashCode & (table.length - 1);\n        Entry e = table[i];\n        if (e != null && e.get() == key)\n            return e;\n        else\n            // 没有命中向后查找\n           return getEntryAfterMiss(key, i, e);\n    }\n    private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {\n        Entry[] tab = table;\n        int len = tab.length;\n   \n        while (e != null) {\n            ThreadLocal<?> k = e.get();\n            if (k == key)\n                return e;\n            if (k == null)\n                // 当key为null，说明被GC回收了，进行清理的操作\n                expungeStaleEntry(i);\n            else\n                i = nextIndex(i, len);\n            e = tab[i];\n        }\n        return null;\n    }\n   ```\n\n   \n\n3. 调用`remove()`时，除了清理当前节点，还会向后进行清理操作\n\n   ```java\n    private void remove(ThreadLocal<?> key) {\n        Entry[] tab = table;\n        int len = tab.length;\n        int i = key.threadLocalHashCode & (len-1);\n        for (Entry e = tab[i];\n             e != null;\n             e = tab[i = nextIndex(i, len)]) {\n             if (e.get() == key) {\n                 e.clear();\n                 // 向后查找，进行清理操作\n                 expungeStaleEntry(i);\n                 return;\n              }\n         }\n    }\n   ```\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"Spring Boot 打包成Jar包运行的原理","url":"/2022/04/05/springbootjar/","content":"\n相比于传统的Java打包方式，使用SpringBoot打包插件打包成jar包后，可以直接使用`java -jar` 运行SpringBoot项目，本篇就来分析一下运行的原理。\n\nSpringBoot打包插件\n\n```xml\n<plugin>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-maven-plugin</artifactId>\n</plugin>\n```\n\n\n\n打包完后会生成两个文件，一个`***.jar`和`***.jar.original`\n\n`.jar`文件是SpringBoot打包后生成的文件，`.jar.original`是用原生方式打包生成的文件，对比一下两个的区别\n\n\n\n`.jar.original`文件\n\n![original](jar.png)\n\n`.jar`文件\n\n![jar](springbootjar.png)\n\n\n\n\n\n`.jar.original`就是普通的jar打包的结构，这里主要看`.jar`文件的结构：\n\n- META-INFO目录：META-INFO/MANIFEST.MF里包含了jar包的元数据，包含了项目的启动类等信息.\n\n- org目录：该目录下包含的是启动项目的一些类，启动的过程就在这个包里。\n\n- BOOT-INFO目录：本地项目的代码（BOOT-INF/classes），以及所需的依赖（BOOT-INFO/lib）\n\n  \n\n重点在META-INFO/MANIFEST.MF里：\n\n```\nManifest-Version: 1.0\nSpring-Boot-Classpath-Index: BOOT-INF/classpath.idx\nImplementation-Title: demo\nImplementation-Version: 0.0.1-SNAPSHOT\nSpring-Boot-Layers-Index: BOOT-INF/layers.idx\nStart-Class: com.example.demo.DemoApplication\nSpring-Boot-Classes: BOOT-INF/classes/\nSpring-Boot-Lib: BOOT-INF/lib/\nBuild-Jdk-Spec: 1.8\nSpring-Boot-Version: 2.4.5\nCreated-By: Maven Jar Plugin 3.2.0\nMain-Class: org.springframework.boot.loader.JarLauncher\n```\n\n这里有几个重点的字段\n\n- Main-Class ：jar包启动类，这是java规定的字段，存在这个字段的情况下， 在`java -jar`时，jar包才会运行起来\n- Start-Class：本地项目的启动类\n- Spring-Boot-Classes：加载应用类的入口\n- Spring-Boot-Lib：项目所需的依赖\n\n\n\n有了Main-Class启动类，那就直接进入到`JarLauncher`里查看运行的过程\n\n```java\n    public static void main(String[] args) throws Exception {\n        (new JarLauncher()).launch(args);\n    }\n```\n\n在`JarLauncher`的`main`方法里调用了`launch`方法，`launch`方法的具体实现在`JarLauncher`的抽象父类`Launcher`中实现\n\n```java\n    protected void launch(String[] args) throws Exception {\n        if (!this.isExploded()) {\n            JarFile.registerUrlProtocolHandler();\n        }\n\n        ClassLoader classLoader = this.createClassLoader(this.getClassPathArchivesIterator());\n        String jarMode = System.getProperty(\"jarmode\");\n        String launchClass = jarMode != null && !jarMode.isEmpty() ? \"org.springframework.boot.loader.jarmode.JarModeLauncher\" : this.getMainClass();\n        this.launch(args, launchClass, classLoader);\n    }\n\n```\n\n- 首先获取了类加载器。\n- 然后获取jarMode，再根据jarMode获取launchClass，如果没有设置jarMode，则根据`getMainClass`方法获取，`getMainClass`的具体实现在`ExecutableArchiveLauncher`中实现\n\n   ```java\n    protected String getMainClass() throws Exception {\n           Manifest manifest = this.archive.getManifest();\n           String mainClass = null;\n           if (manifest != null) {\n               mainClass = manifest.getMainAttributes().getValue(\"Start-Class\");\n           }\n   \n           if (mainClass == null) {\n               throw new IllegalStateException(\"No 'Start-Class' manifest entry specified in \" + this);\n           } else {\n               return mainClass;\n           }\n       }\n   ```\n\n​     在`getMainClass`里获取了`MANIFEST.MF`文件里`Start-Class`字段的值，也就是本地项目的启动类。\n\n- 最后调用`this.launch(args, launchClass, classLoader);`\n\n    ```java\n        protected void launch(String[] args, String launchClass, ClassLoader classLoader) throws Exception {\n            Thread.currentThread().setContextClassLoader(classLoader);\n            this.createMainMethodRunner(launchClass, args, classLoader).run();\n        }\n    ```\n\n   调用`MainMethodRunner`的`run()`方法\n\n```java\n\n    public void run() throws Exception {\n        Class<?> mainClass = Class.forName(this.mainClassName, false, Thread.currentThread().getContextClassLoader());\n        Method mainMethod = mainClass.getDeclaredMethod(\"main\", String[].class);\n        mainMethod.setAccessible(true);\n        mainMethod.invoke((Object)null, this.args);\n    }\n\n```\n\n在`run()`方法里通过反射拿到了项目的启动类的`main`方法，从而启动本地项目。","tags":["Spring Boot"],"categories":["JAVA"]},{"title":"设计一个支持热加载的Java应用启动器","url":"/2021/12/29/hot-loading/","content":"热加载是指在不重启服务的情况下使更改的代码生效。注意和热部署的区别，热加载主要是在开发环境下使用。\n\n首先要知道Java程序是怎么运行起来的，Java类加载分为其7个阶段。\n\n![phase](phase.png)\n\n其中加载阶段是用户可以自定义，而验证阶段、准备阶段、解析阶段、初始化阶段都是用 JVM 来处理的。  \n整个类加载是在Java 中一个叫做类加载器上进行的，如果我们能程序更改后，让程序所在的进程能够实时的获取到编译后的Class类字节码信息，然后重新加载的话，那么就可以实现热加载功能。\n\n### Java 类加载器\n类加载器，顾名思义就是加载Java类的工具，Java默认设置了三个类加载器。\n- BootstrapClassloader\n- ExtClassloader\n- AppClassloader  \n\nBootstrapClassloader 叫做启用类加载器，用于加载JRE核心类库，使用C++实现。加载路径%JAVA_HOME%/lib下的所有类库。  \n\nExtClassloader 扩展类加载器，加载%JAVA_HOME%/lib/ext中的所有类库。  \n\nAppClassloader 应用类加载器也叫系统类加载器System Classloader，加载%CLASSPATH%路径下的所有类库。\n\nJava 也提供了扩展，可以让我们自己实现类加载的功能。类加载器在Java中是`java.lang.ClassLoader`这个类，如果要自定义类加载器，只要实现这个类，重写加载方法就好了。\n\n在Java中，由不同的类加载器加载的两个相同的类在Java虚拟机里是两个不同的类，那么Java是怎么确保一个类不会被多个类加载器重复加载，并且保证核心API不会被篡改的呢？  \n\n这就需要Java的双亲委派机制。\n\n### 双亲委派机制\n\n![classloader](classloader.png)\n\n当一个类加载器接到加载类的请求后，首先会交给父类去加载，如果所有父类都无法加载，自己加载，并将被加载的类缓存起来。。\n\n每加载一个类，所有的类加载器都会判断是否可以加载，最终会委托到启动类加载器来首先加载。所有的类的加载都尽可能由顶层的类加载器加载，这样就保证了加载的类的唯一性。  \n\n启动类加载器、扩展类加载器、应用程序类加载器，都有自己加载的类的范围，因此并不是所有的类父类都可以加载。\n\n\n\nJava 类加载器中还有一个全盘委托机制，当指定一个`ClassLoader`加载一个类时，该类所依赖或者引用的类也会由这个类加载器来加载，除非显示的用别的类加载器加载。\n\n比如：程序入口默认用的是`AppClassloader`，那么以后创建出来的类也是用`AppClassloader`来加载，除非自己显示的用别的类加载器去加载。\n\n### 热加载\nOK，有了以上铺垫，现在可以来实现热加载的功能了，怎么实现呢？  \n\n1、首先要实现自己的类加载器，破坏双亲委派机制。  \n2、通过自定义的类加载器加载所需的类。  \n3、不断的轮询判断类是否有变化，如果有变化重新加载。\n\n\n自定义类加载器\n```java\npublic class MyClassLoader extends ClassLoader {\n\n\n    private static final String SUFFIX = \".class\";\n\n    private String rootPath;\n\n    public MyClassLoader(String rootPath) {\n        this.rootPath = rootPath;\n    }\n\n    /**\n     * 破坏双亲委派机制,自定义类加载方式\n     * @param name\n     * @return\n     * @throws ClassNotFoundException\n     */\n    @Override\n    public Class<?> loadClass(String name) throws ClassNotFoundException {\n        Class<?> loadedClass = findLoadedClass(name);\n        if (null == loadedClass) {\n            try {\n                return findClass(name);\n            } catch (ClassNotFoundException e) {\n                return super.loadClass(name);\n            }\n        }\n\n        return loadedClass;\n    }\n\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        String path = rootPath + name.replace(\".\", \"/\") + SUFFIX;\n        File file = new File(path);\n        byte[] classBytes = null;\n        try {\n            classBytes = getClassBytes(file);\n        } catch (Exception e) {\n        }\n        if (null != classBytes) {\n            if (null != super.findLoadedClass(name)) {\n                return super.findLoadedClass(name);\n            }\n            Class<?> aClass = defineClass(name, classBytes, 0, classBytes.length);\n            if (null != aClass) {\n                return aClass;\n            }\n        }\n        return super.findClass(name);\n    }\n\n    /**\n     * 加载类\n     * @param file\n     * @return\n     * @throws Exception\n     */\n    private byte[] getClassBytes(File file) throws Exception {\n        FileInputStream fileInputStream = new FileInputStream(file);\n        FileChannel fc = fileInputStream.getChannel();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        WritableByteChannel writableByteChannel = Channels.newChannel(baos);\n        ByteBuffer by = ByteBuffer.allocate(1024);\n        while (true) {\n            int read = fc.read(by);\n            if (read == 0 || read == -1) {\n                break;\n            }\n            by.flip();\n            writableByteChannel.write(by);\n            by.clear();\n        }\n        fileInputStream.close();\n        return baos.toByteArray();\n    }\n}\n```\n自定义类加载器重写了`loadClass()`方法和`findClass`方法，破坏了Java的双亲委派机制，先通过自定义的类加载所需的类，如果加载不到，再交给父类加载。  \n\n接下来，写启动器\n```java\npublic class Run {\n\n    public static String rootPath;\n\n    public static void run(Class cl) {\n        rootPath = cl.getClass().getResource(\"/\").getPath();\n        MyClassLoader myClassLoader = new MyClassLoader(rootPath);\n        startFileListener(rootPath);\n        start0(myClassLoader);\n    }\n\n    public static void startFileListener(String rootPath) {\n        FileAlterationObserver fileAlterationObserver = new FileAlterationObserver(rootPath);\n        fileAlterationObserver.addListener(new FileListener());\n        FileAlterationMonitor fileAlterationMonitor = new FileAlterationMonitor(5);\n        fileAlterationMonitor.addObserver(fileAlterationObserver);\n        try {\n            fileAlterationMonitor.start();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n\n    public static void start0(MyClassLoader classLoader) {\n        Class<?> clazz = null;\n        try {\n            clazz = classLoader.findClass(\"com.example.Run\");\n            clazz.getMethod(\"start\").invoke(clazz.newInstance());\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 模拟启动应用程序\n     */\n    public static void start() {\n        Application application = new Application();\n        application.printApplicationName();\n    }\n}\n```\n`run()` 方法是入口，首先自定义了加载器，然后设置了文件监听，这个文件监听用的是`commons-io`\n```\n<dependency>\n    <groupId>commons-io</groupId>\n    <artifactId>commons-io</artifactId>\n    <version>2.4</version>\n</dependency>\n```\n最后调用`start0`来启动项目，在`start0`里通过自定义的类加载器又重新加载了`Run`本身，然后通过反射调用`start()`方法，`start()`方法里启动真正的项目。这样的目的是因为类加载器中的全盘委托机制。Java 默认用的是`AppClassloader`，所以只能显示的通过自定义的类加载器来加载启动类，再启动真正的项目。\n\n文件的监听，使用`commons-io`\n```java\npublic class FileListener extends FileAlterationListenerAdaptor {\n\n    @Override\n    public void onFileCreate(File file) {\n        System.out.println(file.getName());\n        if (file.getName().indexOf(\".class\") != -1) {\n\n            try {\n                MyClassLoader myClassLoader = new MyClassLoader(Run.rootPath);\n                Run.start0(myClassLoader);\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n        super.onFileCreate(file);\n    }\n\n\n    @Override\n    public void onFileChange(File file) {\n        System.out.println(file.getName());\n        if (file.getName().indexOf(\".class\") != -1) {\n\n            try {\n                MyClassLoader myClassLoader = new MyClassLoader(Run.rootPath);\n                Run.start0(myClassLoader);\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n通过监听文件的创建和修改，如果文件有变化，定义一个新的类加载器，重新运行项目。\n\n模拟的真正项目\n```java\npublic class Application {\n\n    public void printApplicationName() {\n        System.out.println(\"应用程序777\");\n    }\n}\n\n```\n\n好了，现在来测试一下项目\n```java\npublic class Main {\n\n    public static void main(String[] args) {\n        Run.run(Main.class);\n    }\n}\n```\n设置一下idea，让编译器可以自动编译\n![idea](classloader.png)\n\n现在修改`Application`里`printApplicationName`输出的内容，等编译器编译完后，可以看到修改的内容了。\n\n\n本文只是一个供学习使用的简单小小的例子，项目github地址：[https://github.com/yaocl0/hot-loading](https://github.com/yaocl0/hot-loading)\n\n\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"聊一聊Tomcat 系统架构设计","url":"/2021/12/22/tomcat-arch/","content":"### 总体架构\n\n\nTomcat 是一个应用服务器，那么要开发一个应用服务器，首先捋一捋它的需求，要实现那些功能。\n\n\n1、 首先可以和客户端建立连接，并且能够处理客户端的连接\n\n2、 其次还要解析处理我们写的 Servlet\n\n3、 最后能够根据客户端的请求找到相应的 Servlet。\n\n在 Tomcat 中将这些需求分为了两大功能\n\n- 处理 Socket 连接，并将网络字节流转换成 Request 对象和 Response 对象\n- 解析、加载和管理 Servlet，处理请求并返回响应数据\n\nTomcat 将这两大功能，设计成了两个主要的组件\n\n- 连接器（Connector）\n- 容器（Container）\n\n来看一下 Tomcat 的总体架构\n\n![all](all.png)\n\n上图中是 Tomcat 的整体架构，一个 Tomcat 代表一个 Server，一个 Server 下包含对个 Service，每个 Service 下包含多个连接器和一个容器。\n\nService 本身没有什么重要的作用，它只是把连接器和容器组装在一起了，但是 Tomcat 可以同时设置多个 Service，也就可以部署多个服务。比如有两个相同的项目，可以把这两个项目放到两个 Service 里，那这两个相同的项目就可以在一个 Tomcat 里运行了，不用担心冲突的问题。\n\n这些配置可以在 conf/server.xml 中查看。\n\n接下来重点关注一下连接器和容器，这是 Tomcat 工作的核心。\n\n#### 连接器（Connector）\n\n在分析连接器之前，先了解一下 Tomcat 支持的 I/O 模型和应用层协议。\n\nI/O 模型：\n\n- NIO：非阻塞 I/O， Java NIO 类库实现。\n- NIO2：异步 I/O， JDK 7 最新的 NIO2 类库实现。\n- APR： Apache 可移植运行库实现，是 C/C++ 编写的本地库。\n\n应用层协议：\n\n- HTTP/1.1\n- AJP：用于和 Web 服务器集成（如 Apache）。\n- HTTP/2：HTTP 2.0 大幅度的提升了 Web 性能。\n\nService 中存在多个连接器就是为了支持 Tomcat 的多个 I/O 模型和应用层协议。\n\nOK，现在来分析连接器。\n\n首先可以先看一看 Tomcat 中连接器的配置\n\n```xml\n    <Connector port=\"24100\" protocol=\"HTTP/1.1\"\n               connectionTimeout=\"20000\"\n               compression=\"on\"\n               compressionMinSize=\"2048\"\n               noCompressionUserAgents=\"gozilla, traviata\"\n               compressableMimeType=\"text/html,text/xml,text/javascript,text/css,text/plain,image/jpeg,image/gif\" />\n```\n\n连接器中配置了监听的端口和使用的应用层协议等信息。\n\n在上面说了，连接器的主要作用是处理 Socket 连接，并将网络字节流转换成 Request 对象和 Response 对象。那么我可以再试着捋一捋连接器的需求\n\n1、 监听端口\n\n2、 建立连接\n\n3、 获取客户端传输的字节流\n\n4、 根据应用层协议解析字节流，将解析的数据交给容器处理\n\n5、 容器返回响应\n\n6、 将响应转换成字节流返回给客户端\n\n根据以上的需求，Tomcat 将整个连接器分为了三部分\n\n- 网络通信\n- 解析应用层协议\n- 与容器进行交互\n\nTomcat 将这三个功能分成了三个模块：Endpoint、Processor 和 Adapter，三个模块只通过抽象接口进行交互，封装了变化，降低了耦合度。\n\n三个模块的处理逻辑为：  \n\n1、Endpoint 接收字节流，并交给 Processor。  \n\n2、Processor 拿到字节流后，将字节流解析成 Tomcat Request 对象并交给 Adapter。  \n\n3、Adapter 拿到 Tomcat Request 对象再解析成 ServletRequest 交给容器。  \n\nTomcat 并没有直接将字节流解析成 ServletRequest 而是先解析成了 Tomcat Request，再通过 Adapter 进行转换，这样做的好处可以使连接器和容器接偶，我们可以自己实现 Adapter 的功能，来对接我们自己实现的类似容器的功能。\n\n由于 Tocmat 支持多种 I/O 模型和应用层协议，并且这些 I/O 模型和应用层协议可以自由组合，比如 NIO + HTTP 或者 NIO2 + AJP。Tomcat 设计了一个 ProtocolHandler，将网络通信和解析应用层协议放到了一起，来封装这两点的变化。\n\n来看一下连接器的结构图\n\n![connector](connector.png)\n\n来看一下连接器各个组件的代码结构\n\n##### Endpoint\n\nEndpoint 不是一个接口，只有对应的实现类 AbstractEndpoint\n\n![Endpoint](Endpoint.png)\n\nAbstractEndpoint 的实现类中包含了 Tomcat 支持的 I/O 模型。\n\n##### Processor\n\n![Processor](Processor.png)\n\nProcessor 的实现类是包含了 Tomcat 支持的所有应用协议。\n\n##### ProtocolHandler\n\n![ProtocolHandler](ProtocolHandler.png)\n\nProtocolHandler 的实现类里包含了每一种 I/O 模型和协议的组合。\n\n##### Adapter\n\nAdapter 只有一个实现类 CoyoteAdapter，CoyoteAdapter 是一个典型的适配器模式的使用，ProtocolHandler 中将不同的 IO 模式和不同的应用层协议通过 Endpoint 和 Processor 封装成 Tomcat Request，这个 Request 在 Adapter 中转换成标准的 ServletRequest。这其实也是一个扩展点，我们可以实现自己的 Adapter，拿到 Request 进行自己的业务处理，甚至可以不用 Servlet 那一套，自己定义一套新的应用处理模式。\n\n#### 容器（Container）\n\n容器的作用是解析、加载和管理 Servlet，处理请求并返回响应数据。在 Tomcat 中设计了四种容器 Engine、Host、Context 和 Wrapper，这四种容器是父子关系。\n\n- Engine 表示引擎，用来管理多个虚拟站点\n\n- Host 代表的是一个虚拟主机，或者说一个站点，可以给 Tomcat 配置多个虚拟主机地址\n\n- Context 表示一个 Web 应用程序，也是就我们写的一个项目\n\n- Wrapper 表示一个 Servlet\n\n一个 Service 最多只能有一个 Engine，一个 Engine 中可以包含多个 Host，一个 Host 中可以包含多个个 Context，一个 Context 可以包含多个 Wrapper\n\n看一下它的结构图\n\n![Container](Container.png)\n\n\n可以结合 conf/server.xml 配置文件来理解容器的设计\n\n```xml\n<Server port=\"8005\" shutdown=\"SHUTDOWN\">\n  <Service name=\"Catalina\">\n\n    <!--连接器-->\n    <Connector port=\"8080\" protocol=\"HTTP/1.1\"\n               connectionTimeout=\"20000\"\n               redirectPort=\"8443\" />\n\n    <!--容器-->\n    <Engine name=\"Catalina\" defaultHost=\"localhost\">\n      <Host name=\"localhost\"  appBase=\"webapps\"\n            unpackWARs=\"true\" autoDeploy=\"true\">\n      </Host>\n    </Engine>\n  </Service>\n</Server>\n```\n\nTomcat 容器是怎么确定请求的是那个 Servlet 的呢？\n\n通过一个例子来说明一下，图片是盗来的，哈哈哈哈。\n\n![demo](demo.png)\n\n上面这个例子中，要访问 `http://user.shopping.com:8080/order/buy`。  Tomcat通过连接器解析数据后，交给容器，\n\n1、 根据域名找到对应的 Host，也就是在 conf/server.xml 中配置的和 Host 的 name 相同的 Host\n\n2、根据 URL 找到 Context\n\n3、根据 URL 找到 Wrapper（Servlet）\n\n当连接器将数据给到容器后，并不是直到找到 Servlet 才开始处理数据，容器的每一层都会对数据进行一些处理。Tomcat 用了一个叫做 Pipeline-Valve 管道的方式来对数据进行处理。\n\n##### Pipeline-Valve 管道\n\nPipeline-Valve 管道是一种责任链模式，其中 Valve 表示一个处理点，Pipeline 中包含多个 Valve，每个容器中包含一个 Pipeline，每个容器中的 Pipeline 必须包含一个 BasicValve，处于调用的最末端，负责调用下个容器的 Value。\n\n用一张图来解释一下\n\n![Pipeline-Valve](Pipeline-Valve.png)\n\nWrapper 容器的最后一个 Valve 会创建一个 Filter 链，并调用 doFilter 方法，最终会调到 Servlet 的 service 方法。\n\n来看一下容器的代码结构\n\nTomcat 设计了一个顶层的容器接口\n\n```java\npublic interface Container extends Lifecycle {\n\n     public Container getParent();\n\n     public void setParent(Container container);\n\n     public void addChild(Container child);\n\n   // ....省略\n}\n```\n\n各个容器继承了这个顶层的容器\n\n![ContainerClass](ContainerClass.png)\n\n`Container`中定义了操作父容器和子容器的方法，很明显的组合模式。\n\n再来看看每个实现类的结构\n\n![standContainerClass](standContainerClass.png)\n\n每个类同时又继承了一个 Container 的实现抽象类`ContainerBase`，看一下这个类\n\n```java\npublic abstract class ContainerBase extends LifecycleMBeanBase\n        implements Container {\n\n    protected final Pipeline pipeline = new StandardPipeline(this);\n\n    // ....省略\n}\n```\n\n在 ContainerBase 中有`Pipeline`的属性，这就是 Pipeline-Valve 管道。\n\n\nOK，最后结合Java类来看看Tomcat组件的总体结构。  \n\n![class](class.png)\n","tags":["Tomcat"],"categories":["JAVA"]},{"title":"Java泛型中的类型擦除以及Type接口","url":"/2021/11/15/type-erasure/","content":"\n> Java 泛型（generics）是JDK1.5中引入的一个新特性，其本质是参数化类型，解决不确定具体对象类型的问题;其所操作的数据类型被指定为一个参数（type parameter）这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口、泛型方法。  \n\n但是在Java中并不是真正的泛型，实际上是“伪泛型”\n\n### 类型擦除（type Erasure）\n为了与之前的版本兼容，JDK1.5中通过类型擦除来增加的泛型功能。Java泛型只是在编译器层次上，在编译后生成的字节码中是不包含泛型中类型的信息的。  \n通过一个例子来证明类型擦除\n```java\npublic class main {\n\n    public static void main(String[] args) {\n        ArrayList<String> sList = new ArrayList<String>();\n        ArrayList<Integer> iList = new ArrayList<Integer>();\n        System.out.println(sList.getClass() == iList.getClass());\n    }\n}\n```\n上面定义了两个ArrayList，一个是ArrayList\\<String>泛型类型的,一个是ArrayList\\<Integer>类型的，但是最后打印的是`true`，说明两个类型相同。  \n用`javap -c`看一下生成的生成的字节码\n\n![1](1.png)\n\n可以看到在字节码中，ArrayList\\<String>和ArrayList\\<Integer>都被编译成了ArrayList类型，可见编译后发生了类型擦除。\n\n1. 既然编译后发生了类型擦除，那么虚拟机解析、反射等场景是怎么获取到正确的类型的？   \n\n在JDk1.5中增加泛型的同时，JCP组织修改了虚拟机规范，增加了`Signature`、`LocalVariableTypeTable`新属性。  \n用`javap -v`查看一下字节码，在`main`方法中包含一段\n ```\nLocalVariableTypeTable:\n  Start  Length  Slot  Name   Signature\n    8      31     1 sList   Ljava/util/ArrayList<Ljava/lang/String;>;\n    16      23     2 iList   Ljava/util/ArrayList<Ljava/lang/Integer;>;\n```\n `LocalVariableTypeTable`是一个可选属性，如果存在泛型，则会出现这个属性。在`Signature`下包含了泛型的信息。\n\n2. 接下来，看这段代码\n\n```java\nArrayList<String> sList = new ArrayList<String>();\nsList.add(\"111\");\nString s = sList.get(0);\n```\n类型擦除之后，当调用`sList.get(0)`是如何确保返回的值不会和String不匹配呢？  \n用`javap -c`查看一下字节码\n```\npublic class com.example.demo.test.main {\n       // .....省略\n  public static void main(java.lang.String[]) throws java.lang.NoSuchFieldException;\n    Code:\n       0: new           #2                  // class java/util/ArrayList\n       3: dup\n       4: invokespecial #3                  // Method java/util/ArrayList.\"<init>\":()V\n       7: astore_1\n       8: aload_1\n       9: ldc           #4                  // String 111\n      11: invokevirtual #5                  // Method java/util/ArrayList.add:(Ljava/lang/Object;)Z\n      14: pop\n      15: aload_1\n      16: iconst_0\n      17: invokevirtual #6                  // Method java/util/ArrayList.get:(I)Ljava/lang/Object;\n      20: checkcast     #7                  // class java/lang/String\n      23: astore_2\n      24: return\n}\n\n```\n在`#7`处有一个`checkcast`指令，`checkcast`用于检查类型强制转换是否可以进行，也就是泛型在获取值的时候进行了强制类型转换。\n\n3. 再来看看下面这段代码  \n\n首先定义一个Java泛型类\n```java\npublic class GenericClass<T> {\n\n    private T value;\n\n    public T getValue() {\n        return value;\n    }\n\n    public void setValue(T value) {\n        this.value = value;\n    }\n}\n```\n再定义一个子类继承它\n```java\npublic class GenericClassTest extends GenericClass<Integer> {\n\n    @Override\n    public void setValue(Integer value) {\n        super.setValue(value);\n    }\n\n    @Override\n    public Integer getValue(){\n        return super.getValue();\n    }\n}\n```\n在`GenericClassTest`中将`GenericClass`的泛型定义为`Integer`类型，并重写了get和set方法，因为存在类型擦除，父类`GenericClass`的泛型被擦除了。  \n用`javap -c` 查看一下`GenericClass`编译后的字节码\n\n![2](2.png)\n\n可以看到类型擦除后泛型变为了`Object`。那么`GenericClass`也就变为了\n```java\npublic class GenericClass {\n\n    private Object value;\n\n    public Object getValue() {\n        return value;\n    }\n\n    public void setValue(Object value) {\n        this.value = value;\n    }\n}\n```\n这样，父类`GenericClass`中set和get方法操作的是Object对象，而子类`GenericClassTest` 操作的是Integer对象，为什么还可以重写？按照正常的继承关系中，这应该是重载。  \n按照重载的方式试一下\n\n![3](3.png)\n\n可以看到设置Object对象出现了红波浪线，不允许这样设置，看来确实是重写，而不是重载。为什么会时重写，这不是跟Java多态冲突么？继续往下研究。  \n现在用`javap -c`看一下子类`GenericClassTest`的字节码文件\n\n\n![4](4.png)\n\n在`GenericClassTest`中get和/set方法都有两个，一个是操作Object对象一个是操作Integer对象。  \n操作Integer对象的是`GenericClassTest`定义的，操作Object对象的是由编译器生成的。  \n再用`javap -v` 查看一下字节码更详细的信息。\n\n\n![5](5.png)\n\n编译器生成的两个操作Object对象的方法中多了两个`ACC_BRIDGE`、`ACC_SYNTHETIC`标志。  \n这就是虚拟机解决类型擦除和多态冲突问题的方法：使用`桥接方法`。  \n`桥接方法`方法是由编译器生成的，我们在代码中并不能直接使用，但是可以通过反射拿到桥接方法再使用。\n\n\n\n泛型一旦编译过后，类型就被擦除了，那到了运行时，怎么获取泛型信息？这就要使用JDK提供的Type类型接口了。\n### Type类型\n在没有泛型之前，所有的类型都通过Class类进行抽象，Class类的一个具体对象就代表了一个类型。  \n在JDK1.5增加了泛型之后，扩充了数据类型，将泛型也包含了。  \nJDK在原来的基础上增加了一个`Type`接口，它是所有类型的父接口，它的子类有\n- `Class`类： 原始/基本类型，包括平时我们所有的类、枚举、数组、注解，还有int、float等基本类型\n- `ParameterizedType`接口：参数化类型，比如List\\<String>\n- `TypeVariable`接口：类型变量，比如List\\<T>中的T就是参数化变量\n- `GenericArrayType`接口： 数组类型，比如List\\<String>[]、T[]\n- `WildcardType`接口：泛型表达式类型，比如List< ? extends Number>\n\n#### ParameterizedType \n参数化类型，即带有参数的类型，也就是带有\\<>的类型\n```java\npublic interface ParameterizedType extends Type {\n\t    Type[] getActualTypeArguments();\n\n\t    Type getRawType();\n\n     Type getOwnerType();\n}\n```\n- `getActualTypeArguments()`: 获取类型内部的参数化类型 比如Map<K,V>里面的K，V类型。\n- `getRawType()`: 类的原始类型，比如Map<K,V>中的Map类型。\n- `getOwnerType()`: 获取所有者类型（只有内部类才有所有者，比如Map.Entry他的所有者就是Map），若不是内部类，此处返回null。  \n\n实例：\n```java\npublic class GenericClass<T> {\n    private List<String> list;\n    private List<T> tList;\n\n    public static void main(String[] args) {\n        Class<GenericClass> genericClassClass = GenericClass.class;\n        Field[] declaredFields = genericClassClass.getDeclaredFields();\n        for (Field declaredField : declaredFields) {\n            Type genericType = declaredField.getGenericType();\n            if (genericType instanceof ParameterizedType) {\n                System.out.println(\"==========\" + genericType.getTypeName() + \"======ParameterizedType类型=====\");\n                ParameterizedType parameterizedType = (ParameterizedType) genericType;\n                System.out.println(\"getActualTypeArguments:\");\n                Type[] actualTypeArguments = (parameterizedType).getActualTypeArguments();\n                for (Type actualTypeArgument : actualTypeArguments) {\n                    System.out.println(\"    \" + actualTypeArgument);\n                }\n                Type rawType = (parameterizedType).getRawType();\n                System.out.println(\"getRawType:\");\n                System.out.println(\"    \" + rawType);\n\n            }\n        }\n    }\n}\n\n```\n输出\n```\n==========java.util.List<java.lang.String>======ParameterizedType类型=====\ngetActualTypeArguments:\n    java.lang.String\ngetRawType:\n    interface java.util.List\n==========java.util.List<T>======ParameterizedType类型=====\ngetActualTypeArguments:\n    T\ngetRawType:\n    interface java.util.List\n\n```\n\n#### TypeVariable\n类型变量，即泛型中的变量，例如：T、K、V等变量，可以表示任何类；\n> 注意: 与ParameterizedType的区别，TypeVariable代表着泛型中的变量，而ParameterizedType则代表整个泛型。比如List\\<T>中，T是TypeVariable类型，List\\<T>是ParameterizedType类型  \n\n```java\npublic interface TypeVariable<D extends GenericDeclaration> extends Type, AnnotatedElement {\n\t\n    Type[] getBounds();\n    \n    D getGenericDeclaration();\n    \n    String getName();\n    // JDK8新增的\n    AnnotatedType[] getAnnotatedBounds();\n}\n```\n- `getBounds()`：类型对应的上限，默认为Object  可以有多个。比如List< T extends Number & Serializable>中的Number和Serializable\n- `getGenericDeclaration()`： 获取声明该类型变量实体，比如GenericClass< T>中的GenericClass\n- `getName()`：获取类型变量在源码中定义的名称；  \n\n实例：\n\n```java\npublic class GenericClass<T extends Number> {\n    private T t;\n\n    public static void main(String[] args) {\n        Class<GenericClass> genericClassClass = GenericClass.class;\n        Field[] declaredFields = genericClassClass.getDeclaredFields();\n        for (Field declaredField : declaredFields) {\n            Type genericType = declaredField.getGenericType();\n            if (genericType instanceof TypeVariable) {\n                System.out.println(\"==========\" + genericType.getTypeName() + \"======TypeVariable类型=====\");\n                TypeVariable typeVariable = (TypeVariable) genericType;\n                Type[] bounds = typeVariable.getBounds();\n                System.out.println(\"getBounds：\");\n                for (Type bound : bounds) {\n                    System.out.println(\"    \" + bound);\n                }\n                System.out.println(\"getGenericDeclaration：\");\n                System.out.println(\"    \" + typeVariable.getGenericDeclaration());\n                System.out.println(\"getName：\");\n                System.out.println(\"    \" + typeVariable.getName());\n\n\n            }\n        }\n    }\n} \n```\n输出：\n```\n==========T======TypeVariable类型=====\ngetBounds：\n    class java.lang.Number\ngetGenericDeclaration：\n    class com.example.demo.test.GenericClass\ngetName：\n    T\n```\n\n#### GenericArrayType\n泛型数组类型，用来描述ParameterizedType、TypeVariable类型的数组；例如：List\\<T>[] 、T[]、List\\<String>[]等。\n> 注意： GenericArrayType是来描述与泛型相关的数组，与String[]、int[]、float[]这种类型不同。\n```java\npublic interface GenericArrayType extends Type {\n\n\tType getGenericComponentType();\n}\n```\n- `getGenericComponentType()`：返回泛型数组中元素的Type类型，比如List\\<String>[] 中的 List\\<String>  \n\n实例：\n```java\npublic class GenericClass<T extends Number> {\n\n    private List<String>[] lists;\n    private T[] ts;\n\n    public static void main(String[] args) {\n        Class<GenericClass> genericClassClass = GenericClass.class;\n        Field[] declaredFields = genericClassClass.getDeclaredFields();\n        for (Field declaredField : declaredFields) {\n            Type genericType = declaredField.getGenericType();\n\n            if (genericType instanceof GenericArrayType) {\n                GenericArrayType genericArrayType = (GenericArrayType) genericType;\n                System.out.println(\"==========\" + genericType.getTypeName() + \"======GenericArrayType类型=====\");\n                Type genericComponentType = genericArrayType.getGenericComponentType();\n                System.out.println(\"getGenericComponentType:\");\n                System.out.println(\"    \" + genericComponentType);\n            }\n        }\n    }\n}\n```\n输出：\n```\n==========java.util.List<java.lang.String>[]======GenericArrayType类型=====\ngetGenericComponentType:\n    java.util.List<java.lang.String>\n==========T[]======GenericArrayType类型=====\ngetGenericComponentType:\n    T\n```\n#### WildcardType\n泛型表达式（通配符表达式）。例如：？ extend Number、？ super Integer。\n> 注意： WildcardType虽然是Type的子接口，但不代表一种类型，，表示的仅仅是类似 ? extends T、? super K这样的通配符表达式。\n```java\npublic interface WildcardType extends Type {\n\t  \n\tType[] getUpperBounds();\n\t \n\tType[] getLowerBounds();\n}\n```\n- `getUpperBounds()` 获得泛型表达式上界（上限） 获取泛型变量的上边界（extends)\n- `getLowerBounds()` 获得泛型表达式下界（下限） 获取泛型变量的下边界（super）  \n\n实例：\n```java\npublic class GenericClass<T extends Number> {\n    private List<? extends Number> numbers;\n\n    private List<? super Integer> integers;\n\n    public static void main(String[] args) {\n        Class<GenericClass> genericClassClass = GenericClass.class;\n        Field[] declaredFields = genericClassClass.getDeclaredFields();\n        for (Field declaredField : declaredFields) {\n            Type genericType = declaredField.getGenericType();\n            if (genericType instanceof ParameterizedType) {\n                ParameterizedType parameterizedType = (ParameterizedType) genericType;\n\n                Type[] actualTypeArguments = (parameterizedType).getActualTypeArguments();\n                for (Type actualTypeArgument : actualTypeArguments) {\n                    if(actualTypeArgument instanceof WildcardType){\n                        System.out.println(\"==========\" + actualTypeArgument.getTypeName() + \"======WildcardType类型=====\");\n                        WildcardType wildcardType = (WildcardType) actualTypeArgument;\n                        System.out.println(\"getUpperBounds:\");\n                        Type[] upperBounds = wildcardType.getUpperBounds();\n                        for (Type upperBound : upperBounds) {\n                            System.out.println(\"    \"+ upperBound);\n                        }\n                        System.out.println(\"getLowerBounds:\");\n                        Type[] lowerBounds = wildcardType.getLowerBounds();\n                        for (Type lowerBound : lowerBounds) {\n                            System.out.println(\"    \"+ lowerBound);\n                        }\n\n                    }\n                }\n            }\n\n        }\n    }\n}\n```\n\n输出：\n```\n==========? extends java.lang.Number======WildcardType类型=====\ngetUpperBounds:\n    class java.lang.Number\ngetLowerBounds:\n==========? super java.lang.Integer======WildcardType类型=====\ngetUpperBounds:\n    class java.lang.Object\ngetLowerBounds:\n    class java.lang.Integer\n\n```","tags":["JAVA"],"categories":["JAVA"]},{"title":"Java函数式编程","url":"/2021/10/24/javalambda/","content":"### 简介\n\n#### 什么是函数式编程\n\n函数式编程是一种编程范式，即一切都是数学函数。在Java面向对象编程中，程序是一系列相互作用（方法）的对象，而在函数式编程中，程序会是一个无状态的函数组合序列。\n\n\n#### 函数是“第一等公民”\n\n“第一等公民”指的是函数和其他数据类型一样，处于平等的地位。可以赋值给变量、可以作为另一个函数的参数或者作为一个函数的返回值。比如\n\n```java\n// 将两数相加的逻辑赋值给变量sum\nvar sum = (a,b)->a+b;\n\n// 将函数作为另一个函数的参数\noperation(sum)\n```\n\n\n\n### Java函数试编程\n\n#### Lambda 表达式\n\n历史上研究函数式编程的理论是Lambda演算，所以我们经常把支持函数式编程的编码风格称为Lambda表达式。  \n\n在Java中Lambda 表达式的表达形式:\n\n```\n(参数)->方法体\n```\n\n1. 参数：可以有多个，如果只有一个可以省略括号\n2. ->：箭头符号。\n3. 方法体：方法体超过一句时，要用{}包裹，可以根据情况看是否需要`return`语句\n\n#### 函数式接口\n\nJava 8提供了函数式编程接口的概念，用作Lambda表达式的类型。 \n\n函数式接口：只定义了*单一抽象方法*的接口。  \n\n举个例子，看一下Java 8中Runnable接口 ： \n\n```java\n@FunctionalInterface\npublic interface Runnable {\n    public abstract void run();\n}\n\n```\n\n在类上多了一个`@FunctionalInterface`注解\n\nJava 8之前定义一个Runnable 对象\n\n```java\nRunnable r = new Runnable() {\n   public void run() {\n       System.out.println(\"Hello World!\");\n   }\n};\n```\n\nJava 8之后可以直接写成\n\n```java\nRunnable r =()-> System.out.println(\"Hello World!\");\n```\n\n`@FunctionalInterface`注解并不是必须的，只要符合单一抽象方法的接口都可以。  \n\n用一个加减乘除的例子来演示一下Java中函数式编程的使用。 \n\n首先定义一个函数式接口，\n\n```java\npublic interface Operate {\n    \n    int operate(int a, int b);\n    \n}\n\n```\n\n将不同的逻辑操作赋值给函数式接口\n\n```java\npublic class Main {\n\n    public static void main(String[] args) {\n        // 加\n        Operate add = (a, b) -> a + b;\n        // 减\n        Operate subtract = (a, b) -> a - b;\n        // 乘\n        Operate multiply = (a, b) -> a * b;\n        // 除\n        Operate divide = (a, b) -> a / b;\n        \n        System.out.println(operate(add, 2, 1));\n        System.out.println(operate(subtract, 2, 1));\n        System.out.println(operate(multiply, 2, 1));\n        System.out.println(operate(divide, 2, 1));\n    }\n\n    static int operate(Operate operate, int a, int b) {\n        return operate.operate(a, b);\n    }\n}\n```\n\n在上面的例子中，加减乘除的每个变量是一个个的函数，具体的函数逻辑在等号的右边。同时定义了一个operate的方法，第一个参数是Operate类型函数式接口，也就是接收的是一个函数，然后运行函数的逻辑，实际上是运行等号右边的逻辑。\n\n在Java 8中，`java.util.function`下定义了许多函数式接口。列一下几个核心的函数式接口\n\n| 接口              | 参数  | 返回类型 | 表述                             |\n| ----------------- | ----- | -------- | -------------------------------- |\n| Predicate<T>      | T     | boolean  | 用于判断操作函数                 |\n| Consumer<T>       | T     | void     | 没有返回结果的函数               |\n| Function<T, R>    | T     | R        | 入参是T，出参是R的函数           |\n| Supplier<T>       |       | T        | 生成一个对象T的函数              |\n| UnaryOperator<T>  | T     | T        | 入参、出参都是T的类型函数        |\n| BinaryOperator<T> | (T,T) | T        | 接收两个入参为T，出参也为T的函数 |\n\n还是那上面加减乘除的例子，可以用`BinaryOperator`函数来表示,表示有两个入参是Integer出参也是Integer。\n\n```java\n// 加\nBinaryOperator<Integer> add = (a, b) -> a + b;\n// 减\nBinaryOperator<Integer> subtract = (a, b) -> a - b;\n// 乘\nBinaryOperator<Integer> multiply = (a, b) -> a * b;\n// 除\nBinaryOperator<Integer> divide = (a, b) -> a / b;\n```\n\n\n\n#### 方法引用\n\n方法引用是用来直接访问类或者实例的已经存在的方法或者构造方法,方法引用的本质其实是简化Lambda 表达式。\n\n方法引用的使用是一对冒号`::`\n\n| 类型         | 方法引用          |        对应的Lambda表达式         |\n| ------------ | ----------------- | :-------------------------------: |\n| 构造方法引用 | 类名::new         |     (args) -> new 类名(args)      |\n| 静态方法引用 | 类名:: 静态方法名 | (args) -> 类名.staticMethod(args) |\n| 实例方法引用 | 类名::方法名      | (inst,args) -> inst.method(args)  |\n| 对象方法引用 | 对象::方法名      |    (args) -> 对象.method(args)    |\n\n定义一个类来说明方法引用的使用\n\n```java\npublic class Person {\n\n    private String name;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public static void say(Person person) {\n        System.out.println(person.getName());\n    }\n\n    public void equals(Person person) {\n        System.out.println(this.getName().equals(person.getName()));\n    }\n\n    public void eat(String food) {\n        System.out.println(\"eat \" + food);\n    }\n}\n```\n\n\n\n#### 构造方法引用\n\n```java\n Supplier<Person> supplier = Person::new;\n//Lambda表达式写法\n Supplier<Person> supplier = ()-> new Person();\n```\n\n`用`Supplier函数式接口是因为调用的构造函数是无参的，符合Supplier函数式接口的定义\n\n`注意：被调用的方法的参数列表和返回值类型需要与函数式接口中抽象方法的参数列表和返回值类型要一致。`\n\n#### 静态方法引用\n\n```java\nConsumer<Person> say = Person::say;\n//Lambda表达式写法\nConsumer<Person> say = person -> Person.say(person); \n```\n\n用Consumer函数式接口是因为say方法是一个包含一个参数，并且没有返回值的函数，符合Consumer函数式接口的定义\n\n注意：被调用的方法的参数列表和返回值类型需要与函数式接口中抽象方法的参数列表和返回值类型要一致。\n\n#### 实例方法引用\n\n```java\nBiConsumer<Person, Person> personPersonBiConsumer = Person::equals;\n//Lambda表达式写法\nBiConsumer<Person, Person> personPersonBiConsumer = (inst, args) -> inst.equals(args);\n```\n\n实例方法引用第一个参数是实例方法的调用者，第二个是实例方法的参数。\n\n`注意：被调用的方法的参数列表和返回值类型需要与函数式接口中抽象方法的参数列表和返回值类型要一致。`\n\n#### 对象方法引用\n\n```java\nPerson person = new Person();\nConsumer<String> eat = person::eat;\n// Lambda表达式写法\nConsumer<String> eat = food -> person.eat(food);\n```\n\n`注意：被调用的方法的参数列表和返回值类型需要与函数式接口中抽象方法的参数列表和返回值类型要一致。`\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"HashMap那些事儿","url":"/2021/09/30/hashmap/","content":"HashMap 在 Java 中是一个使用高频的数据结构，JDK1.8 以后 HashMap 进行了一次翻天覆地的改变。\n\n本文基于 JDK1.8 分析一下 HashMap\n\n### 存储结构转换\n\n在 JDK1.8 以前 HashMap 采用的是`数组+链表`的结构，JDK1.8 以后又引入了红黑树的结构，会在链接和红黑树之间转换，结合源码分析一下 HashMap 对`数组+链表`和`数组+红黑树`的转换  \n首先看一下数据的存储结构\n\n```java\n transient HashMap.Node<K, V>[] table;\n```\n\nHashMap 定义了一个 Node 的数组，Node 的定义\n\n```java\n   static class Node<K, V> implements Entry<K, V> {\n        final int hash;\n        final K key;\n        V value;\n        HashMap.Node<K, V> next;\n        // ....省略\n  }\n```\n\nNode 中包含了四个属性`hash`、`key`、`value`、`next`。\n\n- `key`、`value`是调用 HashMap 的`put()`方法传进来的。\n- `hash` 是判断 key 是否重复的关键\n- `next` 用于构建链表\n\n所以 HashMap 默认是一个`数组+链表`的形式\n\n![list](list.png)\n\n`链表`是否要转换成`红黑树`，是在调用`put()`方法添加数据时判断的，跟着源码分析`链表`转换成`红黑树`的过程\n\n`put()`方法调用的是`putVal()`方法，\n\n```java\n    final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {\n        // ...省略\n        while (true) {\n            if ((e = ((HashMap.Node) p).next) == null) {\n                ((HashMap.Node) p).next = this.newNode(hash, key, value,(HashMap.Node) null);\n                //转换成红黑树\n                if (binCount >= TREEIFY_THRESHOLD - 1) {\n                    this.treeifyBin(tab, hash);\n                }\n                break;\n            }\n            if ((((HashMap.Node) e).hash == hash) &&\n                    (((k = ((HashMap.Node) e).key) == key) ||\n                    ((key != null) && key.equals(k)))) {\n                break;\n            }\n            p = e;\n            ++binCount;\n        }\n        // ...省略\n    }\n```\n\n无关的部分省略了，while 循环中遍历链表中的数量，如果数量大于等于 8，调用`treeifyBin()`方法，\n在`treeifyBin()`中有一行\n\n```java\n  hd.treeify(tab);\n```\n\n`treeify()`方法会将`链表`转换为`红黑树`。同时会将链表中所有节点由`Node`结构转换为`TreeNode`结构。\n\n`TreeNode`继承自`java.util.LinkedHashMap.Entry`，`java.util.LinkedHashMap.Entry`又继承自`Node`\n\n那么`Node`就是`TreeNode`的父类，所以这样转换是不会有问题的。\n\n经过`treeifyBin()`后存储结构变为\n![tree](tree.png)\n\n### put 方法的具体逻辑\n\n`put`方法中可以划分为 4 个部分，看一下方法的执行流程图。\n![put](put.png)\n\n结合一下源码\n![put-source](put-source.png)\n\n结合流程图和源码，对 put 的过程做一个描述  \n①：判断 tab 是否为空，如果为空说明 table 还未初始化，先对数组进行初始化  \n②：先计算在数组中的位置，并判断该位置是否为空，如果为空，则直接赋值。然后跳转到⑥  \n③: 判断节点 key 是否存在，如果存在直接额赋值，不存在则执行 ④  \n④：判断是否是红黑树，如果是则添加到树中，否则进入到⑤\n⑤：为链表的情况，判断长度是否大于等于`TREEIFY_THRESHOLD - 1`，如果是，先将链表转花为红黑树，然后添加到树中。如果不是直接添加到列表中。  \n⑥：插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。\n\n### 扩容\n\n当 HashMap 键值对大于阀值时或者初始化时，会进行扩容。\n阀值是`threshold`的值，是由数组的长度和`loadFactor(默认值是0.75)`决定的，threshold = length \\* loadFactor\n\nHashMap 的扩容是在`resize()`方法里进行的，结合源码分析一下 HashMap 是怎么扩容的，因为 JDk1.8 引入了红黑数，所以代码比较长，就不贴全部的代码了，主要分析一下关键步骤。  \n先看一下初始化的几个变量\n\n```java\nint oldCap = (oldTab == null) ? 0 : oldTab.length; //现在容器的大小\nint oldThr = threshold; 现在的阀值\n int newCap  //计算过后，新的容器的大小\n     , newThr = 0; //计算后阀值的大小\n```\n\n`注意： 扩容不只是改变容器的大小，还要改变阀值的大小`\n\n#### 1. table 容器不为空的情况\n\n```java\n  if (oldCap > 0) {\n     if (oldCap >=  MAXIMUM_CAPACITY) {\n          this.threshold = Integer.MAX_VALUE;\n          return oldTab;\n     }\n\n     else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&\n                  oldCap >= DEFAULT_INITIAL_CAPACITY)\n                 newThr = oldThr << 1;\n  }\n```\n\n- 数量已经大于最大的容量，则将阀值设置为整数最大值，不再扩容\n- `newCap = oldCap << 1` 扩容后仍然小于最大容量 并且 oldCap 大于默认值 16，双倍扩容阀值 threshold\n\n#### 2. 旧的容量为 0，但 threshold 大于零\n\n```java\n   else if (oldThr > 0)\n      newCap = oldThr;\n```\n\n出现这种情况说明有参构造有 initialCapacity 传入，那么 threshold 已经被初始化成最小 2 的 n 次幂，所以直接将该值赋给新的容量\n\n#### 3. 旧的容量为 0，threshold 也等于 0\n\n```java\n else {\n      newCap = DEFAULT_INITIAL_CAPACITY;\n      newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n  }\n```\n\n这种情况说明是通过无参构造函数创建的，也就是`Map map = new HashMap()`这种格式，那么都被赋予默认的大小（默认 16）和默认的阈值（默认 16 \\* 0.75）\n\n#### 4、 计算新的阈值\n\n```java\n if (newThr == 0) {\n    float ft = (float)newCap * loadFactor;\n    newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?\n                      (int)ft : Integer.MAX_VALUE);\n}\n```\n\n这种情况说明是在有参构造时，默认的`loadFactor`被重新赋值，如果`loadFactor`大于 1，那么阈值会比容量大，有可能会超出最大容量，所以要重新计算。  \n还有一种情况在第一步中`newThr = oldThr << 1`，左移超出范围后会置0，也要重新计算。\n\n扩容也就这些了，剩下的代码是扩容后，元素重新排列的逻辑了。\n\n`注意：扩容的大小 （newCap = oldCap << 1） << 相当于乘2,所以HashMap的容量总是2的n次方`\n\n### 确定key在数组中的位置\n在调用`put()`方法添加新数据时，在`put()`方法内部，调用`hash()`操作key，得到一个hash值\n![hash](hash.png)\n\n在`putVal()`方法中，在第②步的时候确定key在数组中的位置\n\n![index](index.png)\n\n\n`hash()`方法的实现\n```java\n    static final int hash(Object key) {\n        int h;\n        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n    }\n```\n在key等于null的情况下，会直接放到0处，不为null时，获取key的`hashCode`后，将`hashCode`的高16位和低16位进行异或。  \n\n获取位置的整个过程有两个问题：\n1. `(n - 1) & hash` 是怎么获取到位置的？  \n    `n`是table数组的长度，而数据的长度又总是2的n次方，所以`(n - 1) & hash`正好是对n取模。  \n    `( (n - 1) & hash) ) == (hash % n)`, 这是一个非常巧妙的设计，用&比%具有更高的效率。\n    \n2. 将`hashCode`的高16位和低16位进行异或的作用是什么？  \n    `hashCode`是一个int类型的数据，占4个字节 32位，而在HashMap中默认的长度是`DEFAULT_INITIAL_CAPACITY = 1 << 4（即2的四次方16）`，要远小于int类型的范围，如果直接用`hashCode`进行运算，那么`hashCode`的高位部分对结果来说不会起太大作用，这样会增加hash碰撞的概率。所以用高16位和低16位进行异或来降低hash冲突的概率\n\n### 使用任意类作为key的情况\nHashMap判断key的位置是基于`hashCode`，如果要使用任意类作为key，必须要考虑是否要重写`hashCode`方法。默认的`hashCode`返回对象的是对象地址，直接使用使用可能会有问题。用伪代码举个例子\n```java\npublic class User{\n  private String name;\n  private int age;\n  \n  // ...省略get set方法\n}\n  \n  User user1 = new User();\n  user1.setName(\"张三\");\n  user1.setAge(\"20\");\n  \n  \n  User user2 = new User();\n  user2.setName(\"张三\");\n  user3.setAge(\"20\");\n\n  Map<User,Stirng> map = new HashMap<>();\n  map.put(user1,\"张三\");\n  map.put(user2,\"张三\");\n```\n这种情况下尽管user1和user2的属性都相同，但是user2并不会覆盖user1,因为user1和user2是两个对象，地址不相同，`hashCode`也不相同。  \n\n> 注意： 重写hashCode()方法时，要注意equals() 和 hashCode() 相关的规则\n#### 为什么String、Integer等包装类可以作为key\n1. String、Integer内部已重写了equals()、hashCode()等方法。\n2. 都是final类型，保证了不可更改性，不会存在获取hash值不同的情况\n\n### 线程安全问题\n在put第①步\n```java\n  if ((tab = table) == null || (n = tab.length) == 0)\n       n = (tab = resize()).length;\n```\n当第一个线程运行到这后已经拿到了数组数据和长度，如果这时让出CPU，而第二个线程进来后把数组数据改变了，那么当第一线程再次拿到CPU后，继续运行的话，会把第二个线程的数据覆盖掉，造成数据丢失。\n在put第⑥步\n```java\nif (++size > threshold)\n     resize();\n```\n`++size`并不是原子操作，当多个线程都执行这行代码时，会存在丢失数据的情况。\n\n来个例子验证一下：\n```java\npublic class HashMapTreadTest extends Thread{\n\n    private  static Map<Integer,Integer> map = new HashMap<>();\n    private static AtomicInteger mapSize = new AtomicInteger();\n\n    @Override\n    public void run() {\n        while (mapSize.get() < 10000){\n            map.put(mapSize.get(),map.get(mapSize));\n            mapSize.incrementAndGet();\n        }\n    }\n\n    public static void main(String[] args) {\n        HashThreadTest hashThreadTest = new HashThreadTest();\n        Thread[] threads=new Thread[5];\n        for (int i = 0; i < 5; i++) {\n            threads[i]=new Thread(hashThreadTest,\"线程\"+i);\n            threads[i].start();\n        }\n        //默认还有个守护线程\n        while (Thread.activeCount() > 2) {\n            Thread.yield();\n        }\n        System.out.println(\"map的数量 = \"+ hashThreadTest.map.size());\n    }\n}\n```\n上面代码功能是向map里添加10000条数据，开启5个线程同时操作，运行完后打印的数量并不是10000，说明数据丢失。","tags":["JAVA"],"categories":["JAVA"]},{"title":"TCP三次握手和四次挥手","url":"/2021/09/28/tcp34/","content":">定义：TCP（Transmission Control Protocol:传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议.\n\nTCP在发送数据前，会在通信双方之间建立一条连接。通过这条连接，客户端和服务端可以保存一份对方的信息，如ip地址、端口号等。通信双方的数据传输就是在这条连接上进行的。这条连接的建立和断开的过程就是所谓的`三次握手`和`四次挥手`\n\n### TCP报文头部数据\n\n在了解`三次握手`和`四次挥手`之前，先来了解一下TCP报文的头部数据结构\n![TCP头部](header.png)\n上图中有几个字段是在`三次握手`和`四次挥手`需要的\n\n1. Sequence number（seq）：序列号 32位\n2. Acknowledgment number（ack）: 确认序列号 32位\n3. SYN、ACK、FIN标志位\n   - SYN : 建立起一个新的连接\n   - ACK ： 确认号有效\n   - FIN ： 释放一个连接\n\n`注意： 不要将ack和ACK理解混了，ack是一串序列号，ACK是一个标志位。当ACK为1时，代表ack序列号有效`\n\n### 三次握手\n\n`三次握手`是TCP建立连接的过程。主要作用是判断通信双方有没有传输数据的能力。看一下整个握手的过程。\n![三次握手](tcp3.png)\n\n`三次握手`步骤：\n\n1. `第一次握手`：客户端主动向服务端发起一个建立连接的请求。请求数据中\n\n   - `SYN=1`表示客户端要与服务端建立一个新的连接\n   - 初始自己的序列号值`seq=x`  \n\n   此时客户端进入到`SYN-SENT`状态等待服务器的回复\n\n2. `第二次握手`：服务端收到客户端的请求后，发现`SYN=1`，知道这是要建立一个连接，于是向客户端发送一个回复消息\n\n   - 初始自己序列号值`seq=y`\n   - `ACK=1`表示确认收到了消息\n   - `SYN=1`表示同意了这次连接，并与客户端建立新连接\n   - `ack=x+1`客户端发过来的序列号+1  \n\n   此时服务器进入到`SYN-RCVD`状态\n\n3. `第三次握手`：客户端收到服务端的回复后，发现`SYN=1``ACK=1``ack=x+1`表示服务端已经收到第一次握手时客户端发送的请求，并同意建立连接，这时，客户端回复一个确认消息\n\n   - `ACK=1`表示确认收到了消息、\n   - `seq=x+1`表示客户端第一次握手x序列号的下一个序列号\n   - `ack=y+1`表示收到了服务端发动过来的`seq=y`的消息  \n\n   此时客户端进入到`ESTAB-LISHED`状态，在服务端收到消息后也进入到`ESTAB-LISHED`状态。\n\nOK，`三次握手`完毕，通信双方可以传输数据了\n\n### 四次挥手\n\n`四次挥手`是TCP断开的过程，主要的作用是确保数据已传输完毕，并断开连接，看一下四次挥手的过程\n![四次挥手](tcp4.png)\n\n`四次挥手`步骤\n\n\n1. `第一次挥手`：客户端主动向服务端发送发断开请求\n\n   - `FIN=1`表示释放连接\n   - `seq=u`客户端当前的序列号\n\n   此时客户端进入到`FIN-WAIT-1`状态\n\n2. `第二次挥手`：服务端收到客户端发来的请求后，发现`FIN=1`，知道了这是一个断开请求，然后给客户端发送一个确认请求\n\n   - `ACK=1`表示确认收到了客户端释放连接的请求\n   - `seq=u`服务器当前的序列号\n   - `ack=u+1`表示服务端收到客户端发来的`seq=u`的断开请求\n\n   此时服务区进入到`CLOSE-WAIT`状态，并且不会立即进行第三次挥手，因为这时数据可能还没有传输完成，需要再等待一段时间。  \n   客户端在接受到回复后进入到`FIN-WAIT-2`状态\n\n3. `第三次挥手`：当服务端发送完所有的数据后，主动向客户端发送断开请求\n\n   - `FIN=1`表示释放连接\n   - `ACK=1、seq=u、ack=u+1`和上一次一样  \n\n   此时服务端进入到`LAST-ACK`状态等待客户端回复\n\n4. `第四次挥手`：客户端收到服务端发来的关闭请求后，向服务端发出确认报文，并进入到`TIME-WAIT`状态。服务端接受到确认报文后，断开连接，而客户端要等2MSL(最长报文段寿命的2倍时长)后才断开连接，所以服务端结束的时间要比客户端早一些。\n\n\n\n### 常见问题\n\n#### 为什么是3次握手，2次不行么？\n\n如果是2次握手，假设在第二次握手的时候服务端发送给客户端的消息丢失了，那么这时服务端进入到`ESTAB-LISHED`状态，准备接收数据了。但是客户端却不知道服务端已经准备好了。那么客户端也不会给服务端发送数据。\n\n而3次握手多了向服务端最后确认阶段，这样就可以确保客户端已经知道服务端已经准备好了。\n\n#### 为什么建立连接的时候是3次，断开连接时是4次？\n\n主要的作用还是确保所有数据已经传输完，第一次挥手客户端主动向服务端发送断开请求表示客户端数据已经传输完毕，第三次挥手服务端主动向客户端发送断开请求表示服务端数据也传输完毕。\n\n#### 第四次挥手后为什么要等2MSL的时间才断开连接？\n\n主要是防止第四次挥手客户端的请求丢失，服务端没有接收到客户端最后的确认请求，那么服务端再发送一次第三次挥手的数据，再加上客户端回复确认消息的时间，所以要等待2MSL\n\n#### 建立连接以后，客户端出现故障怎么办？\n\nTCP有一个`保活机制`：\n在一个时间段内，如果连接没有任何的活动，`保活机制`会起作用，每隔一个时间间隔，会发送一个报文，如果连续几个报文都没有得到响应，就会认为TCP连接已经死亡，这时系统内核会将错误信息通知给上层应用\n\n#### 什么是SYN攻击？，如何避免？\n\n基于第一次握手时，服务器会进入`SYN_RCVD`状态。攻击者在短时间内伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务。\n\n\n这本身是TCP设计的原因，SYN攻击不能完全的避免，只能尽可能减少SYN的危害，常见预防方式：\n\n- 缩短超时（SYN Timeout）时间\n- 增加最大半连接数\n- 过滤网关防护\n- SYN cookies技术\n\n### 参考资料：\n\n- [1] [https://blog.csdn.net/ThinkWon/article/details/104903925#t11](https://blog.csdn.net/ThinkWon/article/details/104903925#t11)\n- [2] [https://www.cnblogs.com/xiaolincoding/p/12638546.html](https://www.cnblogs.com/xiaolincoding/p/12638546.html)\n- [3] [https://hit-alibaba.github.io/interview/basic/network/TCP.html](https://hit-alibaba.github.io/interview/basic/network/TCP.html)\n\n\n","tags":["计算机网络"],"categories":["计算机网络"]},{"title":"Mybatis中mapper生成代理的过程","url":"/2021/09/23/mybatis-mapper/","content":"### 目录\n1. mybatis中mapper代理的生成过程\n2. 与Spring集成时mapper代理的生成过程\n3. 与SpringBoot集成时mapper代理的生成过程\n\n### mybatis中mapper代理的生成过程\n#### 构建代理类工厂\n从入口点开始一步一步看，首先`SqlSessionFactoryBuilder`类中`build()`方法加载配置文件\n```java\n  public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) {\n    try {\n      XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties);\n      return build(parser.parse());\n    } catch (Exception e) {\n      throw ExceptionFactory.wrapException(\"Error building SqlSession.\", e);\n    } finally {\n      // ...省略\n    }\n  }\n```\n将配置文件读取为`XMLConfigBuilder`对象，并调用`parse()`方法来解析文件，进到`parse()`中\n```\n  public Configuration parse() {\n     // ...省略\n    parsed = true;\n    parseConfiguration(parser.evalNode(\"/configuration\"));\n    return configuration;\n  }\n```\n可以看到具体的解析过程是在`parseConfiguration`方法中进行的。\n```java\n  private void parseConfiguration(XNode root) {\n    try {\n       // ...省略\n      //解析mapper\n      mapperElement(root.evalNode(\"mappers\"));\n    } catch (Exception e) {\n      throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e);\n    }\n  }\n```\n这里重点看一下最后解析mapper的方法`mapperElement(root.evalNode(\"mappers\"))`，进到方法里，\n```java\n\n  private void mapperElement(XNode parent) throws Exception {\n    if (parent != null) {\n      for (XNode child : parent.getChildren()) {\n        if (\"package\".equals(child.getName())) {\n          //   package 形式加载 ,加载package下的所有class文件\n          String mapperPackage = child.getStringAttribute(\"name\");\n          configuration.addMappers(mapperPackage);\n        } else {\n          String resource = child.getStringAttribute(\"resource\");\n          String url = child.getStringAttribute(\"url\");\n          String mapperClass = child.getStringAttribute(\"class\");\n          if (resource != null && url == null && mapperClass == null) {\n            // 通过Mapper.xml 加载\n            ErrorContext.instance().resource(resource);\n            InputStream inputStream = Resources.getResourceAsStream(resource);\n            XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments());\n            mapperParser.parse();\n          } else if (resource == null && url != null && mapperClass == null) {\n            // 通过Mapper.xml 加载\n            ErrorContext.instance().resource(url);\n            InputStream inputStream = Resources.getUrlAsStream(url);\n            XMLMapperBuilder mapperParser = new XMLMapperBuilder(inputStream, configuration, url, configuration.getSqlFragments());\n            mapperParser.parse();\n          } else if (resource == null && url == null && mapperClass != null) {\n            // 通过单个class文件加载\n            Class<?> mapperInterface = Resources.classForName(mapperClass);\n            configuration.addMapper(mapperInterface);\n          } else {\n            throw new BuilderException(\"A mapper element may only specify a url, resource or class, but not more than one.\");\n          }\n        }\n      }\n    }\n  }\n```\n整个`mapperElement()`方法就是加载mapper的过程了，可以看到加载mapper\n有两种形式：通过class文件和通过xml文件。  \n构建mapper代理的过程也就是从这开始的，那就一步一步分析。  \n看一下通过XML文件加载的过程，mybatis将mapper相关的配置读取为一个`XMLMapperBuilder`对象，并通过`parse()`方法进行解析，进到这个方法中\n```java\n\n  public void parse() {\n    if (!configuration.isResourceLoaded(resource)) {\n      // 加载xml文件\n      configurationElement(parser.evalNode(\"/mapper\"));\n      configuration.addLoadedResource(resource);\n      // 加载mapper class文件\n      bindMapperForNamespace();\n    }\n   // ...省略\n  }\n```\n`parse()`方法做了主要做了两件事，加载xml文件和加载class文件。  \n看一下加载xml的过程\n```java\n  private void configurationElement(XNode context) {\n    try {\n      // 获取xml文件的namespace\n      String namespace = context.getStringAttribute(\"namespace\");\n      if (namespace == null || namespace.equals(\"\")) {\n        throw new BuilderException(\"Mapper's namespace cannot be empty\");\n      }\n      // 保存获取xml文件的namespace\n      builderAssistant.setCurrentNamespace(namespace);\n       // ...省略\n    } catch (Exception e) {\n      throw new BuilderException(\"Error parsing Mapper XML. The XML location is '\" + resource + \"'. Cause: \" + e, e);\n    }\n  }\n```\n本文是分析mapper代理的生成过程，所以加载xml的具体细节就不详细分析了，这里注意的是读取xml文件中`namespace`标签的值，并将值设置到`builderAssistant`对象中  \n现在回过头来看一下加载class文件的过程。进到`bindMapperForNamespace()`方法中去\n```java\n  private void bindMapperForNamespace() {\n    // 获取xml文件中设置的namespace值\n    String namespace = builderAssistant.getCurrentNamespace();\n    if (namespace != null) {\n      Class<?> boundType = null;\n      try {\n        // 加载类\n        boundType = Resources.classForName(namespace);\n      } catch (ClassNotFoundException e) {\n        //ignore, bound type is not required\n      }\n      if (boundType != null) {\n        if (!configuration.hasMapper(boundType)) {\n          // Spring may not know the real resource name so we set a flag\n          // to prevent loading again this resource from the mapper interface\n          // look at MapperAnnotationBuilder#loadXmlResource\n          configuration.addLoadedResource(\"namespace:\" + namespace);\n          // 添加到configuration中\n          configuration.addMapper(boundType);\n        }\n      }\n    }\n  }\n```\n`bindMapperForNamespace()`通过xml文件中设置的namespace值加载对应的mapper接口，最后通过`configuration.addMapper()`添加到`configuration`中。  \n\n还记不记得刚才提到的加载mapper\n有两种形式：通过class文件和通过xml文件。通过class文件的方式直接调用`configuration.addMapper()`将mapper接口加载到了`configuration` 中了。   \n\n`Configuration`是mybatis的全局配置类，所有的mybatis相关的信息都保存在`Configuration`中。  \n继续进到`Configuration`的`addMapper`方法中\n```java\n  public <T> void addMapper(Class<T> type) {\n    mapperRegistry.addMapper(type);\n  }\n```\n`Configuration`把对应的mapper接口添加到`mapperRegistry`中，再进到`mapperRegistry.addMapper()`方法中\n```java\n  public <T> void addMapper(Class<T> type) {\n    if (type.isInterface()) {\n        // ...省略\n      try {\n        knownMappers.put(type, new MapperProxyFactory<T>(type));\n         // ...省略\n      } finally {\n        if (!loadCompleted) {\n          knownMappers.remove(type);\n        }\n      }\n    }\n  }\n```\n该方法首先判断是否是接口，如果是接口则将mapper接口添加到`knownMappers`中。  \n看一下`knownMappers`的定义\n```java\n  private final Map<Class<?>, MapperProxyFactory<?>> knownMappers = new HashMap<Class<?>, MapperProxyFactory<?>>();\n```\n`knownMappers`是一个`HashMap`，它保存的是所有的mapper接口和对应的mapper代理工厂。\n\n到现在为止，mapper已经加载完了，但是并没有生成mapper的代理对象，只是生成了对应的代理工厂。\n#### 生成并使用代理对象\nmybatis并没有在加载mapper接口的时候生成代理对象，而是在调用的时候生成的。  \n首先从入口开始\n```java\nsqlSession.getMapper(XXX.class)\n```\n`sqlSession`默认是`DefaultSqlSession`。进到`DefaultSqlSession`的`getMapper()`方法中\n```java\n  @Override\n  public <T> T getMapper(Class<T> type) {\n    return configuration.<T>getMapper(type, this);\n  }\n```\n继续到`Configuration`的`getMapper`中  \n```java\n public <T> T getMapper(Class<T> type, SqlSession sqlSession) {\n    return mapperRegistry.getMapper(type, sqlSession);\n  }\n```\n继续到` mapperRegistry.getMapper()`中\n```java\n  public <T> T getMapper(Class<T> type, SqlSession sqlSession) {\n    final MapperProxyFactory<T> mapperProxyFactory = (MapperProxyFactory<T>) knownMappers.get(type);\n    // ...省略\n    }\n    try {\n      return mapperProxyFactory.newInstance(sqlSession);\n    } catch (Exception e) {\n      throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e);\n    }\n  }\n```\n从`knownMappers`中获取到对应mapper接口的代理工厂类`MapperProxyFactory`，然后通过`MapperProxyFactory`获取真正的代理对象。  \n进到`MapperProxyFactory`的`newInstance()`方法中\n```java\n  public T newInstance(SqlSession sqlSession) {\n    final MapperProxy<T> mapperProxy = new MapperProxy<T>(sqlSession, mapperInterface, methodCache);\n    return newInstance(mapperProxy);\n  }\n  \n   protected T newInstance(MapperProxy<T> mapperProxy) {\n    return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);\n  }\n```\n首先生成了`MapperProxy`类，再通过`Proxy`生成真正的代理类。  \n看一下`MapperProxy`类\n```java\npublic class MapperProxy<T> implements InvocationHandler, Serializable {\n  //  ...省略\n}\n```\n`MapperProxy`实现了`InvocationHandler`接口，mapper接口的具体处理逻辑也就是在这类中处理。\n\n到此为止，代理对象才真正的生成。\n\n### 与Spring集成时mapper代理的生成过程\nmybatis与Spring集成时需要用到`mybatis-spring`的jar。\n#### Spring注册mapper代理类\n既然是与Spring集成，那么就要配置一下，将mybatis交给Spring管理。\nspring的xml文件配置\n```xml\n    <bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\">\n        <property name=\"driverClassName\" value=\"driverClassName\"/>\n        <property name=\"url\" value=\"url\"/>\n        <property name=\"username\" value=\"username\"/>\n        <property name=\"password\" value=\"password\"/>\n    </bean>\n\n    <!--sqlSessionFactory-->\n    <bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <property name=\"dataSource\" ref=\"dataSource\"/>\n        <!--绑定mybatis配置文件-->\n        <property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/>\n        <!--注册Mapper.xm映射器-->\n        <property name=\"mapperLocations\" value=\"classpath:cn/ycl/mapper/*.xml\"/>\n    </bean>\n\n    <!--注册所有mapper-->\n    <bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\">\n        <!--basePackage 属性是映射器接口文件的包路径。-->\n        <!--你可以使用分号或逗号 作为分隔符设置多于一个的包路径-->\n        <property name=\"basePackage\" value=\"cn/ycl/mapper\"/>\n        <property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/>\n    </bean>\n```\n将mybatis交给Spring只需要配置3个bean就可以了   \n1、 数据库相关的`dataSource`  \n2、 mybatis的`sqlSessionFactory`  \n3、 将mapper委托给Spring的工具类`MapperScannerConfigurer`  \n生成mapper代理的过程主要在`MapperScannerConfigurer`里，看一下`MapperScannerConfigurer`的定义\n```java\npublic class MapperScannerConfigurer\n    implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware {\n    // ...省略\n}\n```\n关键点在`MapperScannerConfigurer` 实现了`BeanDefinitionRegistryPostProcessor`，`BeanDefinitionRegistryPostProcessor`是Spring留的扩展点，可以往Spring中注册自定义的bean。\n\n`MapperScannerConfigurer`中实现了`BeanDefinitionRegistryPostProcessor`的`postProcessBeanDefinitionRegistry()`方法，mapper的注册就是在该方法中注册的\n```java\n  public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) {\n    // ...省略\n    \n    // 实例化ClassPathMapperScanner，并对scanner相关属性进行配置\n    ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry);\n    scanner.setAddToConfig(this.addToConfig);\n    scanner.setAnnotationClass(this.annotationClass);\n    scanner.setMarkerInterface(this.markerInterface);\n    scanner.setSqlSessionFactory(this.sqlSessionFactory);\n    scanner.setSqlSessionTemplate(this.sqlSessionTemplate);\n    scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName);\n    scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName);\n    scanner.setResourceLoader(this.applicationContext);\n    scanner.setBeanNameGenerator(this.nameGenerator);\n    scanner.setMapperFactoryBeanClass(this.mapperFactoryBeanClass);\n    if (StringUtils.hasText(lazyInitialization)) {\n      scanner.setLazyInitialization(Boolean.valueOf(lazyInitialization));\n    }\n    if (StringUtils.hasText(defaultScope)) {\n      scanner.setDefaultScope(defaultScope);\n    }\n    // 注册扫描规则\n    scanner.registerFilters();\n    // 扫描并注册所有的mapper\n    scanner.scan(\n        StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));\n  }\n```\n`postProcessBeanDefinitionRegistry()`的主要逻辑是定义一个`ClassPathMapperScanner`对象，然后调用`registerFilters()`注册扫描规则,最后调用`scan()`方法。  \n\n在xml中定义`MapperScannerConfigurer`bean时可以设置一个`annotationClass`属性，值是一个注解类，调用`registerFilters()`时，`registerFilters()`会添加一个只扫描设置有`annotationClass`注解的类，这里没有设置，会扫描所有的接口。SpringBoot集成mybatis时会用到这个字段\n\n看一下`ClassPathMapperScanner`类的定义\n```java\npublic class ClassPathMapperScanner extends ClassPathBeanDefinitionScanner {\n    // ...省略\n}\n```\n`ClassPathMapperScanner`继承了`ClassPathBeanDefinitionScanner`，`ClassPathBeanDefinitionScanner`是Spring中定义的，是一个从指定包内扫描所有bean定义的Spring工具。 \n\n看一下`ClassPathMapperScanner`的`scan()`方法\n```java\n  public Set<BeanDefinitionHolder> doScan(String... basePackages) {\n    Set<BeanDefinitionHolder> beanDefinitions = super.doScan(basePackages);\n\n    if (beanDefinitions.isEmpty()) {\n        // ...省略\n    } else {\n      processBeanDefinitions(beanDefinitions);\n    }\n\n    return beanDefinitions;\n  }\n```\n通过`super.doScan(basePackages)`已经扫描到了所有的mapper，继续`processBeanDefinitions()`方法\n```java\n  private void processBeanDefinitions(Set<BeanDefinitionHolder> beanDefinitions) {\n    AbstractBeanDefinition definition;\n    BeanDefinitionRegistry registry = getRegistry();\n    // 遍历扫描到的所有bean\n    for (BeanDefinitionHolder holder : beanDefinitions) {\n      definition = (AbstractBeanDefinition) holder.getBeanDefinition();\n      boolean scopedProxy = false;\n      if (ScopedProxyFactoryBean.class.getName().equals(definition.getBeanClassName())) {\n        definition = (AbstractBeanDefinition) Optional\n            .ofNullable(((RootBeanDefinition) definition).getDecoratedDefinition())\n            .map(BeanDefinitionHolder::getBeanDefinition).orElseThrow(() -> new IllegalStateException(\n                \"The target bean definition of scoped proxy bean not found. Root bean definition[\" + holder + \"]\"));\n        scopedProxy = true;\n      }\n      String beanClassName = definition.getBeanClassName();\n      LOGGER.debug(() -> \"Creating MapperFactoryBean with name '\" + holder.getBeanName() + \"' and '\" + beanClassName\n          + \"' mapperInterface\");\n\n \n      // 增加一个构造方法，接口类型作为构造函数的入参\n      definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); \n\n      // 将bean的类型转换成mapperFactoryBean\n      definition.setBeanClass(this.mapperFactoryBeanClass);\n\n      // 增加addToConfig属性\n      definition.getPropertyValues().add(\"addToConfig\", this.addToConfig);\n\n  \n      definition.setAttribute(FACTORY_BEAN_OBJECT_TYPE, beanClassName);\n\n      boolean explicitFactoryUsed = false;\n      // 增加sqlSessionFactory属性\n      if (StringUtils.hasText(this.sqlSessionFactoryBeanName)) {\n        definition.getPropertyValues().add(\"sqlSessionFactory\",\n            new RuntimeBeanReference(this.sqlSessionFactoryBeanName));\n        explicitFactoryUsed = true;\n      } else if (this.sqlSessionFactory != null) {\n        definition.getPropertyValues().add(\"sqlSessionFactory\", this.sqlSessionFactory);\n        explicitFactoryUsed = true;\n      }\n\n      // 增加sqlSessionTemplate属性\n      if (StringUtils.hasText(this.sqlSessionTemplateBeanName)) {\n        if (explicitFactoryUsed) {\n          LOGGER.warn(\n              () -> \"Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.\");\n        }\n        definition.getPropertyValues().add(\"sqlSessionTemplate\",\n            new RuntimeBeanReference(this.sqlSessionTemplateBeanName));\n        explicitFactoryUsed = true;\n      } else if (this.sqlSessionTemplate != null) {\n        if (explicitFactoryUsed) {\n          LOGGER.warn(\n              () -> \"Cannot use both: sqlSessionTemplate and sqlSessionFactory together. sqlSessionFactory is ignored.\");\n        }\n        definition.getPropertyValues().add(\"sqlSessionTemplate\", this.sqlSessionTemplate);\n        explicitFactoryUsed = true;\n      }\n\n      if (!explicitFactoryUsed) {\n        LOGGER.debug(() -> \"Enabling autowire by type for MapperFactoryBean with name '\" + holder.getBeanName() + \"'.\");\n        definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n      }\n\n      definition.setLazyInit(lazyInitialization);\n\n      if (scopedProxy) {\n        continue;\n      }\n\n      if (ConfigurableBeanFactory.SCOPE_SINGLETON.equals(definition.getScope()) && defaultScope != null) {\n        definition.setScope(defaultScope);\n      }\n\n      if (!definition.isSingleton()) {\n        BeanDefinitionHolder proxyHolder = ScopedProxyUtils.createScopedProxy(holder, registry, true);\n        if (registry.containsBeanDefinition(proxyHolder.getBeanName())) {\n          registry.removeBeanDefinition(proxyHolder.getBeanName());\n        }\n        registry.registerBeanDefinition(proxyHolder.getBeanName(), proxyHolder.getBeanDefinition());\n      }\n\n    }\n  }\n\n```\n这个方法比较长，但是并不复杂，主要逻辑为将扫描的bean的类型修改成`MapperFactoryBean`类型，并增加一个将接口类型作为入参的构造函数，也就是说Spring获取mapper时都是通过FactoryBean生成的。最后通过调用`egistry.registerBeanDefinition()` 方法注册到Spring中。  \n\n看一下mybatis提供的`MapperFactoryBean`的定义\n```java\npublic class MapperFactoryBean<T> extends SqlSessionDaoSupport implements FactoryBean<T> {\n}\n```\n`MapperFactoryBean`实现了`FactoryBean`，`FactoryBean`是一个Spring提供的一个能生产对象的工厂Bean  \n\n`MapperFactoryBean`同时继承了`SqlSessionDaoSupport`，`SqlSessionDaoSupport`继承了`DaoSupport`，`DaoSupport`实现了`InitializingBean`。`InitializingBean`的作用是在Spring初始化bean对象时会首先调用`InitializingBean`的`afterPropertiesSet()`方法。  \n\n`DaoSupport`的`afterPropertiesSet()`中调用了`checkDaoConfig()`方法。\n```java\n    public final void afterPropertiesSet() throws IllegalArgumentException, BeanInitializationException {\n        this.checkDaoConfig();\n\n        try {\n            this.initDao();\n        } catch (Exception var2) {\n            throw new BeanInitializationException(\"Initialization of DAO failed\", var2);\n        }\n    }\n```\n具体`checkDaoConfig()`方法的实现逻辑在`MapperFactoryBean` 中\n```java\n protected void checkDaoConfig() {\n    super.checkDaoConfig();\n\n    notNull(this.mapperInterface, \"Property 'mapperInterface' is required\");\n\n    Configuration configuration = getSqlSession().getConfiguration();\n    if (this.addToConfig && !configuration.hasMapper(this.mapperInterface)) {\n      try {\n        configuration.addMapper(this.mapperInterface);\n      } catch (Exception e) {\n        // ..省略\n      } finally {\n        ErrorContext.instance().reset();\n      }\n    }\n  }\n```\nOK，到这又回到mybatis了。在前面中说了`configuration.addMapper()`方法只是生成了对应的代理工厂。  \n\n以上整个过程，即把mapper注册为Spring的bean，又将mapper设置到mybatis中的`configuration`中，所以，在使用时既可以使用Spring自动注入那一套，又可以使用mybatis中通过`sqlSession`来获取mapper的代理对象\n#### Spring生成代理对象\nSpring中所有的mapper对应的bean是mapper对应的`MapperFactoryBean`，那么在获取mapper bean时是通过`MapperFactoryBean`的`getObject()`方法生成的\n```java\n  public T getObject() throws Exception {\n    return getSqlSession().getMapper(this.mapperInterface);\n  }\n```\n`MapperFactoryBean`先获取到`sqlsession`，再通过`getMapper()`获取到的代理对象。到这里就回到了mybatis生成代理对象的过程了。\n\n\n### 与SpringBoot集成时mapper代理的生成过程\nmybatis与Spring集成时需要用到`mybatis-spring-boot-starter`的jar，`mybatis-spring-boot-starter`依赖`mybatis-spring-boot-autoconfigure`这个jar，而`mybatis-spring-boot-autoconfigure`这个jar又依赖`mybatis-spring`这个jar，所以最终其实还是mybatis集成Spring那一套  \n\n根据SpringBoot自动加载的原理直接看`mybatis-spring-boot-autoconfigure`jar下`META-INF/spring.factories`文件\n```\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\norg.mybatis.spring.boot.autoconfigure.MybatisLanguageDriverAutoConfiguration,\\\norg.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration\n```\nSpringBoot会自动加载`MybatisAutoConfiguration`这个类，直接看这个类，`MybatisAutoConfiguration`定义了mybtis所需的各个bean。\n```java\n\n    //生成SqlSessionFactory\n    @Bean\n    @ConditionalOnMissingBean\n    public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception {\n        // ...省略\n    }\n    \n    //生成SqlSessionTemplate\n    @Bean\n    @ConditionalOnMissingBean\n    public SqlSessionTemplate sqlSessionTemplate(SqlSessionFactory sqlSessionFactory) {\n     // ...省略\n    }\n    \n    //扫描mapper\n     @Configuration\n    @Import({MybatisAutoConfiguration.AutoConfiguredMapperScannerRegistrar.class})\n    @ConditionalOnMissingBean({MapperFactoryBean.class, MapperScannerConfigurer.class})\n    public static class MapperScannerRegistrarNotFoundConfiguration implements InitializingBean {\n        public MapperScannerRegistrarNotFoundConfiguration() {\n        }\n\n        public void afterPropertiesSet() {\n            MybatisAutoConfiguration.logger.debug(\"Not found configuration for registering mapper bean using @MapperScan, MapperFactoryBean and MapperScannerConfigurer.\");\n        }\n    }\n     //扫描mapper\n     public static class AutoConfiguredMapperScannerRegistrar implements BeanFactoryAware, ImportBeanDefinitionRegistrar {\n        private BeanFactory beanFactory;\n\n        public AutoConfiguredMapperScannerRegistrar() {\n        }\n\n        public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {\n            if (!AutoConfigurationPackages.has(this.beanFactory)) {\n                MybatisAutoConfiguration.logger.debug(\"Could not determine auto-configuration package, automatic mapper scanning disabled.\");\n            } else {\n                MybatisAutoConfiguration.logger.debug(\"Searching for mappers annotated with @Mapper\");\n                List<String> packages = AutoConfigurationPackages.get(this.beanFactory);\n                if (MybatisAutoConfiguration.logger.isDebugEnabled()) {\n                    packages.forEach((pkg) -> {\n                        MybatisAutoConfiguration.logger.debug(\"Using auto-configuration base package '{}'\", pkg);\n                    });\n                }\n                //生成MapperScannerConfigurer \n                BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(MapperScannerConfigurer.class);\n                builder.addPropertyValue(\"processPropertyPlaceHolders\", true);\n                // 注册扫描规则\n                builder.addPropertyValue(\"annotationClass\", Mapper.class);\n                builder.addPropertyValue(\"basePackage\", StringUtils.collectionToCommaDelimitedString(packages));\n                BeanWrapper beanWrapper = new BeanWrapperImpl(MapperScannerConfigurer.class);\n                Stream.of(beanWrapper.getPropertyDescriptors()).filter((x) -> {\n                    return x.getName().equals(\"lazyInitialization\");\n                }).findAny().ifPresent((x) -> {\n                    builder.addPropertyValue(\"lazyInitialization\", \"${mybatis.lazy-initialization:false}\");\n                });\n                registry.registerBeanDefinition(MapperScannerConfigurer.class.getName(), builder.getBeanDefinition());\n            }\n        }\n\n        public void setBeanFactory(BeanFactory beanFactory) {\n            this.beanFactory = beanFactory;\n        }\n    }\n    \n```\n","tags":["Mybatis"],"categories":["JAVA"]},{"title":"Java SPI机制","url":"/2021/07/10/spi/","content":"少侠你现在是否还这样连接数据库\n\n```java\ntry {\n    Class.forName(\"com.mysql.jdbc.Driver\");\n    Connection connection = DriverManager.getConnection(\"URL\",\"root\",\"password\");\n} catch (Exception e) {\n    e.printStackTrace();\n}\n```\n\n少侠你知道`Class.forName()`这句早已经没用了么？Java 官方已经把它优化掉了。想知道怎么优化的么？不要急，且看我慢慢道来。\n\n## SPI\n\nSPI 全名：Service Provider Interface，是 JDK 内置的一种服务发现机制，可以将服务接口与服务发现分离以达到解耦的效果。可以提升程序的可扩展性。比如 jdbc 只提供了接口，具体的实现由各个运营商解决、经常用的 log 日志类`LogFactory`，还有阿里的 dubbo 更是将 SPI 运用的淋漓尽致。\n\nSPI 使用说明：\n\n- 在 resources 目录下新建 META-INF/services 目录，并在目录下创建一个文件，文件名字为`接口`的全限定名，文件内容为`实现类`的全限定名。\n- 通过`java.util.ServiceLoder`类加载实现类。\n- SPI 的实现类必须携带一个不带参数的构造方法。\n\n来个示例\n\n首先定义一个接口\n\n```java\npublic interface Pay {\n    void pay();\n}\n```\n\n再来两个实现类\n\n```java\npublic class AliPay implements Pay {\n    @Override\n    public void pay() {\n        System.out.println(\"AliPay\");\n    }\n}\n```\n\n```java\npublic class WeChatPay implements Pay {\n    @Override\n    public void pay() {\n        System.out.println(\"WeChatPay\");\n    }\n}\n```\n\n在 resources 目录下新建 META-INF/services 目录，并在目录下创建一个文件，文件名为接口的权限定名`com.yao.spi.Pay`，文件内容为实现类的全限定名\n\n```java\ncom.yao.spi.AliPay\n```\n\n![](spi.png)\n\n通过`java.util.ServiceLoder`获取实现类。\n\n```java\npublic static void main(String[] args) {\n\n    ServiceLoader<Pay> spiDemoServiceLoader = ServiceLoader.load(Pay.class);\n\n    Iterator<Pay> payIterator = spiDemoServiceLoader.iterator();\n    while (payIterator.hasNext()){\n        Pay pay = payIterator.next();\n        pay.pay();\n    }\n}\n```\n\n看一下结果。\n\n```java\nAliPay\n```\n\n有没有注意到`ServiceLoder`获取到的是一个列表？这说明什么问题？对的，可以一次初始化多个实现类，只要在文件中声明就可以了。现在再把`WechatPay`给添加上\n\n```java\ncom.yao.spi.AliPay\ncom.yao.spi.WeChatPay\n```\n\n看一下运行结果\n\n```java\nAliPay\nWeChatPay\n```\n\n## 源码解析\n\nSPI 的功能比较简单，一个`ServiceLoader`类包含所有的功能。先来看一下有那些主要的属性和内部类的主要属性。\n\n```java\npublic final class ServiceLoader<S> implements Iterable<S> {\n    //配置文件的路径\n    private static final String PREFIX = \"META-INF/services/\";\n    //加载的类或接口\n    private final Class<S> service;\n    //类加载器\n    private final ClassLoader loader;\n    //已加载的服务类\n    private LinkedHashMap<String, S> providers = new LinkedHashMap();\n    //内部类，真正加载类的地方\n    private ServiceLoader<S>.LazyIterator lookupIterator;\n    //内部类\n    private class LazyIterator implements Iterator<S> {\n        //加载的类或接口\n        Class<S> service;\n        //类加载器\n        ClassLoader loader;\n        //保存配置文件中的信息\n        Enumeration<URL> configs;\n        //保存配置文件中所有的实现类的全限定名\n        Iterator<String> pending;\n        String nextName;\n        }\n}\n```\n\n当看到内部类`LazyIterator`这个`Lazy`时，会不会联想到 spring 加载 bean 时的懒加载。这里其实也是一样，当调用`load`方法时，并不会加载类，只初始化一些内部属性。真正加载实现类是在获取实现类时。\n![](source.png)\n\n沿着上面`main`方法第一次获取实现类的过程一步一步解析，第一次以后获取的过程有兴趣的少侠可以自己走一遍。\n\n### 注册实现类\n\n`spiDemoServiceLoader.iterator();`获取的迭代器是`ServiceLoader`重写的迭代器，迭代器中的方法都指向了内部类`LazyIterator`\n\n```java\n public Iterator<S> iterator() {\n        return new Iterator<S>() {\n            Iterator<Entry<String, S>> knownProviders;\n\n            {\n                this.knownProviders = ServiceLoader.this.providers.entrySet().iterator();\n            }\n\n            public boolean hasNext() {\n                return this.knownProviders.hasNext() ? true : ServiceLoader.this.lookupIterator.hasNext();\n            }\n\n            public S next() {\n                return this.knownProviders.hasNext() ? ((Entry)this.knownProviders.next()).getValue() : ServiceLoader.this.lookupIterator.next();\n            }\n\n            public void remove() {\n                throw new UnsupportedOperationException();\n            }\n        };\n    }\n```\n\n当调用`payIterator.hasNext()`时，调用的是重写迭代器中的\n\n```java\n  public boolean hasNext() {\n      return this.knownProviders.hasNext() ? true : ServiceLoader.this.lookupIterator.hasNext();\n  }\n```\n\n然后会调用内部类`LazyIterator`中的`hasNext()`方法\n\n```java\n public boolean hasNext() {\n      if (ServiceLoader.this.acc == null) {\n          return this.hasNextService();\n      } else {\n          //省略\n      }\n  }\n```\n\n接着调用调用内部类`LazyIterator`中的`hasNextService()`方法\n\n```java\n private boolean hasNextService() {\n      if (this.nextName != null) {\n          return true;\n      } else {\n          if (this.configs == null) {\n              try \n                  ////文件路径\n                  String var1 = \"META-INF/services/\" + this.service.getName();\n                  //读取配置文件，并将配置文件内容保存到configs\n                  if (this.loader == null) {\n                      this.configs = ClassLoader.getSystemResources(var1);\n                  } else {\n                      this.configs = this.loader.getResources(var1);\n                  }\n              } catch (IOException var2) {\n                    //省略\n              }\n          }\n\n          while(this.pending == null || !this.pending.hasNext()) {\n            if (!this.configs.hasMoreElements()) {\n                  return false;\n                }\n              //将文件中的实现类权限定名保存到pending中\n              this.pending = ServiceLoader.this.parse(this.service, (URL)this.configs.nextElement());\n              }\n\n          this.nextName = (String)this.pending.next();\n          return true;\n          }\n        }\n```\n\n第一次到这里时，会将配置文件的信息保存到到内部类中的'configs'属性中，并解析文件将配置的所有实现类保存到内部类中的`pending`中，但是这里还是没有未初始化类。\n\n### 获取实现类\n\n当调用`payIterator.next();`时，调用的是重写的\n\n```java\npublic S next() {\n    return this.knownProviders.hasNext() ? ((Entry)this.knownProviders.next()).getValue() : ServiceLoader.this.lookupIterator.next();\n}\n```\n\n并最终调用到内部类`LazyIterator`中的`next()`方法\n\n```java\npublic S next() {\n    if (ServiceLoader.this.acc == null) {\n         return this.nextService();\n    } else {\n        PrivilegedAction var1 = new PrivilegedAction<S>() {\n            public S run() {\n                return LazyIterator.this.nextService();\n            }\n        };\n        return AccessController.doPrivileged(var1, ServiceLoader.this.acc);\n    }\n}\n```\n\n然后调用内部类`LazyIterator`中的`nextService()`方法\n\n```java\nprivate S nextService() {\n    if (!this.hasNextService()) {\n        throw new NoSuchElementException();\n    } else {\n        String var1 = this.nextName;\n        this.nextName = null;\n        Class var2 = null;\n\n        try {\n\t         //初始化实现类\n            var2 = Class.forName(var1, false, this.loader);\n        } catch (ClassNotFoundException var5) {\n         \n        }\n\n        //忽略掉后面的代码\n    }\n}\n```\n\n看到`Class.forName()`，到此才是初始化实现类。\n\n## JDBC 中的运用\n回到最初的话题，既然`Class.forName()`没有用了，那JDBC在那优化的呢？首先要知道`Class.forName()`的作用：强制JVM将com.mysql.jdbc.Driver这个类加载入内存，以便`DriverManager`类使用，现在既然用不到了，那肯定是在别的地方加载了。那用什么方式加载的？当然是SPI了，要不然前面一大堆东西不是白说了么，哈哈哈哈！看看mysql的jar里\n![MySQL](jdbc.png)\n是不是很熟悉，这不就是SPI规范么。\n\nOK，来看看加载的过程。\n既然只需要这一句就可以了\n```java\nConnection connection = DriverManager.getConnection(\"URL\",\"root\",\"password\");\n```\n### 加载\n那就从`DriverManager`类开始，类加载当然要从静态代码块开始了，看一下`DriverManager`的静态代码块。\n```java\n    static {\n        loadInitialDrivers();\n        println(\"JDBC DriverManager initialized\");\n        SET_LOG_PERMISSION = new SQLPermission(\"setLog\");\n        DEREGISTER_DRIVER_PERMISSION = new SQLPermission(\"deregisterDriver\");\n    }\n```\n进`loadInitialDrivers()`方法\n![](jdbc2.png)\n熟不熟悉？是不是SPI机制？`DriverManager`在初始化类时，会先利用SPI机制加载数据库的驱动。那又是怎么注册到`DriverManager`的呢？继续看！\n### 加载\n在上面SPI机制中说了，当调用`next()`方法时会初始化实现类，也就是会初始化`Driver`类，那就再看`Driver`类。\n```java\npublic class Driver extends NonRegisteringDriver implements java.sql.Driver {\n    static {\n        try {\n            java.sql.DriverManager.registerDriver(new Driver());\n        } catch (SQLException E) {\n            throw new RuntimeException(\"Can't register driver!\");\n        }\n    }\n    public Driver() throws SQLException {\n        // Required for Class.forName().newInstance()\n    }\n}\n```\n静态代码块中`DriverManager.registerDriver(new Driver());`就是将`Driver`注册到`DriverManager`。  \n总结一下加载过程：\n1. DriverManager在静态代码块中利用SPI机制获取到数据库驱动，并初始化Driver\n2. Driver初始化时首先运行静态代码块将Driver注册到DriverManager\n\n\n\n\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"Mysql优化工具explain","url":"/2021/06/26/explain/","content":" \nexplain的使用很简单，只要在select语句的前面加上`explain`的关键字就好了，来看个例子\n\n先创建两个表，注意两个表的索引\n```sql\nCREATE TABLE `user` (\n  `id` varchar(32) NOT NULL,\n  `name` varchar(32) DEFAULT NULL,\n  `role` varchar(32) DEFAULT NULL,\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\nINSERT INTO `user` VALUES ('1', '1', '1');\nINSERT INTO `user` VALUES ('10', '10', '5');\nINSERT INTO `user` VALUES ('2', '2', '2');\nINSERT INTO `user` VALUES ('3', '3', '3');\nINSERT INTO `user` VALUES ('4', '4', '4');\nINSERT INTO `user` VALUES ('5', '5', '5');\nINSERT INTO `user` VALUES ('6', '6', '1');\nINSERT INTO `user` VALUES ('7', '7', '2');\nINSERT INTO `user` VALUES ('8', '8', '3');\nINSERT INTO `user` VALUES ('9', '9', '4');\n\nCREATE TABLE `role` (\n  `id` varchar(32) NOT NULL,\n  `name` varchar(32) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `name` (`name`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n\nINSERT INTO `role` VALUES ('1', '1');\nINSERT INTO `role` VALUES ('6', '1');\nINSERT INTO `role` VALUES ('2', '2');\nINSERT INTO `role` VALUES ('3', '3');\nINSERT INTO `role` VALUES ('4', '4');\nINSERT INTO `role` VALUES ('5', '5');\n```\n\n试一下`explain`\n\n```sql\n EXPLAIN SELECT * FROM `user` WHERE id = '1'\n```\n来看输出结果,表格太长了，就不以表格的形式显示结果了\n```\n             id: 1\n   select_type : SIMPLE\n          table: user\n           type: const\n  possible_keys: PRIMARY\n            key: PRIMARY\n        ken_len: 98\n            ref: const\n           rows: 1\n          Extra: NULL\n```\n\n来看看各个字段的含义：\n+ id: select查询的序号。\n+ select_type: 查询的类型\n+ table：查询涉及的表\n+ partitions: 匹配的分区\n+ type：表的连接类型\n+ possible_keys：可能应用到的索引\n+ key：实际被使用的索引列\n+ ken_len： 索引中使用的字节数\n+ ref： 关联的字段\n+ rows: 此查询一共扫描了多少行\n+ filtered: 表示此查询条件所过滤的数据的百分比\n+ extra：执行情况的额外的说明\n\n有两个字段（partitions，filtered）没有在查询的结果中出现，一般也不需要关注这两个字段，同时所有的字段并不是全部是重要的，这里来详细了解下各个字段。\n\n## id\nid的值说明了sql执行的先后顺序，可能出现三种情况：\n### id相同\nid相同时，执行的顺序是自上到下依次运行\n### id不同\n比如使用子查询的情况下，会出现id的值递增的情况。id的值越大执行的优先级越高。\n### id不同和相同的同时存在\n可以把相同的理解为一组，相同一组的执行顺序自上到下依次运行，不同组的id的值越大，执行的优先级越高。\n## select_type\n  select_type的值主要有以下几种：\n### SIMPLE\n简单的`select`,不使用UNION或子查询  \n\n例子\n```sql\nEXPLAIN SELECT * FROM `user` WHERE id = '1'\n```\n### PRIMARY\n最外层查询的`select`查询  \n\n例子\n```sql\nEXPLAIN SELECT * FROM `user`\nWHERE role = (\n  SELECT id FROM role\n  WHERE `name` = '1'\n  )\n```\n其中`user`表的类型是`PRIMARY`\n![](primary.png)\n\n\n### UNION\n`UNION`查询中的第二个语句或后面的语句  \n\n例如\n```sql\nEXPLAIN SELECT * FROM `user` WHERE id = '1'\n         UNION\n         SELECT * FROM `user` WHERE id = '2'\n```\n![](union.png)\n\n### DEPENDENT UNION\nUNION查询中的第二个或后面的查询语句, 取决于外面的查询， 即子查询依赖于外层查询的结果.\n### UNION RESULT  \nUNION查询的结果  \n\n例如\n```sql\nEXPLAIN SELECT * FROM `user` WHERE id = '1'\n         UNION\n         SELECT * FROM `user` WHERE id = '2'\n```\n![](result.png)\n\n### SUBQUERY\n子查询中的第一个`select`  \n\n例如\n```sql\nEXPLAIN SELECT * FROM `user`\nWHERE role = (\n  SELECT id FROM role\n  WHERE `name` = '1'\n  )\n```\n![](subquery.png)\n\n### DEPENDENT SUBQUERY\n子查询中的第一个`select`,取决于外面的查询。\n\n\n## table\n`table`表示该次查询涉及到的表名或表的别名。\n\n\n## type\n`type`是一个非常重要的一个字段。根据`type`字段可以判断查询是否性能高效。\n\n常用的类型有：\n### system\n表示结果集仅有一行，这是`const`类型的一个特例，一般是在`myisam`或`memory`存储引擎中，在`innodb`存储引擎中为`const`\n### const\n表示通过主键或者唯一索引查找数据时只匹配了一行数据，`const`说明查询速度非常快。  \n\n例子\n```sql\nEXPLAIN SELECT * FROM `user` WHERE id = '1'\n```\n### eq_ref\n多出现在联接查询，表示索引是主键或唯一非 NULL 索引时，对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =, 查询效率较高,这是最好的联接类型。  \n\n例子\n```sql\nEXPLAIN SELECT * FROM `user`,role\n         WHERE `user`.id = role.`id`\n```\n说明：\n`user.id`是唯一索引, 每条`user.id`可以联接`role`中的一条数据。\n### ref\n通常出现在多表的联接查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询.  \n\n例子：\n```sql\nEXPLAIN SELECT * FROM `user`,role\n         WHERE `user`.`name` = role.name\n```\n说明：`role.name`是索引，但并不是唯一索引和主键索引\n### range\n表示使用索引范围查询,这个类型通常出现在 =, <>, >, >=, <, <=, IS NULL, <=>, BETWEEN, IN() 操作中。\n\n例子\n```sql\nEXPLAIN SELECT * FROM `user`\n        WHERE id IN ('1','2','3')\n```\n### index\n表示全索引扫描，扫描所有的索引  \n\n例子\n```sql\nEXPLAIN SELECT id,`name` FROM `role` \n```\n### ALL\n表示全表扫描，这是最坏的结果。\n\n最好的结果到最差的结果：system > const > eq_ref > ref > range > index > ALL，一般来说，得保证查询至少达到range级别，最好能达到ref。\n## possible_keys\n可能用到的索引。注意：只是可能。即使有些索引在这个字段中出现。也不一定会被真正用到。\n\n\n## key\n实际被用到的索引列。注意和`possible_keys`做区分\n\n\n## ken_len\n表示索引中使用的字节数，key_len显示的值为索引字段的最大可能长度，并非实际使用长度。这个当然越短越好。\n\n\n## ref\n表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值\n\n\n## rows\n`rows`这个也是非常重要的一个字段,估算要扫描的行数，原则上越少越好。注意：这个值并不是完全准确的值，只是估算。\n\n\n## Extra\n`Extra`提供了多个值，这只说几个比较常见的，有兴趣的少侠可以自行百度，谷歌。\n### Using temporary\n查询时需要用额外的临时表来存储结果集，比较常见在`group by`,`order by`中。\n### Using filesort\n当包含`order by`操作，而且无法利用索引完成的排序操作称为“文件排序”，建议优化。\n### Using join buffer\n在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。\n### Using index\n\"覆盖索引\",表示查询的数据在索引中就可以找到，说明性能不错。\n    \n## 注意\n1. `explain`只能解释`select`\n2. `explain`不计算各种Cache\n3.  部分信息只是估算。","tags":["MySql"],"categories":["MySql"]},{"title":"Java动态代理","url":"/2021/05/15/java-proxy/","content":"JDK动态代理使用的非常广泛，Spring AOP中、MyBatis的mapper中都用到了JDK动态代理。\n\n## JDK动态代理的使用\n1、创建代理类接口及代理类。  \n2、创建一个实现了InvocationHandler接口的类，实现该接口中的invoke方法。  \n3、通过Proxy的newProxyInstance(ClassLoaderloader, Class[] interfaces, InvocationHandler h)方法创建一个代理对象。  \n来个例子：  \n创建一个Hello的接口\n```java\npublic interface Hello {\n\n    void sayHello();\n}\n```\n创建一个实现了Hello接口的实现类。\n```java\npublic class HelloImpl implements Hello {\n\n    public void sayHello() {\n        System.out.println(\"hello\");\n    }\n}\n```\n创建一个实现了InvocationHandler接口的类。\n```java\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\n\npublic class HelloInvocationHandler implements InvocationHandler {\n\n    private Object hello;\n\n    public HelloInvocationHandler(Object hello) {\n        this.hello = hello;\n    }\n\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        System.out.println(\"start\");\n        Object invoke = method.invoke(hello, args);\n        System.out.println(\"end\");\n        return invoke;\n    }\n}\n```\n通过Proxy创建一个代理对象\n```java\nHello hello = new HelloImpl();\nHelloInvocationHandler helloInvocationHandler = new HelloInvocationHandler(hello);\nClassLoader classLoader = hello.getClass().getClassLoader();\nClass<?>[] interfaces = hello.getClass().getInterfaces();\nHello helloProxy = (Hello)Proxy.newProxyInstance(classLoader, interfaces, helloInvocationHandler);\nhelloProxy.sayHello();\n```\n看一看输出结果\n```\nstart\nhello\nend\n```\n\n\n## 源码\n看一下Proxy的newProxyInstance方法\n```java\npublic static Object newProxyInstance(ClassLoader loader,\n                                          Class<?>[] interfaces,\n                                          InvocationHandler h)\n        throws IllegalArgumentException\n    {\n\n\n\t//省略\n\n        /*\n         * 生成代理类    \n         */\n        Class<?> cl = getProxyClass0(loader, intfs);\n\n        /*\n         * Invoke its constructor with the designated invocation handler.\n         */\n        try {\n\t    //省略\n            \n\t    //获取代理类的构造函数\n            final Constructor<?> cons = cl.getConstructor(constructorParams);\n            final InvocationHandler ih = h;\n            if (!Modifier.isPublic(cl.getModifiers())) {\n                AccessController.doPrivileged(new PrivilegedAction<Void>() {\n                    public Void run() {\n                        cons.setAccessible(true);\n                        return null;\n                    }\n                });\n            }\n            // 通过构造函数，将InvocationHandler设置到代理对象中，并创建代理对象\n            return cons.newInstance(new Object[]{h});\n        } catch (IllegalAccessException|InstantiationException e) {\n            throw new InternalError(e.toString(), e);\n        } catch (InvocationTargetException e) {\n            Throwable t = e.getCause();\n            if (t instanceof RuntimeException) {\n                throw (RuntimeException) t;\n            } else {\n                throw new InternalError(t.toString(), t);\n            }\n        } catch (NoSuchMethodException e) {\n            throw new InternalError(e.toString(), e);\n        }\n    }\n\n```\n这段代码的主要功能功能是生成代理类,通过代理类的构造函数创建了一个代理对象，代理类是怎么生成的，继续看`getProxyClass0`方法\n```java\n private static Class<?> getProxyClass0(ClassLoader loader,\n                                           Class<?>... interfaces) {\n        if (interfaces.length > 65535) {\n            throw new IllegalArgumentException(\"interface limit exceeded\");\n        }\n\n        return proxyClassCache.get(loader, interfaces);\n    }\n\n```\n`getProxyClass0`首先判断了接口的数量，然后通过`proxyClassCache`获取到了代理类，`proxyClassCache`是什么东西？看一下`proxyClassCache`的定义\n```java\nprivate static final WeakCache<ClassLoader, Class<?>[], Class<?>>\n        proxyClassCache = new WeakCache<>(new KeyFactory(), new ProxyClassFactory());\n```\n通过定义可以发现，`proxyClassCache`其实是一个缓存类，生成的类是放在缓存里的。接着看一个这个类的构造函数\n```java\n public WeakCache(BiFunction<K, P, ?> subKeyFactory,\n                     BiFunction<K, P, V> valueFactory) {\n        this.subKeyFactory = Objects.requireNonNull(subKeyFactory);\n        this.valueFactory = Objects.requireNonNull(valueFactory);\n    }\n```\n可以看到`subKeyFactory`其实是`KeyFactory`，`valueFactory`其实是`ProxyClassFactory`\n\n好了，现在回到`getProxyClass0`的方法中，上面分析了`proxyClassCache`了，那继续看它的`get`方法\n```java\npublic V get(K key, P parameter) { // key 是ClassLoader parameter是interfaces\n    //省略\n\n    //根据ClassLoader获取cachekey\n    Object cacheKey = CacheKey.valueOf(key, refQueue);\n\n    ConcurrentMap<Object, Supplier<V>> valuesMap = map.get(cacheKey);\n    if (valuesMap == null) {\n        ConcurrentMap<Object, Supplier<V>> oldValuesMap\n            = map.putIfAbsent(cacheKey,\n                              valuesMap = new ConcurrentHashMap<>());\n        if (oldValuesMap != null) {\n            valuesMap = oldValuesMap;\n        }\n    }\n\n    // 根据key 和 interfaces生成subkey\n    Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter));\n    Supplier<V> supplier = valuesMap.get(subKey);\n    Factory factory = null;\n\n    while (true) {\n        if (supplier != null) {\n            V value = supplier.get();\n            if (value != null) {\n                return value;\n            }\n        }\n\n        if (factory == null) {\n            factory = new Factory(key, parameter, subKey, valuesMap);\n        }\n\n        if (supplier == null) {\n            supplier = valuesMap.putIfAbsent(subKey, factory);\n            if (supplier == null) {\n                supplier = factory;\n            }\n        } else {\n            if (valuesMap.replace(subKey, supplier, factory)) {\n                supplier = factory;\n            } else {\n                supplier = valuesMap.get(subKey);\n            }\n        }\n    }\n}\n```\n这段代码看着比较绕，我们知道这个方法的作用主要是生成代理类的，那`retrun value`返回的肯定是代理类，那么不妨反着推一下：  \n`value` 是`supplier.get()`获取的;  \n`supplier`其实是`Factory`;  \n`Factory`是由`key`、`paramter`、`subkey`、`valuesMap`生成的，`key`和`paramter`是方法入参`classloader`和`interfaces`;  \n`subkey` 是由`subKeyFactory`跟据`key`和`paramter`得到的，也就是根据`classloader`和`interfaces`得到的;  \n`vlauesMap`是由`map`根据`cacheKey`获取的，而`cacheKey`是由`key`得到的，也就是根据`classloader`得到的。  \n最后，根据反推的结果再来看一边代码就好理解了，这个方法其实就是根据`map`获取`supplier`，只是这个map的结构比较复杂，它是一个两层的map结构：第一层的key是根据`classloader`生成的一个`cacheKey`对象，第二层的key是`classloader`和`interfaces`生成的一个`subkey`对象。  \n\n接下来接着走到`supplier.get()`这，看看它是怎么生成代理对象的。`supplier`其实是`Factory`，那就直接看`Factory`的get方法\n```java\n @Override\n public synchronized V get() { // serialize access\n      Supplier<V> supplier = valuesMap.get(subKey);\n      if (supplier != this) {\n          return null;\n      }\n\n      V value = null;\n      try {\n          //获取代理类\n          value = Objects.requireNonNull(valueFactory.apply(key, parameter));\n      } finally {\n          if (value == null) { // remove us on failure\n              valuesMap.remove(subKey, this);\n          }\n      }\n      assert value != null;\n\n      CacheValue<V> cacheValue = new CacheValue<>(value);\n\n      reverseMap.put(cacheValue, Boolean.TRUE);\n\n      if (!valuesMap.replace(subKey, this, cacheValue)) {\n          throw new AssertionError(\"Should not reach here\");\n      }\n\n      return value;\n  }\n}\n```\n整个方法的关键点其实在`valueFactory.apply(key,paramter)`这，在前面分析中已经只知道了`valueFactory`其实是`ProxyClassFactory`，直接看`apply`方法\n```java\n@Override\npublic Class<?> apply(ClassLoader loader, Class<?>[] interfaces) {\n\n     //接口验证 省略\n\n\n    String proxyPkg = null;     // package to define proxy class in\n    int accessFlags = Modifier.PUBLIC | Modifier.FINAL;\n\n    //验证接口 省略\n\n    if (proxyPkg == null) {\n        // if no non-public proxy interfaces, use com.sun.proxy package\n        proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\";\n    }\n\n    //拼装生成的类名\n    long num = nextUniqueNumber.getAndIncrement();\n    String proxyName = proxyPkg + proxyClassNamePrefix + num;\n    \n   //获取类的字节数组\n    byte[] proxyClassFile = ProxyGenerator.generateProxyClass(\n            proxyName, interfaces, accessFlags);\n    try {\n        return defineClass0(loader, proxyName,\n                            proxyClassFile, 0, proxyClassFile.length);\n    } catch (ClassFormatError e) {\n            throw new IllegalArgumentException(e.toString());\n        }\n    }\n}\n```\n最后代理类是通过`ProxyGenerator`生成的，具体的生成细节不再分析了，这里涉及到了很多java类字节码的知识，在`ProxyGenerator`中也体现了很多字节码的东西，有兴趣的可以研究、谷歌。\n\n既然能够得到字节数组，那么就可以把它保存成class类，反编译看一下生成的代理类代码。\n```java\n //代理类类名\n String className = \"HelloProxy\";\n int accessFlags = Modifier.PUBLIC | Modifier.FINAL;\n //获取代理类字节数组 \n byte[] data = ProxyGenerator.generateProxyClass(className, new Class[]{Hello.class},accessFlags);\n FileOutputStream out;\n out = null;\n try {\n     //将代理类保存到文件\n     out = new FileOutputStream(className + \".class\");\n     System.out.println((new File(\"HelloProxy\")).getAbsolutePath());\n     out.write(data);\n } catch (FileNotFoundException e) {\n     e.printStackTrace();\n } catch (IOException e) {\n     e.printStackTrace();\n } finally {\n     if (null != out) {\n         try {\n             out.close();\n         } catch (IOException e) {\n             e.printStackTrace();\n         }\n     }\n }\n\n```\n反编译生成的代理类：\n```java\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\nimport java.lang.reflect.UndeclaredThrowableException;\n\npublic final class HelloProxy extends Proxy implements Hello {\n    private static Method m1;\n    private static Method m3;\n    private static Method m2;\n    private static Method m0;\n\n    public Hello(InvocationHandler var1) throws  {\n        super(var1);\n    }\n\n    public final boolean equals(Object var1) throws  {\n        try {\n            return (Boolean)super.h.invoke(this, m1, new Object[]{var1});\n        } catch (RuntimeException | Error var3) {\n            throw var3;\n        } catch (Throwable var4) {\n            throw new UndeclaredThrowableException(var4);\n        }\n    }\n\n    public final void sayHello() throws  {\n        try {\n            super.h.invoke(this, m3, (Object[])null);\n        } catch (RuntimeException | Error var2) {\n            throw var2;\n        } catch (Throwable var3) {\n            throw new UndeclaredThrowableException(var3);\n        }\n    }\n\n    public final String toString() throws  {\n        try {\n            return (String)super.h.invoke(this, m2, (Object[])null);\n        } catch (RuntimeException | Error var2) {\n            throw var2;\n        } catch (Throwable var3) {\n            throw new UndeclaredThrowableException(var3);\n        }\n    }\n\n    public final int hashCode() throws  {\n        try {\n            return (Integer)super.h.invoke(this, m0, (Object[])null);\n        } catch (RuntimeException | Error var2) {\n            throw var2;\n        } catch (Throwable var3) {\n            throw new UndeclaredThrowableException(var3);\n        }\n    }\n\n    static {\n        try {\n            m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\"));\n            m3 = Class.forName(\"Bolg.Hello\").getMethod(\"sayHello\");\n            m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\");\n            m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\");\n        } catch (NoSuchMethodException var2) {\n            throw new NoSuchMethodError(var2.getMessage());\n        } catch (ClassNotFoundException var3) {\n            throw new NoClassDefFoundError(var3.getMessage());\n        }\n    }\n}\n\n```\n代理类用的是反射的方式获取所有被代理对象的方法，在调用方法时其实调用的是从构造函数中传入的`InvocationHandler`的`invoke`方法，并传入被代理对象的方法。\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"Java内省","url":"/2021/04/15/introspector/","content":"内省(Introspector) 是Java 语言对 JavaBean 类属性、事件的一种缺省处理方法。说简单一点就是操作JavaBean的一套API。  \n\n什么是JavaBean？  \njavaBean只是一种规范，大家都按照约定好的一套规则写java类，既然是规范就有一定的要求：  \n+ 类是public的，然后有个无参的构造函数\n+ 属性是private的，通过设置setXXX()和getXXX()来访问\n+ 能支持事件，例如 addXXXXListener(XXXEvent e), 事件可以是 Click 事件，Keyboard 事件等等\n+ 提供应该 反射机制，这样可以查看java bean的各种信息\n+ 可以序列化，可以保存在硬盘上\n例如：\n```java\npublic class User {\n    private String name;\n\n    private String address;\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public String getAddress() {\n        return address;\n    }\n\n    public void setAddress(String address) {\n        this.address = address;\n    }\n}\n\n```\n\n## JDK内省类库\n### PropertyDescriptor类:\n  PropertyDescriptor可以获取某一个具体的属性。主要的方法有： \n  +  getPropertyType()，获得属性的Class对象;\n  +  getReadMethod()，获得用于读取属性值的方法，例如getXXX()方法；\n  +  getWriteMethod()，获得用于写入属性值的方法，例如setXXX()方法;\n  +  hashCode()，获取对象的哈希值;\n  +  setReadMethod(Method readMethod)，设置用于读取属性值的方法;\n  +  setWriteMethod(Method writeMethod)，设置用于写入属性值的方法。\n 示例代码： \n```java\npublic class JavaBeanUtils {\n    public static void main(String[] args) throws IntrospectionException {\n        User user = new User();\n\n        PropertyDescriptor propertyDescriptor = new PropertyDescriptor(\"name\",user.getClass());\n        System.out.println(propertyDescriptor.getPropertyType());\n        Method  method = propertyDescriptor.getReadMethod();\n        System.out.println(method.getName());\n        method = propertyDescriptor.getWriteMethod();\n        System.out.println(method.getName());\n\n    }\n}\n\n```\n输入结果：  \n```\nclass java.lang.String\ngetName\nsetName\n```\n### Introspector类:\n  Introspector可以按照JavaBean的规范将一个类封装成BeanInfo对象。通过调用`getPropertyDescriptors()`方法会返回一个包含所有属性的`PropertyDescriptor`对象数组，通过`PropertyDescriptor`可以操作类的属性。  \n  具体代码如下：\n  ```java\n  public class JavaBeanUtils {\n    public static void main(String[] args) throws IntrospectionException {\n        BeanInfo beanInfo = Introspector.getBeanInfo(User.class);\n        PropertyDescriptor[] pd = beanInfo.getPropertyDescriptors();\n\n        //迭代每一个描述器\n        for (PropertyDescriptor propertyDescriptor : pd) {\n\n            System.out.println(\"属性名 :\"+propertyDescriptor.getName());\n            System.out.println(\"setter :\"+propertyDescriptor.getWriteMethod());\n            System.out.println(\"getter :\"+propertyDescriptor.getReadMethod());\n        }\n    }\n}\n  ```\n","tags":["JAVA"],"categories":["JAVA"]},{"title":"ReentrantLock源码分析","url":"/2021/04/13/rl/","content":"ReentrantLock是一个可重入且独占式的锁，该锁支持获取锁时的公平和非公平选择。\n\n### 公平锁\n公平锁遵循FIFO的原则，所有的线程都会顺序执行\n#### 获取锁\n```java\n\n       //加锁\n    final void lock() {\n        acquire(1);\n    }\n\n   //调用AbstractQueuedSynchronizer\n    public final void acquire(int arg) {\n        if (!tryAcquire(arg) &&\n            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n            selfInterrupt();\n    }\n```\n是否是获得锁，还是进入队列等待的逻辑在`tryAcquire` 函数里。\n```java\n    protected final boolean tryAcquire(int acquires) {\n        //获取当前线程\n        final Thread current = Thread.currentThread();\n            \n        // 获取state值，state代表前线程获取锁的可重入次数\n        int c = getState();\n        /** 如果c为0，判断阻塞队列中是否还有线程，\n        *   如果不存在，设置state的值，并设置当前线程为独占锁的拥有者 \n        *   如果队列中还存在节点，则将该线程加入到队列中。\n        **/\n        if (c == 0) {\n            //判断队列中是否还存在线程\n            if (!hasQueuedPredecessors() &&\n            //设置state值\n                compareAndSetState(0, acquires)) {\n                // 设置当前线程为独占锁的拥有者 \n                setExclusiveOwnerThread(current);\n                //返回ture代表获取锁成功\n                return true;\n            }\n        }\n        /**\n        * 如果c不为0，判断独占锁的拥有者是否是当前线程，\n        * 如果是，则修改state值 \n        **/\n        else if (current == getExclusiveOwnerThread()) {\n            int nextc = c + acquires;\n            if (nextc < 0)\n                throw new Error(\"Maximum lock count exceeded\");\n            setState(nextc);\n            return true;\n        }\n        /**返回 false 代表获取锁失败，\n        * 则AbstractQueuedSynchronizer类的acquire函数继续往下进行，将该线程加入到队列中。\n        **/\n        return false;\n    }\n\n\n    public final boolean hasQueuedPredecessors() {\n        Node t = tail; \n        Node h = head;\n        Node s;\n        return h != t &&\n            ((s = h.next) == null || s.thread != Thread.currentThread());\n    }\n\n```\n#### 释放锁\n```java\n    public void unlock() {\n        sync.release(1);\n    }\n\n   //调用AbstractQueuedSynchronizer\n    public final boolean release(int arg) {\n        if (tryRelease(arg)) {\n            Node h = head;\n            if (h != null && h.waitStatus != 0)\n                unparkSuccessor(h);\n            return true;\n        }\n        return false;\n    }\n```\n具体的释放逻辑在`release`中，free代表该锁是否已完全释放锁，如果为true，AbstractQueuedSynchronizer继续执行`release`，唤醒队列中的下一个节点；\nfalse则该线程继续持有锁。\n```java\n    protected final boolean tryRelease(int releases) {\n        int c = getState() - releases;\n        if (Thread.currentThread() != getExclusiveOwnerThread())\n            throw new IllegalMonitorStateException();\n        boolean free = false;\n        //如果当前可重入次数为0 则清空锁持有线程\n        if (c == 0) {\n            free = true;\n            setExclusiveOwnerThread(null);\n        }\n         setState(c);\n\n        return free;\n    }\n```\n### 非公平锁\n非公平锁不会关注阻塞队列中是否还有线程，而是直接尝试获取锁，获取不到时在将线程加入到队列中。\n#### 获取锁\n```java\n    final void lock() {\n        //修改state的值，修改成功则设值设置当前线程为独占锁的拥有者\n        if (compareAndSetState(0, 1))\n            setExclusiveOwnerThread(Thread.currentThread());\n        else\n            acquire(1);\n    }\n     //调用AbstractQueuedSynchronizer\n    public final void acquire(int arg) {\n        if (!tryAcquire(arg) &&\n            acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n            selfInterrupt();\n    }\n```\n非公平锁与公平锁的差别在于当c为0时，不去查询队列的状态，而是直接尝试修改state的值\n```java\n    protected final boolean tryAcquire(int acquires) {\n         return nonfairTryAcquire(acquires);\n    }\n\n    final boolean nonfairTryAcquire(int acquires) {\n        final Thread current = Thread.currentThread();\n        int c = getState();\n        if (c == 0) {\n            if (compareAndSetState(0, acquires)) {\n                setExclusiveOwnerThread(current);\n                return true;\n            }\n        }\n        else if (current == getExclusiveOwnerThread()) {\n            int nextc = c + acquires;\n            if (nextc < 0) // overflow\n                 throw new Error(\"Maximum lock count exceeded\");\n            setState(nextc);\n            return true;\n        }\n        return false;\n    }   \n```\n非公平锁和共平锁的释放锁逻辑相同。","tags":["JAVA"],"categories":["JAVA"]},{"title":"AbstractQueuedSynchronizer源码分析-独占式","url":"/2021/03/03/aqs2/","content":"\n### 独占式获得锁\n独占式下的顶层函数为`acquire()`,首先调用`tryAcquire()`函数获得锁，如果获取不到锁，则将线程加入到队列中。\n```java\npublic final void acquire(int arg) {\n    if (!tryAcquire(arg) && //尝试获得锁\n       //将线程加入到对列中，循环获取资源，并在一定次数后阻塞\n        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n        //在阻塞过程中线程可能被中断，忽略中断，在获取到锁后再进行中断。\n        selfInterrupt();\n}\n```\n`addWaiter()`将线程加入到阻塞队列中。\n```java\nprivate Node addWaiter(Node mode) {\n\n   //将建一个队列节点，并设置该节点为独占模式\n    Node node = new Node(Thread.currentThread(), mode);\n    // 尝试快速插入到队列中，失败则调用enq函数\n    Node pred = tail;\n    if (pred != null) {\n        node.prev = pred;\n        if (compareAndSetTail(pred, node)) {\n            pred.next = node;\n            return node;\n        }\n    }\n    enq(node);\n    return node;\n}\n```\n将node节点放入到对尾中。\n```java\nprivate Node enq(final Node node) {\n    for (;;) {\n        Node t = tail;\n        //如果队列为空，则设置对尾节点为空，并将队首指向对尾\n        if (t == null) { \n            if (compareAndSetHead(new Node()))\n                tail = head;\n        } else {\n           //将该节点的前趋节点设置为当前对列尾节点\n            node.prev = t;\n            //将对尾节点设置为尾节点\n            if (compareAndSetTail(t, node)) {\n               //将原尾节点的后继指向该节点\n                t.next = node;\n                return t;\n            }\n        }\n    }\n}\n```\n\n`acquireQueued()`通过自旋的方式获取同步状态，在需要阻塞线程的时候阻塞线程。\n```java\nfinal boolean acquireQueued(final Node node, int arg) {\n      boolean failed = true;\n      try {\n          boolean interrupted = false;\n          for (;;) {\n             //获取当前节点的前趋节点\n              final Node p = node.predecessor();\n              //判断前趋节点是否是头节点，如果是，再次掉用tryAcquire尝试获取锁\n              if (p == head && tryAcquire(arg)) {\n                  //如果获取到锁，则将当前节点设置成头节点\n                  setHead(node);\n                  //在设置头节点时，node的前趋节点已经设置成null，所以这里只将p的next设置成null，p节点将不在队列中\n                  p.next = null; // help GC\n                  failed = false;\n                  return interrupted;\n              }\n              //判断是否应该被阻塞，如果应该被阻塞则阻塞该节点\n              if (shouldParkAfterFailedAcquire(p, node) &&\n                  parkAndCheckInterrupt())\n                  interrupted = true;\n          }\n      } finally {\n          if (failed)\n              cancelAcquire(node);\n      }\n  }\n ```\n判断是否应该挂起该线程\n```java\nprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {\n    int ws = pred.waitStatus;\n    if (ws == Node.SIGNAL)\n       //如果当前节点的前趋节点的状态为SIGNAL则阻塞当前节点\n        return true;\n    if (ws > 0) {\n        do {\n           //如果当前节点的前趋节点状态>0(CANCELLED),那就一直往前找\n            node.prev = pred = pred.prev;\n        } while (pred.waitStatus > 0);\n        pred.next = node;\n    } else {\n        //如果前趋节点为正常状态，则修改前趋节点的状态为SIGNAL，用于线程结束时，唤起下一个节点\n        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\n    }\n    return false;\n}\n```\n挂起线程\n```java\nprivate final boolean parkAndCheckInterrupt() {\n    //阻塞当前线程\n    LockSupport.park(this);\n    //当前线程可被中断，返回该线程的中断状态，在该线程获取到锁后，再进行中断\n    return Thread.interrupted();\n}\n```\n### 独占式释放锁\n```java\npublic final boolean release(int arg) {\n//尝试获释放锁\n    if (tryRelease(arg)) {\n        Node h = head;\n        if (h != null && h.waitStatus != 0)\n            unparkSuccessor(h);\n        return true;\n    }\n    return false;\n}\n```\n```java\nprivate void unparkSuccessor(Node node) {\n      int ws = node.waitStatus;\n      //修改头节点的状态\n      if (ws < 0)\n          compareAndSetWaitStatus(node, ws, 0);\n\n      //获取头节点的下一个节点\n      Node s = node.next;\n      \n      //判断s线程是否是null，或线程状态是否是>0(比如CANCELLED状态 代表取消），如果为true，则遍历队列，找到应该被唤醒的线程。\n      if (s == null || s.waitStatus > 0) {\n          s = null;\n          for (Node t = tail; t != null && t != node; t = t.prev)\n              if (t.waitStatus <= 0)\n                  s = t;\n      }\n      if (s != null)\n         //唤醒线程\n          LockSupport.unpark(s.thread);\n  }\n  ```","tags":["JAVA"],"categories":["JAVA"]},{"title":"AbstractQueuedSynchronizer源码分析-共享式","url":"/2021/02/13/aqs1/","content":"\n### 共享式获得锁\n共享式获取锁的顶层函数为`acquireShared()`,该函数首先调用`tryAcquireShared()`尝试互锁，如果获取不到锁，则将该线程加入到队列中。\n```java\npublic final void acquireShared(int arg) {\n          //尝试获取锁\n          //小于0，代表获取锁失败\n          // 具体的逻辑由子类实现\n        if (tryAcquireShared(arg) < 0)\n            doAcquireShared(arg);\n    }\n```\n`doAcquireShared()`函数将该线程加入到队列中，然后通过有限次的循环获取锁，并判断是否该阻塞\n```java\n    private void doAcquireShared(int arg) {\n        //将该线程加入到队列中\n        final Node node = addWaiter(Node.SHARED);\n        boolean failed = true;\n        try {\n            boolean interrupted = false;\n            for (;;) {\n                //获取该线程节点的前趋节点。\n                final Node p = node.predecessor();\n                /**\n                * 如果p为头节点，再次尝试获取锁\n                * p可能是独占式节点（EXCLUSIVE），也可能是共享式节点（SHARED）.\n                * 独占式节点则不能再获取锁\n                * 共享式节点可以获取锁，但当资源用尽时也不能获取到锁\n                * 能不能获取到锁，要看具体tryAcquireShared的实现\n                **/\n                if (p == head) {\n                    int r = tryAcquireShared(arg);\n                    if (r >= 0) {\n\n                        //设置头节点和唤醒下一个共享线程\n                        setHeadAndPropagate(node, r);\n                        p.next = null; // help GC\n                        if (interrupted)\n                            //如果阻塞过程中，有过中断，先不处理，再获取到资源后，再处理中断。\n                            selfInterrupt();\n                        failed = false;\n                        return;\n                    }\n                }\n                // 判断是否应该阻塞，如果要阻塞则将线程阻塞，并判断是否有过中断\n                if (shouldParkAfterFailedAcquire(p, node) &&\n                    parkAndCheckInterrupt())\n                    interrupted = true;\n            }\n        } finally {\n            if (failed)\n                cancelAcquire(node);\n        }\n    }\n```\n```java\n    private void setHeadAndPropagate(Node node, int propagate) {\n        //获取头节点\n        Node h = head; \n        //将当前节点设置成头节点\n        setHead(node);\n        \n        if (propagate > 0 || h == null || h.waitStatus < 0 ||\n            (h = head) == null || h.waitStatus < 0) {\n            Node s = node.next;\n            //如果s是共享节点，则唤醒共享节点\n            if (s == null || s.isShared())\n                doReleaseShared();\n        }\n    }\n\n```\n\n```java\n   private void doReleaseShared() {\n       /*\n     * 下面的循环在 head 节点存在后继节点的情况下，做了两件事情：\n     * 1. 如果 head 节点等待状态为 SIGNAL，则将 head 节点状态设为 0，并唤醒后继节点\n     * 2. 如果 head 节点等待状态为 0，则将 head 节点状态设为 PROPAGATE，保证唤醒能够正\n     *    常传播下去。关于 PROPAGATE 状态的细节分析，后面会讲到。\n     */\n        for (;;) {\n            Node h = head;\n            if (h != null && h != tail) {\n                int ws = h.waitStatus;\n                if (ws == Node.SIGNAL) {\n                    if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                        continue;            // loop to recheck cases\n                    unparkSuccessor(h);\n                }\n                else if (ws == 0 &&\n                         !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n                    continue;                // loop on failed CAS\n            }\n            if (h == head)                   // loop if head changed\n                break;\n        }\n    }\n```\n### 共享式释放锁\n```java\n public final boolean releaseShared(int arg) {\n        if (tryReleaseShared(arg)) {\n            doReleaseShared();\n            return true;\n        }\n        return false;\n    }\n```","tags":["JAVA"],"categories":["JAVA"]}]